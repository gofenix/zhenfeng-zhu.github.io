<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Awesome Fenix</title>
    <link>https://zhenfeng-zhu.github.io/posts/</link>
    <description>Recent content in Posts on Awesome Fenix</description>
    <image>
      <url>https://zhenfeng-zhu.github.io/papermod-cover.png</url>
      <link>https://zhenfeng-zhu.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 04 Jan 2022 10:04:05 +0800</lastBuildDate><atom:link href="https://zhenfeng-zhu.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Blockchain 数据结构分析</title>
      <link>https://zhenfeng-zhu.github.io/posts/blockchain-schema/</link>
      <pubDate>Tue, 04 Jan 2022 10:04:05 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/blockchain-schema/</guid>
      <description>区块 想要了解区块到底是什么，最简单快捷的方法就是分析它的数据结构，以 bitcoin 种的区块为例：
{ &amp;#34;hash&amp;#34;:&amp;#34;00000000000000000018b0a6ae560fa33c469b6528bc9e0fb0c669319a186c33&amp;#34;, &amp;#34;confirmations&amp;#34;:1009, &amp;#34;strippedsize&amp;#34;:956228, &amp;#34;size&amp;#34;:1112639, &amp;#34;weight&amp;#34;:3981323, &amp;#34;height&amp;#34;:514095, &amp;#34;version&amp;#34;:536870912, &amp;#34;versionHex&amp;#34;:&amp;#34;20000000&amp;#34;, &amp;#34;merkleroot&amp;#34;:&amp;#34;5f8f8e053fd4c0c3175c10ac5189c15e6ba218909319850936fe54934dcbfeac&amp;#34;, &amp;#34;tx&amp;#34;:[ // ... 　], &amp;#34;time&amp;#34;:1521380124, &amp;#34;mediantime&amp;#34;:1521377506, &amp;#34;nonce&amp;#34;:3001236454, &amp;#34;bits&amp;#34;:&amp;#34;17514a49&amp;#34;, &amp;#34;difficulty&amp;#34;:3462542391191.563, &amp;#34;chainwork&amp;#34;:&amp;#34;0000000000000000000000000000000000000000014d2b41a340e60b72292430&amp;#34;, &amp;#34;previousblockhash&amp;#34;:&amp;#34;000000000000000000481ab128418847dc25db4dafec464baa5a33e66490990b&amp;#34;, &amp;#34;nextblockhash&amp;#34;:&amp;#34;0000000000000000000c74966205813839ad1c6d55d75f95c9c5f821db9c3510&amp;#34; } 在这个 Block 的结构体中，previousblockhash 和 merkleroot 是两个最重要的字段；前者是一个哈希指针，它其实是前一个 Block 的哈希，通过 previousblockhash 我们能递归地找到全部的 Block，也就是整条主链，后者是一个 Merkle 树的根，Merkle 树中包含整个 Block 中的全部交易，通过保存 merkleroot，我们可以保证当前 Block 中任意交易都不会被修改。 Ethereum 的区块链模型虽然与 Bitcoin 有非常大的不同，但是它的 Block 结构中也有着类似的信息：
{ &amp;#34;jsonrpc&amp;#34;:&amp;#34;2.0&amp;#34;, &amp;#34;result&amp;#34;:{ &amp;#34;author&amp;#34;:&amp;#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d&amp;#34;, &amp;#34;difficulty&amp;#34;:&amp;#34;0x785042b0&amp;#34;, &amp;#34;extraData&amp;#34;:&amp;#34;0x414952412f7630&amp;#34;, &amp;#34;gasLimit&amp;#34;:&amp;#34;0x47b784&amp;#34;, &amp;#34;gasUsed&amp;#34;:&amp;#34;0x44218a&amp;#34;, &amp;#34;hash&amp;#34;:&amp;#34;0x4de91e4af8d135e061d50ddd6d0d6f4119cd0f7062ebe8ff2d79c5af0e8344b9&amp;#34;, &amp;#34;logsBloom&amp;#34;:&amp;#34;0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&amp;#34;, &amp;#34;miner&amp;#34;:&amp;#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d&amp;#34;, &amp;#34;mixHash&amp;#34;:&amp;#34;0xb8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443&amp;#34;, &amp;#34;nonce&amp;#34;:&amp;#34;0xad14fb6803147c7c&amp;#34;, &amp;#34;number&amp;#34;:&amp;#34;0x2000f1&amp;#34;, &amp;#34;parentHash&amp;#34;:&amp;#34;0x31919e2bf29306778f50bbc376bd490a7d056ddfd5b1f615752e79f32c7f1a38&amp;#34;, &amp;#34;receiptsRoot&amp;#34;:&amp;#34;0xa2a7af5e3b9e1bbb6252ba82a09302321b8f0eea7ec8e3bb977401e4f473e672&amp;#34;, &amp;#34;sealFields&amp;#34;:[ &amp;#34;0xa0b8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443&amp;#34;, &amp;#34;0x88ad14fb6803147c7c&amp;#34; ], &amp;#34;sha3Uncles&amp;#34;:&amp;#34;0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347&amp;#34;, &amp;#34;size&amp;#34;:&amp;#34;0x276&amp;#34;, &amp;#34;stateRoot&amp;#34;:&amp;#34;0x87e7e54cf229003014f453d64f0344e2ba4fc7ee3b95c7dd2642cca389fa1efe&amp;#34;, &amp;#34;timestamp&amp;#34;:&amp;#34;0x5a10968a&amp;#34;, &amp;#34;totalDifficulty&amp;#34;:&amp;#34;0x1804de0c47ffe1&amp;#34;, &amp;#34;transactions&amp;#34;:[.</description>
    </item>
    
    <item>
      <title>轻服务 nodejs 助力爬虫 web3</title>
      <link>https://zhenfeng-zhu.github.io/posts/how-to-crawl-a-web-in-nodejs/</link>
      <pubDate>Mon, 20 Dec 2021 09:58:58 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/how-to-crawl-a-web-in-nodejs/</guid>
      <description>周末的时候，写了一个简单的小项目，用来抓取 web3 的文章，然后存到本地。最后选取了公司对外的轻服务：https://qingfuwu.cn/docs/nodejs/
整项目用到了两个库
 axios：用来做 http 请求 cheerio：用来解析 html  观察目标网页的格式 我们以巴比特为例：https://www.8btc.com/web3.0，打开控制台，定位到正文的 div，可以发现是 article-list。
右键复制一下 selector，然后在代码中这样实现就可以了。
抓取网页信息 const cheerio = require(&amp;#39;cheerio&amp;#39;).default const axios = require(&amp;#39;axios&amp;#39;).default async function getData() { const data = await (await axios.get(&amp;#39;https://www.8btc.com/web3.0&amp;#39;, { headers: { &amp;#39;User-Agent&amp;#39;: &amp;#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36&amp;#39; } })).data const $ = cheerio.load(data) let list = [] $(&amp;#39;#news &amp;gt; div.articles-list&amp;#39;).find(&amp;#39;.article-info&amp;#39;).each( (item, elem) =&amp;gt; { const href = $(elem).</description>
    </item>
    
    <item>
      <title>Crystal Roadmap</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal_roadmap/</link>
      <pubDate>Thu, 28 Oct 2021 10:11:41 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal_roadmap/</guid>
      <description>This roadmap defines the things that we want to have in the language and plan to do.
Language Stuff that has to do with the language syntax, semantic and runtime.
Concurrency Finalize multithreading support, so fibers can run on multiple threads.
Windows support Finalize support for Windows platform. The compiler already works, but some stdlib features like concurrency support are still missing. Ongoing efforts on #5430.
Type system review Make a review and possible formalisation of Crystal&amp;rsquo;s type system, with a strong emphasis on generics, type restrictions and the meta-model in general.</description>
    </item>
    
    <item>
      <title>Crystal 1.2 版本更新说明</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal1.2/</link>
      <pubDate>Sun, 17 Oct 2021 23:08:51 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal1.2/</guid>
      <description>Crystal 1.2.0 发布 我们正在发布一个包含多个错误修复和改进的新版本。下面我们列出了最重要或最有趣的变化，但没有提到几个错误修正。有关详细信息，请访问发行说明。重大更改标有 ⚠️。
统计数据 在此版本中，我们包含了自 1.1.1 版本以来 32 位贡献者的 181 个 PR。我们感谢为改进语言及其标准库所做的所有努力！❤️
平台支持 正如在 1.2 的上一篇博客文章中提到的，我们决定降低对 32 位 x86 架构的支持。但是我们确实有一些好消息要分享！
我们在原生 Windows 支持方面取得了进展，在此版本中包括套接字实现（#11205、#11137、#10605、#10605）。
与 Windows 相关，也与 ARM64 架构相关，我们修复了一个重要的代码生成错误。我们现在处于将 aarch64 平台提升到 Tier 1 的条件，预计很快就会支持。这也与带有 M1 芯片组的 macOS 相关：从这个版本开始，我们包含一个适用于 x86 和 M1 mac 的通用 macOS 包。
我们发现 Windows 和 M1 的 mac 上出现的两个错误来自 LLVM 11 和 12。我们预计该修复将随最近发布的 LLVM 13 一起提供。Crystal 1.2.0 与 LLVM 12 兼容，尽管我们建议不要使用 LLVM 11 和 12.
语言变化 现在可以将泛型类的子类分配给父类的实例：</description>
    </item>
    
    <item>
      <title>如何理解可观测性</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</link>
      <pubDate>Fri, 15 Oct 2021 09:45:38 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/</guid>
      <description>可观测性 可观测性 ≠ 监控   核心不同
 监控以运维为核心，通过各项指标来定义整体的运行状态、失败情况。 观测则以开发为核心，除了监控，它还会对系统进行分析。    维度不同
 监控是从外围的角度，通过各种指标（机器 CPU、负载、网络等维度）来判断整个系统的执行情况。 可观测性则在上述外部指标基础上，以应用内的各个维度来展开推测，通过二者的数据结合来真实的反应应用的运行情况。    展现的信息不同
 有些系统在正常运行时十分稳定，但是一到高并发就会出现问题，此时监控只能汇报问题出现的状况，而可观测性可以很好的通过图形化的方式告知我们问题的原因，不用我们通过经验来猜测。    可观测性打破了开发和运维的原有问题解决方式，不再是运维发现问题开发解决，而是以开发为中心。
监控数据来源   端上访问
 用户体验监控  web 页面的白屏时间 dom 元素/资源加载耗时 文档网络耗时 app 卡顿率 崩溃率 热启动加载时长   日志 端到端  用户端到后端的请求状况，访问量、成功率、响应时间等。 还需要端上所处的地区、网络环境、响应状态码   可用率  访问是否可用、响应耗时长短的一些指标和 cdn、dns 等公共资源有关系。      应用程序
 执行情况 资源消耗 vm 指标监控 容量 服务关系 应用日志 健康情况    业务监控</description>
    </item>
    
    <item>
      <title>如何从零开始写一个静态网站生成器</title>
      <link>https://zhenfeng-zhu.github.io/posts/how-to-write-a-static-site-generator/</link>
      <pubDate>Fri, 23 Jul 2021 09:33:18 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/how-to-write-a-static-site-generator/</guid>
      <description>我们常见的静态网站生成器有 Hugo、Hexo 等，程序员们经常会使用类似的工具去将自己的播客托管到 github pages。前段时间研究了一下实现的方式，用 Elixir 简单实现了一个版本。
一个静态网站生成器的工作流程通常有如下几个步骤：
 读取源文件，一般是 markdown 格式的。 模板引擎的渲染 生成目标文件  接下来会从每个步骤来进行简单介绍。
最终版本的请参考：https://github.com/zhenfeng-zhu/ego， 欢迎 pr 和 issue。
极简 MVP 版本介绍 初始化 $ mix new ego 在 mix.exs 中添加依赖
 earmark 是将 markdown 转换为 html。 plug_cowboy 是提供本地预览 html 文件的 server。 json 是一个 json 解析库 指定以 escript 的方式启动  解析 markdown 文件 将一个 markdown 文件转为 html 也是比较简单的，首先读取，然后调用 Earmark.as_html!函数，就能将 markdown 转换为 html 了。
eg.
def gen_blogs(m) do m |&amp;gt; File.</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab2</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab2/</link>
      <pubDate>Tue, 30 Mar 2021 09:57:01 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab2/</guid>
      <description>实验 2 - 测试 在开始实验之前，先创建一个文件夹：
$ mkdir -p lab2 \  &amp;amp;&amp;amp; cd lab2 使用 UI 门户 您现在可以测试 OpenFaaS UI：
如果你已经设置了 $OPENFAAS_URL ，请获取 URL，并点开:
echo $OPENFAAS_URL http://127.0.0.1:31112 如果还没有设置 $OPENFAAS_URL ，那么默认的值通常是： http://127.0.0.1:8080.
我们可以部署一些示例函数，然后使用它们进行测试：
$ faas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 您可以在用户界面中试用它们，例如 Markdown 函数，它将 Markdown 代码转换成超文本标记语言。
在 Request 字段中输入如下的内容：
## The **OpenFaaS** _workshop_ 现在点击 Invoke ，然后就可以看到响应出现在屏幕的下半部分。
I.e.
&amp;lt;h2&amp;gt;The &amp;lt;strong&amp;gt;OpenFaaS&amp;lt;/strong&amp;gt; &amp;lt;em&amp;gt;workshop&amp;lt;/em&amp;gt;&amp;lt;/h2&amp;gt; 您将会看到如下的字段：
 Status - 函数是否准备好运行。在状态显示就绪之前，您将无法从用户界面调用该函数。 Replicas - 在集群中运行的函数的副本数量。 Image - 发布到 Docker Hub 或 Docker 存储库的 Docker 镜像名称和版本。 Invocation count - 这显示了函数被调用的次数，并且每 5 秒更新一次。  多次点击 Invoke ，就可以看到 Invocation count 在递增。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab1b</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1b/</link>
      <pubDate>Tue, 30 Mar 2021 09:55:20 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1b/</guid>
      <description>实验 1 - 使用 Kubernetes 设置 OpenFaaS 安装 kubectl 使用下面的说明或官方文档为您的操作系统安装kubectl。
 Linux  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  MacOS  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/darwin/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  Windows  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/windows/amd64/kubectl.exe chmod +x kubectl.exe mkdir -p $HOME/bin/ mv kubectl $HOME/bin/ 设置 Kubernetes 集群 您可以在使用 Kubernetes 时遵循实验，但您可能需要在此过程中进行一些小的更改。网关的服务地址从http://gateway:8080 更改为http://gateway.openfaas:8080。尽可能记录这些差异，并在每个实验室提供替代方案。
在笔记本电脑上创建本地集群 k3s 和 k3d 如果您的计算机上有 Docker，那么您可以使用 Rancher Labs 的 k3d。它安装了一个名为 k3s 的 Kubernetes 轻量级版本，并在 Docker 容器中运行，这意味着它可以在任何有 Docker 的计算机上工作。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab1</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1/</link>
      <pubDate>Tue, 30 Mar 2021 09:54:25 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1/</guid>
      <description>实验 1 - OpenFaaS 准备 OpenFaaS 需要一个Kubernetes 集群来操作。您可以使用单节点集群或多节点集群，无论是在笔记本电脑上还是在云中。
任何 OpenFaaS 函数的基本基元都是 Docker 镜像，它是使用faas-cli工具链构建的。
先决条件 让我们安装 Docker，OpenFaaS CLI 并设置 Kubernetes。
Docker For Mac
 Docker CE for Mac Edge Edition  For Windows
 仅支持 Windows 10 Pro 或 Enterprise 安装 Docker CE for Windows   请确保通过使用 Windows 任务栏通知区域中的 Docker 菜单来使用Linux容器 Docker 守护进程。
  安装 Git Bash  当您安装 git bash 时，请选择以下选项：“安装 UNIX 命令”和“使用真实类型的字体”。
 注意：所有步骤请使用Git Bash：不要尝试使用PowerShell，WSL或Bash for Windows。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop/</link>
      <pubDate>Tue, 30 Mar 2021 09:53:12 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop/</guid>
      <description>openfaas-研讨会 这是一个自定进度的研讨会，用于学习如何使用 OpenFaaS 构建、部署和运行无服务器功能。
在这个研讨会中，您首先将 OpenFaaS 部署到您的笔记本电脑或带有 Docker for Mac 或 Windows 的远程集群中。然后，您将使用 OpenFaaS 用户界面、CLI 和函数商店来完成最基本的使用。构建完成后，在 Python 中部署调用自己的无服务器函数，您将继续学习以下主题：使用 pip 管理依赖关系、通过安全机密处理应用编程接口令牌、使用 Prometheus 监控函数、异步调用函数以及将函数链接在一起创建应用程序。实验中让人兴奋的是可以让您创建自己的 GitHub 机器人，它可以自动响应问题。同样的方法也可以通过 IFTTT.com 连接到在线事件流，这将使您能够构建机器人、自动响应器以及与社交媒体和物联网设备的集成。
最后，这些实验也涵盖了更高级的主题，并为进一步学习提供建议。
其他语言
 日本語 中文  要求 我们将介绍如何在Lab 1中安装这些要求。请在参加讲师指导的研讨会之前完成Lab 1
 函数将用 Python 编写，因此有编程或脚本经验者优先 安装推荐的代码编辑器/IDE VSCode Windows 安装 Git Bash 首选操作系统： MacOS，Windows 10Pro/Enterprise，Ubuntu Linux  Docker:
 Docker CE for Mac/Windows Edge edition Docker CE for Linux   注意：作为最后的手段，如果您有不兼容的 PC，您可以在https://labs.play-with-docker.com/.上运行研讨会
 讲师主导的研讨会 如果你参加了一个由讲师领导的研讨会，那么将会通过一个链接来加入 OpenFaaS Slack 社区。使用研讨会指定的渠道讨论意见、问题和建议。</description>
    </item>
    
    <item>
      <title>Streaming 101</title>
      <link>https://zhenfeng-zhu.github.io/posts/streaming-101/</link>
      <pubDate>Fri, 26 Mar 2021 14:11:29 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/streaming-101/</guid>
      <description> 有效的复杂系统总是从简单
 </description>
    </item>
    
    <item>
      <title>K3d With Openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/k3d-with-openfaas/</link>
      <pubDate>Wed, 10 Mar 2021 20:09:11 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/k3d-with-openfaas/</guid>
      <description>openfaas https://github.com/openfaas/workshop/blob/master/lab1b.md
安装 docker brew install homebrew/cask/docker 安装单节点 K8S brew install k3d 配置单节点 K8S 集群
k3d cluster create CLUSTER_NAME k3d kubeconfig merge CLUSTER_NAME --kubeconfig-switch-context kubectl get pods --all-namespaces 安装 arkade curl -SLsf https://dl.get-arkade.dev/ | sudo sh 安装 openfaas 客户端 faas-cli brew install faas-cli 安装 openfaas server 端 arkade install openfaas 配置 openfaas 的 ui 界面
kubectl rollout status -n openfaas deploy/gateway kubectl port-forward svc/gateway -n openfaas 8080:8080 这样就可以在浏览器里输入 127.0.0.1:8080 进入到 openfaas 的 ui 界面了。</description>
    </item>
    
    <item>
      <title>换一种方式思考</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%8D%A2%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%9D%E8%80%83/</link>
      <pubDate>Sat, 27 Feb 2021 12:16:48 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%8D%A2%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%9D%E8%80%83/</guid>
      <description> 面向对象不是设计代码的唯一方法 函数式编程不一定是复杂和纯数学的 编程的基础不是赋值、if 语句和循环 并发不一定需要锁、信号量、监视器等类似的东西 进程不必消耗大量的资源 元编程不只是语言的附属品 即使编程是你的工作，也应该是充满乐趣的  </description>
    </item>
    
    <item>
      <title>小白都能快速上手的 Vim 配置</title>
      <link>https://zhenfeng-zhu.github.io/posts/vim/</link>
      <pubDate>Sat, 20 Feb 2021 09:56:31 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/vim/</guid>
      <description>首先把所有的 vim 相关的都删除 cd rm -rf .vim* 创建自己的.vimrc vim .vimrc 一些基本的设置 在.vimrc 中添加下面的代码
&amp;#34; basic set set number set noswapfile set encoding=utf-8 set fileencodings=utf-8,gb18030 set backspace=eol,start,indent set laststatus=2 set colorcolumn=80 set cursorline set linebreak set autoindent set ignorecase set smartcase set ruler set diffopt+=internal,indent-heuristic,algorithm:patience set showcmd set clipboard^=unnamed,unnamedplus set showmode set mouse=a set tabstop=2 set shiftwidth=4 set expandtab set softtabstop=2 set showmatch set incsearch set nobackup set autoread set wildmenu set wildmode=longest:list,full set nofoldenable filetype plugin indent on syntax on 有了上面的设置，会让你的 vim 更好用一些。</description>
    </item>
    
    <item>
      <title>Github Action 自动部署 blog</title>
      <link>https://zhenfeng-zhu.github.io/posts/hugo-github-action/</link>
      <pubDate>Thu, 18 Feb 2021 13:20:11 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hugo-github-action/</guid>
      <description>之前我采用的方式是两个 github repo 的方式：
一个叫 hugo-blog，用于存放 blog 的源文件
一个叫 zhenfeng-zhu.github.io，用于存放生成之后的文件
然后通过写一个 shell 脚本，将生成之后的文件推向 zhenfeng-zhu.github.io 仓库中，同时将 blog 的源文件也做了一个 backup。后来使用了一个 github action 的方式， 就不用在两个仓库中进行折腾，一切都由 github action 来做了。
方案 设置 workflow 首先创建一个.github/workflows/gh-pages.yml
name: github pages on: push: branches: - main  # Set a branch to deploy jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .</description>
    </item>
    
    <item>
      <title>编程语言的世界观</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%96%E7%95%8C%E8%A7%82/</link>
      <pubDate>Thu, 18 Feb 2021 13:05:31 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%96%E7%95%8C%E8%A7%82/</guid>
      <description>Elixir  everything is a process. process are strongly isolated. process creation and destruction is a lightweight operation. message passing is the only way for processes to interact. processes have unique names. if you know the name of a process you can send it a message. processes share no resources. error handling is non-local. processes do what they are supposed to do or fail.  Go  simple, poetic, pithy don&amp;rsquo;t communicate by sharing memory, share memory by communicating concurrency is not parallelism channels orchestrate; mutexes serialize the bigger the interface, the weaker the abstraction make the zero value useful interface{} says nothing gofmt&amp;rsquo;s style is no one&amp;rsquo;s favorite, yet gofmt is everyone&amp;rsquo;s favorite A little copying is better than a little dependency  </description>
    </item>
    
    <item>
      <title>如何建立指标体系</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Thu, 18 Feb 2021 12:48:34 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/</guid>
      <description>什么是指标体系 指标体系是在业务的不同阶段，分析师牵头与业务方协助，制定一套能从各个维度反映业务状况的待实施框架。
关键点  在业务的前期、中期和后期，指标体系是不一样的 一定是由分析师牵头与业务方协助，而不是闭门造车 从各个维度去反应业务的核心状况，指标有很多维度 最后就是一个大的实施框架，一定要实施，否则就是浪费大家的时间  指标选取的几个原则  根本性：对于核心数据一定要理解到位和准确，如果这里错了，后面基本就不用看。 可理解性：所有指标要配上业务解释 结构性：能够充分从各维度对业务进行解读，方便归因。  建立步骤   理清业务阶段和方向 我们需要知道当前产品或者业务处于什么阶段，具体的业务方向是什么。一般都是分为三个阶段： 第一阶段：业务前期。在业务的前期更多的是想要快速推出来，有更多人去使用我们的产品。所以此时我们的指标体系应该更多的围绕用户量提升做各种维度的拆解 第二阶段：业务中期（快速发展期）。在业务中期，除了关注盘子的大小，还要看产品的健康度。 第三阶段：业务后期（成熟期）。主要看变现能力以及市场份额。
  确定核心指标 找核心指标不是一件容易的事儿。 只能多花时间去考虑这个事儿。
  指标核心维度拆解 核心指标的波动必然是由某种维度的波动引起，所以监控核心指标指标，本质是监控核心维度。 通用的拆解方法是先对核心指标进行公式计算，再按照业务路径或者业务模块去拆解。 核心指标的拆解，需要多和业务方进行沟通，把能够考虑的模块都考虑进去，基本上就能比较全面。
  指标宣贯、存档和落地 宣贯：实际上搭建号指标体系之后，要当面触达所有相关的业务接口人。 存档：同时对指标的口径和业务逻辑进行详细的描述存档，也就是指标口径归档 落地：落地就是建立核心指标的相关报表，实际工作中，报表会在埋点前建好，这样一旦版本上线就能立刻看到数据，这样各方的配合度就会很高。
  </description>
    </item>
    
    <item>
      <title>业务代码的成长机会</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%88%90%E9%95%BF%E6%9C%BA%E4%BC%9A/</link>
      <pubDate>Wed, 17 Feb 2021 17:45:40 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%88%90%E9%95%BF%E6%9C%BA%E4%BC%9A/</guid>
      <description>对于大部分公司而言，能够写底层代码或者中间件代码的人总是有限的，写业务代码会面临更高的复杂度。这里分三个层次来看其中的机会：
 第一个层次，让代码写的不一样。可从代码规范、可读性、可扩展性等角度着手，这也是程序员的基本功。 第二个层次，考虑业务问题和技术问题的匹配。可从写业务代码中理解需求，并做好分析设计。被动接收需求和实现接口，确实成长空间不大。 第三个层次，总结相关方法体系，成为业务及技术双料专家。  </description>
    </item>
    
    <item>
      <title>unix 哲学</title>
      <link>https://zhenfeng-zhu.github.io/posts/unix-philosophy/</link>
      <pubDate>Wed, 17 Feb 2021 16:46:52 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/unix-philosophy/</guid>
      <description> 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件，甚至是操作系统，要尽早尝试，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。  </description>
    </item>
    
    <item>
      <title>Web 前端性能优化</title>
      <link>https://zhenfeng-zhu.github.io/posts/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link>
      <pubDate>Fri, 20 Nov 2020 16:01:49 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid>
      <description>一般来说 web 前端是指网站业务逻辑之前的部分，比如：浏览器加载、网站视图模型、图片服务、CDN 服务等等。web 前端优化主要从如下三个方面入手：
浏览器访问优化   减少 http 请求
http 协议是一个无状态的，每次请求都需要建立通信链路进行传输，在服务器端，一般每个请求都会分配一个线程去处理。
减少 http 请求的主要手段是合并 CSS、合并 js、合并图片。
  使用浏览器缓存
css、js、Logo、图标等静态资源文件更新频率较低，可以将这些文件缓存在浏览器中。
在更新 js 等文件的时候，一般不是将文件内容更新，而是生成一个新的文件，然后更新 html 的引用。
更新静态资源的时候，也是要逐量更新，以避免用户浏览器的大量缓存失效，造成服务器负载增加、网络堵塞。
  启用压缩
在服务器对文件压缩，然后在浏览器端解压缩，可以减少通信传输的数据量。
  CSS 放在页面最上面，js 放在页面最下面
浏览器会在下载完全部 CSS 之后才对整个页面进行渲染，而浏览器是在加载 js 之后就立即执行，有可能会阻塞整个页面。因此最好的做法就是把 CSS 放在最上面，js 放在最下面。但是如果是页面解析的时候就用到 js，也是要相应的 js 放在上面。
  减少 cookie 传输
cookie 会包含在每次请求和响应中，太大的 cookie 会影响数据传输，需要慎重考虑哪些数据写入 cookie 中。
对于某些静态资源的访问，如 css 和 js 等，发送 cookie 没意义，可以考虑静态资源使用独立域名访问，避免请求静态资源时发送 cookie。
  CDN 加速 CDN（content distribute network，内容分发网络）的本质仍然是一个缓存。将缓存放在离用户最近的地方，使得用户可以以最快的速度获取数据。</description>
    </item>
    
    <item>
      <title>大型网站发展历程</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</link>
      <pubDate>Fri, 20 Nov 2020 16:00:59 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</guid>
      <description>前几天跟一个朋友聊了一些关于网站缓存分布式的一些东西，发现自己的知识还是太过贫瘠。理论+协议，这是现在我亟待加强的。这个周末买了两本关于分布式网站的书，本着好记性不如烂笔头，便有了这样一系列的文章。希望一同分享，也请多指教。
 code less, play more!
 前言 这个世界上没有哪个网站从诞生起就是大型网站；也没有哪个网站第一次发布的时候就拥有庞大的用户，高并发的访问，海量的数据；大型网站都是从小型网站发展而来。网站的价值在于它能给用户提供什么家宅，在于网站能做什么，而不在于它是怎么做的，所以网站在小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供更好的服务来创造价值，得到用户认可，活下去，野蛮生长。
大型网站软件系统的特点  高并发，大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，发布平频繁 渐进式发展  大型网站的发展历程   初始阶段的网站架构
最开始没有多少人访问，所以应用程序，数据库，文件都在同一台机器上。
  应用服务器和数据服务分离
应用和数据分离之后，一般需要三台服务器。应用服务器，文件服务器和数据库服务器，这三种服务器对于硬件要求各不相同。
 应用服务器：更强大的 CPU 数据库服务器：更快速的磁盘和更大的内存 文件服务器：容量更大的硬盘    使用缓存改善性能
网站的访问也遵循二八定律：80%的业务集中在 20%的数据上。因此可以把这一小部分数据缓存在内存中，减少数据库的访问压力。
网站的缓存可以分为两种：
 本地缓存：缓存在应用服务器上。本地缓存访问速度快，但是受制于内存限制，缓存数量有限，而且也会出现和应用程序争抢内存的情况。 远程分布式缓存：以集群的方式，缓存在大内存的专用缓存服务器。可以在理论上做到不受内存容量限制。    使用应用服务器集群提高并发能力
当一台服务器的处理能力和存储空间不足的时候，不要企图更换更强大的服务器。对于大型网站来说，不管多么强大的服务器，都满足不了网站持续增长的业务需求。此时就可以考虑集群的方式，通过负载均衡调度服务器，可以将来自用户的请求分发到应用服务器集群中的任何一台服务器上。
  数据库读写分离
使用缓存后，大部分的数据读操作访问都可以不通过数据库完成，但是仍有部分读操作（如缓存过期，缓存不命中）和全部的写操作需要访问数据库。
目前大部分数据库都提供主从热备的功能，在写数据的时候，访问主库，主库通过主从复制机制将数据更新同步至从数据库，在读的时候就可以通过从数据库获取数据。
  使用反向代理和 CDN 加速网站响应
在《web 性能权威指南》中有讲到，网站性能的瓶颈，大部分时间都浪费在 TCP 的握手和传输上。因此可以通过 CDN 和反向代理的方式来加快响应。
CDN 和反向代理的本质都是通过缓存，不同的主要是：
 CDN 部署在服务器器上的机房，用户在请求时，从距离自己最近的机房获取数据。 反向代理是部署在中心机房，用户请求到达中心机房之后，首先访问的服务器是反向代理的拂去其，如果反向代理服务器中缓存着用户请求的额资源，就将其返回给用户。    使用分布式文件系统和分布式数据库系统</description>
    </item>
    
    <item>
      <title>Geth 私链</title>
      <link>https://zhenfeng-zhu.github.io/posts/geth-%E7%A7%81%E9%93%BE/</link>
      <pubDate>Fri, 20 Nov 2020 15:59:22 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/geth-%E7%A7%81%E9%93%BE/</guid>
      <description>在上一篇文章《Geth 入门》中，主要讲了开发环境下以太坊 geth 客户端的使用。今天简单说下私链的配置。
genesis.json { &amp;#34;config&amp;#34;: { &amp;#34;chainId&amp;#34;: 10, &amp;#34;homesteadBlock&amp;#34;: 0, &amp;#34;eip155Block&amp;#34;: 0, &amp;#34;eip158Block&amp;#34;: 0 }, &amp;#34;coinbase&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000&amp;#34;, &amp;#34;difficulty&amp;#34; : &amp;#34;0x40000&amp;#34;, &amp;#34;extraData&amp;#34; : &amp;#34;&amp;#34;, &amp;#34;gasLimit&amp;#34; : &amp;#34;0xffffffff&amp;#34;, &amp;#34;nonce&amp;#34; : &amp;#34;0x0000000000000042&amp;#34;, &amp;#34;mixhash&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000000000000000000000000000&amp;#34;, &amp;#34;parentHash&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000000000000000000000000000&amp;#34;, &amp;#34;timestamp&amp;#34; : &amp;#34;0x00&amp;#34;, &amp;#34;alloc&amp;#34;: { } }    参数 描述     nonce nonce 就是一个 64 位随机数，用于挖矿   mixhash 与 nonce 配合用于挖矿，由上一个区块的一部分生成的 hash   difficulty 设置当前区块的难度，如果难度过大，cpu 挖矿就很难，这里设置较小难度   alloc 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以   coinbase 矿工的账号，随便填   timestamp 设置创世块的时间戳   parentHash 上一个区块的 hash 值，因为是创世块，所以这个值是 0   extraData 附加信息，随便填，可以填你的个性信息   gasLimit 该值设置对 GAS 的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大。   config Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的 json 文件中，缺少 config 部分。看到这个信息，我们不需要把 geth 退回到 v1.</description>
    </item>
    
    <item>
      <title>Geth</title>
      <link>https://zhenfeng-zhu.github.io/posts/geth/</link>
      <pubDate>Fri, 20 Nov 2020 10:07:39 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/geth/</guid>
      <description>Geth 简介 go-ethereum
go-ethereum 客户端通常被称为 geth，它是个命令行界面，执行在 Go 上实现的完整以太坊节点。通过安装和运行 geth，可以参与到以太坊前台实时网络并进行以下操作：
 挖掘真的以太币 在不同地址间转移资金 创建合约，发送交易 探索区块历史 及很多其他   网站: http://ethereum.github.io/go-ethereum/
  Github: https://github.com/ethereum/go-ethereum
  维基百科: https://github.com/ethereum/go-ethereum/wiki/geth
  Gitter: https://gitter.im/ethereum/go-ethereum
 mac 下安装 geth  首先安装 homebrew， 使用 brew 安装即可。在安装 geth 的时候，会将 go 也安装上。  brew tap ethereum/ethereum brew install ethereum  在命令行输入 geth —help，如果出现
zhuzhenengdeMBP:blog zhuzhenfeng$ geth --help NAME: geth - the go-ethereum command line interface Copyright 2013-2017 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments.</description>
    </item>
    
    <item>
      <title>hive 常用函数</title>
      <link>https://zhenfeng-zhu.github.io/posts/hive%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</link>
      <pubDate>Thu, 16 Apr 2020 17:59:03 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hive%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</guid>
      <description>json 字符串处理  get_json_object lateral_view explode substr json_tuple  get_json_object get_json_object(string json_string, string path)
解析 json 字符串 json_string，返回 path 指定的内容。如果输入的 json 字符串是无效的，那么返回 null。
path 就是 &amp;lsquo;$.字段名&amp;rsquo;。
如果该字段的 value 也是 json，就可以一直点下去。
如果该字段的 value 是数组，就可以用 &amp;lsquo;$.字段名[0]&#39;，类似这样下标的形式去访问。
explode explode(array)
经常和 lateral view 一起使用，将数组中的元素拆分成多行显示。
substr substr(string A, int start, int len)
返回字符串 A 从 start 位置开始，长度为 len 的字符串
json_tuple json_tuple(string json_string, col1, col2, &amp;hellip;)
经常和 lateral view 一起使用，同时解析多个 json 字符串中的多个字段。
parse_url, regexp_replace, regexp_extract parse_url parse_url(string urlString, string partToExtract, string keyToExtract)</description>
    </item>
    
    <item>
      <title>mysql 的学习</title>
      <link>https://zhenfeng-zhu.github.io/posts/mysql%E7%9A%84%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 16 Apr 2020 17:34:30 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/mysql%E7%9A%84%E5%AD%A6%E4%B9%A0/</guid>
      <description>SQL 条件语句 IF if(exp1, exp2, exp3)
exp1 是条件，条件为 true 的话，是 exp2，否则是 exp3
case when case 列名 when 条件 then 结果 else 其他结果 end 别名 IFNULL IFNULL(exp1, exp2)
在 exp1 的值不为 null 的情况下，返回 exp1，如果 exp1 位 null，返回 exp2 的值。</description>
    </item>
    
    <item>
      <title>clickhouse</title>
      <link>https://zhenfeng-zhu.github.io/posts/clickhouse/</link>
      <pubDate>Sat, 12 Oct 2019 06:48:01 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/clickhouse/</guid>
      <description>ClickHouse ClickHouse 是一个用于联机分析（Online Analytical Processing：OLAP）的列式数据库管理系统(DBMS)。通过使用 OLAP 工具，用户能够从多个角度交互地分析多维数据。
OLAP 由三个基本的分析操作组成：上卷（roll-up）、钻取（drill-down）、切片（slicing）和切块（dicing）。
  上卷（roll-up）：涉及可以在一个或多个维度中累积和计算的数据的聚合。例如，所有的销售办事处汇总到销售部门，以预测销售趋势。
  钻取（drill-down）：是一种允许用户浏览详细信息的技术。例如，用户可以查看组成一个地区销售额的单个产品的销售额。
  切片（slicing）和切块（dicing）：用户可以从 OLAP 多维数据集中取出（切片）一组特定的数据，并从不同的角度查看（切块）切片。这些角度有时被称为维度（例如按销售人员、按日期、按客户、按产品或按地区查看相同的销售情况等）。
  传统行式数据库中，处于同一行中的数据总是被物理的存在一起。列式数据库总是将同一列的数据存储在一起，不同列的数据分开存储。
行式数据库：mysql，pg
列式数据库：vertica，druid
OLAP 的关键特征  大多是读请求 数据总是以相当大的批（&amp;gt;1000w）进行写入 不修改已经添加的数据 每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列 宽表，即每个表包含大量的列 较少的查询（通常每台服务器每秒数百个查询或更少） 对于简单的查询，允许延迟大约 50ms 列中的数据相对较小：数字和短字符串 处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行） 事务不是必须的 对数据一致性要求低 每一个查询除了一个大表外都很小 查询结果明显小于数据源，换句话说，数据被过滤或者聚合之后能够被放在单台服务器的内存中  列式数据库更适合 OLAP 场景 Input/Output  分析类的查询，通常只需要读取表的一小部分列。 数据总是打包成批量读取，列压缩更容易 IO 降低了  CPU 由于执行一个查询需要处理大量的行，因此在整个向量上执行所有操作将比在每一行上执行所有操作更加高效。同时这将有助于实现一个几乎没有调用成本的查询引擎。
 向量引擎 代码生成  为了提高 CPU 效率，查询语言必须是声明型的(SQL 或 MDX)， 或者至少一个向量(J，K)。 查询应该只包含隐式循环，允许进行优化。
clickhouse 的独特功能 真正的列式数据库管理系统 </description>
    </item>
    
    <item>
      <title>每日学习 2</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-29/</link>
      <pubDate>Sun, 29 Sep 2019 02:19:03 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-29/</guid>
      <description>https://mubu.com/doc/oHlgG0FSu0</description>
    </item>
    
    <item>
      <title>每日学习-2019-09-24</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-24/</link>
      <pubDate>Sun, 29 Sep 2019 02:17:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-24/</guid>
      <description>开言英语 极客时间 编译原理之美 语义分析（下）：如何做上下文相关情况的处理  语义分析的本质，就是针对上下文相关的情况做处理。  引用消解：不同作用域里可能有相同名称的变量，必须找到正确的那个，这个过程就是引用消解。  函数引用消解 命名空间引用消解   左值和右值  左值取的是变量的地址或者说是变量的引用，获得地址之后，我们就可以把新值写进去。 右值就是我们常说的值。 不是所有的表达式都能生成一个合格的左值。   属性计算  上下文分析或者说语义分析的一种算法。 属性文法的主要思路是计算机科学的重要开拓者，是在上下文无关文法的基础上做了一些增强，使之可以计算属性值。   过程  类型和作用域解析 类型的消解 引用的消解和 S 属性的类型推导 做类型检查 做一些语义合法性检查      趣谈 Linux 操作系统 Namespace 技术：内部创业公司应该独立运营 为了隔离不同类型的资源，Linux 内核里面有如下几种不同类型的 namespace：
 UTS，表示不同的 namespace 可以配置不同的 hostname User，可以配置不同的用户和组 Mount，文件系统挂载点是隔离的 PID，有完全独立的 pid Network，有独立的网络协议栈  </description>
    </item>
    
    <item>
      <title>tmux</title>
      <link>https://zhenfeng-zhu.github.io/posts/tmux/</link>
      <pubDate>Wed, 28 Aug 2019 12:03:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/tmux/</guid>
      <description>折腾一下 tmux
安装 brew install tmux 概念  session：理解为一个会话，持久保存工作状态。 window：可以理解为我们常说的 tab 页。 pane：一个 window 被分成若干个 pane，理解为 iterm 的分屏。  session 新建
tmux new -s your-session-name 断开
tmux detach 恢复
tmux attach-session -t your-session-name 或者 tmux a -t your-session-name 关闭
 kill-server kill-session kill-window kill-pane  tmux kill-session -t your-session-name tmux kill-server 查看
tmux list-session tmux ls tmux 的基础配置 prefix 是 tmux 的前缀键，默认是 ctrl+b 。只有按下前缀键，才会激活 tmux，然后再按其他的键进行 tmux 操作。这样可以避免与其他应用的快捷键进行冲突。
配置前缀 需要去 tmux.conf 中去配置</description>
    </item>
    
    <item>
      <title>crystal 开发环境</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Tue, 27 Aug 2019 14:03:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>突然搞明白了 crystal 的 vscode 插件的正确使用姿势，记录一下。
安装 crystal brew install crystal 安装 vscode 插件 https://marketplace.visualstudio.com/items?itemName=faustinoaq.crystal-lang
安装 scry scry 是 crystal 的 language server 的 client 工具，在本地安装 scry 就可以做到代码跳转了。
$ git clone https://github.com/crystal-lang-tools/scry.git $ cd scry $ shards build -v Dependencies are satisfied Building: scry crystal build -o /Users/lucas/Documents/demos/crystal/scry/bin/scry src/scry.cr /Users/lucas/Documents/demos/crystal/scry/bin/scry 就是编译出来的二进制的路径
配置插件 &amp;#34;crystal-lang.compiler&amp;#34;: &amp;#34;crystal&amp;#34;, &amp;#34;crystal-lang.server&amp;#34;: &amp;#34;/Users/lucas/Documents/demos/crystal/scry/bin/scry&amp;#34;, &amp;#34;crystal-lang.maxNumberOfProblems&amp;#34;: 20, &amp;#34;crystal-lang.mainFile&amp;#34;: &amp;#34;${workspaceRoot}/src/main.cr&amp;#34;, &amp;#34;crystal-lang.processesLimit&amp;#34;: 5, &amp;#34;crystal-lang.hover&amp;#34;: true, &amp;#34;crystal-lang.problems&amp;#34;: &amp;#34;build&amp;#34;, &amp;#34;crystal-lang.implementations&amp;#34;: true, &amp;#34;crystal-lang.completion&amp;#34;: true, &amp;#34;crystal-lang.logLevel&amp;#34;: &amp;#34;info&amp;#34;, 把上面的配置加到 vscode 的 settings 文件中，就可以愉快的开发啦。</description>
    </item>
    
    <item>
      <title>crystal 简介</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Tue, 27 Aug 2019 02:14:18 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal%E7%AE%80%E4%BB%8B/</guid>
      <description>关注 crystal 也有一段时间了，看到多线程的 pr 已经提了，今天简单写一下。
 Fast as C, Slick as Ruby
 语法 crystal 的语法和 Ruby 比较类似。
# A very basic HTTP server require &amp;#34;http/server&amp;#34; server = HTTP::Server.new do |context| context.response.content_type = &amp;#34;text/plain&amp;#34; context.response.print &amp;#34;Hello world, got #{context.request.path}!&amp;#34; end puts &amp;#34;Listening on http://127.0.0.1:8080&amp;#34; server.listen(8080) 类型系统 crystal 的一大卖点就是静态类型系统，但是写起来又和脚本语言类似。
def shout(x) # Notice that both Int32 and String respond_to `to_s` x.to_s.upcase end foo = ENV[&amp;#34;FOO&amp;#34;]? || 10 typeof(foo) # =&amp;gt; (Int32 | String) typeof(shout(foo)) # =&amp;gt; String 空引用检查 crystal 可以在编译的时候检查空引用，避免出现空指针异常。</description>
    </item>
    
    <item>
      <title>socket</title>
      <link>https://zhenfeng-zhu.github.io/posts/socket/</link>
      <pubDate>Mon, 26 Aug 2019 06:54:14 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/socket/</guid>
      <description>Socket 网络模型 osi 七层模型  应用层 表示层 会话层 传输层 网络层 数据链路层 物理层  对应的 tcpip 就是  应用层  dns http   传输层  icmp tcp udp   ip 层  ipv4 ipv6   mac 层  arp vlan   物理层  Ethernet    为什么要分层 因为网络环境过于复杂，不是一个能够集中控制的体系。全球的服务器和设备各有各的体系，但是可以通过同一套网络协议栈切分成多个层次和组合，来满足不同设备之间的通信需求。
二层到四层，即 mac、ip 和传输等层都是 Linux 内核中处理。应用层的如浏览器、Nginx 和 Tomcat 等都是用户态的。
传输层的 tcp 和 udp 里都有端口的概念，不同应用监听不同的段即可。
应用层和内核的互通机制，就是通过 socket 系统调用。其实 socket 哪一层都不属于，它是属于操作系统的概念，而不是网络分层的概念。因为操作系统把二层到四层的处理代码在内核里，应用层的处理代码让应用自己做，两者需要跨内核态和用户态进行通信，这个就是 socket。</description>
    </item>
    
    <item>
      <title>go 进阶</title>
      <link>https://zhenfeng-zhu.github.io/posts/go%E8%BF%9B%E9%98%B6/</link>
      <pubDate>Mon, 26 Aug 2019 06:53:32 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go%E8%BF%9B%E9%98%B6/</guid>
      <description>Diagnostics go 提供了一系列诊断逻辑和性能问题的工具。
 profiling 分析 tracing 跟踪 debuging 调试 运行时统计信息和事件  Profiling profiling 信息可以在 go test 或者 net/http/pprof 包的时候使用。
runtime/pprof 包有：
 cpu  主动消费 cpu 周期所花费的时间，不包括睡眠或者 io 等待   heap  报告内存分配采样； 当前或历史内存使用状况 检测内存泄露   threadcreate  报告创建新的系统线程   goroutine  当前所有协程的堆栈跟踪   block  显示 goroutine 阻塞等待同步原语的位置。 默认不开启，使用 runtime.SetBlockProfileRate 启用   mutex  报告锁竞争。 如果认为自己的程序因为互斥锁导致 cpu 不能充分利用的时候，使用这个。 默认也是不开启，使用 runtime.SetMutexProfileFraction 启用。    其他可用的的性能分析工具</description>
    </item>
    
    <item>
      <title>mysql</title>
      <link>https://zhenfeng-zhu.github.io/posts/mysql/</link>
      <pubDate>Sat, 01 Dec 2018 15:54:53 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/mysql/</guid>
      <description>MySQL 基本架构 客户端
server 层
  连接器：管理连接，权限验证
  查询缓存：命中规则，直接返回结果 8.0 之后全部删除了这个模块
  分析器：词法分析，语法分析
  优化器：执行计划生成，索引选择
  执行器：操作引擎，返回结果
  存储引擎：存储数据，提供读写接口
数据库中的长连接指连接成功之后，如果客户端持续有请求，则一直使用同一个连接。短连接是指每次执行完很少的几次查询之后就断开连接，下次再重新建立。
如果全部使用长连接，会导致 mysql 内存涨的很快，可能出现 OOM，因此要定期断开长连接，或者在执行一个比较大的操作之后，执行 mysql_reset_connection 重置一下。
日志系统 redo log 重做日志 redo log 是 innodb 引擎特有的。物理日志，记录的是某个数据页上做了什么修改。循环写入。
WAL 技术：Write-Ahead Logging：关键点就是先写日志，再写磁盘。当一条记录更新时，先把记录写到 redolog 中，更新到内存，这时这个更新操作就成功了。然后 innodb 引擎就会在适当的时候，将这个操作记录更新到磁盘中。因此在数据库异常重启的时候，之前的提交的记录不会丢失。
binlog 归档日志 binlog 是 server 层实现的，所有的引擎都可以使用。binlog 是逻辑日志，记录的是这个语句的原始逻辑。binlog 是写到一定大小后，切换下一个，不会覆盖以前的日志。
因此一个 update 操作就是：
找到该行
判断数据页是否在内存中，如果是返回行数据，否则从磁盘读入到内存中。
将值进行更新，写入新行
新行更新到内存
写入 redolog，处于 prepare 阶段
写入 binlog
提交事务，处于 commit 阶段。</description>
    </item>
    
    <item>
      <title>graphql</title>
      <link>https://zhenfeng-zhu.github.io/posts/graphql/</link>
      <pubDate>Thu, 08 Nov 2018 18:28:13 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/graphql/</guid>
      <description>graphql 经常被认为是聚焦于前端的技术。
核心概念 SDL：schema definition language（模式定义语言） 如：
type Person{ name: String! age: Int! } 这个类型有两个字段，name 和 age，他们的类型是 String 和 Int。！的意思代表他们是必需的。
type Post{ title: String! author: Person! } 接下来的 Post 也有两个字段，其中 Person 也是可以作为一个类型。
也可以这样，在 Person 中添加一个 post：
type Person{ name: String! age: Int! posts: [Post!]! } 通过 Query 获取数据 基本查询 客户端发送下面的数据给服务器
{ allPersons { name } } allPersons 是根字段（root field），它下面的成为查询的 payload，这里仅包含了一个 name。
服务器返回的结果会是这样的：
{ &amp;#34;allPersons&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Johnny&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;Sarah&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;Alice&amp;#34; } ] } 可以看到只返回了 name 字段，age 字段是不会返回的。</description>
    </item>
    
    <item>
      <title>go-best-practice</title>
      <link>https://zhenfeng-zhu.github.io/posts/go-best-practice/</link>
      <pubDate>Wed, 07 Nov 2018 17:16:07 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go-best-practice/</guid>
      <description> 短变量名称在声明和上次使用之间的距离很短时效果很好。 长变量名称需要证明自己的合理性; 名称越长，需要提供的价值越高。冗长的名称与页面上的重量相比，信号量较小。 请勿在变量名称中包含类型名称。 常量应该描述它们持有的值，而不是该如何使用。 对于循环和分支使用单字母变量，参数和返回值使用单个字，函数和包级别声明使用多个单词 方法、接口和包使用单个词。 请记住，包的名称是调用者用来引用名称的一部分，因此要好好利用这一点。  变量的名称应描述其内容，而不是内容的类型。
典型错误：
var usersMap map[string]*User 如果users的描述性都不够用，那么usersMap也不会。
声明变量但没有初始化时，请使用 var。
在声明和初始化时，使用:=。
关于变量和常量的注释应描述其内容而非其目的  任何既不明显也不简短的公共功能必须予以注释。 无论长度或复杂程度如何，对库中的任何函数都必须进行注释  在编写函数之前，请编写描述函数的注释。 如果你发现很难写出注释，那么这就表明你将要编写的代码很难理解。
以包所提供的内容来命名，而不是它包含的内容。
避免使用类似base，common或util的包名称 尽早return而不是深度嵌套 使用internal包来减少公共 API 不鼓励使用nil作为参数 首选可变参数函数而非[]T参数 通过消除错误来消除错误处理 使用github.com/pkg/errors包装errors 永远不要启动一个停止不了的 goroutine </description>
    </item>
    
    <item>
      <title>kubernetes</title>
      <link>https://zhenfeng-zhu.github.io/posts/kubernetes/</link>
      <pubDate>Mon, 08 Oct 2018 15:29:21 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kubernetes/</guid>
      <description>docker 利用 Linux 的 cgroups 和 namespace，构建一个沙箱运行环境。
docker 镜像 其实就是一个压缩包，这个压缩包是由一个完整的操作系统的所有文件目录构成，包含了这个应用运行所需要的所有依赖，所以本地开发环境和测试环境是一样的。
解决了应用打包的根本性问题。
容器编排 对 Docker 容器的一系列定义、配置和创建动作的管理
 容器本身没有价值，有价值的是“容器编排”。
 原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造一个“边界”。
在创建一个容器进程的时候，指定了这个进程所需要启动的一组 Namespace 参数，这样容器就只能看到当前 Namespace 所限定的资源、文件、设备、状态或配置。
Cgroups 主要作用是为一个进程组设置资源上限，如 CPU、内存、磁盘和带宽等。也可以设置进程优先级，审计，挂起，重启等。
因此，一个正在运行的 Docker 容器，其实就是一个启用了多个 Namespace 的应用进程，而这个进程能够使用的资源是由 Cgroups 来限制。
挂载在容器根目录上，用来为容器进程提供隔离后执行环境的文件系统，就是容器镜像，rootfs。
 启动 Namespace 配置 设置 Cgroups 参数 切换进程根目录 rootf  docker 镜像设计时，引入了层（layer），用户制作镜像的每一步操作都会生成一个层，也就是一个增量的 rootfs。AuFS，所以就有了共享层，镜像不用那么大。
一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到进入这个进程所在的容器的目的，这正是 docker exec 的实现原理。
volume 机制，允许你将宿主机上指定的目录或文件，挂载到容器里面进行读取和修改操作。
主要依赖 Linux 依赖三大技术  Namespace Cgroups rootfs  和虚拟机比较 虚拟机是通过硬件虚拟化功能，模拟一套操作系统所需要的各种硬件，如 CPU、内存、IO 设备等，然后安装一个新的操作系统。
docker 是利用 Linux 的 Namespace 原理，帮助用户启动的还是系统的应用进程，只是加了一些参数，限制其能看到的资源。因此相对于虚拟机资源消耗更小，而且轻量级，敏捷高性能。</description>
    </item>
    
    <item>
      <title>watchdog</title>
      <link>https://zhenfeng-zhu.github.io/posts/watchdog/</link>
      <pubDate>Thu, 06 Sep 2018 16:23:57 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/watchdog/</guid>
      <description>监视器
监视器提供了一个外部世界和函数之间的非托管的通用接口。它的工作是收集从 API 网关来的 HTTP 请求，然后调用程序。监视器是一个小型的 Golang 服务——下图展示了它是如何工作的：
 上图：一个小型的 web 服务，可以为每个传入的 HTTP 请求分配所需要的进程。
 每个函数都需要嵌入这个二进制文件并将其作为ENTRYPOINT 或 CMD，实际上是把它作为容器的初始化进程。一旦你的进程被创建分支，监视器就会通过stdin 传递 HTTP 请求并从stdout中读取 HTTP 响应。这意味着你的程序无需知道 web 和 HTTP 的任何信息。
轻松创建新函数 从 CLI 创建一个函数
创建函数最简单的方法是使用 FaaS CLI 和模板。CLI 抽象了所有 Docker 的知识，使得你只需要编写所支持语言的 handler 文件即可。
 你的第一个使用 OpenFaaS 的无服务器 Python 函数 阅读有关 FaaS CLI 的教程  深入研究 Package your function 打包你的函数
如果你不想使用 CLI 或者现有的二进制文件或镜像，可以使用下面的方法去打包函数：
 使用一个现有的或者一个新的 Docker 镜像作为基础镜像 FROM 通过curl 或 ADD https://从 Releases 页面 添加 fwatchdog 二进制文件 为每个你要运行的函数设置 fprocess(函数进程) 环境变量 Expose port 8080 暴露端口 8080 Set the CMD to fwatchdog 设置 CMD为fwatchdog  一个echo函数的示例 Dockerfile：</description>
    </item>
    
    <item>
      <title>queue-worker</title>
      <link>https://zhenfeng-zhu.github.io/posts/queue-worker/</link>
      <pubDate>Thu, 06 Sep 2018 16:23:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/queue-worker/</guid>
      <description>queue-worker 源码分析 异步函数和同步函数 在 OpenFaaS 中同步调用函数时，将会连接到网关，直到函数成功返回才会关闭连接。同步调用是阻塞的。
 网关的路由是：/function/&amp;lt;function_name&amp;gt; 必须等待 在结束的时候得到结果 明确知道是成功还是失败  异步函数会有一些差异：
 网关的路由是：/async-function/&amp;lt;function_name&amp;gt; 客户端获得 202 的即时响应码 从 queue-worker 中调用函数 默认情况下，结果是被丢弃的。  查看 queue-worker 的日志 docker service logs -f func_queue-worker 利用 requestbin 和 X-Callback-Url 获取异步函数的结果 如果需要获得异步函数的结果，有两个方法：
 更改代码，将结果返回给端点或者消息系统 利用内置的回调 内置的回调将会允许函数提供一个 url，queue-worker 会报告函数的成功或失败。 requestbin 会创建一个新的 bin，这是互联网的一个 url 地址，可以从这里获取函数的结果。  源码分析 依赖项 github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/faas go-nats 和 go-nats-streaming 是 nats 和 nats-streaming 的 go 版本的客户端。
faas 这个依赖其实是只用到了 queue 包下面的 types.go 文件。这个文件是定义了异步请求的 Request 结构体和一个 CanQueueRequests 接口。如下所示：</description>
    </item>
    
    <item>
      <title>区块链学习笔记</title>
      <link>https://zhenfeng-zhu.github.io/posts/blockchain/</link>
      <pubDate>Thu, 23 Aug 2018 15:14:02 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/blockchain/</guid>
      <description>本文是阅读http://www.netkiller.cn/blockchain/ch01s10.html 上的一些笔记。
 理解区块链的分布式记账 http://www.netkiller.cn/blockchain/ch01s10.html
区块链中提到的账本，记账等词汇是和会计无关的词汇。
我们传统理解的账本是一个二维的表格，记录了某年某月某日的费用：
   时间 用途 金额     2018-08-23 借 100   2018-08-22 还 200   2018-08-21 借 50   2018-08-20 还 1000    如果账目比较多，可以拆账，将不同分类的账目放在特定的账本中，而且二维表格还可以设置索引等，快速找到一笔交易。
但是区块链的记账形式是：
可以发现，区块链的这种记账方式是做了行列矩阵转换，节点之间收尾相互连接，成为链式结构，所有的账目都在一条链上。
所谓分布式记账，其实就是上述链状的数据结构保存在所有的节点上，形成分布式集群。
之所以采用区块链来做分布式记账，主要是区块链有如下好处：
  去中心化
传统的数据库存储是中心化的，通过暴露 ip 地址和端口号提供服务，后来分布式进群化之后，出现了主主从架构等。
与数据库相比，区块链是多主架构，而且实现更为复杂，节点之间的数据之间不是简单的二进制日志同步，而是要通过加密技术，节点达成共识之后才存储。
  可追溯
  安全
安全分为很多层，区块链只能做到存储层的安全。
区块链无法解决用户层，应用层，逻辑层等安全问题，他只能保证存储在硬盘上的区块不被修改。
  不可篡改
很多人认为区块链数据一旦创建之后就不能修改，所以采用区块链技术很安全。其实不然，数据是可以修改的，但是不能篡改。
撰改是指非法修改区块链数据，而修改则是合法变更数据。
通常撰改区块链数据多指数据存储层面的修改。而修改则是通过合约提供的修改函数变更区块链里面的数据。
多数区块链平台没有用户认证权限管理模块。所以无法控制区块中的哪些数据能被修改，哪些不能修改，哪些用户可以修改等等。即使有些区块链平台具备权限控制，颗粒度也无法达到目前的数据库控制的那么细。
  采用区块链作为账本的时候，会面临如下几个问题：
  不能建立索引，无法快速搜索出区块中的数据，必须依赖区块链以外的技术，如搜索引擎，数据库等。例如；etherscan.</description>
    </item>
    
    <item>
      <title>谈谈聊天机器人框架的实现原理</title>
      <link>https://zhenfeng-zhu.github.io/posts/botbuilder/</link>
      <pubDate>Wed, 22 Aug 2018 19:39:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/botbuilder/</guid>
      <description>在这篇文章不考虑人工智能，谈谈我对聊天机器人框架实现机制的理解。
聊天机器人  聊天机器人（Chatterbot）是经由对话或文字进行交谈的计算机程序[1]。能够模拟人类对话，通过图灵测试。
 我们可以看到现有的 IM 工具上已经有了很多机器人，其实聊天机器人不只是单纯的和用户进行聊天，他其实还可以做很多事情，例如根据用户输入的一些话，可以帮用户订餐。另外在运维领域，也出现了 chatops，通过和机器人聊天，进行运维操作。
机器人开发框架 作为聊天机器人开发者，面对如此多的 IM 工具和 SDK，常会感到无所适从。Bot 开发框架就是对聊天机器人开发过程中的人工内容做抽象化处理。简单地解释，机器人开发框架就是用来制造机器人并定义其行为。
然而尽管很多机器人框架宣称「代码一旦写好可部署到任何地方」，但是还会是出现为每一个 IM 工具开发一个单独的聊天机器人。而一个良好的机器人框架主要包含开发 SDK，连接器和模拟器等。
使用机器人框架其实并不适合初学者学习聊天机器人开发。它们尝试自动化太多工作，对初学者掩盖了基础机制。
实现方式  webhook 事件回调 FSM 状态机 workflow 工作流  最简单的机器人是没有上下文的语义理解的一问一答，仅仅是对用户的对话进行响应，这种就可以采用 webhook 的方式进行开发。不需要采用什么开发框架。
那么对于多轮对话的时候，就需要进行一定的对话管理。由此引入了 FSM 状态机。
可能有人不是很懂有限状态机，这里做一下简单说明。
 有限状态机在现实生活中其实随处可见，伸缩式圆珠笔其实就是一个有限状态机（两种状态互相转换）。
有限状态机，缩写为 FSM，又称为有限状态自动机，简称状态机。是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。
可以总结为：f(state, action) =&amp;gt; state’
也就是说，这个函数采用当前的状态和一次行动（即更改状态的方法），之后将该行动应用于这种状态并返回新的状态。
可以认为状态机是图灵完备的。
 我们可以将对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。
我们可以将对话的过程，分为一个个的状态，然后使用 DSL 来实现一个 FSM，对于开发者来讲，我们只需要关注一个个状态函数即可。
特点是：
 人为定义对话流程 完全有系统主导，系统问用户答 答非所问的情况直接忽略 建模简单，能清晰明了的把交互匹配到模型 难以扩展，很容易变的复杂 适用于简单的任务，难以处理复杂问题 缺少灵活性，表达能力有限，输入有限，对话结构和流转路径有限  示例：
const {startWith, when, goto, stay, stop} = botkit.</description>
    </item>
    
    <item>
      <title>基于以太坊的 Parity 联盟链部署</title>
      <link>https://zhenfeng-zhu.github.io/posts/parity/</link>
      <pubDate>Wed, 22 Aug 2018 16:51:13 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/parity/</guid>
      <description>公司项目中使用公网上的以太坊私链，交易速度比较慢，于是这几天都在鼓捣基于以太坊的联盟链，parity 是可以构建出一个基于 PoA 共识的私链，而且兼容以太坊的合约。这篇文章主要是记录自己的踩坑经历，主要实现了节点的搭建，合约的部署以及本地以太坊浏览器的启动。
部署联盟链 parity 的文档：https://wiki.parity.io/Demo-PoA-tutorial
安装 首先是下载 parity，在 mac 下是直接 brew 安装即可。
brew tap paritytech/paritytech brew install parity 创世区块 创世区块的配置文件：
// demo-spec.json { &amp;quot;name&amp;quot;: &amp;quot;DemoPoA&amp;quot;, &amp;quot;engine&amp;quot;: { &amp;quot;authorityRound&amp;quot;: { &amp;quot;params&amp;quot;: { &amp;quot;stepDuration&amp;quot;: &amp;quot;5&amp;quot;, &amp;quot;validators&amp;quot;: { &amp;quot;list&amp;quot;: [ &amp;quot;0x00bd138abd70e2f00903268f3db08f2d25677c9e&amp;quot;, &amp;quot;0x00aa39d30f0d20ff03a22ccfc30b7efbfca597c2&amp;quot; ] } } } }, &amp;quot;params&amp;quot;: { &amp;quot;gasLimitBoundDivisor&amp;quot;: &amp;quot;0x400&amp;quot;, &amp;quot;maximumExtraDataSize&amp;quot;: &amp;quot;0x20&amp;quot;, &amp;quot;minGasLimit&amp;quot;: &amp;quot;0x1388&amp;quot;, &amp;quot;networkID&amp;quot;: &amp;quot;0x2323&amp;quot;, &amp;quot;eip155Transition&amp;quot;: 0, &amp;quot;validateChainIdTransition&amp;quot;: 0, &amp;quot;eip140Transition&amp;quot;: 0, &amp;quot;eip211Transition&amp;quot;: 0, &amp;quot;eip214Transition&amp;quot;: 0, &amp;quot;eip658Transition&amp;quot;: 0 }, &amp;quot;genesis&amp;quot;: { &amp;quot;seal&amp;quot;: { &amp;quot;authorityRound&amp;quot;: { &amp;quot;step&amp;quot;: &amp;quot;0x0&amp;quot;, &amp;quot;signature&amp;quot;: &amp;quot;0x0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&amp;quot; } }, &amp;quot;difficulty&amp;quot;: &amp;quot;0x20000&amp;quot;, &amp;quot;gasLimit&amp;quot;: &amp;quot;0x5B8D80&amp;quot; }, &amp;quot;accounts&amp;quot;: { &amp;quot;0x0000000000000000000000000000000000000001&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;ecrecover&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 3000, &amp;quot;word&amp;quot;: 0 } } } }, &amp;quot;0x0000000000000000000000000000000000000002&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;sha256&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 60, &amp;quot;word&amp;quot;: 12 } } } }, &amp;quot;0x0000000000000000000000000000000000000003&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;ripemd160&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 600, &amp;quot;word&amp;quot;: 120 } } } }, &amp;quot;0x0000000000000000000000000000000000000004&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;identity&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 15, &amp;quot;word&amp;quot;: 3 } } } }, &amp;quot;0x004ec07d2329997267ec62b4166639513386f32e&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;10000000000000000000000&amp;quot; } } } node0 node0 节点：</description>
    </item>
    
    <item>
      <title>dive-into-redis</title>
      <link>https://zhenfeng-zhu.github.io/posts/dive-into-redis/</link>
      <pubDate>Mon, 20 Aug 2018 09:39:08 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/dive-into-redis/</guid>
      <description>redis 持久化，
机制有两种：
 快照：全量备份，二进制序列化，存储紧凑 AOF 日志：连续的增量备份，内存数据修改的文本  </description>
    </item>
    
    <item>
      <title>golang 踩坑</title>
      <link>https://zhenfeng-zhu.github.io/posts/golang%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Tue, 14 Aug 2018 20:10:55 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/golang%E8%B8%A9%E5%9D%91/</guid>
      <description>一  x509 error when using HTTPS inside a Docker container
 因为 docker 中没有 CA 证书。
普通的镜像解决办法
FROM ubuntu:14.04.1 RUN apt-get update RUN apt-get install -y ca-certificates CMD curl https://www.google.com 如果是 alpine 的参考这个：
FROM docker.finogeeks.club/base/alpine MAINTAINER &amp;#34;zhuzhenfeng@finogeeks.club&amp;#34; RUN set -ex \ &amp;amp;&amp;amp; apk add --no-cache ca-certificates COPY src/wallet/wallet /opt/wallet ENTRYPOINT /opt/wallet 二  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x38 pc=0x26df]
 &amp;ldquo;An error is returned if caused by client policy (such as CheckRedirect), or if there was an HTTP protocol error.</description>
    </item>
    
    <item>
      <title>以太坊开发总结</title>
      <link>https://zhenfeng-zhu.github.io/posts/eth-tools/</link>
      <pubDate>Fri, 10 Aug 2018 18:57:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/eth-tools/</guid>
      <description>最近因公司项目需要，做为一个打杂工程师，操起键盘和笔记本开始了以太坊的踩坑之旅。以太坊的开发比较新，变化也比较多，还好有@cctanfujun的手把手带领下，半只脚踏入了以太坊的开发的大门。
在这篇文章中，我将会简单介绍一下以太坊的基本概念，以及我现在用到的一些工具，还有具体的一个开发流程。因为我还没有接触到如何上主链，所以这些都是基于测试链讲解。希望能给大家带来一些帮助。
什么是区块链
相信大家对区块链都有自己的理解，不仅仅是互联网公司，传统企业也在“币改转型”。
**简言之，区块链就是数据库。**它是特定数据的数据库，里面的数据不断增长，具有非凡特性：
 一旦数据存储于数据库，永远都无法被修改或删除。区块链上的每个记录会被永久保存下来。 没有单独的个人或组织能维护该数据库。必须要上千个人才行，每个人都有数据库的副本。  什么是以太坊？
 以太坊（英语：Ethereum）是一个开源的有智能合约功能的公共区块链平台[1][2]。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。
 为什么选择以太坊？
  智能合约
  代币
  资料相对完善，相对容易开发
  大佬对以太坊比较熟悉
  大佬对以太坊比较熟悉
  大佬对以太坊比较熟悉
  重要的事情说三遍，有一个经验丰富的人带领，做东西肯定事半功倍。
自己动手写区块链
这里提供两个教程，一个是书，一个是视频。其中视频和书是对应的，不清楚是不是同一个作者。
Blockchain Tutorial
私有区块链，我们一起 GO
以太坊开发
由于我是专注于后端的开发，现在的技术栈是
 node go  正式进入以太坊的开发。这是我这段时间接触到的一些资源：
  go-ethereum：也就是 geth，官方的 go 版本的客户端
  solidity：智能合约编程语言
  truffle：智能合约的编程框架，基于 nodejs
  Ganache：启动了多个节点本地私链
  Rinkeby：以太坊测试链
  Etherscan：以太坊区块链浏览器，可以查询交易</description>
    </item>
    
    <item>
      <title>以太坊</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A/</link>
      <pubDate>Tue, 07 Aug 2018 20:09:26 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A/</guid>
      <description>参与了公司的一个项目，上了以太坊，这里简单记录一下踩坑。
首先先把 go 的依赖下载下来：
go get -u -v github.com/ethereum/go-ethereum 有时候下载的很慢，可以从 github 上拉下来代码。
账户 以太坊的地址在离线状态下也可以创建到。
创建账户有两种方式：
以公钥和私钥的形式创建 func CreateAccount() (string, error) { key, err := crypto.GenerateKey() if err != nil { log.Fatalln(err) return &amp;#34;&amp;#34;, nil } address := crypto.PubkeyToAddress(key.PublicKey).Hex() log.Println(&amp;#34;address: &amp;#34;, address) privateKey := hex.EncodeToString(key.D.Bytes()) log.Println(&amp;#34;privateKey: &amp;#34;, privateKey) return address, nil } 这种方式一般用的比较少。
以 keystore 的形式创建 keystore 会创建一个文件，这个文件如下所示：
{ &amp;quot;address&amp;quot;: &amp;quot;d93688757810e644f0b9c162102d9c598813f0dd&amp;quot;, &amp;quot;crypto&amp;quot;: { &amp;quot;cipher&amp;quot;: &amp;quot;aes-128-ctr&amp;quot;, &amp;quot;ciphertext&amp;quot;: &amp;quot;71ae7c8144729b2f9e0c51d95c6dfb73e63f14b5332b3594e8a1f325237c27ed&amp;quot;, &amp;quot;cipherparams&amp;quot;: { &amp;quot;iv&amp;quot;: &amp;quot;620c73001081c014a862ce80003a4648&amp;quot; }, &amp;quot;kdf&amp;quot;: &amp;quot;scrypt&amp;quot;, &amp;quot;kdfparams&amp;quot;: { &amp;quot;dklen&amp;quot;: 32, &amp;quot;n&amp;quot;: 262144, &amp;quot;p&amp;quot;: 1, &amp;quot;r&amp;quot;: 8, &amp;quot;salt&amp;quot;: &amp;quot;bd272aa37271ef9913eb095a4d143be238e348c48fce6459896e1bb1b0236741&amp;quot; }, &amp;quot;mac&amp;quot;: &amp;quot;2b3ade771645090a2b34c214906c592a1300d529e459faefb1421ba496b6fe1d&amp;quot; }, &amp;quot;id&amp;quot;: &amp;quot;e4dd5384-56a8-4ec7-b6e0-492dcd3742e9&amp;quot;, &amp;quot;version&amp;quot;: 3 } 在生成这个文件的时候，会让你输一个密码，这个文件加密码其实就是一个私钥。</description>
    </item>
    
    <item>
      <title>contract</title>
      <link>https://zhenfeng-zhu.github.io/posts/contract/</link>
      <pubDate>Fri, 03 Aug 2018 14:32:03 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/contract/</guid>
      <description>类型 Solidity 是静态类型的语言。
值类型  bool int/uint fixed/unfixed address  balance 和 transfer send call, callcode 和 delegatecall   byte bytes 和 string 十六进制 hex&amp;quot;0012&amp;quot; enum function  引用类型   数组
uint[]
  结构体
struct
  映射
mapping(key =&amp;gt; value)
  单元和全局变量   以太币的单位
在数字后面加上 wei、 finney、 szabo 或 ether。默认是 wei
  时间单位
数字后面带有 seconds、 minutes、 hours、 days、 weeks 和 years。默认是秒。
  区块和交易</description>
    </item>
    
    <item>
      <title>faas-provider</title>
      <link>https://zhenfeng-zhu.github.io/posts/faas-provider/</link>
      <pubDate>Wed, 01 Aug 2018 19:53:23 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/faas-provider/</guid>
      <description>faas-provider 是一个模板，只要实现了这个模板的接口，就可以自定义实现自己的 provider。
faas-provider OpenFaaS 官方提供了两套后台 provider：
 Docker Swarm Kubernetes  这两者在部署和调用函数的时候流程图如下：
部署一个函数
调用一个函数
provider 要提供的一些 API 有：
 List / Create / Delete 一个函数  /system/functions
方法: GET / POST / DELETE
 获取一个函数  /system/function/{name:[-a-zA-Z_0-9]+}
方法: GET
 伸缩一个函数  /system/scale-function/{name:[-a-zA-Z_0-9]+}
方法: POST
 调用一个函数  /function/{name:[-a-zA-Z_0-9]+}
方法: POST
在 provider 的 server.go 的 serve 方法，可以看到这个 serve 方法创建了几个路由，接受一个 FaaSHandler 对象。
// Serve load your handlers into the correct OpenFaaS route spec.</description>
    </item>
    
    <item>
      <title>gateway-reading</title>
      <link>https://zhenfeng-zhu.github.io/posts/gateway-reading/</link>
      <pubDate>Wed, 01 Aug 2018 09:15:35 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/gateway-reading/</guid>
      <description>OpenFaaS 的 Gateway 是一个 golang 实现的请求转发的网关，在这个网关服务中，主要有以下几个功能：
 UI 部署函数 监控 自动伸缩  架构分析 从图中可以发现，当 Gateway 作为一个入口，当 CLI 或者 web 页面发来要部署或者调用一个函数的时候，Gateway 会将请求转发给 Provider，同时会将监控指标发给 Prometheus。AlterManager 会根据需求，调用 API 自动伸缩函数。
源码分析 依赖 github.com/gorilla/mux github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/nats-queue-worker github.com/prometheus/client_golang mux 是一个用来执行 http 请求的路由和分发的第三方扩展包。
go-nats-streaming，go-nats，nats-queue-worker 这三个依赖是异步函数的时候才会用到，在分析 queue-worker 的时候有说到 Gateway 也是一个发布者。
client_golang 是 Prometheus 的客户端。
项目结构 ├── Dockerfile ├── Dockerfile.arm64 ├── Dockerfile.armhf ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── assets ├── build.sh ├── handlers │ ├── alerthandler.go │ ├── alerthandler_test.</description>
    </item>
    
    <item>
      <title>NATS streaming</title>
      <link>https://zhenfeng-zhu.github.io/posts/nats-streaming/</link>
      <pubDate>Mon, 30 Jul 2018 14:51:26 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/nats-streaming/</guid>
      <description>市面上常见到的和 Nats 功能类似的消息通信系统有：
ActiveMQ（Java 编写）、KafKa（Scala 编写）、RabbitMq（Ruby 编写）、Nats（之前是 Ruby 编写现已修改为 Go）、Redis（C 语言编写）、Kestrel（Scala 编写不常用）、NSQ（Go 语言编写），这些消息通信系统在 Broker 吞吐量方面的比较：
可以看到 NATS 的吞吐量特别高， NATS 原来是使用 Ruby 编写，可以实现每秒 150k 消息，后来使用 Go 语言重写，能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。关于 NATS 的详细介绍，请参考上篇文章：NATS 简介
NATS Streaming NATS Streaming 是由 NATS 驱动的数据流系统，也是由 go 语言写成的，在保证吞吐量和时延的基础上，解决了 Nats 消息投递一致性的问题。nats streaming 可以和核心 nats 平台无缝嵌入，扩展和互动。
功能 除了 nats 平台的一些功能，nats streaming 还支持以下的：
 增强的消息协议 消息/事件持久化 至少一次投递 发布者速率限制 每个订阅者的速率匹配/限制 可重复消费 持久订阅  使用 首先安装 nats-streaming-server 服务，有多种方式，这里介绍两种：
  homebrew</description>
    </item>
    
    <item>
      <title>nats 简介</title>
      <link>https://zhenfeng-zhu.github.io/posts/nats/</link>
      <pubDate>Mon, 30 Jul 2018 11:15:39 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/nats/</guid>
      <description>nats 是一个开源的，云原生的消息系统。Apcera，百度，西门子，VMware，HTC 和爱立信等公司都有在使用。
核心基于 EventMachine 开发，原理是基于消息发布订阅机制，每台服务器上的每个模块会根据自己的消息类别向 MessageBus 发布多个消息主题，而同时也向自己需要交互的模块，按照需要的主题订阅消息。能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。使用 nats streaming 可以做到持久化，缓存等功能。
NATS server nats 提供了一个 go 编写的轻量级服务器。发行版包括二进制和 docker 镜像
NATS clients
nats 官方提供的客户端有 Go，Node，Ruby，Java，C，C＃，NGINX 等。
NATS 设计目标
核心原则是性能，可伸缩和易用性。
 高效 始终在线和可用 非常轻巧 支持多种质量的服务 支持各种消息传递模型和使用场景  NATS 使用场景 nats 是一个简单且强大的消息系统，为支持现代云原生架构设计。由于可伸缩性的复杂性，nats 旨在容易使用和实现，且能提供多种质量的服务。
一些适用 nats 的场景有：
 高吞吐量的消息分散 —— 少数的生产者需要将数据发送给很多的消费者。 寻址和发现 —— 将数据发送给特定的应用实例，设备或者用户，也可用于发现并连接到基础架构中的实例，设备或用户。 命令和控制（控制面板）—— 向程序或设备发送指令，并从程序/设备中接收状态，如 SCADA，卫星遥感，物联网等。 负载均衡 —— 主要应用于程序会生成大量的请求，且可动态伸缩程序实例。 N 路可扩展性 —— 通信基础架构能够充分利用 go 的高效并发/调度机制，以增强水平和垂直的扩展性。 位置透明 —— 程序在各个地理位置上分布者大量实例，且你无法了解到程序之间的端点配置详情，及他们所生产或消费的数据。 容错  使用 nats-streaming 的附加场景有：</description>
    </item>
    
    <item>
      <title>overview-of-openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/overview-of-openfaas/</link>
      <pubDate>Thu, 26 Jul 2018 17:41:33 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/overview-of-openfaas/</guid>
      <description>OpenFaaS 概览  无服务器函数变得简单。
 函数监视器  你可以通过添加函数监视器 (一个小型的 Golang HTTP 服务)把任何一个 Docker 镜像变成无服务器函数。 函数监视器是允许 HTTP 请求通过 STDIN 转发到目标进程的入口点。响应会从你应用写入 STDOUT 返回给调用者。  API 网关/UI 门户  API 网关为你的函数提供外部路由，并通过 Prometheus 收集云原生指标。 你的 API 网关将会根据需求更改 Docker Swarm 或 Kubernetes API 中的服务副本数来实现伸缩性。 UI 是允许你在浏览器中调用函数或者根据需要创建新的函数。   API 网关是一个 RESTful 形式的微服务，你可以在这里查看Swagger 文档。
 命令行 Docker 中的任何容器或者进程都可以是 FaaS 中的一个无服务器函数。使用FaaS CLI ，你可以快速的部署函数。
可以从 Node.js, Python, Go 或者更多的语言模板中创建新的函数。如果你无法找到一个合适的模板，甚至可以使用一个 Dockerfile。
 CLI 实际上是 API 网关的一个 RESTful 客户端。
 在配置好 OpenFaaS 之后，你可以在这里开始学习 CLI开始学习 CLI</description>
    </item>
    
    <item>
      <title>OpenFaaS on Rancher 2.0</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-on-rancher/</link>
      <pubDate>Thu, 26 Jul 2018 09:50:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-on-rancher/</guid>
      <description>这是一篇关于如何在 Rancher 2.0 上创建 OpenFaaS 栈的文章。我假设你已经准备好了 Rancher 2.0 集群，如果没有请按照官方文档创建一个。
下面的视频展示了如何创建 OpenFaaS 栈，并在实际中使用：
https://www.youtube.com/watch?v=kX8mXv5d1qg&amp;amp;feature=youtu.be
这里是创建栈的compose.yml文件：
version: &amp;#34;2&amp;#34; services: alertmanager: image: functions/alertmanager:latest labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 faas-rancher: environment: - CATTLE_URL=${CATTLE_URL} - CATTLE_ACCESS_KEY=${CATTLE_ACCESS_KEY} - CATTLE_SECRET_KEY=${CATTLE_SECRET_KEY} - FUNCTION_STACK_NAME=faas-functions image: kenfdev/faas-rancher:v3 labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 gateway: environment: - functions_provider_url=http://faas-rancher:8080/ image: functions/gateway:0.6.6-beta1 labels: io.rancher.container.pull_image: always ports: - 8080:8080/tcp stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 prometheus: command: [-config.</description>
    </item>
    
    <item>
      <title>openfaas-workshop-lab4</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab4/</link>
      <pubDate>Mon, 02 Jul 2018 09:32:59 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab4/</guid>
      <description>Lab 4 - 深入函数 在开始本实验之前，创建一个新的文件夹，把 lab3 的文件拷贝到 lab4 里：
$ cp -r lab3 lab4 \ &amp;amp;&amp;amp; cd lab4 通过环境变量注入配置 It is useful to be able to control how a function behaves at runtime, we can do that in at least two ways:
控制函数在运行时的行为很有用，我们至少可以通过两种方式来实现：
在部署时  在部署时设置环境变量  我们在 Lab3 时用了 write_debug 来做——你也可以在这里设置你想要的任何自定义的环境变量。例如：如果你想为 hello world 函数配置一种语言，可以引入一个 spoken_language 变量。
使用 HTTP 上下文——querystring / headers  使用 querystring 和 HTTP headers  另一个更为动态的选项是可以在每个请求级别上进行修改，即使用 querystrings 和 HTTP headers，这两者都可以通过 faas-cli 或者 curl 传递。</description>
    </item>
    
    <item>
      <title>ubuntu-docker-sudo</title>
      <link>https://zhenfeng-zhu.github.io/posts/ubuntu-docker-sudo/</link>
      <pubDate>Fri, 29 Jun 2018 13:54:25 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/ubuntu-docker-sudo/</guid>
      <description>sudo chown &amp;#34;$USER&amp;#34;:&amp;#34;$USER&amp;#34; /home/&amp;#34;$USER&amp;#34;/.docker -R sudo chmod g+rwx &amp;#34;/home/$USER/.docker&amp;#34; -R https://api.finochat.com/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI http://localhost:3000/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI </description>
    </item>
    
    <item>
      <title>openfaas-workshop-lab3</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab3/</link>
      <pubDate>Thu, 28 Jun 2018 17:29:56 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab3/</guid>
      <description>Lab3 - 函数的介绍 在开始本实验之前，创建一个新文件夹：
$ mkdir -p lab3 \ &amp;amp;&amp;amp; cd lab3 创建一个新函数 创建函数有两种方式：
 使用内置的或社区提供的代码末班创建一个函数脚手架（默认）   将现有的二进制文件作为函数（高级）  生成一个新函数 在使用模板创建一个新函数之前，首先确认你已经从 Github 上拉下来模板文件：
$ faas-cli template pull Fetch templates from repository: https://github.com/openfaas/templates.git Attempting to expand templates from https://github.com/openfaas/templates.git Fetched 11 template(s) : [csharp dockerfile go go-armhf node node-arm64 node-armhf python python-armhf python3 ruby] 之后找到可用的语言：
$ faas-cli new --list Languages available as templates: - csharp - dockerfile - go - go-armhf - node - node-arm64 - node-armhf - python - python-armhf - python3 - ruby Or alternatively create a folder containing a Dockerfile, then pick the &amp;#34;Dockerfile&amp;#34; lang type in your YAML file.</description>
    </item>
    
    <item>
      <title>译：openfaas-workshop-Lab1</title>
      <link>https://zhenfeng-zhu.github.io/posts/workshop-lab1/</link>
      <pubDate>Mon, 25 Jun 2018 18:04:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/workshop-lab1/</guid>
      <description>今天大多数公司在开发应用程序并将其部署在服务器上的时候，无论是选择公有云还是私有的数据中心，都需要提前了解究竟需要多少台服务器、多大容量的存储和数据库的功能等。并需要部署运行应用程序和依赖的软件到基础设施之上。假设我们不想在这些细节上花费精力，是否有一种简单的架构模型能够满足我们这种想法？这个答案已经存在，这就是今天软件架构世界中新鲜但是很热门的一个话题——Serverless（无服务器）架构。
目前已经有一批优秀的 serverless 架构开源项目，OpenFaas 就是其中的佼佼者。奈何其中的中文资料比较少，我也是边学边翻译，希望能够抛砖引玉，助力 serverless 的发展。
这是一个自学研讨会，学习如何构建、部署和运行 OpenFaas 函数。
Lab1 - OpenFaas 的准备工作 OpenFaas 可以在 Docker Swarm 和 Kubernetes 的过几个主要平台之上运行。在此教程里，我们将会在的您本地电脑使用 Docker Swarm 来入门。
预备条件 Docker Mac
 Docker CE for Mac Edge Edition  Windows
 仅针对 windows10 专业版或企业版 安装Docker CE for Windows 安装Git Bash   备注：所有步骤中请使用 Git Bash：不要尝试使用 WSL 或 Bash for Windows。
 Linux - Ubuntu 或 Debian
 Docker CE for Linux   你可以从Docker Store中安装 Docker CE</description>
    </item>
    
    <item>
      <title>openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas/</link>
      <pubDate>Sun, 24 Jun 2018 15:43:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas/</guid>
      <description>对于 mac 环境来讲，首先安装新版 docker:
brew cask install docker 然后启动 docker。
命令行登陆 docker hub
docker login 启动 docker swarm
docker swarm init 安装 faas-cli
brew install faas-cli clone 下来代码：
git clone https://github.com/openfaas/faas 然后执行
./deploy_stack.sh 部署一些示例
faas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 使用浏览器打开 http://127.0.0.1:8080 就可以看到 ui 界面了。
安装 grafana 进行监控
docker service create -d \ --name=grafana \ --publish=3000:3000 \ --network=func_functions \ stefanprodan/faas-grafana:4.6.3 浏览器打开： http://127.0.0.1:3000 登陆 admin admin 查看。
常用命令：
$ faas-cli new --list $ faas-cli build -f .</description>
    </item>
    
    <item>
      <title>java-reactive-web</title>
      <link>https://zhenfeng-zhu.github.io/posts/java-reactive-web/</link>
      <pubDate>Sat, 23 Jun 2018 15:05:32 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/java-reactive-web/</guid>
      <description>Spring web mvc： 传统 servlet web
spring web flux： Reactive web
 编程模式： non-blocking 非阻塞  nio：同步？异步？   并行模型  sync 同步 async 异步    Reactive 概念 Reactive programming： 响应式编程
In computing, reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. With this paradigm it is possible to express static (e.g. arrays) or dynamic (e.g. event emitters) data streams with ease, and also communicate that an inferred dependency within the associated execution model exists, which facilitates the automatic propagation of the changed data flow.</description>
    </item>
    
    <item>
      <title>kafka</title>
      <link>https://zhenfeng-zhu.github.io/posts/kafka/</link>
      <pubDate>Thu, 21 Jun 2018 17:49:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kafka/</guid>
      <description>启动 zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties 启动 kafka
bin/kafka-server-start.sh config/server.properties 创建一个主题
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test bin/kafka-topics.sh --list --zookeeper localhost:2181 生产者
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 消费者
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning kafka connect
echo -e &amp;#34;zhisheng\ntian&amp;#34; &amp;gt; test.txt ls
zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ echo -e &amp;#34;zhisheng\ntian&amp;#34; &amp;gt; test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ ls LICENSE NOTICE bin config libs logs site-docs test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ 启动连接器</description>
    </item>
    
    <item>
      <title>译：vertx-kotlin-coroutine</title>
      <link>https://zhenfeng-zhu.github.io/posts/vertx-kotlin-coroutine/</link>
      <pubDate>Sat, 02 Jun 2018 16:00:52 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/vertx-kotlin-coroutine/</guid>
      <description>尝试翻译 vertx 的文档。尊重原文，部分使用自己的理解。
 Vert.x 的 kotlin 协程提供了 async/await 或者和 go 类似的 channel。这使得你能够以熟悉的顺序风格写垂直代码。
vertx-lang-kotlin-coroutines 集成了 kotlin 协程，用于执行异步操作和处理事件。这样就能够以同步代码的模型编写代码，而且不会阻塞内核线程。
简介 vert.x 与许多旧的应用平台相比的一个主要优势是它几乎完全是非阻塞的（内核线程）。这允许基于 vert.x 的程序使用极少数的内核线程处理大量的并发（例如：许多连接和消息），可以获得更好的伸缩性。
vert.x 的非阻塞特性形成了非阻塞 API。非阻塞 API 可以采用多种形式来实现，包括回调函数，promise，fibers 或者响应式扩展。vert.x 的核心 API 使用回调函数的风格，但是它也支持其他模型，如 RxJava 1 和 2。
在某些情况下，使用异步的 API 编程可能比使用经典的顺序代码风格更具有挑战性，特别是需要按照顺序完成若干操作。另外，使用异步 API 时，错误的传播也更为复杂。
vertx-lang-kotlin-coroutines 使用协程。协程是非常轻量级的线程，而且不与底层的内核线程对应。所以当协程需要“阻塞”时，它会暂停并释放当前的内核线程，使得另一个协程可以处理事件。
vertx-lang-kotlin-coroutines 使用 kotlinx.coroutines 来实现协程。
 vertx-lang-kotlin-coroutines 目前仅适用于 kotlin，而且是 kotlin1.1 的一个实验特性。
 从一个 vertx.x 的 contex 中启动协程 导入 io.vertx.kotlin.coroutines.VertxCoroutine，launch（协程生成器）方法中允许运行一段代码作为可以暂停的协程：
val vertx = Vertx.vertx() vertx.deployVerticle(ExampleVerticle()) launch(vertx.dispatcher()) { val timerId = awaitEvent&amp;lt;Long&amp;gt; { handler -&amp;gt; vertx.</description>
    </item>
    
    <item>
      <title>小议 async/await 和 coroutine</title>
      <link>https://zhenfeng-zhu.github.io/posts/async/</link>
      <pubDate>Mon, 21 May 2018 19:37:14 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/async/</guid>
      <description>Being happy doesn&amp;rsquo;t mean that everything is perfect. It means that you decided to look beyond the imperfections.
 后端编程，涉及最多的就是并发。简单理解就是：
 并发是同时管理多个任务去执行，并行是针对多核处理器，同时执行多个任务。可以理解为一个是 manage，一个是 run。
 并发一般特指 IO，IO 是独立于 CPU 的设备，IO 设备通常远远慢于 CPU，所以我们引入了并发的概念，让 CPU 可以一次性发起多个 IO 操作而不用等待 IO 设备做完一个操作再做令一个。原理就是非阻塞操作+事件通知。
硬件底层上我其实不关心，主要就是在写程序上，如何简单的去写并发的代码。在语法层面上对并发做的比较好的，很适合做服务端，比如 go，比如 node，又比如某些函数式语言。我最近最近主要使用的是 node 和 kotlin。
那么在写并发代码的时候，就会时不时的想这样一个问题：
一个问题 当代码遇到一个“暂时不能完成”的流程时（例如建立一个 tcp 链接，可能需要 5ms 才能建立），他不想阻塞在这里睡眠，想暂时离开现场去干点别的事情（例如看看另外一个已经建立的链接是否可以收包了）。问题是：离开现场后，当你回来的时候，上下文还像你走的时候吗？
跳转离开，在任何语言里都有 2 种最基本的方法：1）从当前函数返回； 2）调用一个新的函数。 前者会把上下文中的局部变量和函数参数全部摧毁，除非他返回前把这些变量找个别的地方保存起来；后者则能保护住整个上下文的内存（除了协程切换后会摧毁一些寄存器），而且跳转回来也是常规方法：函数返回。
在写 node 的时候，基本上是无脑上 async/await。每次看到回调函数的时候，强迫症就犯了，总是想方设法将那个方法转成 promise，然后使用 await 获得结果。无脑尝试了 bluebird 和 node 的 util，虽然有些是很好用的，但是有的还是无法达到我预期的。靠着无脑的 async/await，实现了很多功能，代码写起来也是快的飞起，但是只顾着做业务而不深入思考的话，是一个不好的表现，所以我就停下来搜了很多 async/await 的东西，特别是从阮一峰老师那里收获了很多。</description>
    </item>
    
    <item>
      <title>elasticsearch</title>
      <link>https://zhenfeng-zhu.github.io/posts/elasticsearch/</link>
      <pubDate>Sun, 20 May 2018 14:17:07 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/elasticsearch/</guid>
      <description>以前没有好好学的东西，现在在工作中慢慢的补回来了。
基础概念  索引  es 是将数据存储在一个或者多个索引（index）中。
索引就像是数据库。
 文档  文档是 es 的实体。由字段构成，每个字段包含字段名和一个或者多个字段值。
文档就像数据库中的一条条记录。
 类型  每个文档都有一个类型与之相对应。
类型就像数据库中的表。
 映射  所有文档在被写入到 es 中，都会被分析。由用户设置一些参数决定如何分割词条、哪些字应该被过滤掉等等。
 节点  单个 es 服务实例就是一个节点。
 集群  多个协同工作的 es 节点的集合就是集群。
 分片  es 将数据分散到多个物理的 Lucene 索引上，这些物理 Lucene 索引被称为分片。
 副本  副本就是每个分片都做冗余处理，一个宕机之后，不影响服务。
快速入门 安装 es 的安装很简单，我这里使用的是 mac，下载下来 zip 包，解压即可使用。
[elasticsearch-6.2.4] pwd /Users/zhuzhenfeng/Documents/software/elasticsearch-6.2.4 [elasticsearch-6.2.4] ./bin/elasticsearch Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.</description>
    </item>
    
    <item>
      <title>git 常用操作</title>
      <link>https://zhenfeng-zhu.github.io/posts/git/</link>
      <pubDate>Mon, 14 May 2018 10:04:02 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/git/</guid>
      <description>整理一下常用的 git 操作，不用再到处找了。
git 放弃本地修改，强制更新 git fetch --all git reset --hard origin/master git 修改远程仓库地址 git remote set-url origin url cherry-pick 当你通过一番挣扎终于搞定一个 bug,顺手提交到 git 服务器,心里一阵暗爽. 这时发现你当前所在的分支是 master !!!
这个分支不是开发者用来提交代码的,可惜现在剁手也晚了.
 先切换到 master  git checkout master git log  复制提交的 commit id
  切换到 dev, cherry-pick
  git checkout dev git cherry-pic ${commit_id} 常用开发流程 git checkout -b feature1
git commit 之后，进行 rebase
git pull &amp;ndash;rebase
gca!
git rvm</description>
    </item>
    
    <item>
      <title>node 的 cluster</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84cluster/</link>
      <pubDate>Sat, 05 May 2018 15:45:47 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84cluster/</guid>
      <description>我们知道 js 是运行单线程的，也就是说一个 node 进程只能运行在一个 cpu 上。那么如果用 node 来做 web server 的话，就无法享受到多核运算的好处。
一个问题就是：
如何榨干服务器资源，利用多核CPU的并发优势。 node 官方提供的解决方案是 cluster。
1 cluster 是什么 简单来说：
 在服务器上同时启动多个进程。 每个进程都跑的是同一份源码。 这些进程可以同时监听一个端口。  其中：
 负责启动其他进程的叫做 master 进程，不做具体工作，只负责启动其他进程。 其他被启动的叫 worker 进程。他们接收请求，对外提供服务。 worker 进程的数量一般根据服务器的 cpu 核数来决定，这样就可以完美利用多核资源。  以下是官方文档的一个例子：
const cluster = require(&amp;#39;cluster&amp;#39;); const http = require(&amp;#39;http&amp;#39;); const numCPUs = require(&amp;#39;os&amp;#39;).cpus().length; if (cluster.isMaster) { console.log(`主进程 ${process.pid} 正在运行`); // 衍生工作进程。 for (let i = 0; i &amp;lt; numCPUs; i++) { cluster.</description>
    </item>
    
    <item>
      <title>node 踩坑</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Sat, 05 May 2018 15:32:59 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E8%B8%A9%E5%9D%91/</guid>
      <description>module 首先第一个就是 es6 的 module。
看到别人写的
import { a } from &amp;#34;./module&amp;#34;; 所以自己也想要这么写，但是每次运行的时候都会报错。
// demo2.js export const a = &amp;#34;hello&amp;#34;; //demo1.js import { a } from &amp;#34;./demo2&amp;#34;; function hello() { console.log(a); } zhuzhenfengdeMacBook-Pro :: node/node-example » node demo1.js /Users/zhuzhenfeng/Documents/github/node/node-example/demo1.js:1 (function (exports, require, module, __filename, __dirname) { import { a } from &amp;#34;./demo2&amp;#34;; ^ SyntaxError: Unexpected token { at new Script (vm.js:74:7) at createScript (vm.js:246:10) at Object.runInThisContext (vm.js:298:10) at Module._compile (internal/modules/cjs/loader.js:646:28) at Object.</description>
    </item>
    
    <item>
      <title>node 学习笔记</title>
      <link>https://zhenfeng-zhu.github.io/posts/node-learning/</link>
      <pubDate>Sun, 22 Apr 2018 15:41:21 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node-learning/</guid>
      <description>写 node 也有一段时间了，整理一下学习笔记，共同进步
什么是 node 首先看一下什么是 node.js
 Node 是一个服务器端 JavaScript Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效 Node.js 的包管理器 npm，是全球最大的开源库生态系统  模块系统是 node 最基本也是最常用的。一般可以分为四类：
 原生模块 文件模块 第三方模块 自定义模块  node 社区崇尚 DRY 文化，即 Don&amp;rsquo;t repeate yourself。这种文化使得 node 的生态异常繁荣，同样也由于某些包的质量低下引来了一些诟病。
谈谈自定义模块 我们在写 node 程序的时候，一般都是在写自定义模块。
  创建模块
// b.js function FunA(){ return &amp;#34;hello world&amp;#34;; } // 暴露方法FunA module.exports = FunA;   加载模块
// a.js const FunA=require(&amp;#39;.</description>
    </item>
    
    <item>
      <title>node 的 redis 实战</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84redis%E5%AE%9E%E6%88%98/</link>
      <pubDate>Fri, 13 Apr 2018 10:00:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84redis%E5%AE%9E%E6%88%98/</guid>
      <description>Node.js Redis 客户端模块 为了追新，这里我使用的 yarn，毕竟我是 HDD（面向热点编程）编程实践者。
模块安装
yarn add redis 模块使用实例
const redis = require(&amp;#39;redis&amp;#39;) const client = redis.createClient(&amp;#39;6379&amp;#39;, &amp;#39;127.0.0.1&amp;#39;) client.on(&amp;#34;error&amp;#34;, function (err) { console.log(&amp;#34;Error &amp;#34; + err); }); client.set(&amp;#34;string key&amp;#34;, &amp;#34;string val&amp;#34;, redis.print); client.hset(&amp;#34;hash key&amp;#34;, &amp;#34;hashtest 1&amp;#34;, &amp;#34;some value&amp;#34;, redis.print); client.hset([&amp;#34;hash key&amp;#34;, &amp;#34;hashtest 2&amp;#34;, &amp;#34;some other value&amp;#34;], redis.print); client.hkeys(&amp;#34;hash key&amp;#34;, function (err, replies) { console.log(replies.length + &amp;#34; replies:&amp;#34;); replies.forEach(function (reply, i) { console.log(&amp;#34; &amp;#34; + i + &amp;#34;: &amp;#34; + reply); }); client.</description>
    </item>
    
    <item>
      <title>谈谈 web 框架</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E8%B0%88%E8%B0%88web%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Sun, 08 Apr 2018 16:01:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E8%B0%88%E8%B0%88web%E6%A1%86%E6%9E%B6/</guid>
      <description>这篇文章打的标签比较多，也基本涵盖了我所了解的一些知识，归纳总结一下自己对 web 框架的理解。自己了解的也不是很多，也请多多指教。
写程序免不了要做 web 相关的，现在由于前后端的分离，后端一般只提供 rest 接口，前端一般使用 node 来做渲染。在之前使用 jsp 那一套的时候，基本上都要写 html+js 的前端的一套，也要写后端 java 的 CRUD。
我理解的 web 框架中，大致是分为这么两类：
 router 框架 mvc 框架  mvc 类框架 mvc，初级程序员面试笔试的时候必考的一个知识点。model-view-controller，即模型-视图-控制器。
 m，模型主要用于封装与应用程序相关的数据以及对数据的处理方法。 v，在 View 中一般没有程序上的逻辑。为了实现 View 上的刷新功能，View 需要访问它监视的数据模型（Model），因此应该事先在被它监视的数据那里注册。 c，用于控制应用程序的流程。  我了解比较多的 mvc 框架是 spring mvc。spring、spring mvc 和 spring boot 等，他们并不是一个概念，也不是仅仅用于 web 开发。但是在这里我就不分那么细，统一用 spring 来代替。这里所说的 spring 都是指狭义上的 web 开发方面。
在做 web 开发的时候，项目目录一般是这样的：
$ tree [16:23:43] . ├── mvnw ├── mvnw.cmd ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── example │ │ └── demo │ │ └── DemoApplication.</description>
    </item>
    
    <item>
      <title>技术栈</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%8A%80%E6%9C%AF%E6%A0%88/</link>
      <pubDate>Thu, 05 Apr 2018 09:49:06 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%8A%80%E6%9C%AF%E6%A0%88/</guid>
      <description>创业公司真的比较锻炼人，接触了很多的东西，视野开阔了，但是在某些时候自己疲于奔命，每个东西都是接触了一点点就被赶鸭子上架开始开发了。
技术栈  Docker  docker 是一个容器，以前就看过 docker 相关的东西，但是没有仔细研究，docker 的命令会用一些，在工作中使用了，看了一本 docker 的书，能够编写 docker 的 compose 文件。
 rancher  rancher 是一个做容器管理的。我们把主机添加到 rancher 中，他就可以自动做到 LB，服务的发现编排。我们部署的时候只需要编写 catalog，他就可以自动发现 docker 应用，然后拉取镜像，部署到相关的机器上，很是方便。
 aws  近期主要是对 aws 的进行公司服务的部署，搭建一套 rancher 的环境。aws 的服务特别多，ec2 是实例主机，就和虚拟机一样，VPC 就像机房，ec2 依托于 VPC 而存在，在这基础上又了解了子网、DHCP 弹性 IP 等等。
 kotlin  之前自己用 kotlin 开发过一个博客，对 kotlin 的感觉是有些东西写的很爽，但是还是觉得 java 好用一些，对 kotlin 的态度是用不用都无所谓。
 guice  这个我之前都读错了，我读成了盖斯，其实是和果汁的英文发音很像，ju 斯。只是一个依赖注入框架，只是单纯的去做 DI，比 spring 更轻量级一些。
需要我们编写 AppModule.java 去手动配置哪个类注入哪个类。
 rxjava  rxjava 我都没有找到一个系统的教程，不知道该从哪里学习。</description>
    </item>
    
    <item>
      <title>同步一个 fork</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%AA-fork/</link>
      <pubDate>Wed, 04 Apr 2018 16:01:31 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%AA-fork/</guid>
      <description>具体方法 Configuring a remote for a fork  给 fork 配置一个 remote 主要使用 git remote -v 查看远程状态。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)  添加一个将被同步给 fork 远程的上游仓库  git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git  再次查看状态确认是否配置成功。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push) Syncing a fork  从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master git fetch upstream  git fetch upstream # remote: Counting objects: 75, done.</description>
    </item>
    
    <item>
      <title>Go 语言体会</title>
      <link>https://zhenfeng-zhu.github.io/posts/go%E8%AF%AD%E8%A8%80%E4%BD%93%E4%BC%9A/</link>
      <pubDate>Wed, 04 Apr 2018 13:48:57 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go%E8%AF%AD%E8%A8%80%E4%BD%93%E4%BC%9A/</guid>
      <description>最近公司要统一技术栈，在 kotlin 和 go 之间选。我心里是比较倾向 go 的，主要有如下几点体会。
 语言简单，上手快。 gorotuine 易发布 垃圾回收 约定大于配置  我最早听说协程，是在大三找实习的时候，那个时候面试会问线程和进程的关系，问的深一些就是协程和线程的区别。游戏公司基本都用 lua，看了 lua 的资料后，对协程有了一些自己的了解，随后就是在做 Unity 相关的开发，在 unity 中使用了很多的协程，但是在 unity 中使用的协程好像跟主流的不太一样，在看了 go 之后，豁然开朗。
goroutine 使用的内存比线程更少，go 在运行的时候会自动在配置的一组逻辑处理器上调度执行。比如：
func log(msg string){ ... } go log(&amp;#34;&amp;#34;) 使用关键字 go，即可让 log 函数在一个 goroutine 里执行了。
并发最难的部分是要确保其他并发运行的进程、线程或者 goroutine 不会以外的修改数据。go 使用了 Channel 的方式来解决这个问题。对于通道模式，保证同一时刻只会有一个 goroutine 修改数据。
说起 go 的语言简单，其实主要是他的类型比较简单。go 使用的是组合模式，只需要将一个类型嵌入到另外一个类型就可以复用所有的功能。而且 go 还具有独特的接口实现机制，允许用户对行为进行建模，在 go 中不需要声明某个类型实现了某个接口，编译器会自动判断一个实例是使用什么接口。
对于 java 来说，所有的设计都是围绕着接口展开，于是在设计模式中，就是面向接口编程：
interface User{ void login(); void logout(); } 在 java 中，继承的类必须显式声明继承了此接口。而在 go 中接口只是描述一个动作，如果说是实现这个接口，只需要让某个实例实现了这个接口中的所有方法就行了。</description>
    </item>
    
    <item>
      <title>关于时间管理</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</link>
      <pubDate>Sun, 25 Mar 2018 20:28:42 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</guid>
      <description>主动管理时间，敢于说不。
有目标向前看，没目标向钱看。</description>
    </item>
    
    <item>
      <title>一致性哈希算法</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sat, 24 Mar 2018 19:03:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</guid>
      <description>当我们在做数据库分库分表或者做分布式缓存的时候，不可避免的都会遇到一个问题：
如何将数据均匀的分散到各个节点中，并且尽量的在加减节点的时能使受影响的数据最少。
1 hash 取模 随机放置就不多说了。通常最容易想到的方案是哈希取模了。
可以将传入的 key 按照 $$ index=hash(key) % N $$ 这样来计算出需要存放的节点。
这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性比较差。比如增加或者删除一个节点的时候，所有的 key 都要重新计算，显然这样的成本比较高，为此需要一个算法来满足均匀的同时也要有良好的容错性和扩展性。
2 一致性 hash 算法 一致性 hash 算法是将所有的哈希值构成了一个环，其范围是 0~2^32-1。如图：
之后将各个服务器节点散列到这个环上，可以用节点的 IP，hostname 这样唯一性的字段作为 key 进行 hash。散列之后如下：
之后需要将数据定位到对应的节点上，使用同样的 hash 函数将 key 也映射到这个环上。
这样就按照顺时针方向就可以将 k1 定位到 N1 节点，k2 定位到 N3 节点，k3 定位到 N2 节点。
2.1 容错性 假设 N1 宕机了：
依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少部分数据。
2.2 扩展性 当新增一个节点时：
在 N2 和 N3 之间新增了一个节点 N4，这时受影响的数据只有 k3，其余的数据也是保持不变。</description>
    </item>
    
    <item>
      <title>Spring Boot 启动原理分析</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 24 Mar 2018 19:03:22 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</guid>
      <description>Spring Boot 启动原理分析 我们在开发 spring boot 应用的时候，一般会遇到如下的启动类：
@SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 从这段代码可以看出，注解@SpringBootApplication 和 SpringApplication.run()是比较重要的两个东西。
1 @SpringApplication 注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ... } 在这段代码里，比较重要的只有三个注解：
 @Configuration（@SpringBootConfiguration 点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan  其实，我们使用这三个注解来修饰 springboot 的启动类也可以正常运行,如下所示：
@ComponentScan @EnableAutoConfiguration @Configuration public class DemoApplication { public static void main(String[] args) { SpringApplication.</description>
    </item>
    
    <item>
      <title>Spring Data Jpa 实战</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-data-jpa%E5%AE%9E%E6%88%98/</link>
      <pubDate>Sat, 24 Mar 2018 19:02:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-data-jpa%E5%AE%9E%E6%88%98/</guid>
      <description>为了解决抽象各个 Java 实体基本的“增删改查”操作，我们通常会以泛型的方式封装一个模板 Dao 来进行抽象简化，但是这样依然不是很方便，我们需要针对每个实体编写一个继承自泛型模板 Dao 的接口，再编写该接口的实现。虽然一些基础的数据访问已经可以得到很好的复用，但是在代码结构上针对每个实体都会有一堆 Dao 的接口和实现。
由于模板 Dao 的实现，使得这些具体实体的 Dao 层已经变的非常“薄”，有一些具体实体的 Dao 实现可能完全就是对模板 Dao 的简单代理，并且往往这样的实现类可能会出现在很多实体上。Spring-data-jpa 的出现正可以让这样一个已经很“薄”的数据访问层变成只是一层接口的编写方式。
1 工程配置 1.1 pom &amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;com.example&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jpa-demo&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt; &amp;lt;name&amp;gt;jpa-demo&amp;lt;/name&amp;gt; &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt; &amp;lt;parent&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.5.9.RELEASE&amp;lt;/version&amp;gt; &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt; &amp;lt;/parent&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt; &amp;lt;project.reporting.outputEncoding&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt; &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-jpa&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title>spring boot 多数据源配置</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 24 Mar 2018 19:01:37 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</guid>
      <description>spring boot 多数据源配置 在单数据源的情况下，Spring Boot 的配置非常简单，只需要在 application.properties 文件中配置连接参数即可。但是往往随着业务量发展，我们通常会进行数据库拆分或是引入其他数据库，从而我们需要配置多个数据源。
1 准备 1.1 禁止 DataSourceAutoConfiguration 首先要将 spring boot 自带的DataSourceAutoConfiguration禁掉，因为它会读取application.properties文件的spring.datasource.*属性并自动配置单数据源。在@SpringBootApplication注解中添加exclude属性即可：
@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(JpaDemoApplication.class, args); } } 1.2 配置数据库连接 然后在application.properties中配置多数据源连接信息：
spring.datasource.primary.url=jdbc:mysql://localhost:3306/test spring.datasource.primary.username=root spring.datasource.primary.password=root spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver spring.datasource.secondary.url=jdbc:mysql://localhost:3306/test1 spring.datasource.secondary.username=root spring.datasource.secondary.password=root spring.datasource.secondary.driver-class-name=com.mysql.jdbc.Driver 1.3 手段创建数据源 由于我们禁掉了自动数据源配置，因些下一步就需要手动将这些数据源创建出来：
@Configuration public class DataSourceConfig { @Bean(name = &amp;#34;primaryDataSource&amp;#34;) // @Qualifier(value = &amp;#34;primaryDataSource&amp;#34;) @ConfigurationProperties(prefix = &amp;#34;spring.datasource.primary&amp;#34;) public DataSource primaryDataSource(){ return DataSourceBuilder.create().build(); } @Bean(name = &amp;#34;secondaryDataSource&amp;#34;) // @Qualifier(value = &amp;#34;secondaryDataSource&amp;#34;) @ConfigurationProperties(prefix = &amp;#34;spring.</description>
    </item>
    
    <item>
      <title>spring boot 连接 redis</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E8%BF%9E%E6%8E%A5redis/</link>
      <pubDate>Sat, 24 Mar 2018 19:00:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E8%BF%9E%E6%8E%A5redis/</guid>
      <description>Spring-data-redis为 spring-data 模块中对 redis 的支持部分，简称为“SDR”，提供了基于 jedis 客户端 API 的高度封装以及与 spring 容器的整合，
jedis 客户端在编程实施方面存在如下不足：
 connection 管理缺乏自动化，connection-pool 的设计缺少必要的容器支持。 数据操作需要关注“序列化”/“反序列化”，因为 jedis 的客户端 API 接受的数据类型为 string 和 byte，对结构化数据(json,xml,pojo 等)操作需要额外的支持。 事务操作纯粹为硬编码 pub/sub 功能，缺乏必要的设计模式支持，对于开发者而言需要关注的太多。  1 spring-data-redis 特性  连接池自动管理，提供了一个高度封装的“RedisTemplate”类 针对 jedis 客户端中大量 api 进行了归类封装,将同一类型操作封装为 operation 接口  ValueOperations：简单 K-V 操作 SetOperations：set 类型数据操作 ZSetOperations：zset 类型数据操作 HashOperations：针对 map 类型的数据操作 ListOperations：针对 list 类型的数据操作   提供了对 key 的“bound”(绑定)便捷化操作 API，可以通过 bound 封装指定的 key，然后进行一系列的操作而无须“显式”的再次指定 Key，即 BoundKeyOperations：  BoundValueOperations BoundSetOperations BoundListOperations BoundSetOperations BoundHashOperations   将事务操作封装，有容器控制。 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)  JdkSerializationRedisSerializer：POJO 对象的存取场景，使用 JDK 本身序列化机制，将 pojo 类通过 ObjectInputStream/ObjectOutputStream 进行序列化操作，最终 redis-server 中将存储字节序列。是目前最常用的序列化策略。 StringRedisSerializer：Key 或者 value 为字符串的场景，根据指定的 charset 对数据的字节序列编码成 string，是“new String(bytes, charset)”和“string.</description>
    </item>
    
    <item>
      <title>最终一致性的实现手段</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%AE%B5/</link>
      <pubDate>Sat, 24 Mar 2018 18:59:55 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%AE%B5/</guid>
      <description>最终一致性的实现手段 实现最终一致性有三种手段：可靠事件模式、业务补偿模式和 TCC 模式
1 可靠事件模式 可靠事件模式属于事件驱动架构，当某件重要的事情发生时，比如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会将订阅事件的微服务推送事件。
要实现这种模式需要消息队列实现事件的持久化和 at least once 的可靠事件投递模式。
1.1 本地事件表 本地事件表方法是将事件和业务数据保存在同一个数据库中，使用一个额外的事件恢复服务来恢复事件，由本地事物保证更新业务和发布事件的原子性。
但是业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。
1.2 外部事件 此方法是将事件持久化到外部的事件系统，事件系统需要提供实时事件服务以接受微服务发布的事件，同时事件系统还需要提供事件恢复服务来确认恢复事件。
1.3 不足 此过程可能出现重复消费的情况。
2 补偿模式 一般来讲，异常一般是由以下两种情况造成的：
业务异常：业务逻辑产生的错误，比如余额不足、库存不足等。
技术异常：非业务逻辑产生的异常，比如网络连接异常、超时等。
补偿模式就是使用一个额外的协调服务来协调各个需要保证一致性的其他服务。协调服务按顺序调用每一个服务，如果某个服务调用异常就取消之前所有已经调用成功的服务。
建议仅用于技术异常的情况。对于业务异常来讲，应该尽可能的去优化业务模式，以避免要求补偿事务。
2.1 常用手段 在实现补偿模式时应该做到两点：
 首先要确定失败的步骤和状态，从而确定要补偿的范围。 其次要能提供补偿操作使用的业务数据。  可以通过记录完整的业务流水的方法来实现上面两点要求。但是对于一个通用的补偿框架来说，预先知道微服务需要记录的业务要素是不可能的，那么就需要一种办法来保证业务流水的可扩展性，实践中主要有两种方法：大表和关联表。
 大表，顾明思议就是设计时除了必须的字段外，还需要预留大量的备用字段，框架可以提供辅助工具来将业务数据映射到备用字段中。大表对于框架层实现起来比较简单，但是也有一些难点，比如预留多少个字段合适，每个字段又需要预留多长。还有一个难点是如果仅从数据层面来查询数据，很难一眼看出备用字段的业务含义，维护过程不友好。 关联表，分为技术表和业务表。技术表中保存为实现补偿操作所需要的技术数据，业务表中保存业务数据。通过在技术表中增加业务表名和业务表主键来建立和业务数据的关联。关联表更灵活，能支持不同业务类型记录不同的业务要素。但是在框架的实现上难度较高，每次查询都需要复杂的关联动作，性能会受到影响。  2.2 重试 补偿过程作为一个服务，在调用的时候也会出现不成功的情况，这时就要通过重试机制来保证补偿的成功率。因此要求补偿操作具有幂等性。
但是也不是盲目的重试，我们需要根据服务执行失败的原因来选择不同的策略：
 因业务因素导致失败，需要停止重试。 罕见的异常，如网络中断，传输过程中数据丢失，应该立即重试。 如果是因为系统繁忙，此时需要等待一段时间再重试。  2.3 不足 在补偿模式中有一个明显的缺陷是隔离性，从第一个服务开始一直到补偿完成，不一致性是对其他服务可见的。另外补偿模式过分依赖协调服务的健壮性，如果协调服务异常，则没办法达到一致性。
3 TCC 模式 TCC，是 Try，Confirm 和 Cancel 的缩写。一个完整的 TCC 业务一般是由一个主业务和若干个从业务组成。
 Try  完成所有业务检查 预留必须的业务资源   Confirm  真正执行业务 不做任何业务检查 只使用 Try 阶段预留的业务资源 满足幂等性   Cancel  释放 Try 阶段预留的业务资源 满足幂等性    3.</description>
    </item>
    
    <item>
      <title>Reactive 微服务</title>
      <link>https://zhenfeng-zhu.github.io/posts/reactive%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Sat, 24 Mar 2018 17:57:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/reactive%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>Reactive 微服务 分布式系统构建起来很困难，因为它们容易出问题，运行缓慢，并且被 CAP 和 FLP 理论所限制。换句话说，它们的构建和运维都特别复杂。为了解决这个问题，reactive 便出现了。
Reactive 编程：一种开发模型，其专注于数据流向、对变化的反馈，以及传播他们。
在 reactive 编程中，刺激信号是数据的转移，叫做 streams。其实很像生产者——消费者模式，消费者对值进行订阅并响应。
Reactive 系统：一种架构风格，其基于异步消息来构建响应式的分布式系统。
reactive 系统使用了消息驱动的方法。所有的构建通过异步消息的发送和接收来交互。消息投递的逻辑由底层的实现决定。发送者不会阻塞着等待回复，它们可能会稍后才接收到回复。
reactive 系统会有两个重要的特征：
  伸缩性——可以横向伸缩
伸缩性来自消息传递的解耦。消息被发送到一个地址之后，可以被一组消费者按照一种负载均衡方法消费。当 reactive 系统遇到负载高峰时，它可以创造出新的消费者，并在此之后销毁它们。
  恢复性——可以处理错误并且恢复
首先，这种消息交互模式允许组件在其本地处理错误，组件不需要等待消息，因此当一个组件发生错误时，其他组件仍然会正常工作。其次，当一个处理消息的组件发生错误后，消息可以可以传递给在相同地址注册的其他组件。
  reactive 微服务系统是由 reactive 微服务组成的。这些微服务有下面四个特征：
 自治性 异步性 恢复性 伸缩性  Reactive 微服务是可自治的。他们可以根据周围的服务是否可用来调整自己的行为。自治性往往伴随着孤立性；Reactive 微服务可以在本地处理错误、独立地完成任务，并在必要时和其他服务合作。它们使用异步消息传递的机制和其他服务沟通；它们也会接收消息并且对其作出回应。
得益于异步消息机制，reactive 微服务可以处理错误并根据情况调整自己的行为。错误不会被扩散，而是在靠近错误源头的地方被处理掉。当一个微服务挂掉之后，它的消费者微服务要能够处理错误并避免扩散。这一孤立原则是避免错误逐层上浮而毁掉整个系统的关键。可恢复性不只是关于处理错误，它还涉及到自愈性；一个 reactive 微服务应该能够从错误中恢复并且对错误进行补救。
最后，reactive 微服务必须是可伸缩的，这样系统才可以根据负载情况来调整节点数量。这一特性意味着将会有一系列的限制，比如不能有在内存中的状态，要能够在必要时同步状态信息，或者要能够将消息路由到状态信息相同的节点。
Vert.x Vert.x 是一个用于构建 reactive 和分布式系统的工具箱，其使用了异步非阻塞编程模型。当使用 Vert.x 构建微服务的时候，微服务会自然地带上一个核心特征：所有事情都是异步的。
传统编程模式
int res = compute(1, 2); 在这段代码中，是在等待 compute 函数计算出来结果之后再进行剩下的操作。而在异步非阻塞的编程模式中，将会创建一个 handler：
compute(1, 2, res -&amp;gt; { // called with the result }); 在上述代码中，compute 函数不再返回一个结果，而是传一个 handler，当结果准备好时调用就可以了。得益于这种开发模型，可以使用很少的线程去处理高并发工作。在 vert.</description>
    </item>
    
    <item>
      <title>Guice 快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/guice%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:57:15 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/guice%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>Guice 快速入门 接手的新项目主要是使用 kotlin+vert.x 来写的，使用 gradle 构建，依赖注入框架使用了 guice。这段时间都是在熟悉代码的过程，恶补一些知识。
guice 是谷歌推出的一个轻量级的依赖注入框架，当然 spring 也可以实现依赖注入，只是 spring 太庞大了。
1 基本使用 引入依赖 使用 gradle 或者 maven，引入 guice。
maven:
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.google.inject&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;guice&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.1.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; Gradle:
compile &amp;#34;com.google.inject:guice:4.1.0&amp;#34; 项目骨架 首先需要一个业务接口，包含一个方法来执行业务逻辑，它的实现非常简单：
package com.learning.guice; public interface UserService { void process(); } package com.learning.guice; public class UserServiceImpl implements UserService { @Override public void process() { System.out.println(&amp;#34;我需要做一些业务逻辑&amp;#34;); } } 然后写一个日志的接口：
package com.learning.guice; public interface LogService { void log(String msg); } package com.</description>
    </item>
    
    <item>
      <title>kotlin 快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/kotlin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:56:45 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kotlin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>快速浏览一下 Kotlin 的语法。
基本语法 包定义和引用 在源文件头部：
package my.demo import java.util.* 方法定义  带有方法体，并且返回确定类型数据的定义方式，例如接受 Int 类型的参数并返回 Int 类型的值：  fun sum(a: Int, b: Int): Int { return a + b }  带有方法体，返回推断类型数据的定义方式，例如：  fun sum(a: Int, b: Int) = a + b  返回无意义类型的定义方式：  fun printSum(a: Int, b: Int): Unit { println(&amp;#34;sum of $aand $bis ${a + b}&amp;#34;) } 或者省略 Unit：
fun printSum(a: Int, b: Int) { println(&amp;#34;sum of $aand $bis ${a + b}&amp;#34;) } 变量定义  只赋值一次（只读）本地变量，val：  val a:Int = 1 // 指定初始值 val b = 2 // 类型自推断为 `Int` val c:Int // 当不指定初始值时需要指定类型 c = 3 // 延迟赋值   可变变量， var：  var x = 5 // 类型自推断为 `Int` x += 1  顶层变量  val PI = 3.</description>
    </item>
    
    <item>
      <title>RxJava2 快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/rxjava2%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:55:56 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/rxjava2%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>RxJava2 快速入门 引入依赖 compile &amp;#39;io.reactivex.rxjava2:rxjava:2.0.1&amp;#39; 写法 简单版本 private static void helloSimple() { Consumer&amp;lt;String&amp;gt; consumer = new Consumer&amp;lt;String&amp;gt;() { @Override public void accept(String s) throws Exception { System.out.println(&amp;#34;consumer accept is &amp;#34; + s); } }; Observable.just(&amp;#34;hello world&amp;#34;).subscribe(consumer); } 复杂版本 private static void helloComplex() { Observer&amp;lt;String&amp;gt; observer = new Observer&amp;lt;String&amp;gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(&amp;#34;onSubscribe: &amp;#34; + d); } @Override public void onNext(String s) { System.out.println(&amp;#34;onNext: &amp;#34; + s); } @Override public void onError(Throwable e) { System.</description>
    </item>
    
    <item>
      <title>领域实体类</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E7%B1%BB/</link>
      <pubDate>Sat, 24 Mar 2018 17:53:42 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E7%B1%BB/</guid>
      <description>在看项目代码的时候，发现了 entity 包和 dto 包，里面都是只保存数据的类，仔细查了资料，才发现 java 对于只保存数据的类有好几个分类。
 pojo 类：这是普通的 java 类，具有一部分的 get 和 set 方法。 dto 类：data transfer object 数据传输对象类，泛指用于展示层与服务层之间传输的对象。 vo 类：vo 有两种说法，一种是 view object，一种是 value object。 po 类：persisent object 持久对象。和 pojo 类一样，也是只有 get set 方法，但是这种类一般是用于持久层。 bo 类：business object，业务对象，表示应用程序领域内事物的所有实体类。 do 类：domain object，领域对象，就是从现实中抽象出来的有形或者无形的业务实体。  根据我的经验来看，大部分人都没有分那么清楚，一般是把数据类放在 domain 包，或者 entity 包里。再细分一下的话，可以把 dto 类单独提取到一个包里。</description>
    </item>
    
    <item>
      <title>docker</title>
      <link>https://zhenfeng-zhu.github.io/posts/docker/</link>
      <pubDate>Sat, 24 Mar 2018 17:42:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/docker/</guid>
      <description>docker 常用命令 docker   获取镜像
docker pull
  新建并启动
docker run
  列出镜像
docker image ls
docker images
  删除虚悬镜像
docker image prune
  删除本地镜像
docker iamge rm
  查看应用信息
docker logs
  dockerfile 一般步骤  在一个目录里，新建一个文件，命名为 Dockerfile 在 Dockerfile 的目录内，执行 docker build  常用指令   FROM 指定基础镜像，且是第一条命令
  RUN 执行命令
shell 格式
exec 格式
  COPY 和 ADD 指令是复制文件</description>
    </item>
    
    <item>
      <title>express</title>
      <link>https://zhenfeng-zhu.github.io/posts/express/</link>
      <pubDate>Sat, 24 Mar 2018 17:41:01 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/express/</guid>
      <description>Express 快速入门 安装 npm init npm install --save express hello world var express = require(&amp;#39;express&amp;#39;); var app = express(); app.get(&amp;#39;/&amp;#39;, function (req, res) { res.send(&amp;#39;Hello World!&amp;#39;); }); app.listen(3000, function () { console.log(&amp;#39;Example app listening on port 3000!&amp;#39;); }); 执行命令运行应用程序
node app.js 然后，在浏览器中输入 http://localhost:3000/ 以查看输出。
express 程序生成器 安装 npm install -g express-generator 示例 以下语句在当前工作目录中创建名为 myapp 的 Express 应用程序：
express --view=pug myapp 在 MacOS 或 Linux 上，采用以下命令运行此应用程序：
DEBUG=myapp:* npm start 然后在浏览器中输入 http://localhost:3000/ 以访问此应用程序。</description>
    </item>
    
    <item>
      <title>碎碎念</title>
      <link>https://zhenfeng-zhu.github.io/posts/a-month-in-finogeeks/</link>
      <pubDate>Sat, 24 Mar 2018 15:55:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/a-month-in-finogeeks/</guid>
      <description>一直没有机会写 2017 的年终总结，想到去年写的新的一年的计划，好像自己都没有按照计划来做，而且写的计划也不知道写到哪里去了。
站在现在的时间点去审视过去的一年，这个本命年还是发生了很多对自己的未来有着比较大影响的的事情。房子+女朋友+新工作，这些事情突然的涌现出来，搞得自己有些手忙脚乱。
梳理一下自己的收获吧：
首先当然是结识了一帮小伙伴，我们一起打农药，一起调 bug，一起奋战双十一。
在技术上也有了一定的提升，关键是自己的视野上有了很大的变化，不再是像当初大学的时候，不知道自己在做什么。这里对我影响比较大的一个是 phodal，看了他写的博客和书之后，对自己的触动很大，感觉他懂得很多东西，知识面很广，而且能够写出来，扩大了自己的影响力，所以我就想着自己能不能模仿他。另外一个就是田哥了，我觉得他是我认识的同龄人中，比较有自己想法的一个人，打进 acm world final 的人就是不一样，他看问题的角度比较新颖，而且归纳总结能力很强，给了我一些在编程上的指点，让我少走了很多弯路。
也很感谢自己的几个室友，让我不再感到孤单。自从刘巍来了深圳之后，11I 更欢乐了，也更污了。我们经常在家里煮火锅吃，吃的特别爽，以至于现在我都不想去火锅店里吃，总觉得在家吃的比较爽。
女朋友，出乎我的意料，现在想想还是感觉活在梦里，略过略过。
至于买房，没买之前的想法盲目乐观，后来算了一下，要是在深圳买房的话，我每个月的房贷是 2 万多，关键是首付还不一定能搞得出来。还是建议在北上广深工作的人，有机会现在老家的省会一类的城市，先搞一套，以后可以置换，能上车的时候早点上车，也是相当于变相攒钱了。对于不会投资或者创业的朋友，有时候辛辛苦苦干一年之后算一下，不知不觉中，自己的钱都不知道花在了哪里，如果有房贷的话，等用的时候说不定卖掉还能赚一些钱。
感觉自己换公司还是挺戏剧化的，当时也没想着真的就换工作吧，只是想投投简历，然后去面试一波看看自己的水平怎么样。总觉得自己在招银的舒适区待的太久了，没有什么激情了。同时自己也想出来试试，万一公司上市，摇身一变成为富翁了。当然这是白日梦了，路还是要一步一步的走的。
总感觉自己想了很多东西，但是就是写不出来，自己讲故事的能力还是要提升一些。</description>
    </item>
    
    <item>
      <title>Java 内存模型和线程</title>
      <link>https://zhenfeng-zhu.github.io/posts/java-memory-thread/</link>
      <pubDate>Thu, 22 Mar 2018 19:16:37 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/java-memory-thread/</guid>
      <description>java 内存模型和线程  并发不一定依赖多线程，但是在 java 里面谈论并发，大多与线程脱不开关系。
 线程是大多是面试都会问到的问题。我们都知道，线程是比进程更轻量级的调度单位，线程之间可以共享内存。之前面试的时候，也是这样回答，迷迷糊糊，没有一个清晰的概念。
大学的学习的时候，写 C 和 C++，自己都没有用过多线程，看过一个 Windows 编程的书，里面讲多线程的时候，一大堆大写的字母，看着一点都不爽，也是惭愧。后来的实习，写 unity，unity 的 C#使用的是协程。只有在做了 java 后端之后，才知道线程到底是怎么用的。了解了java 内存模型之后，仔细看了一些资料，对 java 线程有了更深入的认识，整理写成这篇文章，用来以后参考。
1 Java 内存模型 Java 虚拟机规范试图定义一种 java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 java 程序在各种平台下都能达到一致性内存访问的效果。
java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量的底层细节。（这里所说的变量包括了实例字段、静态字段和数组等，但不包括局部变量与方法参数，因为这些是线程私有的，不被共享。）
1.1 主内存和工作内存 java 规定所有的变量都存储在主内存。每条线程有自己的工作内存。
线程的工作内存中的变量是主内存中该变量的副本，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存来完成。
1.2 内存之间的交互 关于主内存和工作内存之间的具体交互协议，java 内存模型定义了 8 中操作来完成，虚拟机实现的时候必须保证每个操作都是原子的，不可分割的（对于 long 和 double 有例外）
 lock 锁定：作用于主内存变量，代表一个变量是一条线程独占。 unlock 解锁：作用于主内存变量，把锁定的变量解锁。 read 读取：作用于主内存变量，把变量值从主内存传到线程的工作内存中，供 load 使用。 load 载入：作用工作内存变量，把上一个 read 到的值放入到工作内存中的变量中。 use 使用：作用于工作内存变量，把工作内存中的一个变量的值传递给执行引擎。 assign：作用于工作内存变量，把执行引擎执行过的值赋给工作内存中的变量。 store 存储：作用于工作内存变量，把工作内存中的变量值传给主内存，供 write 使用。  这些操作要满足一定的规则。</description>
    </item>
    
    <item>
      <title>aws.md</title>
      <link>https://zhenfeng-zhu.github.io/posts/aws-md/</link>
      <pubDate>Thu, 22 Mar 2018 14:04:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/aws-md/</guid>
      <description>一些基础概念
EC2 云服务器，可以理解成虚拟机，新建一个实例，就是新建一个虚拟机并安装操作系统（Linux 或者 windows）。
VPC Virtual Private Cloud。可以理解成数据中心，机房。对于灾备或者双活需要的，可以创建两个 VPC。
子网 一个 VPC 里可以有多个子网。比如某机构的一个 VPC 可以办公网和生产网段，或者内网和外网。一般外网可以被访问，内网的话可以是数据库的服务器之类的。
IAM 角色 类似于用户，可以被分配权限。
安全组 控制连接到此 EC2 实例的流量，或者是控制对外暴露的端口。
CIDR CIDR 主要是一个按位的、基于前缀的，用于解释 IP 地址的标准。当用二进制表示这些地址时，它们有着在开头部分的一系列相同的位。
IPv4 的 CIDR 地址块的表示方法和 IPv4 地址的表示方法是相似的：由四部分组成的点分十进制地址，后跟一个斜线，最后是范围在 0 到 32 之间的一个数字：A.B.C.D/N。点分十进制的部分和 IPv4 地址一样是一个被分成四个八位位组的 32 位二进制数。斜线后面的数字就是前缀长度，也就是从左到右，被地址块里的地址所共享的位的数目。
十进制部分有时会被省略，因此，/20 就表示一个前缀长度是 20 的 CIDR 地址块。如果一个 IP 地址的前 N 位与一个 CIDR 地址块的前缀是相同的话，那么就说这个地址属于这个 CIDR 地址块，也可以说是与 CIDR 地址块的前缀匹配。所以，要理解 CIDR，就要把地址写成二进制的形式。</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://zhenfeng-zhu.github.io/posts/hello-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hello-world/</guid>
      <description>Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick Start Create a new post $ hexo new &amp;#34;My New Post&amp;#34; More info: Writing
Run server $ hexo server More info: Server
Generate static files $ hexo generate More info: Generating
Deploy to remote sites $ hexo deploy More info: Deployment</description>
    </item>
    
  </channel>
</rss>
