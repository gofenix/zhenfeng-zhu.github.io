<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Go Data</title>
    <link>https://zhenfeng-zhu.github.io/posts/</link>
    <description>Recent content in Posts on Go Data</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 23 Jul 2021 09:33:18 +0800</lastBuildDate><atom:link href="https://zhenfeng-zhu.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>如何从零开始写一个静态网站生成器</title>
      <link>https://zhenfeng-zhu.github.io/posts/how-to-write-a-static-site-generator/</link>
      <pubDate>Fri, 23 Jul 2021 09:33:18 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/how-to-write-a-static-site-generator/</guid>
      <description>我们常见的静态网站生成器有 Hugo、Hexo 等，程序员们经常会使用类似的工具去将自己的播客托管到 github pages。前段时间研究了一下实现的方式，用 Elixir 简单实现了一个版本。
一个静态网站生成器的工作流程通常有如下几个步骤：
 读取源文件，一般是 markdown 格式的。 模板引擎的渲染 生成目标文件  接下来会从每个步骤来进行简单介绍。
最终版本的请参考：https://github.com/zhenfeng-zhu/ego， 欢迎pr和issue。
极简 MVP 版本介绍 初始化 $ mix new ego 在 mix.exs 中添加依赖
 earmark 是将 markdown 转换为 html。 plug_cowboy 是提供本地预览 html 文件的 server。 json 是一个 json 解析库 指定以 escript 的方式启动  解析 markdown 文件 将一个 markdown 文件转为 html 也是比较简单的，首先读取，然后调用 Earmark.as_html!函数，就能将 markdown 转换为 html 了。
eg.
def gen_blogs(m) do m |&amp;gt; File.read!() |&amp;gt; Earmark.as_html!() end 更进一步的我们认为 markdown 的博客源文件都在当前项目目录下面，即{current_dir()}/contents/。如果要获取到所有的文件，可以使用 wildcard 函数。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab2</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab2/</link>
      <pubDate>Tue, 30 Mar 2021 09:57:01 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab2/</guid>
      <description>实验 2 - 测试 在开始实验之前，先创建一个文件夹：
$ mkdir -p lab2 \  &amp;amp;&amp;amp; cd lab2 使用 UI 门户 您现在可以测试 OpenFaaS UI：
如果你已经设置了 $OPENFAAS_URL ，请获取 URL，并点开:
echo $OPENFAAS_URL http://127.0.0.1:31112 如果还没有设置 $OPENFAAS_URL ，那么默认的值通常是： http://127.0.0.1:8080.
我们可以部署一些示例函数，然后使用它们进行测试：
$ faas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 您可以在用户界面中试用它们，例如 Markdown 函数，它将 Markdown 代码转换成超文本标记语言。
在 Request 字段中输入如下的内容：
## The **OpenFaaS** _workshop_ 现在点击 Invoke ，然后就可以看到响应出现在屏幕的下半部分。
I.e.
&amp;lt;h2&amp;gt;The &amp;lt;strong&amp;gt;OpenFaaS&amp;lt;/strong&amp;gt; &amp;lt;em&amp;gt;workshop&amp;lt;/em&amp;gt;&amp;lt;/h2&amp;gt; 您将会看到如下的字段：
 Status - 函数是否准备好运行。在状态显示就绪之前，您将无法从用户界面调用该函数。 Replicas - 在集群中运行的函数的副本数量。 Image - 发布到 Docker Hub 或 Docker 存储库的 Docker 镜像名称和版本。 Invocation count - 这显示了函数被调用的次数，并且每 5 秒更新一次。  多次点击 Invoke ，就可以看到 Invocation count 在递增。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab1b</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1b/</link>
      <pubDate>Tue, 30 Mar 2021 09:55:20 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1b/</guid>
      <description>实验 1 - 使用 Kubernetes 设置 OpenFaaS 安装 kubectl 使用下面的说明或官方文档为您的操作系统安装kubectl。
 Linux  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  MacOS  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/darwin/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  Windows  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/windows/amd64/kubectl.exe chmod +x kubectl.exe mkdir -p $HOME/bin/ mv kubectl $HOME/bin/ 设置 Kubernetes 集群 您可以在使用 Kubernetes 时遵循实验，但您可能需要在此过程中进行一些小的更改。网关的服务地址从http://gateway:8080 更改为http://gateway.openfaas:8080。尽可能记录这些差异，并在每个实验室提供替代方案。
在笔记本电脑上创建本地集群 k3s 和 k3d 如果您的计算机上有 Docker，那么您可以使用 Rancher Labs 的 k3d。它安装了一个名为 k3s 的 Kubernetes 轻量级版本，并在 Docker 容器中运行，这意味着它可以在任何有 Docker 的计算机上工作。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop Lab1</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1/</link>
      <pubDate>Tue, 30 Mar 2021 09:54:25 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1/</guid>
      <description>实验 1 - OpenFaaS 准备 OpenFaaS 需要一个Kubernetes 集群来操作。您可以使用单节点集群或多节点集群，无论是在笔记本电脑上还是在云中。
任何 OpenFaaS 函数的基本基元都是 Docker 镜像，它是使用faas-cli工具链构建的。
先决条件： 让我们安装 Docker，OpenFaaS CLI 并设置 Kubernetes。
Docker For Mac
 Docker CE for Mac Edge Edition  For Windows
 仅支持 Windows 10 Pro 或 Enterprise 安装 Docker CE for Windows   请确保通过使用 Windows 任务栏通知区域中的 Docker 菜单来使用Linux容器 Docker 守护进程。
  安装 Git Bash  当您安装 git bash 时，请选择以下选项：“安装 UNIX 命令”和“使用真实类型的字体”。
 注意：所有步骤请使用Git Bash：不要尝试使用PowerShell，WSL或Bash for Windows。</description>
    </item>
    
    <item>
      <title>Openfaas Workshop</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop/</link>
      <pubDate>Tue, 30 Mar 2021 09:53:12 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop/</guid>
      <description>openfaas-研讨会 这是一个自定进度的研讨会，用于学习如何使用 OpenFaaS 构建、部署和运行无服务器功能。
在这个研讨会中，您首先将 OpenFaaS 部署到您的笔记本电脑或带有 Docker for Mac 或 Windows 的远程集群中。然后，您将使用 OpenFaaS 用户界面、CLI 和函数商店来完成最基本的使用。构建完成后，在 Python 中部署调用自己的无服务器函数，您将继续学习以下主题：使用 pip 管理依赖关系、通过安全机密处理应用编程接口令牌、使用 Prometheus 监控函数、异步调用函数以及将函数链接在一起创建应用程序。实验中让人兴奋的是可以让您创建自己的 GitHub 机器人，它可以自动响应问题。同样的方法也可以通过 IFTTT.com 连接到在线事件流，这将使您能够构建机器人、自动响应器以及与社交媒体和物联网设备的集成。
最后，这些实验也涵盖了更高级的主题，并为进一步学习提供建议。
其他语言
 日本語 中文  要求： 我们将介绍如何在Lab 1中安装这些要求。请在参加讲师指导的研讨会之前完成Lab 1
 函数将用 Python 编写，因此有编程或脚本经验者优先 安装推荐的代码编辑器/IDE VSCode Windows 安装 Git Bash 首选操作系统： MacOS，Windows 10Pro/Enterprise，Ubuntu Linux  Docker:
 Docker CE for Mac/Windows Edge edition Docker CE for Linux   注意：作为最后的手段，如果您有不兼容的 PC，您可以在https://labs.play-with-docker.com/.上运行研讨会
 讲师主导的研讨会 如果你参加了一个由讲师领导的研讨会，那么将会通过一个链接来加入 OpenFaaS Slack 社区。使用研讨会指定的渠道讨论意见、问题和建议。</description>
    </item>
    
    <item>
      <title>Streaming 101</title>
      <link>https://zhenfeng-zhu.github.io/posts/streaming-101/</link>
      <pubDate>Fri, 26 Mar 2021 14:11:29 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/streaming-101/</guid>
      <description> 有效的复杂系统总是从简单
 </description>
    </item>
    
    <item>
      <title>K3d With Openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/k3d-with-openfaas/</link>
      <pubDate>Wed, 10 Mar 2021 20:09:11 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/k3d-with-openfaas/</guid>
      <description>openfaas https://github.com/openfaas/workshop/blob/master/lab1b.md
安装docker brew install homebrew/cask/docker 安装单节点K8S brew install k3d 配置单节点K8S集群
k3d cluster create CLUSTER_NAME k3d kubeconfig merge CLUSTER_NAME --kubeconfig-switch-context kubectl get pods --all-namespaces 安装arkade curl -SLsf https://dl.get-arkade.dev/ | sudo sh 安装openfaas客户端 faas-cli brew install faas-cli 安装openfaas server端 arkade install openfaas 配置openfaas的ui界面
kubectl rollout status -n openfaas deploy/gateway kubectl port-forward svc/gateway -n openfaas 8080:8080 这样就可以在浏览器里输入 127.0.0.1:8080 进入到openfaas的ui界面了。
但是当你打开页面的时候，要输入密码，那就需要下面的操作：
# This command retrieves your password PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath=&amp;quot;{.</description>
    </item>
    
    <item>
      <title>换一种方式思考</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%8D%A2%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%9D%E8%80%83/</link>
      <pubDate>Sat, 27 Feb 2021 12:16:48 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%8D%A2%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%9D%E8%80%83/</guid>
      <description> 面向对象不是设计代码的唯一方法 函数式编程不一定是复杂和纯数学的 编程的基础不是赋值、if语句和循环 并发不一定需要锁、信号量、监视器等类似的东西 进程不必消耗大量的资源 元编程不只是语言的附属品 即使编程是你的工作，也应该是充满乐趣的  </description>
    </item>
    
    <item>
      <title>小白都能快速上手的Vim配置</title>
      <link>https://zhenfeng-zhu.github.io/posts/vim/</link>
      <pubDate>Sat, 20 Feb 2021 09:56:31 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/vim/</guid>
      <description>首先把所有的vim相关的都删除。 cd rm -rf .vim* 创建自己的.vimrc vim .vimrc 一些基本的设置 在.vimrc中添加下面的代码
&amp;quot; basic set set number set noswapfile set encoding=utf-8 set fileencodings=utf-8,gb18030 set backspace=eol,start,indent set laststatus=2 set colorcolumn=80 set cursorline set linebreak set autoindent set ignorecase set smartcase set ruler set diffopt+=internal,indent-heuristic,algorithm:patience set showcmd set clipboard^=unnamed,unnamedplus set showmode set mouse=a set tabstop=2 set shiftwidth=4 set expandtab set softtabstop=2 set showmatch set incsearch set nobackup set autoread set wildmenu set wildmode=longest:list,full set nofoldenable filetype plugin indent on syntax on 有了上面的设置，会让你的vim更好用一些。</description>
    </item>
    
    <item>
      <title>Github Action自动部署blog</title>
      <link>https://zhenfeng-zhu.github.io/posts/hugo-github-action/</link>
      <pubDate>Thu, 18 Feb 2021 13:20:11 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hugo-github-action/</guid>
      <description>之前我采用的方式是两个github repo的方式：
一个叫hugo-blog，用于存放blog的源文件
一个叫zhenfeng-zhu.github.io，用于存放生成之后的文件
然后通过写一个shell脚本，将生成之后的文件推向zhenfeng-zhu.github.io仓库中，同时将blog的源文件也做了一个backup。后来使用了一个github action的方式， 就不用在两个仓库中进行折腾，一切都由github action来做了。
方案 设置workflow 首先创建一个.github/workflows/gh-pages.yml
name: github pages on: push: branches: - main  # Set a branch to deploy jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: &amp;#39;latest&amp;#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.</description>
    </item>
    
    <item>
      <title>编程语言的世界观</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%96%E7%95%8C%E8%A7%82/</link>
      <pubDate>Thu, 18 Feb 2021 13:05:31 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%96%E7%95%8C%E8%A7%82/</guid>
      <description>Elixir  everything is a process. process are strongly isolated. process creation and destruction is a lightweight operation. message passing is the only way for processes to interact. processes have unique names. if you know the name of a process you can send it a message. processes share no resources. error handling is non-local. processes do what they are supposed to do or fail.  Go  simple, poetic, pithy don&amp;rsquo;t communicate by sharing memory, share memory by communicating concurrency is not parallelism channels orchestrate; mutexes serialize the bigger the interface, the weaker the abstraction make the zero value useful interface{} says nothing gofmt&amp;rsquo;s style is no one&amp;rsquo;s favorite, yet gofmt is everyone&amp;rsquo;s favorite A little copying is better than a little dependency  </description>
    </item>
    
    <item>
      <title>如何建立指标体系</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/</link>
      <pubDate>Thu, 18 Feb 2021 12:48:34 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/</guid>
      <description>什么是指标体系 指标体系是在业务的不同阶段，分析师牵头与业务方协助，制定一套能从各个维度反映业务状况的待实施框架。
关键点  在业务的前期、中期和后期，指标体系是不一样的 一定是由分析师牵头与业务方协助，而不是闭门造车 从各个维度去反应业务的核心状况，指标有很多维度 最后就是一个大的实施框架，一定要实施，否则就是浪费大家的时间  指标选取的几个原则  根本性：对于核心数据一定要理解到位和准确，如果这里错了，后面基本就不用看。 可理解性：所有指标要配上业务解释 结构性：能够充分从各维度对业务进行解读，方便归因。  建立步骤   理清业务阶段和方向 我们需要知道当前产品或者业务处于什么阶段，具体的业务方向是什么。一般都是分为三个阶段： 第一阶段：业务前期。在业务的前期更多的是想要快速推出来，有更多人去使用我们的产品。所以此时我们的指标体系应该更多的围绕用户量提升做各种维度的拆解 第二阶段：业务中期（快速发展期）。在业务中期，除了关注盘子的大小，还要看产品的健康度。 第三阶段：业务后期（成熟期）。主要看变现能力以及市场份额。
  确定核心指标 找核心指标不是一件容易的事儿。 只能多花时间去考虑这个事儿。
  指标核心维度拆解 核心指标的波动必然是由某种维度的波动引起，所以监控核心指标指标，本质是监控核心维度。 通用的拆解方法是先对核心指标进行公式计算，再按照业务路径或者业务模块去拆解。 核心指标的拆解，需要多和业务方进行沟通，把能够考虑的模块都考虑进去，基本上就能比较全面。
  指标宣贯、存档和落地 宣贯：实际上搭建号指标体系之后，要当面触达所有相关的业务接口人。 存档：同时对指标的口径和业务逻辑进行详细的描述存档，也就是指标口径归档 落地：落地就是建立核心指标的相关报表，实际工作中，报表会在埋点前建好，这样一旦版本上线就能立刻看到数据，这样各方的配合度就会很高。
  </description>
    </item>
    
    <item>
      <title>业务代码的成长机会</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%88%90%E9%95%BF%E6%9C%BA%E4%BC%9A/</link>
      <pubDate>Wed, 17 Feb 2021 17:45:40 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%88%90%E9%95%BF%E6%9C%BA%E4%BC%9A/</guid>
      <description>对于大部分公司而言，能够写底层代码或者中间件代码的人总是有限的，写业务代码会面临更高的复杂度。这里分三个层次来看其中的机会：
 第一个层次，让代码写的不一样。可从代码规范、可读性、可扩展性等角度着手，这也是程序员的基本功。 第二个层次，考虑业务问题和技术问题的匹配。可从写业务代码中理解需求，并做好分析设计。被动接收需求和实现接口，确实成长空间不大。 第三个层次，总结相关方法体系，成为业务及技术双料专家。  </description>
    </item>
    
    <item>
      <title>unix 哲学</title>
      <link>https://zhenfeng-zhu.github.io/posts/unix-philosophy/</link>
      <pubDate>Wed, 17 Feb 2021 16:46:52 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/unix-philosophy/</guid>
      <description> 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件，甚至是操作系统，要尽早尝试，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。  </description>
    </item>
    
    <item>
      <title>Web前端性能优化</title>
      <link>https://zhenfeng-zhu.github.io/posts/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</link>
      <pubDate>Fri, 20 Nov 2020 16:01:49 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</guid>
      <description>一般来说web前端是指网站业务逻辑之前的部分，比如：浏览器加载、网站视图模型、图片服务、CDN服务等等。web前端优化主要从如下三个方面入手：
浏览器访问优化   减少http请求
http协议是一个无状态的，每次请求都需要建立通信链路进行传输，在服务器端，一般每个请求都会分配一个线程去处理。
减少http请求的主要手段是合并CSS、合并js、合并图片。
  使用浏览器缓存
css、js、Logo、图标等静态资源文件更新频率较低，可以将这些文件缓存在浏览器中。
在更新js等文件的时候，一般不是将文件内容更新，而是生成一个新的文件，然后更新html的引用。
更新静态资源的时候，也是要逐量更新，以避免用户浏览器的大量缓存失效，造成服务器负载增加、网络堵塞。
  启用压缩
在服务器对文件压缩，然后在浏览器端解压缩，可以减少通信传输的数据量。
  CSS放在页面最上面，js放在页面最下面
浏览器会在下载完全部CSS之后才对整个页面进行渲染，而浏览器是在加载js之后就立即执行，有可能会阻塞整个页面。因此最好的做法就是把CSS放在最上面，js放在最下面。但是如果是页面解析的时候就用到js，也是要相应的js放在上面。
  减少cookie传输
cookie会包含在每次请求和响应中，太大的cookie会影响数据传输，需要慎重考虑哪些数据写入cookie中。
对于某些静态资源的访问，如css和js等，发送cookie没意义，可以考虑静态资源使用独立域名访问，避免请求静态资源时发送cookie。
  CDN加速 CDN（content distribute network，内容分发网络）的本质仍然是一个缓存。将缓存放在离用户最近的地方，使得用户可以以最快的速度获取数据。
CDN缓存的一般是静态资源，如图片、文件、CSS、js、静态网页等。
反向代理 反向代理服务器位于网站中心机房的一侧，代理网站web服务器接收http请求。
反向代理可以在一定程度上保护网站安全，来自互联网的访问请求必须经过代理服务器，相当于在web服务器和攻击之间加了一个屏障。
反向代理也可以通过配置缓存，静态资源被缓存在反向代理服务器，当用户访问时，可以从反向代理服务器上返回。有些网站也会将部分动态内容缓存在代理服务器上，通过内部通知机制，更新缓存。
反向代理也可以实现负载均衡的功能。
写在最后 可以发现，在web前端性能优化的时候，提到最多的就是缓存。
 网站性能优化第一定律：优先考虑使用缓存！
 </description>
    </item>
    
    <item>
      <title>大型网站发展历程</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</link>
      <pubDate>Fri, 20 Nov 2020 16:00:59 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/</guid>
      <description>前几天跟一个朋友聊了一些关于网站缓存分布式的一些东西，发现自己的知识还是太过贫瘠。理论+协议，这是现在我亟待加强的。这个周末买了两本关于分布式网站的书，本着好记性不如烂笔头，便有了这样一系列的文章。希望一同分享，也请多指教。
 code less, play more!
 前言 这个世界上没有哪个网站从诞生起就是大型网站；也没有哪个网站第一次发布的时候就拥有庞大的用户，高并发的访问，海量的数据；大型网站都是从小型网站发展而来。网站的价值在于它能给用户提供什么家宅，在于网站能做什么，而不在于它是怎么做的，所以网站在小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供更好的服务来创造价值，得到用户认可，活下去，野蛮生长。
大型网站软件系统的特点  高并发，大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，发布平频繁 渐进式发展  大型网站的发展历程   初始阶段的网站架构
最开始没有多少人访问，所以应用程序，数据库，文件都在同一台机器上。
  应用服务器和数据服务分离
应用和数据分离之后，一般需要三台服务器。应用服务器，文件服务器和数据库服务器，这三种服务器对于硬件要求各不相同。
 应用服务器：更强大的CPU 数据库服务器：更快速的磁盘和更大的内存 文件服务器：容量更大的硬盘    使用缓存改善性能
网站的访问也遵循二八定律：80%的业务集中在20%的数据上。因此可以把这一小部分数据缓存在内存中，减少数据库的访问压力。
网站的缓存可以分为两种：
 本地缓存：缓存在应用服务器上。本地缓存访问速度快，但是受制于内存限制，缓存数量有限，而且也会出现和应用程序争抢内存的情况。 远程分布式缓存：以集群的方式，缓存在大内存的专用缓存服务器。可以在理论上做到不受内存容量限制。    使用应用服务器集群提高并发能力
当一台服务器的处理能力和存储空间不足的时候，不要企图更换更强大的服务器。对于大型网站来说，不管多么强大的服务器，都满足不了网站持续增长的业务需求。此时就可以考虑集群的方式，通过负载均衡调度服务器，可以将来自用户的请求分发到应用服务器集群中的任何一台服务器上。
  数据库读写分离
使用缓存后，大部分的数据读操作访问都可以不通过数据库完成，但是仍有部分读操作（如缓存过期，缓存不命中）和全部的写操作需要访问数据库。
目前大部分数据库都提供主从热备的功能，在写数据的时候，访问主库，主库通过主从复制机制将数据更新同步至从数据库，在读的时候就可以通过从数据库获取数据。
  使用反向代理和CDN加速网站响应
在《web性能权威指南》中有讲到，网站性能的瓶颈，大部分时间都浪费在TCP的握手和传输上。因此可以通过CDN和反向代理的方式来加快响应。
CDN和反向代理的本质都是通过缓存，不同的主要是：
 CDN部署在服务器器上的机房，用户在请求时，从距离自己最近的机房获取数据。 反向代理是部署在中心机房，用户请求到达中心机房之后，首先访问的服务器是反向代理的拂去其，如果反向代理服务器中缓存着用户请求的额资源，就将其返回给用户。    使用分布式文件系统和分布式数据库系统
随着业务的发展，依旧不能满足的时候，就采用分布式的文件和分布式的数据库系统。
分布式数据库是数据库拆分的最后手段，只用在单表数据规模特别庞大的时候才使用。更常用的拆分手段是业务分库，将不同的业务数据存储在不同的数据库中。
  使用NoSQL和搜索引擎
对数据检索和存储越来越复杂的时候，就可以采用一些非关系型数据库如HBase和非数据库查询技术如ElasticSearch等等
  业务拆分</description>
    </item>
    
    <item>
      <title>Geth 私链</title>
      <link>https://zhenfeng-zhu.github.io/posts/geth-%E7%A7%81%E9%93%BE/</link>
      <pubDate>Fri, 20 Nov 2020 15:59:22 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/geth-%E7%A7%81%E9%93%BE/</guid>
      <description>在上一篇文章《Geth入门》中，主要讲了开发环境下以太坊geth客户端的使用。今天简单说下私链的配置。
genesis.json { &amp;#34;config&amp;#34;: { &amp;#34;chainId&amp;#34;: 10, &amp;#34;homesteadBlock&amp;#34;: 0, &amp;#34;eip155Block&amp;#34;: 0, &amp;#34;eip158Block&amp;#34;: 0 }, &amp;#34;coinbase&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000&amp;#34;, &amp;#34;difficulty&amp;#34; : &amp;#34;0x40000&amp;#34;, &amp;#34;extraData&amp;#34; : &amp;#34;&amp;#34;, &amp;#34;gasLimit&amp;#34; : &amp;#34;0xffffffff&amp;#34;, &amp;#34;nonce&amp;#34; : &amp;#34;0x0000000000000042&amp;#34;, &amp;#34;mixhash&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000000000000000000000000000&amp;#34;, &amp;#34;parentHash&amp;#34; : &amp;#34;0x0000000000000000000000000000000000000000000000000000000000000000&amp;#34;, &amp;#34;timestamp&amp;#34; : &amp;#34;0x00&amp;#34;, &amp;#34;alloc&amp;#34;: { } }    参数 描述     nonce nonce就是一个64位随机数，用于挖矿   mixhash 与nonce配合用于挖矿，由上一个区块的一部分生成的hash   difficulty 设置当前区块的难度，如果难度过大，cpu挖矿就很难，这里设置较小难度   alloc 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以   coinbase 矿工的账号，随便填   timestamp 设置创世块的时间戳   parentHash 上一个区块的hash值，因为是创世块，所以这个值是0   extraData 附加信息，随便填，可以填你的个性信息   gasLimit 该值设置对GAS的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大。   config Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的json文件中，缺少config部分。看到这个信息，我们不需要把geth退回到v1.</description>
    </item>
    
    <item>
      <title>Geth</title>
      <link>https://zhenfeng-zhu.github.io/posts/geth/</link>
      <pubDate>Fri, 20 Nov 2020 10:07:39 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/geth/</guid>
      <description>Geth简介 go-ethereum
go-ethereum客户端通常被称为geth，它是个命令行界面，执行在Go上实现的完整以太坊节点。通过安装和运行geth，可以参与到以太坊前台实时网络并进行以下操作：
 挖掘真的以太币 在不同地址间转移资金 创建合约，发送交易 探索区块历史 及很多其他   网站: http://ethereum.github.io/go-ethereum/
  Github: https://github.com/ethereum/go-ethereum
  维基百科: https://github.com/ethereum/go-ethereum/wiki/geth
  Gitter: https://gitter.im/ethereum/go-ethereum
 mac下安装geth  首先安装homebrew， 使用brew安装即可。在安装geth的时候，会将go也安装上。  brew tap ethereum/ethereum brew install ethereum  在命令行输入geth —help，如果出现
zhuzhenengdeMBP:blog zhuzhenfeng$ geth --help NAME: geth - the go-ethereum command line interface Copyright 2013-2017 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments...] VERSION: 1.7.3-unstable-eea996e4 证明安装成功。
  使用Geth   打开终端，输入以下命令，以开发的方式启动geth</description>
    </item>
    
    <item>
      <title>hive常用函数</title>
      <link>https://zhenfeng-zhu.github.io/posts/hive%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</link>
      <pubDate>Thu, 16 Apr 2020 17:59:03 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hive%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</guid>
      <description>json 字符串处理  get_json_object lateral_view explode substr json_tuple  get_json_object get_json_object(string json_string, string path)
解析 json 字符串 json_string，返回 path 指定的内容。如果输入的 json 字符串是无效的，那么返回 null。
path 就是 &amp;lsquo;$.字段名&amp;rsquo;。
如果该字段的 value 也是 json，就可以一直点下去。
如果该字段的 value 是数组，就可以用 &amp;lsquo;$.字段名[0]&#39;，类似这样下标的形式去访问。
explode explode(array)
经常和 lateral view 一起使用，将数组中的元素拆分成多行显示。
substr substr(string A, int start, int len)
返回字符串 A 从 start 位置开始，长度为 len 的字符串
json_tuple json_tuple(string json_string, col1, col2, &amp;hellip;)
经常和 lateral view 一起使用，同时解析多个 json 字符串中的多个字段。
parse_url, regexp_replace, regexp_extract parse_url parse_url(string urlString, string partToExtract, string keyToExtract)</description>
    </item>
    
    <item>
      <title>mysql的学习</title>
      <link>https://zhenfeng-zhu.github.io/posts/mysql%E7%9A%84%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Thu, 16 Apr 2020 17:34:30 +0800</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/mysql%E7%9A%84%E5%AD%A6%E4%B9%A0/</guid>
      <description>SQL条件语句 IF if(exp1, exp2, exp3)
exp1是条件，条件为true的话，是exp2，否则是exp3
case when case 列名 when 条件 then 结果 else 其他结果 end 别名 IFNULL IFNULL(exp1, exp2)
在exp1的值不为null的情况下，返回exp1，如果exp1位null，返回exp2的值。</description>
    </item>
    
    <item>
      <title>clickhouse</title>
      <link>https://zhenfeng-zhu.github.io/posts/clickhouse/</link>
      <pubDate>Sat, 12 Oct 2019 06:48:01 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/clickhouse/</guid>
      <description>ClickHouse ClickHouse 是一个用于联机分析（Online Analytical Processing：OLAP）的列式数据库管理系统(DBMS)。通过使用 OLAP 工具，用户能够从多个角度交互地分析多维数据。
OLAP 由三个基本的分析操作组成：上卷（roll-up）、钻取（drill-down）、切片（slicing）和切块（dicing）。
  上卷（roll-up）：涉及可以在一个或多个维度中累积和计算的数据的聚合。例如，所有的销售办事处汇总到销售部门，以预测销售趋势。
  钻取（drill-down）：是一种允许用户浏览详细信息的技术。例如，用户可以查看组成一个地区销售额的单个产品的销售额。
  切片（slicing）和切块（dicing）：用户可以从 OLAP 多维数据集中取出（切片）一组特定的数据，并从不同的角度查看（切块）切片。这些角度有时被称为维度（例如按销售人员、按日期、按客户、按产品或按地区查看相同的销售情况等）。
  传统行式数据库中，处于同一行中的数据总是被物理的存在一起。列式数据库总是将同一列的数据存储在一起，不同列的数据分开存储。
行式数据库：mysql，pg
列式数据库：vertica，druid
OLAP的关键特征  大多是读请求 数据总是以相当大的批（&amp;gt;1000w）进行写入 不修改已经添加的数据 每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列 宽表，即每个表包含大量的列 较少的查询（通常每台服务器每秒数百个查询或更少） 对于简单的查询，允许延迟大约50ms 列中的数据相对较小：数字和短字符串 处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行） 事务不是必须的 对数据一致性要求低 每一个查询除了一个大表外都很小 查询结果明显小于数据源，换句话说，数据被过滤或者聚合之后能够被放在单台服务器的内存中  列式数据库更适合OLAP场景 Input/Output  分析类的查询，通常只需要读取表的一小部分列。 数据总是打包成批量读取，列压缩更容易 IO降低了  CPU 由于执行一个查询需要处理大量的行，因此在整个向量上执行所有操作将比在每一行上执行所有操作更加高效。同时这将有助于实现一个几乎没有调用成本的查询引擎。
 向量引擎 代码生成  为了提高CPU效率，查询语言必须是声明型的(SQL或MDX)， 或者至少一个向量(J，K)。 查询应该只包含隐式循环，允许进行优化。
clickhouse的独特功能 真正的列式数据库管理系统    </description>
    </item>
    
    <item>
      <title>每日学习2</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-29/</link>
      <pubDate>Sun, 29 Sep 2019 02:19:03 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-29/</guid>
      <description>https://mubu.com/doc/oHlgG0FSu0</description>
    </item>
    
    <item>
      <title>每日学习-2019-09-24</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-24/</link>
      <pubDate>Sun, 29 Sep 2019 02:17:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-24/</guid>
      <description>开言英语 极客时间 编译原理之美 语义分析（下）：如何做上下文相关情况的处理？  语义分析的本质，就是针对上下文相关的情况做处理。  引用消解：不同作用域里可能有相同名称的变量，必须找到正确的那个，这个过程就是引用消解。  函数引用消解 命名空间引用消解   左值和右值  左值取的是变量的地址或者说是变量的引用，获得地址之后，我们就可以把新值写进去。 右值就是我们常说的值。 不是所有的表达式都能生成一个合格的左值。   属性计算  上下文分析或者说语义分析的一种算法。 属性文法的主要思路是计算机科学的重要开拓者，是在上下文无关文法的基础上做了一些增强，使之可以计算属性值。   过程  类型和作用域解析 类型的消解 引用的消解和S属性的类型推导 做类型检查 做一些语义合法性检查      趣谈Linux操作系统 Namespace技术：内部创业公司应该独立运营 为了隔离不同类型的资源，Linux内核里面有如下几种不同类型的namespace：
 UTS，表示不同的namespace可以配置不同的hostname User，可以配置不同的用户和组 Mount，文件系统挂载点是隔离的 PID，有完全独立的pid Network，有独立的网络协议栈  </description>
    </item>
    
    <item>
      <title>tmux</title>
      <link>https://zhenfeng-zhu.github.io/posts/tmux/</link>
      <pubDate>Wed, 28 Aug 2019 12:03:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/tmux/</guid>
      <description>折腾一下 tmux
安装 brew install tmux 概念  session：理解为一个会话，持久保存工作状态。 window：可以理解为我们常说的 tab 页。 pane：一个 window 被分成若干个 pane，理解为 iterm 的分屏。  session 新建
tmux new -s your-session-name 断开
tmux detach 恢复
tmux attach-session -t your-session-name 或者 tmux a -t your-session-name 关闭
 kill-server kill-session kill-window kill-pane  tmux kill-session -t your-session-name tmux kill-server 查看
tmux list-session tmux ls tmux 的基础配置 prefix 是 tmux 的前缀键，默认是 ctrl+b 。只有按下前缀键，才会激活 tmux，然后再按其他的键进行 tmux 操作。这样可以避免与其他应用的快捷键进行冲突。
配置前缀 需要去tmux.conf中去配置
分屏 水平分屏：prefix+&amp;quot;，前缀键加引号 垂直分屏：prefix+%，前缀键加百分号</description>
    </item>
    
    <item>
      <title>crystal开发环境</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Tue, 27 Aug 2019 14:03:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/</guid>
      <description>突然搞明白了 crystal 的 vscode 插件的正确使用姿势，记录一下。
安装 crystal brew install crystal 安装 vscode 插件 https://marketplace.visualstudio.com/items?itemName=faustinoaq.crystal-lang
安装 scry scry 是 crystal 的 language server 的 client 工具，在本地安装 scry 就可以做到代码跳转了。
$ git clone https://github.com/crystal-lang-tools/scry.git $ cd scry $ shards build -v Dependencies are satisfied Building: scry crystal build -o /Users/lucas/Documents/demos/crystal/scry/bin/scry src/scry.cr /Users/lucas/Documents/demos/crystal/scry/bin/scry 就是编译出来的二进制的路径
配置插件 &amp;#34;crystal-lang.compiler&amp;#34;: &amp;#34;crystal&amp;#34;, &amp;#34;crystal-lang.server&amp;#34;: &amp;#34;/Users/lucas/Documents/demos/crystal/scry/bin/scry&amp;#34;, &amp;#34;crystal-lang.maxNumberOfProblems&amp;#34;: 20, &amp;#34;crystal-lang.mainFile&amp;#34;: &amp;#34;${workspaceRoot}/src/main.cr&amp;#34;, &amp;#34;crystal-lang.processesLimit&amp;#34;: 5, &amp;#34;crystal-lang.hover&amp;#34;: true, &amp;#34;crystal-lang.problems&amp;#34;: &amp;#34;build&amp;#34;, &amp;#34;crystal-lang.implementations&amp;#34;: true, &amp;#34;crystal-lang.completion&amp;#34;: true, &amp;#34;crystal-lang.logLevel&amp;#34;: &amp;#34;info&amp;#34;, 把上面的配置加到 vscode 的 settings 文件中，就可以愉快的开发啦。</description>
    </item>
    
    <item>
      <title>crystal简介</title>
      <link>https://zhenfeng-zhu.github.io/posts/crystal%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Tue, 27 Aug 2019 02:14:18 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/crystal%E7%AE%80%E4%BB%8B/</guid>
      <description>关注 crystal 也有一段时间了，看到多线程的 pr 已经提了，今天简单写一下。
 Fast as C, Slick as Ruby
 语法 crystal 的语法和 Ruby 比较类似。
# A very basic HTTP server require &amp;#34;http/server&amp;#34; server = HTTP::Server.new do |context| context.response.content_type = &amp;#34;text/plain&amp;#34; context.response.print &amp;#34;Hello world, got #{context.request.path}!&amp;#34; end puts &amp;#34;Listening on http://127.0.0.1:8080&amp;#34; server.listen(8080) 类型系统 crystal 的一大卖点就是静态类型系统，但是写起来又和脚本语言类似。
def shout(x) # Notice that both Int32 and String respond_to `to_s` x.to_s.upcase end foo = ENV[&amp;#34;FOO&amp;#34;]? || 10 typeof(foo) # =&amp;gt; (Int32 | String) typeof(shout(foo)) # =&amp;gt; String 空引用检查 crystal 可以在编译的时候检查空引用，避免出现空指针异常。</description>
    </item>
    
    <item>
      <title>socket</title>
      <link>https://zhenfeng-zhu.github.io/posts/socket/</link>
      <pubDate>Mon, 26 Aug 2019 06:54:14 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/socket/</guid>
      <description>Socket 网络模型 osi七层模型  应用层 表示层 会话层 传输层 网络层 数据链路层 物理层  对应的tcpip就是  应用层  dns http   传输层  icmp tcp udp   ip层  ipv4 ipv6   mac层  arp vlan   物理层  Ethernet    为什么要分层 因为网络环境过于复杂，不是一个能够集中控制的体系。全球的服务器和设备各有各的体系，但是可以通过同一套网络协议栈切分成多个层次和组合，来满足不同设备之间的通信需求。
二层到四层，即mac、ip和传输等层都是Linux内核中处理。应用层的如浏览器、Nginx和Tomcat等都是用户态的。
传输层的tcp和udp里都有端口的概念，不同应用监听不同的段即可。
应用层和内核的互通机制，就是通过socket系统调用。其实socket哪一层都不属于，它是属于操作系统的概念，而不是网络分层的概念。因为操作系统把二层到四层的处理代码在内核里，应用层的处理代码让应用自己做，两者需要跨内核态和用户态进行通信，这个就是socket。
TCP和UDP的区别  tcp是面向连接的，udp是面向无连接的 tcp提供可靠交付，无差错、不丢失、不重复、并且按序到达。udp不提供可靠交付，可能丢失，不按顺序。 tcp是面向字节流的，发送的是一个流，无头无尾。udp是数据报文的，一个一个发送。 tcp可以提供流量控制和拥塞控制，可以防止对端被压垮，也防止网络被压垮。  所谓的连接，指两端的数据结构状态的协同，两边状态对的上，符合tcp协议的规则，就认为连接是存在的，否则就是断掉的。
所谓的建立连接，其实是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态。并用这样的数据结构来保证面向连接的特性。tcp无法左右中间的任何通路，也没有什么虚拟的连接。
所谓的可靠，也是两端的数据结构做的事情。不丢失其实是数据结构在“点名”，顺序到达是数据结构在“排序”，面向数据流其实是数据结构将零散的包，按照顺序捏成一个流发给应用层。
所谓的流量控制和拥塞控制，其实就是根据收到的对端的网络包，调整两端的数据结构状态。
socket函数 int socket(int domain, int type, int protocol) socket函数用于创建一个socket文件描述符。</description>
    </item>
    
    <item>
      <title>go进阶</title>
      <link>https://zhenfeng-zhu.github.io/posts/go%E8%BF%9B%E9%98%B6/</link>
      <pubDate>Mon, 26 Aug 2019 06:53:32 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go%E8%BF%9B%E9%98%B6/</guid>
      <description>Diagnostics go提供了一系列诊断逻辑和性能问题的工具。
 profiling分析 tracing跟踪 debuging调试 运行时统计信息和事件  Profiling profiling信息可以在go test或者net/http/pprof包的时候使用。
runtime/pprof包有：
 cpu  主动消费cpu周期所花费的时间，不包括睡眠或者io等待   heap  报告内存分配采样； 当前或历史内存使用状况 检测内存泄露   threadcreate  报告创建新的系统线程   goroutine  当前所有协程的堆栈跟踪   block  显示goroutine阻塞等待同步原语的位置。 默认不开启，使用runtime.SetBlockProfileRate启用   mutex  报告锁竞争。 如果认为自己的程序因为互斥锁导致cpu不能充分利用的时候，使用这个。 默认也是不开启，使用 runtime.SetMutexProfileFraction 启用。    其他可用的的性能分析工具
Linux使用https://perf.wiki.kernel.org/index.php/Tutorial，perf可以分析cgo/SWIG代码和系统内核。
mac上使用 https://developer.apple.com/library/content/documentation/DeveloperTools/Conceptual/InstrumentsUserGuide/ 就足够了。
分析线上处于生产状态服务
在生产上分析程序也是没问题的，但是开启某些指标会增加成本。
可视化分析数据
go 提供了很多可视化的工具，参考https://blog.golang.org/profiling-go-programs
也可以创建自定义的profil文件：参考https://golang.org/pkg/runtime/pprof/#Profile
也可以自定义修改pprof程序监听的端口和路径，参考：
package main import ( &amp;#34;log&amp;#34; &amp;#34;net/http&amp;#34; &amp;#34;net/http/pprof&amp;#34; ) func main() { mux := http.</description>
    </item>
    
    <item>
      <title>mysql</title>
      <link>https://zhenfeng-zhu.github.io/posts/mysql/</link>
      <pubDate>Sat, 01 Dec 2018 15:54:53 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/mysql/</guid>
      <description>MySQL基本架构 客户端
server层
  连接器：管理连接，权限验证
  查询缓存：命中规则，直接返回结果 8.0之后全部删除了这个模块
  分析器：词法分析，语法分析
  优化器：执行计划生成，索引选择
  执行器：操作引擎，返回结果
  存储引擎：存储数据，提供读写接口
数据库中的长连接指连接成功之后，如果客户端持续有请求，则一直使用同一个连接。短连接是指每次执行完很少的几次查询之后就断开连接，下次再重新建立。
如果全部使用长连接，会导致mysql内存涨的很快，可能出现OOM，因此要定期断开长连接，或者在执行一个比较大的操作之后，执行mysql_reset_connection重置一下。
日志系统 redo log重做日志 redo log是innodb引擎特有的。物理日志，记录的是某个数据页上做了什么修改。循环写入。
WAL技术：Write-Ahead Logging：关键点就是先写日志，再写磁盘。当一条记录更新时，先把记录写到redolog中，更新到内存，这时这个更新操作就成功了。然后innodb引擎就会在适当的时候，将这个操作记录更新到磁盘中。因此在数据库异常重启的时候，之前的提交的记录不会丢失。
binlog归档日志 binlog是server层实现的，所有的引擎都可以使用。binlog是逻辑日志，记录的是这个语句的原始逻辑。binlog是写到一定大小后，切换下一个，不会覆盖以前的日志。
因此一个update操作就是：
找到该行
判断数据页是否在内存中，如果是返回行数据，否则从磁盘读入到内存中。
将值进行更新，写入新行
新行更新到内存
写入redolog，处于prepare阶段
写入binlog
提交事务，处于commit阶段。
这个就是两阶段提交。
事务隔离 Isolation：隔离性
脏读，幻读，不可重复读
隔离的越严实，效率越低。
SQL的标准隔离级别：
读未提交：一个事务没提交的时候，它做的变更就能被别的事务看到
读提交：一个事务提交之后，做的变更才能被其他事务看到
可重复读：一个事务执行时看到的数据，总是跟这个事务启动时看到的数据时一致的。
串行化：顾名思义，对于同一行记录，写会加写锁，读也会加读锁。当读写锁冲突时，后访问的事务，必须等前一个事务完成。
在实现的时候，数据库会创建一个视图，访问的时候以视图的逻辑结果为准。
 可重复读，这个视图是在事务启动时创建，整个事务存在期间都用这个视图。 读提交，这个视图在每个sql语句开始执行的时候创建 读未提交直接返回记录的最新值，没有视图的概念。 串行化是用加锁的方式。  mysql在每条记录更新的时候，都会记录一条回滚操作，记录上的最新值都可以通过回滚操作，得到前一个状态的值。当没有事务需要用到回滚日志时，就会被删除。所以不建议使用长事务，这样会占用存储空间和锁。
mysql启动事务的方式
 显式启动：begin或者start transaction。配套的提交语句是commit，回滚语句是rollback。 set autocommit=0这个命令会将这个线程的自动提交关闭。意味着如果只执行一个select语句，事务就启动了，而且不会自动关闭，除非主动执行commit或者rollback，或者断开连接。  因此一般set autocommit=1，打开显示启动的模式。</description>
    </item>
    
    <item>
      <title>graphql</title>
      <link>https://zhenfeng-zhu.github.io/posts/graphql/</link>
      <pubDate>Thu, 08 Nov 2018 18:28:13 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/graphql/</guid>
      <description>graphql经常被认为是聚焦于前端的技术。
核心概念 SDL：schema definition language（模式定义语言） 如：
type Person{ name: String! age: Int! } 这个类型有两个字段，name和age，他们的类型是String和Int。！的意思代表他们是必需的。
type Post{ title: String! author: Person! } 接下来的Post也有两个字段，其中Person也是可以作为一个类型。
也可以这样，在Person中添加一个post：
type Person{ name: String! age: Int! posts: [Post!]! } 通过Query获取数据 基本查询 客户端发送下面的数据给服务器
{ allPersons { name } } allPersons是根字段（root field），它下面的成为查询的payload，这里仅包含了一个name。
服务器返回的结果会是这样的：
{ &amp;#34;allPersons&amp;#34;: [ { &amp;#34;name&amp;#34;: &amp;#34;Johnny&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;Sarah&amp;#34; }, { &amp;#34;name&amp;#34;: &amp;#34;Alice&amp;#34; } ] } 可以看到只返回了name字段，age字段是不会返回的。
如果使用如下的payload就会返回：
{ allPersons { name age } } 还可以查询posts中的title：</description>
    </item>
    
    <item>
      <title>go-best-practice</title>
      <link>https://zhenfeng-zhu.github.io/posts/go-best-practice/</link>
      <pubDate>Wed, 07 Nov 2018 17:16:07 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go-best-practice/</guid>
      <description> 短变量名称在声明和上次使用之间的距离很短时效果很好。 长变量名称需要证明自己的合理性; 名称越长，需要提供的价值越高。冗长的名称与页面上的重量相比，信号量较小。 请勿在变量名称中包含类型名称。 常量应该描述它们持有的值，而不是该如何使用。 对于循环和分支使用单字母变量，参数和返回值使用单个字，函数和包级别声明使用多个单词 方法、接口和包使用单个词。 请记住，包的名称是调用者用来引用名称的一部分，因此要好好利用这一点。  变量的名称应描述其内容，而不是内容的类型。
典型错误：
var usersMap map[string]*User 如果users的描述性都不够用，那么usersMap也不会。
声明变量但没有初始化时，请使用var。
在声明和初始化时，使用:=。
关于变量和常量的注释应描述其内容而非其目的  任何既不明显也不简短的公共功能必须予以注释。 无论长度或复杂程度如何，对库中的任何函数都必须进行注释  在编写函数之前，请编写描述函数的注释。 如果你发现很难写出注释，那么这就表明你将要编写的代码很难理解。
以包所提供的内容来命名，而不是它包含的内容。
避免使用类似base，common或util的包名称 尽早return而不是深度嵌套 使用internal包来减少公共API 不鼓励使用nil作为参数 首选可变参数函数而非[]T参数 通过消除错误来消除错误处理 使用github.com/pkg/errors包装errors 永远不要启动一个停止不了的goroutine。 </description>
    </item>
    
    <item>
      <title>kubernetes</title>
      <link>https://zhenfeng-zhu.github.io/posts/kubernetes/</link>
      <pubDate>Mon, 08 Oct 2018 15:29:21 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kubernetes/</guid>
      <description>docker 利用Linux的cgroups和namespace，构建一个沙箱运行环境。
docker镜像 其实就是一个压缩包，这个压缩包是由一个完整的操作系统的所有文件目录构成，包含了这个应用运行所需要的所有依赖，所以本地开发环境和测试环境是一样的。
解决了应用打包的根本性问题。
容器编排 对 Docker 容器的一系列定义、配置和创建动作的管理
 容器本身没有价值，有价值的是“容器编排”。
 原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造一个“边界”。
在创建一个容器进程的时候，指定了这个进程所需要启动的一组Namespace参数，这样容器就只能看到当前Namespace所限定的资源、文件、设备、状态或配置。
Cgroups主要作用是为一个进程组设置资源上限，如CPU、内存、磁盘和带宽等。也可以设置进程优先级，审计，挂起，重启等。
因此，一个正在运行的Docker容器，其实就是一个启用了多个Namespace的应用进程，而这个进程能够使用的资源是由Cgroups来限制。
挂载在容器根目录上，用来为容器进程提供隔离后执行环境的文件系统，就是容器镜像，rootfs。
 启动Namespace配置 设置Cgroups参数 切换进程根目录rootf  docker镜像设计时，引入了层（layer），用户制作镜像的每一步操作都会生成一个层，也就是一个增量的rootfs。AuFS，所以就有了共享层，镜像不用那么大。
一个进程，可以选择加入到某个进程已有的 Namespace当中，从而达到进入这个进程所在的容器的目的，这正是docker exec的实现原理。
volume机制，允许你将宿主机上指定的目录或文件，挂载到容器里面进行读取和修改操作。
主要依赖Linux依赖三大技术：  Namespace Cgroups rootfs  和虚拟机比较 虚拟机是通过硬件虚拟化功能，模拟一套操作系统所需要的各种硬件，如CPU、内存、IO设备等，然后安装一个新的操作系统。
docker是利用Linux的Namespace原理，帮助用户启动的还是系统的应用进程，只是加了一些参数，限制其能看到的资源。因此相对于虚拟机资源消耗更小，而且轻量级，敏捷高性能。
不过缺点就是隔离不彻底，多个容器进程公用宿主机操作系统内核。有些资源和对象不可以被Namespace化的，如时间。
kubernetes要解决的问题
编排？调度？容器云？集群管理？
 master  kube-apiserver：API服务 kube-scheduler：调度 kube-controller-manager：编排   node  kubelet：同容器运行时打交道。依赖于CRI（container runtime interface容器运行接口）远程调用接口，这个接口定义了容器运行时的各项核心操作。    etcd  运行在大规模集群中的各种任务之间，实际存在各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。
sudo
 首先，通过一个编排对象，如pod，job或cronjob等，来描述你试图管理的应用； 然后，再为它定义一些服务对象，如service，secret，autoscaler等。这些对象，会负责具体的平台级功能。  这种使用方法，就是所谓的“声明式API”。这种API对应的编排对象和服务对象，都是k8s项目中的API对象。
简单使用 $ kubectl create -f 我的配置文件 pod就是k8s世界中的应用，而一个应用可以由多个容器组成。</description>
    </item>
    
    <item>
      <title>watchdog</title>
      <link>https://zhenfeng-zhu.github.io/posts/watchdog/</link>
      <pubDate>Thu, 06 Sep 2018 16:23:57 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/watchdog/</guid>
      <description>监视器
监视器提供了一个外部世界和函数之间的非托管的通用接口。它的工作是收集从API网关来的HTTP请求，然后调用程序。监视器是一个小型的Golang服务——下图展示了它是如何工作的：
 上图：一个小型的web服务，可以为每个传入的HTTP请求分配所需要的进程。
 每个函数都需要嵌入这个二进制文件并将其作为ENTRYPOINT 或 CMD，实际上是把它作为容器的初始化进程。一旦你的进程被创建分支，监视器就会通过stdin 传递HTTP请求并从stdout中读取HTTP响应。这意味着你的程序无需知道web和HTTP的任何信息。
轻松创建新函数 从CLI创建一个函数
创建函数最简单的方法是使用FaaS CLI和模板。CLI抽象了所有Docker的知识，使得你只需要编写所支持语言的handler文件即可。
 你的第一个使用OpenFaaS的无服务器Python函数 阅读有关FaaS CLI的教程  深入研究 Package your function打包你的函数
如果你不想使用CLI或者现有的二进制文件或镜像，可以使用下面的方法去打包函数：
 使用一个现有的或者一个新的Docker镜像作为基础镜像 FROM 通过curl 或 ADD https://从 Releases 页面 添加fwatchdog二进制文件 为每个你要运行的函数设置 fprocess(函数进程) 环境变量 Expose port 8080 暴露端口8080 Set the CMD to fwatchdog 设置 CMD为fwatchdog  一个echo函数的示例Dockerfile：
FROM alpine:3.7 ADD https://github.com/openfaas/faas/releases/download/0.8.0/fwatchdog /usr/bin RUN chmod +x /usr/bin/fwatchdog # Define your binary here ENV fprocess=&amp;#34;/bin/cat&amp;#34; CMD [&amp;#34;fwatchdog&amp;#34;] Implementing a Docker healthcheck实现一个Docker健康检查</description>
    </item>
    
    <item>
      <title>queue-worker</title>
      <link>https://zhenfeng-zhu.github.io/posts/queue-worker/</link>
      <pubDate>Thu, 06 Sep 2018 16:23:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/queue-worker/</guid>
      <description>queue-worker源码分析 异步函数和同步函数 在OpenFaaS中同步调用函数时，将会连接到网关，直到函数成功返回才会关闭连接。同步调用是阻塞的。
 网关的路由是：/function/&amp;lt;function_name&amp;gt; 必须等待 在结束的时候得到结果 明确知道是成功还是失败  异步函数会有一些差异：
 网关的路由是：/async-function/&amp;lt;function_name&amp;gt; 客户端获得202的即时响应码 从queue-worker中调用函数 默认情况下，结果是被丢弃的。  查看queue-worker的日志 docker service logs -f func_queue-worker 利用requestbin和X-Callback-Url获取异步函数的结果 如果需要获得异步函数的结果，有两个方法：
 更改代码，将结果返回给端点或者消息系统 利用内置的回调 内置的回调将会允许函数提供一个url，queue-worker会报告函数的成功或失败。 requestbin会创建一个新的bin，这是互联网的一个url地址，可以从这里获取函数的结果。  源码分析 依赖项 github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/faas go-nats和go-nats-streaming是nats和nats-streaming的go版本的客户端。
faas这个依赖其实是只用到了queue包下面的types.go文件。这个文件是定义了异步请求的Request结构体和一个CanQueueRequests接口。如下所示：
package queue import &amp;quot;net/url&amp;quot; import &amp;quot;net/http&amp;quot; // Request for asynchronous processing type Request struct { Header http.Header Body []byte Method string QueryString string Function string CallbackURL *url.URL `json:&amp;quot;CallbackUrl&amp;quot;` } // CanQueueRequests can take on asynchronous requests type CanQueueRequests interface { Queue(req *Request) error } 从这里我们就可以明白作者的设计思路，只要是实现了这个CanQueueRequests接口，就可以作为一个queue-worker。</description>
    </item>
    
    <item>
      <title>区块链学习笔记</title>
      <link>https://zhenfeng-zhu.github.io/posts/blockchain/</link>
      <pubDate>Thu, 23 Aug 2018 15:14:02 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/blockchain/</guid>
      <description>本文是阅读http://www.netkiller.cn/blockchain/ch01s10.html上的一些笔记。
 理解区块链的分布式记账 http://www.netkiller.cn/blockchain/ch01s10.html
区块链中提到的账本，记账等词汇是和会计无关的词汇。
我们传统理解的账本是一个二维的表格，记录了某年某月某日的费用：
   时间 用途 金额     2018-08-23 借 100   2018-08-22 还 200   2018-08-21 借 50   2018-08-20 还 1000    如果账目比较多，可以拆账，将不同分类的账目放在特定的账本中，而且二维表格还可以设置索引等，快速找到一笔交易。
但是区块链的记账形式是：
可以发现，区块链的这种记账方式是做了行列矩阵转换，节点之间收尾相互连接，成为链式结构，所有的账目都在一条链上。
所谓分布式记账，其实就是上述链状的数据结构保存在所有的节点上，形成分布式集群。
之所以采用区块链来做分布式记账，主要是区块链有如下好处：
  去中心化
传统的数据库存储是中心化的，通过暴露ip地址和端口号提供服务，后来分布式进群化之后，出现了主主从架构等。
与数据库相比，区块链是多主架构，而且实现更为复杂，节点之间的数据之间不是简单的二进制日志同步，而是要通过加密技术，节点达成共识之后才存储。
  可追溯
  安全
安全分为很多层，区块链只能做到存储层的安全。
区块链无法解决用户层，应用层，逻辑层等安全问题，他只能保证存储在硬盘上的区块不被修改。
  不可篡改
很多人认为区块链数据一旦创建之后就不能修改，所以采用区块链技术很安全。其实不然，数据是可以修改的，但是不能篡改。
撰改是指非法修改区块链数据，而修改则是合法变更数据。
通常撰改区块链数据多指数据存储层面的修改。而修改则是通过合约提供的修改函数变更区块链里面的数据。
多数区块链平台没有用户认证权限管理模块。所以无法控制区块中的哪些数据能被修改，哪些不能修改，哪些用户可以修改等等。即使有些区块链平台具备权限控制，颗粒度也无法达到目前的数据库控制的那么细。
  采用区块链作为账本的时候，会面临如下几个问题：
  不能建立索引，无法快速搜索出区块中的数据，必须依赖区块链以外的技术，如搜索引擎，数据库等。例如；etherscan.io就是把以太坊上的区块重新入库，借助数据库实现数据检索。
  区块链只能顺序检索，运算成本高。例如在中心化账本中汇总求和操作，区块链必须从头向后遍历。</description>
    </item>
    
    <item>
      <title>谈谈聊天机器人框架的实现原理</title>
      <link>https://zhenfeng-zhu.github.io/posts/botbuilder/</link>
      <pubDate>Wed, 22 Aug 2018 19:39:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/botbuilder/</guid>
      <description>在这篇文章不考虑人工智能，谈谈我对聊天机器人框架实现机制的理解。
聊天机器人  聊天机器人（Chatterbot）是经由对话或文字进行交谈的计算机程序[1]。能够模拟人类对话，通过图灵测试。
 我们可以看到现有的IM工具上已经有了很多机器人，其实聊天机器人不只是单纯的和用户进行聊天，他其实还可以做很多事情，例如根据用户输入的一些话，可以帮用户订餐。另外在运维领域，也出现了chatops，通过和机器人聊天，进行运维操作。
机器人开发框架 作为聊天机器人开发者，面对如此多的IM工具和SDK，常会感到无所适从。Bot 开发框架就是对聊天机器人开发过程中的人工内容做抽象化处理。简单地解释，机器人开发框架就是用来制造机器人并定义其行为。
然而尽管很多机器人框架宣称「代码一旦写好可部署到任何地方」，但是还会是出现为每一个IM工具开发一个单独的聊天机器人。而一个良好的机器人框架主要包含开发SDK，连接器和模拟器等。
使用机器人框架其实并不适合初学者学习聊天机器人开发。它们尝试自动化太多工作，对初学者掩盖了基础机制。
实现方式  webhook事件回调 FSM状态机 workflow工作流  最简单的机器人是没有上下文的语义理解的一问一答，仅仅是对用户的对话进行响应，这种就可以采用webhook的方式进行开发。不需要采用什么开发框架。
那么对于多轮对话的时候，就需要进行一定的对话管理。由此引入了FSM状态机。
可能有人不是很懂有限状态机，这里做一下简单说明。
 有限状态机在现实生活中其实随处可见，伸缩式圆珠笔其实就是一个有限状态机（两种状态互相转换）。
有限状态机，缩写为FSM，又称为有限状态自动机，简称状态机。是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。
可以总结为：f(state, action) =&amp;gt; state’
也就是说，这个函数采用当前的状态和一次行动（即更改状态的方法），之后将该行动应用于这种状态并返回新的状态。
可以认为状态机是图灵完备的。
 我们可以将对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。
我们可以将对话的过程，分为一个个的状态，然后使用DSL来实现一个FSM，对于开发者来讲，我们只需要关注一个个状态函数即可。
特点是：
 人为定义对话流程 完全有系统主导，系统问用户答 答非所问的情况直接忽略 建模简单，能清晰明了的把交互匹配到模型 难以扩展，很容易变的复杂 适用于简单的任务，难以处理复杂问题 缺少灵活性，表达能力有限，输入有限，对话结构和流转路径有限  示例：
const {startWith, when, goto, stay, stop} = botkit.DSL(fsm); startWith(MyStates.IDLE, {counter: 0}); when(MyStates.IDLE)(async (sender, content, data) =&amp;gt; { }); when(MyStates.UI)((sender, content, data) =&amp;gt; { }); when(MyStates.STEP1)((sender, content, data) =&amp;gt; { }); when(MyStates.</description>
    </item>
    
    <item>
      <title>基于以太坊的Parity联盟链部署</title>
      <link>https://zhenfeng-zhu.github.io/posts/parity/</link>
      <pubDate>Wed, 22 Aug 2018 16:51:13 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/parity/</guid>
      <description>公司项目中使用公网上的以太坊私链，交易速度比较慢，于是这几天都在鼓捣基于以太坊的联盟链，parity是可以构建出一个基于PoA共识的私链，而且兼容以太坊的合约。这篇文章主要是记录自己的踩坑经历，主要实现了节点的搭建，合约的部署以及本地以太坊浏览器的启动。
部署联盟链 parity的文档：https://wiki.parity.io/Demo-PoA-tutorial
安装 首先是下载parity，在mac下是直接brew安装即可。
brew tap paritytech/paritytech brew install parity 创世区块 创世区块的配置文件：
// demo-spec.json { &amp;quot;name&amp;quot;: &amp;quot;DemoPoA&amp;quot;, &amp;quot;engine&amp;quot;: { &amp;quot;authorityRound&amp;quot;: { &amp;quot;params&amp;quot;: { &amp;quot;stepDuration&amp;quot;: &amp;quot;5&amp;quot;, &amp;quot;validators&amp;quot;: { &amp;quot;list&amp;quot;: [ &amp;quot;0x00bd138abd70e2f00903268f3db08f2d25677c9e&amp;quot;, &amp;quot;0x00aa39d30f0d20ff03a22ccfc30b7efbfca597c2&amp;quot; ] } } } }, &amp;quot;params&amp;quot;: { &amp;quot;gasLimitBoundDivisor&amp;quot;: &amp;quot;0x400&amp;quot;, &amp;quot;maximumExtraDataSize&amp;quot;: &amp;quot;0x20&amp;quot;, &amp;quot;minGasLimit&amp;quot;: &amp;quot;0x1388&amp;quot;, &amp;quot;networkID&amp;quot;: &amp;quot;0x2323&amp;quot;, &amp;quot;eip155Transition&amp;quot;: 0, &amp;quot;validateChainIdTransition&amp;quot;: 0, &amp;quot;eip140Transition&amp;quot;: 0, &amp;quot;eip211Transition&amp;quot;: 0, &amp;quot;eip214Transition&amp;quot;: 0, &amp;quot;eip658Transition&amp;quot;: 0 }, &amp;quot;genesis&amp;quot;: { &amp;quot;seal&amp;quot;: { &amp;quot;authorityRound&amp;quot;: { &amp;quot;step&amp;quot;: &amp;quot;0x0&amp;quot;, &amp;quot;signature&amp;quot;: &amp;quot;0x0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000&amp;quot; } }, &amp;quot;difficulty&amp;quot;: &amp;quot;0x20000&amp;quot;, &amp;quot;gasLimit&amp;quot;: &amp;quot;0x5B8D80&amp;quot; }, &amp;quot;accounts&amp;quot;: { &amp;quot;0x0000000000000000000000000000000000000001&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;ecrecover&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 3000, &amp;quot;word&amp;quot;: 0 } } } }, &amp;quot;0x0000000000000000000000000000000000000002&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;sha256&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 60, &amp;quot;word&amp;quot;: 12 } } } }, &amp;quot;0x0000000000000000000000000000000000000003&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;ripemd160&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 600, &amp;quot;word&amp;quot;: 120 } } } }, &amp;quot;0x0000000000000000000000000000000000000004&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;1&amp;quot;, &amp;quot;builtin&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;identity&amp;quot;, &amp;quot;pricing&amp;quot;: { &amp;quot;linear&amp;quot;: { &amp;quot;base&amp;quot;: 15, &amp;quot;word&amp;quot;: 3 } } } }, &amp;quot;0x004ec07d2329997267ec62b4166639513386f32e&amp;quot;: { &amp;quot;balance&amp;quot;: &amp;quot;10000000000000000000000&amp;quot; } } } node0 node0节点：</description>
    </item>
    
    <item>
      <title>dive-into-redis</title>
      <link>https://zhenfeng-zhu.github.io/posts/dive-into-redis/</link>
      <pubDate>Mon, 20 Aug 2018 09:39:08 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/dive-into-redis/</guid>
      <description>redis持久化，
机制有两种：
 快照：全量备份，二进制序列化，存储紧凑 AOF日志：连续的增量备份，内存数据修改的文本  </description>
    </item>
    
    <item>
      <title>golang踩坑</title>
      <link>https://zhenfeng-zhu.github.io/posts/golang%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Tue, 14 Aug 2018 20:10:55 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/golang%E8%B8%A9%E5%9D%91/</guid>
      <description>一  x509 error when using HTTPS inside a Docker container
 因为docker中没有CA证书。
普通的镜像解决办法
FROM ubuntu:14.04.1 RUN apt-get update RUN apt-get install -y ca-certificates CMD curl https://www.google.com 如果是alpine的参考这个：
FROM docker.finogeeks.club/base/alpine MAINTAINER &amp;quot;zhuzhenfeng@finogeeks.club&amp;quot; RUN set -ex \ &amp;amp;&amp;amp; apk add --no-cache ca-certificates COPY src/wallet/wallet /opt/wallet ENTRYPOINT /opt/wallet 二  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x38 pc=0x26df]
 &amp;ldquo;An error is returned if caused by client policy (such as CheckRedirect), or if there was an HTTP protocol error.</description>
    </item>
    
    <item>
      <title>以太坊开发总结</title>
      <link>https://zhenfeng-zhu.github.io/posts/eth-tools/</link>
      <pubDate>Fri, 10 Aug 2018 18:57:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/eth-tools/</guid>
      <description>最近因公司项目需要，做为一个打杂工程师，操起键盘和笔记本开始了以太坊的踩坑之旅。以太坊的开发比较新，变化也比较多，还好有@cctanfujun的手把手带领下，半只脚踏入了以太坊的开发的大门。
在这篇文章中，我将会简单介绍一下以太坊的基本概念，以及我现在用到的一些工具，还有具体的一个开发流程。因为我还没有接触到如何上主链，所以这些都是基于测试链讲解。希望能给大家带来一些帮助。
什么是区块链
相信大家对区块链都有自己的理解，不仅仅是互联网公司，传统企业也在“币改转型”。
**简言之，区块链就是数据库。**它是特定数据的数据库，里面的数据不断增长，具有非凡特性：
 一旦数据存储于数据库，永远都无法被修改或删除。区块链上的每个记录会被永久保存下来。 没有单独的个人或组织能维护该数据库。必须要上千个人才行，每个人都有数据库的副本。  什么是以太坊？
 以太坊（英语：Ethereum）是一个开源的有智能合约功能的公共区块链平台[1][2]。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。
 为什么选择以太坊？
  智能合约
  代币
  资料相对完善，相对容易开发
  大佬对以太坊比较熟悉
  大佬对以太坊比较熟悉
  大佬对以太坊比较熟悉
  重要的事情说三遍，有一个经验丰富的人带领，做东西肯定事半功倍。
自己动手写区块链
这里提供两个教程，一个是书，一个是视频。其中视频和书是对应的，不清楚是不是同一个作者。
Blockchain Tutorial
私有区块链，我们一起GO
以太坊开发
由于我是专注于后端的开发，现在的技术栈是
 node go  正式进入以太坊的开发。这是我这段时间接触到的一些资源：
  go-ethereum：也就是geth，官方的go版本的客户端
  solidity：智能合约编程语言
  truffle：智能合约的编程框架，基于nodejs
  Ganache：启动了多个节点本地私链
  Rinkeby：以太坊测试链
  Etherscan：以太坊区块链浏览器，可以查询交易
  MetaMask：chrome的钱包插件</description>
    </item>
    
    <item>
      <title>以太坊</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A/</link>
      <pubDate>Tue, 07 Aug 2018 20:09:26 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A/</guid>
      <description>参与了公司的一个项目，上了以太坊，这里简单记录一下踩坑。
首先先把go的依赖下载下来：
go get -u -v github.com/ethereum/go-ethereum 有时候下载的很慢，可以从github上拉下来代码。
账户 以太坊的地址在离线状态下也可以创建到。
创建账户有两种方式：
以公钥和私钥的形式创建 func CreateAccount() (string, error) { key, err := crypto.GenerateKey() if err != nil { log.Fatalln(err) return &amp;quot;&amp;quot;, nil } address := crypto.PubkeyToAddress(key.PublicKey).Hex() log.Println(&amp;quot;address: &amp;quot;, address) privateKey := hex.EncodeToString(key.D.Bytes()) log.Println(&amp;quot;privateKey: &amp;quot;, privateKey) return address, nil } 这种方式一般用的比较少。
以keystore的形式创建 keystore会创建一个文件，这个文件如下所示：
{ &amp;quot;address&amp;quot;: &amp;quot;d93688757810e644f0b9c162102d9c598813f0dd&amp;quot;, &amp;quot;crypto&amp;quot;: { &amp;quot;cipher&amp;quot;: &amp;quot;aes-128-ctr&amp;quot;, &amp;quot;ciphertext&amp;quot;: &amp;quot;71ae7c8144729b2f9e0c51d95c6dfb73e63f14b5332b3594e8a1f325237c27ed&amp;quot;, &amp;quot;cipherparams&amp;quot;: { &amp;quot;iv&amp;quot;: &amp;quot;620c73001081c014a862ce80003a4648&amp;quot; }, &amp;quot;kdf&amp;quot;: &amp;quot;scrypt&amp;quot;, &amp;quot;kdfparams&amp;quot;: { &amp;quot;dklen&amp;quot;: 32, &amp;quot;n&amp;quot;: 262144, &amp;quot;p&amp;quot;: 1, &amp;quot;r&amp;quot;: 8, &amp;quot;salt&amp;quot;: &amp;quot;bd272aa37271ef9913eb095a4d143be238e348c48fce6459896e1bb1b0236741&amp;quot; }, &amp;quot;mac&amp;quot;: &amp;quot;2b3ade771645090a2b34c214906c592a1300d529e459faefb1421ba496b6fe1d&amp;quot; }, &amp;quot;id&amp;quot;: &amp;quot;e4dd5384-56a8-4ec7-b6e0-492dcd3742e9&amp;quot;, &amp;quot;version&amp;quot;: 3 } 在生成这个文件的时候，会让你输一个密码，这个文件加密码其实就是一个私钥。</description>
    </item>
    
    <item>
      <title>contract</title>
      <link>https://zhenfeng-zhu.github.io/posts/contract/</link>
      <pubDate>Fri, 03 Aug 2018 14:32:03 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/contract/</guid>
      <description>类型 Solidity是静态类型的语言。
值类型  bool int/uint fixed/unfixed address  balance和transfer send call, callcode和delegatecall   byte bytes 和 string 十六进制hex&amp;quot;0012&amp;quot; enum function  引用类型   数组
uint[]
  结构体
struct
  映射
mapping(key =&amp;gt; value)
  单元和全局变量   以太币的单位
在数字后面加上 wei、 finney、 szabo 或 ether。默认是wei
  时间单位
数字后面带有 seconds、 minutes、 hours、 days、 weeks 和 years。默认是秒。
  区块和交易
 block.blockhash(uint blockNumber) returns (bytes32)：指定区块的区块哈希。 block.coinbase (address): 挖出当前区块的矿工地址 block.</description>
    </item>
    
    <item>
      <title>faas-provider</title>
      <link>https://zhenfeng-zhu.github.io/posts/faas-provider/</link>
      <pubDate>Wed, 01 Aug 2018 19:53:23 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/faas-provider/</guid>
      <description>faas-provider是一个模板，只要实现了这个模板的接口，就可以自定义实现自己的provider。
faas-provider OpenFaaS官方提供了两套后台provider：
 Docker Swarm Kubernetes  这两者在部署和调用函数的时候流程图如下：
部署一个函数
调用一个函数
provider要提供的一些API有：
 List / Create / Delete 一个函数  /system/functions
方法: GET / POST / DELETE
 获取一个函数  /system/function/{name:[-a-zA-Z_0-9]+}
方法: GET
 伸缩一个函数  /system/scale-function/{name:[-a-zA-Z_0-9]+}
方法: POST
 调用一个函数  /function/{name:[-a-zA-Z_0-9]+}
方法: POST
在provider的server.go的serve方法，可以看到这个serve方法创建了几个路由，接受一个FaaSHandler对象。
// Serve load your handlers into the correct OpenFaaS route spec. This function is blocking. func Serve(handlers *types.FaaSHandlers, config *types.FaaSConfig) { r.HandleFunc(&amp;quot;/system/functions&amp;quot;, handlers.FunctionReader).Methods(&amp;quot;GET&amp;quot;) r.HandleFunc(&amp;quot;/system/functions&amp;quot;, handlers.</description>
    </item>
    
    <item>
      <title>gateway-reading</title>
      <link>https://zhenfeng-zhu.github.io/posts/gateway-reading/</link>
      <pubDate>Wed, 01 Aug 2018 09:15:35 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/gateway-reading/</guid>
      <description>OpenFaaS的Gateway是一个golang实现的请求转发的网关，在这个网关服务中，主要有以下几个功能：
 UI 部署函数 监控 自动伸缩  架构分析 从图中可以发现，当Gateway作为一个入口，当CLI或者web页面发来要部署或者调用一个函数的时候，Gateway会将请求转发给Provider，同时会将监控指标发给Prometheus。AlterManager会根据需求，调用API自动伸缩函数。
源码分析 依赖 github.com/gorilla/mux github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/nats-queue-worker github.com/prometheus/client_golang mux 是一个用来执行http请求的路由和分发的第三方扩展包。
go-nats-streaming，go-nats，nats-queue-worker这三个依赖是异步函数的时候才会用到，在分析queue-worker的时候有说到Gateway也是一个发布者。
client_golang是Prometheus的客户端。
项目结构 ├── Dockerfile ├── Dockerfile.arm64 ├── Dockerfile.armhf ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── assets ├── build.sh ├── handlers │ ├── alerthandler.go │ ├── alerthandler_test.go │ ├── asyncreport.go │ ├── baseurlresolver_test.go │ ├── basic_auth.go │ ├── basic_auth_test.go │ ├── callid_middleware.go │ ├── cors.go │ ├── cors_test.go │ ├── forwarding_proxy.go │ ├── forwarding_proxy_test.</description>
    </item>
    
    <item>
      <title>NATS streaming</title>
      <link>https://zhenfeng-zhu.github.io/posts/nats-streaming/</link>
      <pubDate>Mon, 30 Jul 2018 14:51:26 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/nats-streaming/</guid>
      <description>市面上常见到的和Nats功能类似的消息通信系统有：
ActiveMQ（Java编写）、KafKa（Scala编写）、RabbitMq（Ruby编写）、Nats（之前是Ruby编写现已修改为Go）、Redis（C语言编写）、Kestrel（Scala编写不常用）、NSQ（Go语言编写），这些消息通信系统在Broker吞吐量方面的比较：
可以看到NATS的吞吐量特别高， NATS原来是使用Ruby编写，可以实现每秒150k消息，后来使用Go语言重写，能够达到每秒8-11百万个消息，整个程序很小只有3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。关于NATS的详细介绍，请参考上篇文章：NATS简介
NATS Streaming NATS Streaming是由NATS驱动的数据流系统，也是由go语言写成的，在保证吞吐量和时延的基础上，解决了Nats消息投递一致性的问题。nats streaming可以和核心nats平台无缝嵌入，扩展和互动。
功能 除了nats平台的一些功能，nats streaming还支持以下的：
 增强的消息协议 消息/事件持久化 至少一次投递 发布者速率限制 每个订阅者的速率匹配/限制 可重复消费 持久订阅  使用 首先安装nats-streaming-server服务，有多种方式，这里介绍两种：
  homebrew
直接在命令行启动
brew install nats-streaming-server   go get
这种方式可以让我们直接运行源码启动
go get github.com/nats-io/nats-streaming-server   启动nats-streaming-server
有三种启动方式
  直接启动
nats-streaming-server   开启nats监控的启动
nats-streaming-server -m 8222   源码方式启动
cd $GOPATH/src/github.com/nats-io/nats-streaming-server go run nats-streaming-server.go   客户端 直接下载go的客户端
go get github.com/nats-io/go-nats-streaming 运行发布者</description>
    </item>
    
    <item>
      <title>nats简介</title>
      <link>https://zhenfeng-zhu.github.io/posts/nats/</link>
      <pubDate>Mon, 30 Jul 2018 11:15:39 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/nats/</guid>
      <description>nats是一个开源的，云原生的消息系统。Apcera，百度，西门子，VMware，HTC和爱立信等公司都有在使用。
核心基于EventMachine开发，原理是基于消息发布订阅机制，每台服务器上的每个模块会根据自己的消息类别向MessageBus发布多个消息主题，而同时也向自己需要交互的模块，按照需要的主题订阅消息。能够达到每秒8-11百万个消息，整个程序很小只有3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。使用nats streaming可以做到持久化，缓存等功能。
NATS server nats提供了一个go编写的轻量级服务器。发行版包括二进制和docker镜像
NATS clients
nats官方提供的客户端有Go，Node，Ruby，Java，C，C＃，NGINX等。
NATS 设计目标
核心原则是性能，可伸缩和易用性。
 高效 始终在线和可用 非常轻巧 支持多种质量的服务 支持各种消息传递模型和使用场景  NATS 使用场景 nats是一个简单且强大的消息系统，为支持现代云原生架构设计。由于可伸缩性的复杂性，nats旨在容易使用和实现，且能提供多种质量的服务。
一些适用nats的场景有：
 高吞吐量的消息分散 —— 少数的生产者需要将数据发送给很多的消费者。 寻址和发现 —— 将数据发送给特定的应用实例，设备或者用户，也可用于发现并连接到基础架构中的实例，设备或用户。 命令和控制（控制面板）—— 向程序或设备发送指令，并从程序/设备中接收状态，如SCADA，卫星遥感，物联网等。 负载均衡 —— 主要应用于程序会生成大量的请求，且可动态伸缩程序实例。 N路可扩展性 —— 通信基础架构能够充分利用go的高效并发/调度机制，以增强水平和垂直的扩展性。 位置透明 —— 程序在各个地理位置上分布者大量实例，且你无法了解到程序之间的端点配置详情，及他们所生产或消费的数据。 容错  使用nats-streaming的附加场景有：
 从特定时间或顺序消费 持久性 有保证的消息投递  NATS消息传递模型  发布订阅 请求回复 排队  NATS的特点 nats的独特功能有：
 纯净的pub-sub 集群模式的server 订阅者的自动裁剪 基于文本的协议 多种服务质量  最多一次投递 至少一次投递   持久 缓存  </description>
    </item>
    
    <item>
      <title>overview-of-openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/overview-of-openfaas/</link>
      <pubDate>Thu, 26 Jul 2018 17:41:33 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/overview-of-openfaas/</guid>
      <description>OpenFaaS概览  无服务器函数变得简单。
 函数监视器  你可以通过添加函数监视器 (一个小型的Golang HTTP服务)把任何一个Docker镜像变成无服务器函数。 函数监视器是允许HTTP请求通过STDIN转发到目标进程的入口点。响应会从你应用写入STDOUT返回给调用者。  API网关/UI门户  API网关为你的函数提供外部路由，并通过Prometheus收集云原生指标。 你的API网关将会根据需求更改Docker Swarm 或 Kubernetes API中的服务副本数来实现伸缩性。 UI是允许你在浏览器中调用函数或者根据需要创建新的函数。   API网关是一个RESTful形式的微服务，你可以在这里查看Swagger文档。
 命令行 Docker中的任何容器或者进程都可以是FaaS中的一个无服务器函数。使用FaaS CLI ，你可以快速的部署函数。
可以从Node.js, Python, Go 或者更多的语言模板中创建新的函数。如果你无法找到一个合适的模板，甚至可以使用一个Dockerfile。
 CLI实际上是API网关的一个RESTful客户端。
 在配置好OpenFaaS之后，你可以在这里开始学习CLI开始学习CLI
函数示例 你可以通过 使用FaaS-CLI和其内置的模板创建新函数，也可以在Docker中使用Windows或Linux的二进制文件。
 Python示例：  import requests def handle(req): r = requests.get(req, timeout = 1) print(req +&amp;quot; =&amp;gt; &amp;quot; + str(r.status_code)) handler.py
 Node.js示例：  &amp;quot;use strict&amp;quot; module.exports = (callback, context) =&amp;gt; { callback(null, {&amp;quot;message&amp;quot;: &amp;quot;You said: &amp;quot; + context}) } handler.</description>
    </item>
    
    <item>
      <title>OpenFaaS on Rancher 2.0</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-on-rancher/</link>
      <pubDate>Thu, 26 Jul 2018 09:50:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-on-rancher/</guid>
      <description>这是一篇关于如何在Rancher 2.0上创建OpenFaaS栈的文章。我假设你已经准备好了Rancher 2.0集群，如果没有请按照官方文档创建一个。
下面的视频展示了如何创建OpenFaaS栈，并在实际中使用：
https://www.youtube.com/watch?v=kX8mXv5d1qg&amp;amp;feature=youtu.be
这里是创建栈的compose.yml文件：
version: &amp;#34;2&amp;#34; services: alertmanager: image: functions/alertmanager:latest labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 faas-rancher: environment: - CATTLE_URL=${CATTLE_URL} - CATTLE_ACCESS_KEY=${CATTLE_ACCESS_KEY} - CATTLE_SECRET_KEY=${CATTLE_SECRET_KEY} - FUNCTION_STACK_NAME=faas-functions image: kenfdev/faas-rancher:v3 labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 gateway: environment: - functions_provider_url=http://faas-rancher:8080/ image: functions/gateway:0.6.6-beta1 labels: io.rancher.container.pull_image: always ports: - 8080:8080/tcp stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 prometheus: command: [-config.</description>
    </item>
    
    <item>
      <title>openfaas-workshop-lab4</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab4/</link>
      <pubDate>Mon, 02 Jul 2018 09:32:59 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab4/</guid>
      <description>Lab 4 - 深入函数 在开始本实验之前，创建一个新的文件夹，把 lab3 的文件拷贝到 lab4 里：
$ cp -r lab3 lab4 \ &amp;amp;&amp;amp; cd lab4 通过环境变量注入配置 It is useful to be able to control how a function behaves at runtime, we can do that in at least two ways:
控制函数在运行时的行为很有用，我们至少可以通过两种方式来实现：
在部署时  在部署时设置环境变量  我们在 Lab3 时用了 write_debug 来做——你也可以在这里设置你想要的任何自定义的环境变量。例如：如果你想为 hello world 函数配置一种语言，可以引入一个 spoken_language 变量。
使用 HTTP 上下文——querystring / headers  使用 querystring 和 HTTP headers  另一个更为动态的选项是可以在每个请求级别上进行修改，即使用 querystrings 和 HTTP headers，这两者都可以通过 faas-cli 或者 curl 传递。</description>
    </item>
    
    <item>
      <title>ubuntu-docker-sudo</title>
      <link>https://zhenfeng-zhu.github.io/posts/ubuntu-docker-sudo/</link>
      <pubDate>Fri, 29 Jun 2018 13:54:25 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/ubuntu-docker-sudo/</guid>
      <description>sudo chown &amp;quot;$USER&amp;quot;:&amp;quot;$USER&amp;quot; /home/&amp;quot;$USER&amp;quot;/.docker -R sudo chmod g+rwx &amp;quot;/home/$USER/.docker&amp;quot; -R https://api.finochat.com/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI http://localhost:3000/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI </description>
    </item>
    
    <item>
      <title>openfaas-workshop-lab3</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab3/</link>
      <pubDate>Thu, 28 Jun 2018 17:29:56 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab3/</guid>
      <description>Lab3 - 函数的介绍 在开始本实验之前，创建一个新文件夹：
$ mkdir -p lab3 \ &amp;amp;&amp;amp; cd lab3 创建一个新函数 创建函数有两种方式：
 使用内置的或社区提供的代码末班创建一个函数脚手架（默认）   将现有的二进制文件作为函数（高级）  生成一个新函数 在使用模板创建一个新函数之前，首先确认你已经从 Github 上拉下来模板文件：
$ faas-cli template pull Fetch templates from repository: https://github.com/openfaas/templates.git Attempting to expand templates from https://github.com/openfaas/templates.git Fetched 11 template(s) : [csharp dockerfile go go-armhf node node-arm64 node-armhf python python-armhf python3 ruby] 之后找到可用的语言：
$ faas-cli new --list Languages available as templates: - csharp - dockerfile - go - go-armhf - node - node-arm64 - node-armhf - python - python-armhf - python3 - ruby Or alternatively create a folder containing a Dockerfile, then pick the &amp;quot;Dockerfile&amp;quot; lang type in your YAML file.</description>
    </item>
    
    <item>
      <title>译：openfaas-workshop-Lab1</title>
      <link>https://zhenfeng-zhu.github.io/posts/workshop-lab1/</link>
      <pubDate>Mon, 25 Jun 2018 18:04:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/workshop-lab1/</guid>
      <description>今天大多数公司在开发应用程序并将其部署在服务器上的时候，无论是选择公有云还是私有的数据中心，都需要提前了解究竟需要多少台服务器、多大容量的存储和数据库的功能等。并需要部署运行应用程序和依赖的软件到基础设施之上。假设我们不想在这些细节上花费精力，是否有一种简单的架构模型能够满足我们这种想法？这个答案已经存在，这就是今天软件架构世界中新鲜但是很热门的一个话题——Serverless（无服务器）架构。
目前已经有一批优秀的serverless架构开源项目，OpenFaas就是其中的佼佼者。奈何其中的中文资料比较少，我也是边学边翻译，希望能够抛砖引玉，助力serverless的发展。
这是一个自学研讨会，学习如何构建、部署和运行OpenFaas 函数。
Lab1 - OpenFaas的准备工作 OpenFaas可以在Docker Swarm和Kubernetes的过几个主要平台之上运行。在此教程里，我们将会在的您本地电脑使用Docker Swarm来入门。
预备条件 Docker Mac
 Docker CE for Mac Edge Edition  Windows
 仅针对windows10 专业版或企业版 安装Docker CE for Windows 安装Git Bash   备注：所有步骤中请使用Git Bash：不要尝试使用WSL或Bash for Windows。
 Linux - Ubuntu 或 Debian
 Docker CE for Linux   你可以从Docker Store中安装Docker CE
 设置一个单节点的Docker Swarm OpenFaas在Docker Swarm和Kubernetes上工作。因为Docker Swarm很容易设置，所以在此Workshop中我们使用Docker Swarm。在文档中有他们两个的指南。
在你的笔记本或虚拟机中设置一个单节点的Docker Swarm：
$ docker swarm init  如果运行此命令出错，加上 &amp;ndash;advertise-addr 你的IP 参数。</description>
    </item>
    
    <item>
      <title>openfaas</title>
      <link>https://zhenfeng-zhu.github.io/posts/openfaas/</link>
      <pubDate>Sun, 24 Jun 2018 15:43:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/openfaas/</guid>
      <description>对于mac环境来讲，首先安装新版docker:
brew cask install docker 然后启动docker。
命令行登陆docker hub
docker login 启动docker swarm
docker swarm init 安装faas-cli
brew install faas-cli clone下来代码：
git clone https://github.com/openfaas/faas 然后执行
./deploy_stack.sh 部署一些示例
faas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 使用浏览器打开 http://127.0.0.1:8080 就可以看到ui界面了。
安装grafana进行监控
docker service create -d \ --name=grafana \ --publish=3000:3000 \ --network=func_functions \ stefanprodan/faas-grafana:4.6.3 浏览器打开： http://127.0.0.1:3000 登陆admin admin 查看。
常用命令：
$ faas-cli new --list $ faas-cli build -f ./hello-openfaas.yml $ faas-cli push -f ./hello-openfaas.yml $ faas-cli deploy -f .</description>
    </item>
    
    <item>
      <title>java-reactive-web</title>
      <link>https://zhenfeng-zhu.github.io/posts/java-reactive-web/</link>
      <pubDate>Sat, 23 Jun 2018 15:05:32 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/java-reactive-web/</guid>
      <description>Spring web mvc： 传统servlet web
spring web flux： Reactive web
 编程模式： non-blocking 非阻塞  nio：同步？异步？   并行模型  sync 同步 async 异步    Reactive 概念 Reactive programming： 响应式编程
In computing, reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. With this paradigm it is possible to express static (e.g. arrays) or dynamic (e.g. event emitters) data streams with ease, and also communicate that an inferred dependency within the associated execution model exists, which facilitates the automatic propagation of the changed data flow.</description>
    </item>
    
    <item>
      <title>kafka</title>
      <link>https://zhenfeng-zhu.github.io/posts/kafka/</link>
      <pubDate>Thu, 21 Jun 2018 17:49:46 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kafka/</guid>
      <description>启动zookeeper
bin/zookeeper-server-start.sh config/zookeeper.properties 启动kafka
bin/kafka-server-start.sh config/server.properties 创建一个主题
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test bin/kafka-topics.sh --list --zookeeper localhost:2181 生产者
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 消费者
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning kafka connect
echo -e &amp;quot;zhisheng\ntian&amp;quot; &amp;gt; test.txt ls
zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ echo -e &amp;quot;zhisheng\ntian&amp;quot; &amp;gt; test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ ls LICENSE NOTICE bin config libs logs site-docs test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ 启动连接器
bin/connect-standalone.sh config/connect-standalone.</description>
    </item>
    
    <item>
      <title>译：vertx-kotlin-coroutine</title>
      <link>https://zhenfeng-zhu.github.io/posts/vertx-kotlin-coroutine/</link>
      <pubDate>Sat, 02 Jun 2018 16:00:52 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/vertx-kotlin-coroutine/</guid>
      <description>尝试翻译vertx的文档。尊重原文，部分使用自己的理解。
 Vert.x的kotlin协程提供了async/await或者和go类似的channel。这使得你能够以熟悉的顺序风格写垂直代码。
vertx-lang-kotlin-coroutines集成了kotlin协程，用于执行异步操作和处理事件。这样就能够以同步代码的模型编写代码，而且不会阻塞内核线程。
简介 vert.x与许多旧的应用平台相比的一个主要优势是它几乎完全是非阻塞的（内核线程）。这允许基于vert.x的程序使用极少数的内核线程处理大量的并发（例如：许多连接和消息），可以获得更好的伸缩性。
vert.x的非阻塞特性形成了非阻塞API。非阻塞API可以采用多种形式来实现，包括回调函数，promise，fibers或者响应式扩展。vert.x的核心API使用回调函数的风格，但是它也支持其他模型，如RxJava 1和2。
在某些情况下，使用异步的API编程可能比使用经典的顺序代码风格更具有挑战性，特别是需要按照顺序完成若干操作。另外，使用异步API时，错误的传播也更为复杂。
vertx-lang-kotlin-coroutines使用协程。协程是非常轻量级的线程，而且不与底层的内核线程对应。所以当协程需要“阻塞”时，它会暂停并释放当前的内核线程，使得另一个协程可以处理事件。
vertx-lang-kotlin-coroutines使用kotlinx.coroutines来实现协程。
 vertx-lang-kotlin-coroutines目前仅适用于kotlin，而且是kotlin1.1的一个实验特性。
 从一个vertx.x的contex中启动协程 导入io.vertx.kotlin.coroutines.VertxCoroutine，launch（协程生成器）方法中允许运行一段代码作为可以暂停的协程：
val vertx = Vertx.vertx() vertx.deployVerticle(ExampleVerticle()) launch(vertx.dispatcher()) { val timerId = awaitEvent&amp;lt;Long&amp;gt; { handler -&amp;gt; vertx.setTimer(1000, handler) } println(&amp;#34;Event fired from timer with id ${timerId}&amp;#34;) } vertx.dispatcher()返回一个使用vert.x的事件循环执行协程的disptacher。
awaitEvent函数暂停协程的执行直到定时器触发为止，并使用赋给handler的值恢复协程。
有关handlers，events和事件流的更多细节，将在下一节中给出。
继承CoroutineVerticle 你可以将代码部署为io.vertx.kotlin.coroutines.CoroutineVerticle的实例，这是kotlin协程的专用类型。你应该重载verticle的start()方法，stop()方法的重载是可选的：
class MyVerticle : CoroutineVerticle() { suspend override fun start() { // ...  } } 获得一次性的异步结果 vert.x的许多异步操作都采用Handler&amp;lt;AsyncResult&amp;gt;作为最后一个参数。一个例子就是使用vert.x的mongo client执行对象检索，或者是发送一个事件总线消息之后等待回复。
这是通过awaitResult方法来实现，它返回一个值或者抛出一个异常。
协程会一直处于暂停的状态知道事件被处理，并且这时没有内核线程被阻塞。
The method is executed by specifying the asynchronous operation that needs to be executed in the form of a block that is passed to the handler at run-time.</description>
    </item>
    
    <item>
      <title>小议async/await和coroutine</title>
      <link>https://zhenfeng-zhu.github.io/posts/async/</link>
      <pubDate>Mon, 21 May 2018 19:37:14 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/async/</guid>
      <description>Being happy doesn&amp;rsquo;t mean that everything is perfect. It means that you decided to look beyond the imperfections.
 后端编程，涉及最多的就是并发。简单理解就是：
 并发是同时管理多个任务去执行，并行是针对多核处理器，同时执行多个任务。可以理解为一个是manage，一个是run。
 并发一般特指IO，IO是独立于CPU的设备，IO设备通常远远慢于CPU，所以我们引入了并发的概念，让CPU可以一次性发起多个IO操作而不用等待IO设备做完一个操作再做令一个。原理就是非阻塞操作+事件通知。
硬件底层上我其实不关心，主要就是在写程序上，如何简单的去写并发的代码。在语法层面上对并发做的比较好的，很适合做服务端，比如go，比如node，又比如某些函数式语言。我最近最近主要使用的是node和kotlin。
那么在写并发代码的时候，就会时不时的想这样一个问题：
一个问题 当代码遇到一个“暂时不能完成”的流程时（例如建立一个tcp链接，可能需要5ms才能建立），他不想阻塞在这里睡眠，想暂时离开现场去干点别的事情（例如看看另外一个已经建立的链接是否可以收包了）。问题是：离开现场后，当你回来的时候，上下文还像你走的时候吗？
跳转离开，在任何语言里都有2种最基本的方法：1）从当前函数返回； 2）调用一个新的函数。 前者会把上下文中的局部变量和函数参数全部摧毁，除非他返回前把这些变量找个别的地方保存起来；后者则能保护住整个上下文的内存（除了协程切换后会摧毁一些寄存器），而且跳转回来也是常规方法：函数返回。
在写node的时候，基本上是无脑上async/await。每次看到回调函数的时候，强迫症就犯了，总是想方设法将那个方法转成promise，然后使用await获得结果。无脑尝试了bluebird和node的util，虽然有些是很好用的，但是有的还是无法达到我预期的。靠着无脑的async/await，实现了很多功能，代码写起来也是快的飞起，但是只顾着做业务而不深入思考的话，是一个不好的表现，所以我就停下来搜了很多async/await的东西，特别是从阮一峰老师那里收获了很多。
js异步编程 因为js是单线程，所以异步编程对js特别重要。
实现异步主要有如下几种：
  回调函数
callback，英语直译就是重新调用。
所谓的回调函数就是把任务的第二段单独写在一个函数里面，等到重新执行这个任务的时候，直接调用这个函数。
回调本身没问题，但是就怕多重嵌套。
  promise
promise是一种新的写法，把回调函数的横向嵌套，用then的形式改成纵向的加载。
  协程
协程就是比线程更小的单位。
执行过程大致如下：
第一步，协程A开始执行。
第二步，协程A执行到一半，进入暂停，执行权转移到协程B。
第三步，（一段时间后）协程B交还执行权。
第四步，协程A恢复执行。
后面再展开说协程。
  很明显，在go火起来之后，很多编程语言都在往协程上靠，因为协程很好的将异步的写法转化成了同步的写法，降低了心智负担。js当然也不落后。
js的异步写法的演进
  generator
es6增加了generator函数，就是协程的一种实现，最大特点就是使用yield关键字就是用来交出函数的执行权。
function* gen(x){ var y = yield x + 2; return y; } 不同于普通函数的地方在于调用generator函数的时候，不返回结果，而是会返回一个内部的指针。调用指针的next方法，会移动内部指针（即执行异步任务的第一段），遇到的yield语句就交出执行权，执行别的代码。下次再调用该函数指针的next方法，就继续执行到该函数的下一个yield语句。</description>
    </item>
    
    <item>
      <title>elasticsearch</title>
      <link>https://zhenfeng-zhu.github.io/posts/elasticsearch/</link>
      <pubDate>Sun, 20 May 2018 14:17:07 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/elasticsearch/</guid>
      <description>以前没有好好学的东西，现在在工作中慢慢的补回来了。
基础概念  索引  es是将数据存储在一个或者多个索引（index）中。
索引就像是数据库。
 文档  文档是es的实体。由字段构成，每个字段包含字段名和一个或者多个字段值。
文档就像数据库中的一条条记录。
 类型  每个文档都有一个类型与之相对应。
类型就像数据库中的表。
 映射  所有文档在被写入到es中，都会被分析。由用户设置一些参数决定如何分割词条、哪些字应该被过滤掉等等。
 节点  单个es服务实例就是一个节点。
 集群  多个协同工作的es节点的集合就是集群。
 分片  es将数据分散到多个物理的Lucene索引上，这些物理Lucene索引被称为分片。
 副本  副本就是每个分片都做冗余处理，一个宕机之后，不影响服务。
快速入门 安装 es的安装很简单，我这里使用的是mac，下载下来zip包，解压即可使用。
[elasticsearch-6.2.4] pwd /Users/zhuzhenfeng/Documents/software/elasticsearch-6.2.4 [elasticsearch-6.2.4] ./bin/elasticsearch Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. [2018-05-20T17:18:37,619][INFO ][o.e.n.Node ] [] initializing .</description>
    </item>
    
    <item>
      <title>git常用操作</title>
      <link>https://zhenfeng-zhu.github.io/posts/git/</link>
      <pubDate>Mon, 14 May 2018 10:04:02 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/git/</guid>
      <description>整理一下常用的git操作，不用再到处找了。
git放弃本地修改，强制更新 git fetch --all git reset --hard origin/master git修改远程仓库地址 git remote set-url origin url cherry-pick 当你通过一番挣扎终于搞定一个bug,顺手提交到 git 服务器,心里一阵暗爽. 这时发现你当前所在的分支是 master !!!
这个分支不是开发者用来提交代码的,可惜现在剁手也晚了.
 先切换到master  git checkout master git log  复制提交的commit id
  切换到dev, cherry-pick
  git checkout dev git cherry-pic ${commit_id} 常用开发流程 git checkout -b feature1
git commit之后，进行rebase
git pull &amp;ndash;rebase
gca!
git rvm</description>
    </item>
    
    <item>
      <title>node的cluster</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84cluster/</link>
      <pubDate>Sat, 05 May 2018 15:45:47 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84cluster/</guid>
      <description>我们知道js是运行单线程的，也就是说一个node进程只能运行在一个cpu上。那么如果用node来做web server的话，就无法享受到多核运算的好处。
一个问题就是：
如何榨干服务器资源，利用多核CPU的并发优势。 node官方提供的解决方案是cluster。
1 cluster是什么 简单来说：
 在服务器上同时启动多个进程。 每个进程都跑的是同一份源码。 这些进程可以同时监听一个端口。  其中：
 负责启动其他进程的叫做master进程，不做具体工作，只负责启动其他进程。 其他被启动的叫worker进程。他们接收请求，对外提供服务。 worker进程的数量一般根据服务器的cpu核数来决定，这样就可以完美利用多核资源。  以下是官方文档的一个例子：
const cluster = require(&#39;cluster&#39;); const http = require(&#39;http&#39;); const numCPUs = require(&#39;os&#39;).cpus().length; if (cluster.isMaster) { console.log(`主进程 ${process.pid} 正在运行`); // 衍生工作进程。 for (let i = 0; i &amp;lt; numCPUs; i++) { cluster.fork(); } cluster.on(&#39;exit&#39;, (worker, code, signal) =&amp;gt; { console.log(`工作进程 ${worker.process.pid} 已退出`); }); } else { // 工作进程可以共享任何 TCP 连接。 // 在本例子中，共享的是一个 HTTP 服务器。 http.</description>
    </item>
    
    <item>
      <title>node踩坑</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E8%B8%A9%E5%9D%91/</link>
      <pubDate>Sat, 05 May 2018 15:32:59 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E8%B8%A9%E5%9D%91/</guid>
      <description>module 首先第一个就是es6的module。
看到别人写的
import { a } from &amp;quot;./module&amp;quot;; 所以自己也想要这么写，但是每次运行的时候都会报错。
// demo2.js export const a = &amp;quot;hello&amp;quot;; //demo1.js import { a } from &amp;quot;./demo2&amp;quot;; function hello() { console.log(a); } zhuzhenfengdeMacBook-Pro :: node/node-example » node demo1.js /Users/zhuzhenfeng/Documents/github/node/node-example/demo1.js:1 (function (exports, require, module, __filename, __dirname) { import { a } from &amp;quot;./demo2&amp;quot;; ^ SyntaxError: Unexpected token { at new Script (vm.js:74:7) at createScript (vm.js:246:10) at Object.runInThisContext (vm.js:298:10) at Module._compile (internal/modules/cjs/loader.js:646:28) at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10) at Module.</description>
    </item>
    
    <item>
      <title>node学习笔记</title>
      <link>https://zhenfeng-zhu.github.io/posts/node-learning/</link>
      <pubDate>Sun, 22 Apr 2018 15:41:21 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node-learning/</guid>
      <description>写node也有一段时间了，整理一下学习笔记，共同进步
什么是node？ 首先看一下什么是node.js
 Node 是一个服务器端 JavaScript Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效 Node.js 的包管理器 npm，是全球最大的开源库生态系统  模块系统是node最基本也是最常用的。一般可以分为四类：
 原生模块 文件模块 第三方模块 自定义模块  node社区崇尚DRY文化，即Don&amp;rsquo;t repeate yourself。这种文化使得node的生态异常繁荣，同样也由于某些包的质量低下引来了一些诟病。
谈谈自定义模块 我们在写node程序的时候，一般都是在写自定义模块。
  创建模块
// b.js function FunA(){ return &amp;quot;hello world&amp;quot;; } // 暴露方法FunA module.exports = FunA;   加载模块
// a.js const FunA=require(&#39;./b.js&#39;); // 运行FunA const name=FunA(); console.log(name);   在做模块到处的时候有两种方式：
  module.exports
module.exports 就 Node.</description>
    </item>
    
    <item>
      <title>node的redis实战</title>
      <link>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84redis%E5%AE%9E%E6%88%98/</link>
      <pubDate>Fri, 13 Apr 2018 10:00:12 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/node%E7%9A%84redis%E5%AE%9E%E6%88%98/</guid>
      <description>Node.js Redis客户端模块 为了追新，这里我使用的yarn，毕竟我是HDD（面向热点编程）编程实践者。
模块安装
yarn add redis 模块使用实例
const redis = require(&#39;redis&#39;) const client = redis.createClient(&#39;6379&#39;, &#39;127.0.0.1&#39;) client.on(&amp;quot;error&amp;quot;, function (err) { console.log(&amp;quot;Error &amp;quot; + err); }); client.set(&amp;quot;string key&amp;quot;, &amp;quot;string val&amp;quot;, redis.print); client.hset(&amp;quot;hash key&amp;quot;, &amp;quot;hashtest 1&amp;quot;, &amp;quot;some value&amp;quot;, redis.print); client.hset([&amp;quot;hash key&amp;quot;, &amp;quot;hashtest 2&amp;quot;, &amp;quot;some other value&amp;quot;], redis.print); client.hkeys(&amp;quot;hash key&amp;quot;, function (err, replies) { console.log(replies.length + &amp;quot; replies:&amp;quot;); replies.forEach(function (reply, i) { console.log(&amp;quot; &amp;quot; + i + &amp;quot;: &amp;quot; + reply); }); client.</description>
    </item>
    
    <item>
      <title>谈谈web框架</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E8%B0%88%E8%B0%88web%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Sun, 08 Apr 2018 16:01:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E8%B0%88%E8%B0%88web%E6%A1%86%E6%9E%B6/</guid>
      <description>这篇文章打的标签比较多，也基本涵盖了我所了解的一些知识，归纳总结一下自己对web框架的理解。自己了解的也不是很多，也请多多指教。
写程序免不了要做web相关的，现在由于前后端的分离，后端一般只提供rest接口，前端一般使用node来做渲染。在之前使用jsp那一套的时候，基本上都要写html+js的前端的一套，也要写后端java的CRUD。
我理解的web框架中，大致是分为这么两类：
 router框架 mvc框架  mvc类框架 mvc，初级程序员面试笔试的时候必考的一个知识点。model-view-controller，即模型-视图-控制器。
 m，模型主要用于封装与应用程序相关的数据以及对数据的处理方法。 v，在 View 中一般没有程序上的逻辑。为了实现 View 上的刷新功能，View 需要访问它监视的数据模型（Model），因此应该事先在被它监视的数据那里注册。 c，用于控制应用程序的流程。  我了解比较多的mvc框架是spring mvc。spring、spring mvc和spring boot等，他们并不是一个概念，也不是仅仅用于web开发。但是在这里我就不分那么细，统一用spring来代替。这里所说的spring都是指狭义上的web开发方面。
在做web开发的时候，项目目录一般是这样的：
 $ tree [16:23:43] . ├── mvnw ├── mvnw.cmd ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── example │ │ └── demo │ │ └── DemoApplication.java │ └── resources │ ├── application.properties │ ├── static │ └── templates └── test └── java └── com └── example └── demo └── DemoApplicationTests.</description>
    </item>
    
    <item>
      <title>技术栈</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%8A%80%E6%9C%AF%E6%A0%88/</link>
      <pubDate>Thu, 05 Apr 2018 09:49:06 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%8A%80%E6%9C%AF%E6%A0%88/</guid>
      <description>创业公司真的比较锻炼人，接触了很多的东西，视野开阔了，但是在某些时候自己疲于奔命，每个东西都是接触了一点点就被赶鸭子上架开始开发了。
技术栈  Docker  docker是一个容器，以前就看过docker相关的东西，但是没有仔细研究，docker的命令会用一些，在工作中使用了，看了一本docker的书，能够编写docker的compose文件。
 rancher  rancher是一个做容器管理的。我们把主机添加到rancher中，他就可以自动做到LB，服务的发现编排。我们部署的时候只需要编写catalog，他就可以自动发现docker应用，然后拉取镜像，部署到相关的机器上，很是方便。
 aws  近期主要是对aws的进行公司服务的部署，搭建一套rancher的环境。aws的服务特别多，ec2是实例主机，就和虚拟机一样，VPC就像机房，ec2依托于VPC而存在，在这基础上又了解了子网、DHCP弹性IP等等。
 kotlin  之前自己用kotlin开发过一个博客，对kotlin的感觉是有些东西写的很爽，但是还是觉得java好用一些，对kotlin的态度是用不用都无所谓。
 guice  这个我之前都读错了，我读成了盖斯，其实是和果汁的英文发音很像，ju斯。只是一个依赖注入框架，只是单纯的去做DI，比spring更轻量级一些。
需要我们编写AppModule.java去手动配置哪个类注入哪个类。
 rxjava  rxjava我都没有找到一个系统的教程，不知道该从哪里学习。
 vertx  vertx+Reactive编程的方式相当考验心智，自己脑子中的编程方式还没转过来。
 ES6  node代码中都是用es6来写的，async和await现在也会用了。
 express  想到自己大学的时候看过node的书，里面讲的就是express，只是自己当时没想明白，现在看的回调多了，算是熟悉了他这种的编程模式，所以觉得express特别简单易上手。
 typescript  还没它去写东西，可能下周会用它来写个机器人。
貌似自己已经完全抛弃了spring+java的那一套东西，没机会用到。
知识面扩展  监控  grafana+Prometheus+graylog去做可视化和日志的监控。
对于业务的数据，需要在代码层面进行埋点，把要监控的数据传给普罗米修斯。
 FSM状态机  机器人的框架使用的是FSM状态机来管理，以前做游戏的时候接触过。
 网关  网关现在已经是微服务架构中的标配了，用它来做一些限流，LB和日志收集等等。
我们使用的是kong，在这里kong加上一些插件，相当好用。
 规则引擎  在规则引擎中，都是一个个规则。
 DSL  领域特定语言，在规则引擎和机器人的时候，就用了DSL。我现在的理解就是DSL就是用编程语言实现的一些函数。
 Key Transparency  谷歌的一个公钥管理库，保证了无法被篡改。</description>
    </item>
    
    <item>
      <title>同步一个 fork</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%AA-fork/</link>
      <pubDate>Wed, 04 Apr 2018 16:01:31 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%AA-fork/</guid>
      <description>具体方法 Configuring a remote for a fork  给 fork 配置一个 remote 主要使用 git remote -v 查看远程状态。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)  添加一个将被同步给 fork 远程的上游仓库  git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git  再次查看状态确认是否配置成功。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push) Syncing a fork  从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master git fetch upstream  git fetch upstream # remote: Counting objects: 75, done.</description>
    </item>
    
    <item>
      <title>Go语言体会</title>
      <link>https://zhenfeng-zhu.github.io/posts/go%E8%AF%AD%E8%A8%80%E4%BD%93%E4%BC%9A/</link>
      <pubDate>Wed, 04 Apr 2018 13:48:57 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/go%E8%AF%AD%E8%A8%80%E4%BD%93%E4%BC%9A/</guid>
      <description>最近公司要统一技术栈，在kotlin和go之间选。我心里是比较倾向go的，主要有如下几点体会。
 语言简单，上手快。 gorotuine 易发布 垃圾回收 约定大于配置  我最早听说协程，是在大三找实习的时候，那个时候面试会问线程和进程的关系，问的深一些就是协程和线程的区别。游戏公司基本都用lua，看了lua的资料后，对协程有了一些自己的了解，随后就是在做Unity相关的开发，在unity中使用了很多的协程，但是在unity中使用的协程好像跟主流的不太一样，在看了go之后，豁然开朗。
goroutine使用的内存比线程更少，go在运行的时候会自动在配置的一组逻辑处理器上调度执行。比如：
func log(msg string){ ... } go log(&amp;quot;&amp;quot;) 使用关键字go，即可让log函数在一个goroutine里执行了。
并发最难的部分是要确保其他并发运行的进程、线程或者goroutine不会以外的修改数据。go使用了Channel的方式来解决这个问题。对于通道模式，保证同一时刻只会有一个goroutine修改数据。
说起go的语言简单，其实主要是他的类型比较简单。go使用的是组合模式，只需要将一个类型嵌入到另外一个类型就可以复用所有的功能。而且go还具有独特的接口实现机制，允许用户对行为进行建模，在go中不需要声明某个类型实现了某个接口，编译器会自动判断一个实例是使用什么接口。
对于java来说，所有的设计都是围绕着接口展开，于是在设计模式中，就是面向接口编程：
interface User{ void login(); void logout(); } 在java中，继承的类必须显式声明继承了此接口。而在go中接口只是描述一个动作，如果说是实现这个接口，只需要让某个实例实现了这个接口中的所有方法就行了。
type Reader interface{ Read(p []byte))(n int, err error) } 这其实和传统的oop语言的接口有着本质的区别，go中的接口一般只定义一个单一的动作，实际使用的过程中，这更有利于使用组合来复用代码。
约定大于配置这点，go在这方面上做的感觉有点儿吹毛求疵了，但是这样也使得程序可读性更强，没有很多垃圾代码。比如go的文件结构必须是src pkg 和bin 三个包，而且go也不允许你声明一个变量却不使用，导入了一个包却不使用，而且程序的代码也有约定，init方法比main方法更早执行。
go的并发 说到并发，就会想到另外一个概念，并行。可以简单这样的理解：
并发是同时管理多个事情，而并行是同时做很多事情。也就是并发是manage，并行是run。 对于单核处理器来讲，同一时刻只能有一个任务在执行，那么并发就是同时管理多个任务，让他们交替执行。并行是针对于多核处理器的，同一时刻可以把多个任务放在不同的处理器上执行，这样就可以同时执行。
在go里面主要是采用协程来实现并发的，也就是goroutine。与其他语言不同的是，go是在语法层面做到的，即go func();
语法 go f(x, y) go是关键字，后面跟函数。
例子 package main import ( &amp;quot;log&amp;quot; &amp;quot;time&amp;quot; ) func doSomething(id int) { log.Printf(&amp;quot;before do job:(%d) \n&amp;quot;, id) time.</description>
    </item>
    
    <item>
      <title>关于时间管理</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</link>
      <pubDate>Sun, 25 Mar 2018 20:28:42 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/</guid>
      <description>主动管理时间，敢于说不。
有目标向前看，没目标向钱看。</description>
    </item>
    
    <item>
      <title>一致性哈希算法</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sat, 24 Mar 2018 19:03:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/</guid>
      <description>当我们在做数据库分库分表或者做分布式缓存的时候，不可避免的都会遇到一个问题：
如何将数据均匀的分散到各个节点中，并且尽量的在加减节点的时能使受影响的数据最少。
1 hash取模 随机放置就不多说了。通常最容易想到的方案是哈希取模了。
可以将传入的key按照 $$ index=hash(key) % N $$ 这样来计算出需要存放的节点。
这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性比较差。比如增加或者删除一个节点的时候，所有的key都要重新计算，显然这样的成本比较高，为此需要一个算法来满足均匀的同时也要有良好的容错性和扩展性。
2 一致性hash算法 一致性hash算法是将所有的哈希值构成了一个环，其范围是0~2^32-1。如图：
之后将各个服务器节点散列到这个环上，可以用节点的IP，hostname这样唯一性的字段作为key进行hash。散列之后如下：
之后需要将数据定位到对应的节点上，使用同样的hash函数将key也映射到这个环上。
这样就按照顺时针方向就可以将k1定位到N1节点，k2定位到N3节点，k3定位到N2节点。
2.1 容错性 假设N1宕机了：
依然根据顺时针方向，k2和k3保持不变，只有k1被重新映射到了N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少部分数据。
2.2 扩展性 当新增一个节点时：
在N2和N3之间新增了一个节点N4，这时受影响的数据只有k3，其余的数据也是保持不变。
2.3 虚拟节点 到目前为止，该算法也有一些问题：
当节点较少的时候可能出现数据不均匀的情况：
这样会导致大部分数据都在N1节点，只有少量的数据在N2节点。
为了解决这个问题，一致性哈希算法引入了虚拟节点。
将每一个节点进行多次哈希，生成的节点放置在环上成为虚拟节点。
计算时可以在 IP 后加上编号来生成哈希值。
这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。
3 参考 https://crossoverjie.top/2018/01/08/Consistent-Hash/#more</description>
    </item>
    
    <item>
      <title>Spring Boot启动原理分析</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 24 Mar 2018 19:03:22 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/</guid>
      <description>Spring Boot启动原理分析 我们在开发spring boot应用的时候，一般会遇到如下的启动类：
@SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 从这段代码可以看出，注解@SpringBootApplication和SpringApplication.run()是比较重要的两个东西。
1 @SpringApplication注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ... } 在这段代码里，比较重要的只有三个注解：
 @Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan  其实，我们使用这三个注解来修饰springboot的启动类也可以正常运行,如下所示：
@ComponentScan @EnableAutoConfiguration @Configuration public class DemoApplication { public static void main(String[] args) { SpringApplication.</description>
    </item>
    
    <item>
      <title>Spring Data Jpa实战</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-data-jpa%E5%AE%9E%E6%88%98/</link>
      <pubDate>Sat, 24 Mar 2018 19:02:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-data-jpa%E5%AE%9E%E6%88%98/</guid>
      <description>为了解决抽象各个Java实体基本的“增删改查”操作，我们通常会以泛型的方式封装一个模板Dao来进行抽象简化，但是这样依然不是很方便，我们需要针对每个实体编写一个继承自泛型模板Dao的接口，再编写该接口的实现。虽然一些基础的数据访问已经可以得到很好的复用，但是在代码结构上针对每个实体都会有一堆Dao的接口和实现。
由于模板Dao的实现，使得这些具体实体的Dao层已经变的非常“薄”，有一些具体实体的Dao实现可能完全就是对模板Dao的简单代理，并且往往这样的实现类可能会出现在很多实体上。Spring-data-jpa的出现正可以让这样一个已经很“薄”的数据访问层变成只是一层接口的编写方式。
1 工程配置 1.1 pom &amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;UTF-8&amp;#34;?&amp;gt; &amp;lt;project xmlns=&amp;#34;http://maven.apache.org/POM/4.0.0&amp;#34; xmlns:xsi=&amp;#34;http://www.w3.org/2001/XMLSchema-instance&amp;#34; xsi:schemaLocation=&amp;#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&amp;#34;&amp;gt; &amp;lt;modelVersion&amp;gt;4.0.0&amp;lt;/modelVersion&amp;gt; &amp;lt;groupId&amp;gt;com.example&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;jpa-demo&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;0.0.1-SNAPSHOT&amp;lt;/version&amp;gt; &amp;lt;packaging&amp;gt;jar&amp;lt;/packaging&amp;gt; &amp;lt;name&amp;gt;jpa-demo&amp;lt;/name&amp;gt; &amp;lt;description&amp;gt;Demo project for Spring Boot&amp;lt;/description&amp;gt; &amp;lt;parent&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-parent&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.5.9.RELEASE&amp;lt;/version&amp;gt; &amp;lt;relativePath/&amp;gt; &amp;lt;!-- lookup parent from repository --&amp;gt; &amp;lt;/parent&amp;gt; &amp;lt;properties&amp;gt; &amp;lt;project.build.sourceEncoding&amp;gt;UTF-8&amp;lt;/project.build.sourceEncoding&amp;gt; &amp;lt;project.reporting.outputEncoding&amp;gt;UTF-8&amp;lt;/project.reporting.outputEncoding&amp;gt; &amp;lt;java.version&amp;gt;1.8&amp;lt;/java.version&amp;gt; &amp;lt;/properties&amp;gt; &amp;lt;dependencies&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-jpa&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-web&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt; &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-test&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;/dependencies&amp;gt; &amp;lt;build&amp;gt; &amp;lt;plugins&amp;gt; &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.</description>
    </item>
    
    <item>
      <title>spring boot多数据源配置</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 24 Mar 2018 19:01:37 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/</guid>
      <description>spring boot多数据源配置 在单数据源的情况下，Spring Boot的配置非常简单，只需要在application.properties文件中配置连接参数即可。但是往往随着业务量发展，我们通常会进行数据库拆分或是引入其他数据库，从而我们需要配置多个数据源。
1 准备 1.1 禁止DataSourceAutoConfiguration 首先要将spring boot自带的DataSourceAutoConfiguration禁掉，因为它会读取application.properties文件的spring.datasource.*属性并自动配置单数据源。在@SpringBootApplication注解中添加exclude属性即可：
@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(JpaDemoApplication.class, args); } } 1.2 配置数据库连接 然后在application.properties中配置多数据源连接信息：
spring.datasource.primary.url=jdbc:mysql://localhost:3306/test spring.datasource.primary.username=root spring.datasource.primary.password=root spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver spring.datasource.secondary.url=jdbc:mysql://localhost:3306/test1 spring.datasource.secondary.username=root spring.datasource.secondary.password=root spring.datasource.secondary.driver-class-name=com.mysql.jdbc.Driver 1.3 手段创建数据源 由于我们禁掉了自动数据源配置，因些下一步就需要手动将这些数据源创建出来：
@Configuration public class DataSourceConfig { @Bean(name = &amp;quot;primaryDataSource&amp;quot;) // @Qualifier(value = &amp;quot;primaryDataSource&amp;quot;) @ConfigurationProperties(prefix = &amp;quot;spring.datasource.primary&amp;quot;) public DataSource primaryDataSource(){ return DataSourceBuilder.create().build(); } @Bean(name = &amp;quot;secondaryDataSource&amp;quot;) // @Qualifier(value = &amp;quot;secondaryDataSource&amp;quot;) @ConfigurationProperties(prefix = &amp;quot;spring.</description>
    </item>
    
    <item>
      <title>spring boot连接redis</title>
      <link>https://zhenfeng-zhu.github.io/posts/spring-boot%E8%BF%9E%E6%8E%A5redis/</link>
      <pubDate>Sat, 24 Mar 2018 19:00:48 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/spring-boot%E8%BF%9E%E6%8E%A5redis/</guid>
      <description>Spring-data-redis为spring-data模块中对redis的支持部分，简称为“SDR”，提供了基于jedis客户端API的高度封装以及与spring容器的整合，
jedis客户端在编程实施方面存在如下不足：
 connection管理缺乏自动化，connection-pool的设计缺少必要的容器支持。 数据操作需要关注“序列化”/“反序列化”，因为jedis的客户端API接受的数据类型为string和byte，对结构化数据(json,xml,pojo等)操作需要额外的支持。 事务操作纯粹为硬编码 pub/sub功能，缺乏必要的设计模式支持，对于开发者而言需要关注的太多。  1 spring-data-redis特性  连接池自动管理，提供了一个高度封装的“RedisTemplate”类 针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口  ValueOperations：简单K-V操作 SetOperations：set类型数据操作 ZSetOperations：zset类型数据操作 HashOperations：针对map类型的数据操作 ListOperations：针对list类型的数据操作   提供了对key的“bound”(绑定)便捷化操作API，可以通过bound封装指定的key，然后进行一系列的操作而无须“显式”的再次指定Key，即BoundKeyOperations：  BoundValueOperations BoundSetOperations BoundListOperations BoundSetOperations BoundHashOperations   将事务操作封装，有容器控制。 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)  JdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream/ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。 StringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。 JacksonJsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。因为jackson工具在序列化和反序列化时，需要明确指定Class类型，因此此策略封装起来稍微复杂。 OxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。   基于设计模式，和JMS开发思路，将pub/sub的API设计进行了封装，使开发更加便捷。 spring-data-redis中，并没有对sharding提供良好的封装，如果你的架构是基于sharding，那么你需要自己去实现，这也是sdr和jedis相比，唯一缺少的特性。  2 引入依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-redis&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; 3 配置 # REDIS (RedisProperties) # Redis数据库索引（默认为0） spring.redis.database=0 # Redis服务器地址 spring.redis.host=localhost # Redis服务器连接端口 spring.redis.port=6379 # Redis服务器连接密码（默认为空） spring.redis.password=root # 连接池最大连接数（使用负值表示没有限制） spring.redis.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制） spring.</description>
    </item>
    
    <item>
      <title>最终一致性的实现手段</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%AE%B5/</link>
      <pubDate>Sat, 24 Mar 2018 18:59:55 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%AE%B5/</guid>
      <description>最终一致性的实现手段 实现最终一致性有三种手段：可靠事件模式、业务补偿模式和TCC模式
1 可靠事件模式 可靠事件模式属于事件驱动架构，当某件重要的事情发生时，比如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会将订阅事件的微服务推送事件。
要实现这种模式需要消息队列实现事件的持久化和at least once的可靠事件投递模式。
1.1 本地事件表 本地事件表方法是将事件和业务数据保存在同一个数据库中，使用一个额外的事件恢复服务来恢复事件，由本地事物保证更新业务和发布事件的原子性。
但是业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。
1.2 外部事件 此方法是将事件持久化到外部的事件系统，事件系统需要提供实时事件服务以接受微服务发布的事件，同时事件系统还需要提供事件恢复服务来确认恢复事件。
1.3 不足 此过程可能出现重复消费的情况。
2 补偿模式 一般来讲，异常一般是由以下两种情况造成的：
业务异常：业务逻辑产生的错误，比如余额不足、库存不足等。
技术异常：非业务逻辑产生的异常，比如网络连接异常、超时等。
补偿模式就是使用一个额外的协调服务来协调各个需要保证一致性的其他服务。协调服务按顺序调用每一个服务，如果某个服务调用异常就取消之前所有已经调用成功的服务。
建议仅用于技术异常的情况。对于业务异常来讲，应该尽可能的去优化业务模式，以避免要求补偿事务。
2.1 常用手段 在实现补偿模式时应该做到两点：
 首先要确定失败的步骤和状态，从而确定要补偿的范围。 其次要能提供补偿操作使用的业务数据。  可以通过记录完整的业务流水的方法来实现上面两点要求。但是对于一个通用的补偿框架来说，预先知道微服务需要记录的业务要素是不可能的，那么就需要一种办法来保证业务流水的可扩展性，实践中主要有两种方法：大表和关联表。
 大表，顾明思议就是设计时除了必须的字段外，还需要预留大量的备用字段，框架可以提供辅助工具来将业务数据映射到备用字段中。大表对于框架层实现起来比较简单，但是也有一些难点，比如预留多少个字段合适，每个字段又需要预留多长。还有一个难点是如果仅从数据层面来查询数据，很难一眼看出备用字段的业务含义，维护过程不友好。 关联表，分为技术表和业务表。技术表中保存为实现补偿操作所需要的技术数据，业务表中保存业务数据。通过在技术表中增加业务表名和业务表主键来建立和业务数据的关联。关联表更灵活，能支持不同业务类型记录不同的业务要素。但是在框架的实现上难度较高，每次查询都需要复杂的关联动作，性能会受到影响。  2.2 重试 补偿过程作为一个服务，在调用的时候也会出现不成功的情况，这时就要通过重试机制来保证补偿的成功率。因此要求补偿操作具有幂等性。
但是也不是盲目的重试，我们需要根据服务执行失败的原因来选择不同的策略：
 因业务因素导致失败，需要停止重试。 罕见的异常，如网络中断，传输过程中数据丢失，应该立即重试。 如果是因为系统繁忙，此时需要等待一段时间再重试。  2.3 不足 在补偿模式中有一个明显的缺陷是隔离性，从第一个服务开始一直到补偿完成，不一致性是对其他服务可见的。另外补偿模式过分依赖协调服务的健壮性，如果协调服务异常，则没办法达到一致性。
3 TCC模式 TCC，是Try，Confirm和Cancel的缩写。一个完整的TCC业务一般是由一个主业务和若干个从业务组成。
 Try  完成所有业务检查 预留必须的业务资源   Confirm  真正执行业务 不做任何业务检查 只使用Try阶段预留的业务资源 满足幂等性   Cancel  释放Try阶段预留的业务资源 满足幂等性    3.</description>
    </item>
    
    <item>
      <title>Reactive微服务</title>
      <link>https://zhenfeng-zhu.github.io/posts/reactive%E5%BE%AE%E6%9C%8D%E5%8A%A1/</link>
      <pubDate>Sat, 24 Mar 2018 17:57:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/reactive%E5%BE%AE%E6%9C%8D%E5%8A%A1/</guid>
      <description>Reactive微服务 分布式系统构建起来很困难，因为它们容易出问题，运行缓慢，并且被CAP和FLP理论所限制。换句话说，它们的构建和运维都特别复杂。为了解决这个问题，reactive便出现了。
Reactive编程：一种开发模型，其专注于数据流向、对变化的反馈，以及传播他们。
在reactive编程中，刺激信号是数据的转移，叫做streams。其实很像生产者——消费者模式，消费者对值进行订阅并响应。
Reactive系统：一种架构风格，其基于异步消息来构建响应式的分布式系统。
reactive系统使用了消息驱动的方法。所有的构建通过异步消息的发送和接收来交互。消息投递的逻辑由底层的实现决定。发送者不会阻塞着等待回复，它们可能会稍后才接收到回复。
reactive系统会有两个重要的特征：
  伸缩性——可以横向伸缩
伸缩性来自消息传递的解耦。消息被发送到一个地址之后，可以被一组消费者按照一种负载均衡方法消费。当reactive系统遇到负载高峰时，它可以创造出新的消费者，并在此之后销毁它们。
  恢复性——可以处理错误并且恢复
首先，这种消息交互模式允许组件在其本地处理错误，组件不需要等待消息，因此当一个组件发生错误时，其他组件仍然会正常工作。其次，当一个处理消息的组件发生错误后，消息可以可以传递给在相同地址注册的其他组件。
  reactive微服务系统是由reactive微服务组成的。这些微服务有下面四个特征：
 自治性 异步性 恢复性 伸缩性  Reactive微服务是可自治的。他们可以根据周围的服务是否可用来调整自己的行为。自治性往往伴随着孤立性；Reactive微服务可以在本地处理错误、独立地完成任务，并在必要时和其他服务合作。它们使用异步消息传递的机制和其他服务沟通；它们也会接收消息并且对其作出回应。
得益于异步消息机制，reactive微服务可以处理错误并根据情况调整自己的行为。错误不会被扩散，而是在靠近错误源头的地方被处理掉。当一个微服务挂掉之后，它的消费者微服务要能够处理错误并避免扩散。这一孤立原则是避免错误逐层上浮而毁掉整个系统的关键。可恢复性不只是关于处理错误，它还涉及到自愈性；一个reactive微服务应该能够从错误中恢复并且对错误进行补救。
最后，reactive微服务必须是可伸缩的，这样系统才可以根据负载情况来调整节点数量。这一特性意味着将会有一系列的限制，比如不能有在内存中的状态，要能够在必要时同步状态信息，或者要能够将消息路由到状态信息相同的节点。
Vert.x Vert.x是一个用于构建reactive和分布式系统的工具箱，其使用了异步非阻塞编程模型。当使用Vert.x构建微服务的时候，微服务会自然地带上一个核心特征：所有事情都是异步的。
传统编程模式
int res = compute(1, 2); 在这段代码中，是在等待compute函数计算出来结果之后再进行剩下的操作。而在异步非阻塞的编程模式中，将会创建一个handler：
compute(1, 2, res -&amp;gt; { // called with the result }); 在上述代码中，compute函数不再返回一个结果，而是传一个handler，当结果准备好时调用就可以了。得益于这种开发模型，可以使用很少的线程去处理高并发工作。在vert.x中，到处都可以看到这种形式的代码，比如创建http服务器时：
vertx.createHttpServer() .requestHandler(request -&amp;gt; { request.response().end(&amp;quot;hello vert.x&amp;quot;); }) .listen(8080); 这个例子中，我们让一个requestHandler接收HTTP请求(事件)并且返回&amp;quot;hello vert.x&amp;quot;。Handler是一个函数，当事件发生时，它会被调用。在我们的例子中，handler代码会在每次请求进来时被调用执行。要注意的是，Handler并不会返回一个结果，但是它可以提供一个结果；这个结果是怎样被提供的，这个要看是哪种交互行为。在上面的代码段中，它只是向一个HTTP response写入了结果。这个Handler后面跟了一个方法令其监听8080端口。调用这个HTTP服务它会返回一个简单的response。
event loop 绝大多数情况，Vert.x会用一个叫做event loop的线程来调用所有的handler。
基于消息循环的线程模型有一个很大的优点：它简化了并发。因为只有一个线程存在，因此永远都只被一个线程调用而不存在并发的情况。但是同样也有一个限制：
 不要阻塞消息循环
 因为没有阻塞，一个消息循环线程可以短时间内分发巨量的事件，这个模式就叫做reactor模式。
verticles Verticles是被Vert.x部署和运行的代码块。一个微服务的应用，是由运行在同一个Vert.x实例上的若干verticle组成的。一个verticle通常会创建服务器或客户端、注册一组Handler，以及封装一部分系统的业务处理逻辑。</description>
    </item>
    
    <item>
      <title>Guice快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/guice%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:57:15 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/guice%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>Guice快速入门 接手的新项目主要是使用kotlin+vert.x来写的，使用gradle构建，依赖注入框架使用了guice。这段时间都是在熟悉代码的过程，恶补一些知识。
guice是谷歌推出的一个轻量级的依赖注入框架，当然spring也可以实现依赖注入，只是spring太庞大了。
1 基本使用 引入依赖 使用gradle或者maven，引入guice。
maven:
&amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.google.inject&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;guice&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;4.1.0&amp;lt;/version&amp;gt; &amp;lt;/dependency&amp;gt; Gradle:
compile &amp;quot;com.google.inject:guice:4.1.0&amp;quot; 项目骨架 首先需要一个业务接口，包含一个方法来执行业务逻辑，它的实现非常简单：
package com.learning.guice; public interface UserService { void process(); } package com.learning.guice; public class UserServiceImpl implements UserService { @Override public void process() { System.out.println(&amp;quot;我需要做一些业务逻辑&amp;quot;); } } 然后写一个日志的接口：
package com.learning.guice; public interface LogService { void log(String msg); } package com.learning.guice; public class LogServiceImpl implements LogService { @Override public void log(String msg) { System.out.println(&amp;quot;------LOG: &amp;quot; + msg); } } 最后是一个系统接口和相应的实现，在实现中使用了业务接口和日志接口处理业务逻辑和打印日志信息：</description>
    </item>
    
    <item>
      <title>kotlin快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/kotlin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:56:45 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/kotlin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>快速浏览一下 Kotlin 的语法。
基本语法 包定义和引用 在源文件头部：
package my.demo import java.util.* 方法定义  带有方法体，并且返回确定类型数据的定义方式，例如接受 Int 类型的参数并返回 Int 类型的值：  fun sum(a: Int, b: Int): Int { return a + b }  带有方法体，返回推断类型数据的定义方式，例如：  fun sum(a: Int, b: Int) = a + b  返回无意义类型的定义方式：  fun printSum(a: Int, b: Int): Unit { println(&amp;#34;sum of $aand $bis ${a + b}&amp;#34;) } 或者省略 Unit：
fun printSum(a: Int, b: Int) { println(&amp;#34;sum of $aand $bis ${a + b}&amp;#34;) } 变量定义  只赋值一次（只读）本地变量，val：  val a:Int = 1 // 指定初始值 val b = 2 // 类型自推断为 `Int` val c:Int // 当不指定初始值时需要指定类型 c = 3 // 延迟赋值   可变变量， var：  var x = 5 // 类型自推断为 `Int` x += 1  顶层变量  val PI = 3.</description>
    </item>
    
    <item>
      <title>RxJava2快速入门</title>
      <link>https://zhenfeng-zhu.github.io/posts/rxjava2%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 24 Mar 2018 17:55:56 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/rxjava2%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</guid>
      <description>RxJava2快速入门 引入依赖 compile &#39;io.reactivex.rxjava2:rxjava:2.0.1&#39; 写法 简单版本 	private static void helloSimple() { Consumer&amp;lt;String&amp;gt; consumer = new Consumer&amp;lt;String&amp;gt;() { @Override public void accept(String s) throws Exception { System.out.println(&amp;quot;consumer accept is &amp;quot; + s); } }; Observable.just(&amp;quot;hello world&amp;quot;).subscribe(consumer); } 复杂版本 	private static void helloComplex() { Observer&amp;lt;String&amp;gt; observer = new Observer&amp;lt;String&amp;gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(&amp;quot;onSubscribe: &amp;quot; + d); } @Override public void onNext(String s) { System.out.println(&amp;quot;onNext: &amp;quot; + s); } @Override public void onError(Throwable e) { System.</description>
    </item>
    
    <item>
      <title>领域实体类</title>
      <link>https://zhenfeng-zhu.github.io/posts/%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E7%B1%BB/</link>
      <pubDate>Sat, 24 Mar 2018 17:53:42 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E7%B1%BB/</guid>
      <description>在看项目代码的时候，发现了entity包和dto包，里面都是只保存数据的类，仔细查了资料，才发现java对于只保存数据的类有好几个分类。
 pojo类：这是普通的java类，具有一部分的get和set方法。 dto类：data transfer object 数据传输对象类，泛指用于展示层与服务层之间传输的对象。 vo类：vo有两种说法，一种是view object，一种是value object。 po类：persisent object 持久对象。和pojo类一样，也是只有get set方法，但是这种类一般是用于持久层。 bo类：business object，业务对象，表示应用程序领域内事物的所有实体类。 do类：domain object，领域对象，就是从现实中抽象出来的有形或者无形的业务实体。  根据我的经验来看，大部分人都没有分那么清楚，一般是把数据类放在domain包，或者entity包里。再细分一下的话，可以把dto类单独提取到一个包里。</description>
    </item>
    
    <item>
      <title>docker</title>
      <link>https://zhenfeng-zhu.github.io/posts/docker/</link>
      <pubDate>Sat, 24 Mar 2018 17:42:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/docker/</guid>
      <description>docker常用命令 docker   获取镜像
docker pull
  新建并启动
docker run
  列出镜像
docker image ls
docker images
  删除虚悬镜像
docker image prune
  删除本地镜像
docker iamge rm
  查看应用信息
docker logs
  dockerfile 一般步骤：  在一个目录里，新建一个文件，命名为Dockerfile 在Dockerfile的目录内，执行docker build  常用指令   FROM 指定基础镜像，且是第一条命令
  RUN 执行命令
shell格式
exec格式
  COPY和ADD指令是复制文件
  CMD指令和RUN类似，容器启动命令
shell格式
exec格式
参数列表格式
  ENV 设置环境变量</description>
    </item>
    
    <item>
      <title>express</title>
      <link>https://zhenfeng-zhu.github.io/posts/express/</link>
      <pubDate>Sat, 24 Mar 2018 17:41:01 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/express/</guid>
      <description>Express 快速入门 安装 npm init npm install --save express hello world var express = require(&#39;express&#39;); var app = express(); app.get(&#39;/&#39;, function (req, res) { res.send(&#39;Hello World!&#39;); }); app.listen(3000, function () { console.log(&#39;Example app listening on port 3000!&#39;); }); 执行命令运行应用程序
node app.js 然后，在浏览器中输入 http://localhost:3000/ 以查看输出。
express程序生成器 安装 npm install -g express-generator 示例 以下语句在当前工作目录中创建名为 myapp 的 Express 应用程序：
express --view=pug myapp 在 MacOS 或 Linux 上，采用以下命令运行此应用程序：
DEBUG=myapp:* npm start 然后在浏览器中输入 http://localhost:3000/ 以访问此应用程序。</description>
    </item>
    
    <item>
      <title>碎碎念</title>
      <link>https://zhenfeng-zhu.github.io/posts/a-month-in-finogeeks/</link>
      <pubDate>Sat, 24 Mar 2018 15:55:58 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/a-month-in-finogeeks/</guid>
      <description>一直没有机会写2017的年终总结，想到去年写的新的一年的计划，好像自己都没有按照计划来做，而且写的计划也不知道写到哪里去了。
站在现在的时间点去审视过去的一年，这个本命年还是发生了很多对自己的未来有着比较大影响的的事情。房子+女朋友+新工作，这些事情突然的涌现出来，搞得自己有些手忙脚乱。
梳理一下自己的收获吧：
首先当然是结识了一帮小伙伴，我们一起打农药，一起调bug，一起奋战双十一。
在技术上也有了一定的提升，关键是自己的视野上有了很大的变化，不再是像当初大学的时候，不知道自己在做什么。这里对我影响比较大的一个是phodal，看了他写的博客和书之后，对自己的触动很大，感觉他懂得很多东西，知识面很广，而且能够写出来，扩大了自己的影响力，所以我就想着自己能不能模仿他。另外一个就是田哥了，我觉得他是我认识的同龄人中，比较有自己想法的一个人，打进acm world final的人就是不一样，他看问题的角度比较新颖，而且归纳总结能力很强，给了我一些在编程上的指点，让我少走了很多弯路。
也很感谢自己的几个室友，让我不再感到孤单。自从刘巍来了深圳之后，11I更欢乐了，也更污了。我们经常在家里煮火锅吃，吃的特别爽，以至于现在我都不想去火锅店里吃，总觉得在家吃的比较爽。
女朋友，出乎我的意料，现在想想还是感觉活在梦里，略过略过。
至于买房，没买之前的想法盲目乐观，后来算了一下，要是在深圳买房的话，我每个月的房贷是2万多，关键是首付还不一定能搞得出来。还是建议在北上广深工作的人，有机会现在老家的省会一类的城市，先搞一套，以后可以置换，能上车的时候早点上车，也是相当于变相攒钱了。对于不会投资或者创业的朋友，有时候辛辛苦苦干一年之后算一下，不知不觉中，自己的钱都不知道花在了哪里，如果有房贷的话，等用的时候说不定卖掉还能赚一些钱。
感觉自己换公司还是挺戏剧化的，当时也没想着真的就换工作吧，只是想投投简历，然后去面试一波看看自己的水平怎么样。总觉得自己在招银的舒适区待的太久了，没有什么激情了。同时自己也想出来试试，万一公司上市，摇身一变成为富翁了。当然这是白日梦了，路还是要一步一步的走的。
总感觉自己想了很多东西，但是就是写不出来，自己讲故事的能力还是要提升一些。</description>
    </item>
    
    <item>
      <title>Java内存模型和线程</title>
      <link>https://zhenfeng-zhu.github.io/posts/java-memory-thread/</link>
      <pubDate>Thu, 22 Mar 2018 19:16:37 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/java-memory-thread/</guid>
      <description>java内存模型和线程  并发不一定依赖多线程，但是在java里面谈论并发，大多与线程脱不开关系。
 线程是大多是面试都会问到的问题。我们都知道，线程是比进程更轻量级的调度单位，线程之间可以共享内存。之前面试的时候，也是这样回答，迷迷糊糊，没有一个清晰的概念。
大学的学习的时候，写C和C++，自己都没有用过多线程，看过一个Windows编程的书，里面讲多线程的时候，一大堆大写的字母，看着一点都不爽，也是惭愧。后来的实习，写unity，unity的C#使用的是协程。只有在做了java后端之后，才知道线程到底是怎么用的。了解了java内存模型之后，仔细看了一些资料，对java线程有了更深入的认识，整理写成这篇文章，用来以后参考。
1 Java内存模型 Java虚拟机规范试图定义一种java内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致性内存访问的效果。
java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量的底层细节。（这里所说的变量包括了实例字段、静态字段和数组等，但不包括局部变量与方法参数，因为这些是线程私有的，不被共享。）
1.1 主内存和工作内存 java规定所有的变量都存储在主内存。每条线程有自己的工作内存。
线程的工作内存中的变量是主内存中该变量的副本，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存来完成。
1.2 内存之间的交互 关于主内存和工作内存之间的具体交互协议，java内存模型定义了8中操作来完成，虚拟机实现的时候必须保证每个操作都是原子的，不可分割的（对于long和double有例外）
 lock锁定：作用于主内存变量，代表一个变量是一条线程独占。 unlock解锁：作用于主内存变量，把锁定的变量解锁。 read读取：作用于主内存变量，把变量值从主内存传到线程的工作内存中，供load使用。 load载入：作用工作内存变量，把上一个read到的值放入到工作内存中的变量中。 use使用：作用于工作内存变量，把工作内存中的一个变量的值传递给执行引擎。 assign：作用于工作内存变量，把执行引擎执行过的值赋给工作内存中的变量。 store存储：作用于工作内存变量，把工作内存中的变量值传给主内存，供write使用。  这些操作要满足一定的规则。
1.3 volatile volatile可以说是java的最轻量级的同步机制。
当一个变量被定义为volatile之后，他就具备两种特性：
  保证此变量对所有线程都是可见的
这里的可见性是指当一个线程修改了某变量的值，新值对于其他线程来讲是立即得知的。而普通变量做不到，因为普通变量需要传递到主内存中才可以做到这点。
  禁止指令重排
对于普通变量来说，仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执性顺序一致。
若用volatile修饰变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。
  volatile对于单个的共享变量的读/写具有原子性，但是像num++这种复合操作，volatile无法保证其原子性。
1.4 long和double long和double是一个64位的数据类型。
虚拟机允许将没有被volatile修饰的64位变量的读写操作分为两次32位的操作来进行。因此当多个线程操作一个没有声明为volatile的long或者double变量，可能出现操作半个变量的情况。
但是这种情况是罕见的，一般商用的虚拟机都是讲long和double的读写当成原子操作进行的，所以在写代码时不需要将long和double专门声明为volatile。
1.5 原子性、可见性和有序性 java的内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性。
原子性
基本数据类型的访问读写是剧本原子性的。
如果需要一个更大范围的原子性保证，java提供了lock和unlock操作，对应于写代码时就是synchronized关键字，因此在synchronized块之间的操作也是具备原子性的。
可见性
可见性是指当一个线程修改到了一个共享变量的值，其他的线程能够立即得知这个修改。共享变量的读写都是通过主内存作为媒介来处理可见性的。
volatile的特殊规则保证了新值可以立即同步到主内存，每次使用前立即从主内存刷新。
synchronized同步块的可见性是由”对于一个变量unlock操作之前，必须先把此变量同步回内存中“来实现的。
final的可见性是指被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把this的引用传递出去，那么在其他线程中就能看见final字段的值。
有序性
如果在本线程内观察，所有的操作都是有序的；如果在一个线程内观察另一个线程，所有的操作都是无序的。 volatile关键字本身就包含了禁止指令重排的语义，而synchronized则是由“一个变量在同一时刻只允许一条线程对其进行lock操作”这条规则来实现有序性的。
1.6 先行发生原则 如果java内存模型中的所有有序性都是靠着volatile和synchronized来完成，那有些操作将会变得很繁琐，但是我们在写java并发代码的时候没有感受到这一点，都是因为java有一个“先行发生”原则。
先行发生是java内存模型中定义的两项操作之间的偏序关系，如果说操作A先发生于操作B，其实就是说在发生B之前，A产生的影响都能被B观察到，这里的影响包括修改了内存中共享变量的值、发送了消息、调用了方法等等。
  程序次序规则
在一个线程内，按程序代码控制流顺序执行。</description>
    </item>
    
    <item>
      <title>aws.md</title>
      <link>https://zhenfeng-zhu.github.io/posts/aws-md/</link>
      <pubDate>Thu, 22 Mar 2018 14:04:09 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/aws-md/</guid>
      <description>一些基础概念
EC2 云服务器，可以理解成虚拟机，新建一个实例，就是新建一个虚拟机并安装操作系统（Linux或者windows）。
VPC Virtual Private Cloud。可以理解成数据中心，机房。对于灾备或者双活需要的，可以创建两个VPC。
子网 一个VPC里可以有多个子网。比如某机构的一个VPC可以办公网和生产网段，或者内网和外网。一般外网可以被访问，内网的话可以是数据库的服务器之类的。
IAM角色 类似于用户，可以被分配权限。
安全组 控制连接到此EC2实例的流量，或者是控制对外暴露的端口。
CIDR CIDR主要是一个按位的、基于前缀的，用于解释IP地址的标准。当用二进制表示这些地址时，它们有着在开头部分的一系列相同的位。
IPv4的CIDR地址块的表示方法和IPv4地址的表示方法是相似的：由四部分组成的点分十进制地址，后跟一个斜线，最后是范围在0到32之间的一个数字：A.B.C.D/N。点分十进制的部分和IPv4地址一样是一个被分成四个八位位组的32位二进制数。斜线后面的数字就是前缀长度，也就是从左到右，被地址块里的地址所共享的位的数目。
十进制部分有时会被省略，因此，/20就表示一个前缀长度是20的CIDR地址块。如果一个IP地址的前N位与一个CIDR地址块的前缀是相同的话，那么就说这个地址属于这个CIDR地址块，也可以说是与CIDR地址块的前缀匹配。所以，要理解CIDR，就要把地址写成二进制的形式。</description>
    </item>
    
    <item>
      <title>Hello World</title>
      <link>https://zhenfeng-zhu.github.io/posts/hello-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://zhenfeng-zhu.github.io/posts/hello-world/</guid>
      <description>Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.
Quick Start Create a new post $ hexo new &amp;#34;My New Post&amp;#34; More info: Writing
Run server $ hexo server More info: Server
Generate static files $ hexo generate More info: Generating
Deploy to remote sites $ hexo deploy More info: Deployment</description>
    </item>
    
  </channel>
</rss>
