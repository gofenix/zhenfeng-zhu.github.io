[{"content":"永别了 正如 Semisonic 在 90 年代的热门歌曲 \u0026ldquo;Closing Time \u0026ldquo;所告诉我们的那样，每一个新的开始都来自于其他一些开始的结束。恭喜你，高贵的读者，完成了这次 Clojure 之旅。我希望你发现它是有价值的，我也希望你期待着更多的东西！相信我，还有更多的东西等着你。\n相信我，还有很多东西。我最喜欢 Clojure 的一点是，它有一个完整的世界可以探索。逻辑编程、解析器、类型系统……只要你能说出计算机科学的一个有趣领域，你就可以用 Clojure 来研究它。我把我对下一步要去哪里的建议留给你。\n如果你想对 Clojure 生态系统有一个广泛的了解，请查看The Clojure Toolbox，它列出了数百个 Clojure 项目，并按照它们所解决的问题进行组织。\n如果你对网络编程感兴趣，一个很好的开始是 Luminus 框架（Luminus - 一个 Clojure 网络框架）。它的文档非常好，你很快就会有一个网站在运行。\n要想了解 Clojure 的最新动态，Eric Normand 的 Clojure Gazzette 是一个很好的资源（注册每周功能编程通讯）。当然，还有 Clojure 邮件列表（https://groups.google.com/forum/#!forum/clojure）和 Clojure subreddit 也是一个有用的、友好的地方（http://www.reddit.com/r/clojure）。\n如果 Twitter 是你选择的社交媒体，那么@swannodette (David Nolen), @gigasquid (Carin Meier), @puredanger (Alex Miller), @ztellman (Zach Tellman), @bbatsov (Bozidar Batsov) 和 @stuartsierra (Stuart Sierra) 是你的小红帽。你也可以关注我，@nonrecursive!\n再见了，小茶杯，祝你 Clojuring 愉快\n","permalink":"https://zhenfeng-zhu.github.io/posts/farewell/","summary":"永别了 正如 Semisonic 在 90 年代的热门歌曲 \u0026ldquo;Closing Time \u0026ldquo;所告诉我们的那样，每一个新的开始都来自于其他一些开始的结束。恭喜你，高贵的读者，完成了这次 Clojure 之旅。我希望你发现它是有价值的，我也希望你期待着更多的东西！相信我，还有更多的东西等着你。\n相信我，还有很多东西。我最喜欢 Clojure 的一点是，它有一个完整的世界可以探索。逻辑编程、解析器、类型系统……只要你能说出计算机科学的一个有趣领域，你就可以用 Clojure 来研究它。我把我对下一步要去哪里的建议留给你。\n如果你想对 Clojure 生态系统有一个广泛的了解，请查看The Clojure Toolbox，它列出了数百个 Clojure 项目，并按照它们所解决的问题进行组织。\n如果你对网络编程感兴趣，一个很好的开始是 Luminus 框架（Luminus - 一个 Clojure 网络框架）。它的文档非常好，你很快就会有一个网站在运行。\n要想了解 Clojure 的最新动态，Eric Normand 的 Clojure Gazzette 是一个很好的资源（注册每周功能编程通讯）。当然，还有 Clojure 邮件列表（https://groups.google.com/forum/#!forum/clojure）和 Clojure subreddit 也是一个有用的、友好的地方（http://www.reddit.com/r/clojure）。\n如果 Twitter 是你选择的社交媒体，那么@swannodette (David Nolen), @gigasquid (Carin Meier), @puredanger (Alex Miller), @ztellman (Zach Tellman), @bbatsov (Bozidar Batsov) 和 @stuartsierra (Stuart Sierra) 是你的小红帽。你也可以关注我，@nonrecursive!\n再见了，小茶杯，祝你 Clojuring 愉快","title":"Farewell 永别了"},{"content":"Boot，花哨的 Clojure 构建框架 Boot 是 Leiningen 的替代品，提供同样的功能。Leiningen 更受欢迎（截至 2015 年夏天），但我个人喜欢用 Boot 工作，因为它更容易扩展。本附录解释了 Boot 的基本概念，并指导你编写你的第一个 Boot 任务。如果你对使用 Boot 构建项目感兴趣，请查看它的 GitHub README（GitHub - boot-clj/boot: Build tooling for Clojure.）和它的 wiki（Home - boot-clj/boot Wiki - GitHub）。\n注意 截至本文写作时，Boot 对 Windows 的支持有限。Boot 团队欢迎大家的贡献!\nBoot 的抽象 Boot 由 Micha Niskin 和 Alan Dipert 创建，是对 Clojure 工具领域的一个有趣而强大的补充。从表面上看，它是构建 Clojure 应用程序和从命令行运行 Clojure 任务的一种便捷方式。深入研究一下，你会发现 Boot 就像 Git 和 Unix 的爱情结晶，它提供的抽象使你在操作系统和应用程序的交叉点上编写代码时更加愉快。\nUnix 提供了我们都很熟悉的抽象，以至于我们认为它们是理所当然的。(偶尔带你的电脑去吃一顿好的餐厅会死吗？) 进程抽象让你把程序推理成独立的逻辑单元，可以通过 STDIN 和 STDOUT 文件描述符轻松地组成一个流处理管道。这些抽象使某些类型的操作，如文本处理，变得非常直接。\n同样，Boot 也提供了一些抽象，使得独立的操作很容易被组合成构建工具最终要做的那种复杂、协调的操作，比如将 ClojureScript 转换为 JavaScript。 Boot 的任务抽象让你可以轻松地定义逻辑单元，通过文件集合进行通信。文件集合抽象可以跟踪不断变化的构建环境，并提供一个定义明确、可靠的任务协调方法。\n这就是很多高层次的描述，希望能吸引你的注意力。但是，如果我带着一板一眼的隐喻离开你，那就太丢人了。哦，不，亲爱的读者，这只是开胃菜而已。在本附录的其余部分，你将学习如何建立自己的 Boot 任务。在这一过程中，你会发现，构建工具实际上是有概念基础的。\n任务 像 make、rake、grunt 和其他以前的构建工具一样，Boot 让你定义任务。 任务是命名的操作，接受由某个中间程序（make、rake、Boot）调度的命令行选项。\nBoot 提供了调度程序boot和一个 Clojure 库，使你可以很容易地用deftask宏来定义命名的操作及其命令行选项。为了看看所有的大惊小怪，让我们来创建你的第一个任务。通常情况下，编程教程鼓励你写代码来打印 \u0026ldquo;Hello World\u0026rdquo;，但我希望我的例子能有真实的效用，所以你的任务是打印 \u0026ldquo;我的裤子着火了！\u0026rdquo; 这个信息客观上更有用。首先，安装 Boot；然后创建一个名为boot-walkthrough的新目录，导航到该目录，创建一个名为*build.boot**的文件，*然后这样写。\n(deftask fire \u0026quot;Prints 'My pants are on fire!'\u0026quot; [] (println \u0026quot;My pants are on fire!\u0026quot;)) 现在用boot fire从命令行运行这个任务；你应该看到你写的信息被打印到终端。这个任务展示了三个任务组件中的两个：任务被命名为（fire），并且由 boot 调度。这真是太酷了。你基本上已经创建了一个 Clojure shell 脚本，独立的 Clojure 代码，你可以轻松地从命令行运行。不需要project.clj，不需要目录结构，也不需要命名空间!\n让我们扩展一下这个例子，演示一下你如何编写命令行选项。\n(deftask fire \u0026quot;Announces that something is on fire\u0026quot; [t thing THING str \u0026quot;The thing that's on fire\u0026quot; p pluralize bool \u0026quot;Whether to pluralize\u0026quot;] (let [verb (if pluralize \u0026quot;are\u0026quot; \u0026quot;is\u0026quot;)] (println \u0026quot;My\u0026quot; thing verb \u0026quot;on fire!\u0026quot;))) 试着像这样运行该任务。\nboot fire -t heart # =\u0026gt; My heart is on fire! boot fire -t logs -p # =\u0026gt; My logs are on fire! 在第一种情况下，要么你是新近恋爱，要么你需要赶到急诊室。在第二个例子中，你是一个童子军，尴尬地表达了你对达到功绩勋章要求的兴奋。在这两种情况下，你都能轻松地指定任务的选项。\n这次对fire任务的改进引入了两个命令行选项，thing和pluralize。这两个选项都是用*域特定语言（DSL）*定义的。DSL 是他们自己的主题，但简单地说，这个术语指的是微型语言，你可以在一个大的程序中使用，为狭义的领域（如定义选项）编写紧凑的、富有表现力的代码。\n在选项thing中，t指定其短名称，thing指定其长名称。 THING有点复杂，我稍后会讲到它。 str指定了选项的类型，Boot 用它来验证参数并进行转换。 \u0026quot;着火的东西 \u0026quot;是该选项的文档。你可以用boot task-name -h`在终端查看一个任务的文档。\nboot fire -h # Announces that something is on fire # # Options: # -h, --help Print this help info. # -t, --thing THING Set the thing that's on fire to THING. # -p, --pluralize Whether to pluralize 相当棒的! Boot 使编写要从命令行调用的代码变得非常容易。\n现在，让我们看看THING。THING是一个optarg，它表示这个选项需要一个参数。当你定义一个选项时，你不需要包括 optarg（注意pluralize选项没有 optarg）。optarg 不必与选项的全名相对应；你可以用BILLY_JOEL'或其他你想要的东西来代替THING'，任务也会照常进行。你也可以使用 optarg 来指定复杂的选项。(访问https://github.com/boot-clj/boot/wiki/Task-Options-DSL#complex-options了解 Boot 关于这个问题的文档。) 基本上，复杂选项允许你指定选项参数应被视为 Map、集合、Vector，甚至是嵌套集合。这是很强大的。\nBoot 为你提供了用 Clojure 构建命令行界面所需的所有工具。而你才刚刚开始学习它!\nThe REPL Boot 有许多有用的内置任务，包括一个 REPL 任务。运行 boot repl 来启动这个小家伙。Boot 的 REPL 与 Leiningen 的类似，它负责加载你的项目代码，这样你就可以随意玩耍。你可能认为这不适用于你所写的项目，因为你只写了任务，但实际上你可以在 REPL 中运行任务（我省略了boot.user=\u0026gt;提示）。你可以用一个字符串指定选项。\n(fire \u0026quot;-t\u0026quot; \u0026quot;NBA Jam guy\u0026quot;) ; My NBA Jam guy is on fire! ; =\u0026gt; nil 注意，选项的值就在选项的后面。\n你也可以用关键字来指定一个选项。\n(fire :thing \u0026quot;NBA Jam guy\u0026quot;) ; My NBA Jam guy is on fire! ; =\u0026gt; nil 你也可以结合选项。\n(fire \u0026quot;-p\u0026quot; \u0026quot;-t\u0026quot; \u0026quot;NBA Jam guys\u0026quot;) ; My NBA Jam guys are on fire! ; =\u0026gt; nil (fire :pluralize true :thing \u0026quot;NBA Jam guys\u0026quot;) ; My NBA Jam guys are on fire! ; =\u0026gt; nil 当然，你也可以在 REPL 中使用deftask，毕竟这只是 Clojure。我们的收获是，Boot 可以让你把任务作为 Clojure 函数进行交互，因为它们就是这样的。\n组成和协调 如果到目前为止你所看到的就是 Boot 所能提供的一切，那它将是一个非常棒的工具，但它与其他构建工具没有什么不同。让 Boot 与众不同的一个特点是，它可以让你编排任务。为了便于比较，这里有一个 Rake 调用的例子（Rake 是主要的 Ruby 构建工具）。\nrake db:create d{:tag :a, :attrs {:href \u0026quot;db:seed\u0026quot;}, :content [\u0026quot;b:migra\u0026quot;]}te db:seed 这段代码将创建一个数据库，在其上运行迁移，并在 Rails 项目中运行时向其填充种子数据。然而，值得注意的是，Rake 并没有提供任何方法让这些任务之间相互通信。指定多个任务只是为了方便，让你不必运行rake db:create; rake db:migrate; rake db:seed。如果你想在任务 B 中访问任务 A 的结果，构建工具并不能帮助你；你必须自己管理这种协调。通常，你要做的是把任务 A 的结果塞进文件系统中的一个特殊位置，然后确保任务 B 读取这个特殊位置。这看起来就像用易变的全局变量进行编程，而且它也是很脆弱的。\nHandler 和中间件 Boot 通过将任务视为中间**件工厂来解决这个任务通信问题。如果你熟悉 Ring，Boot 的任务工作起来非常相似，所以请随意跳到\u0026ldquo;任务是中间件工厂 \u0026ldquo;第 287 页。如果你对中间件的概念不熟悉，请允许我解释一下! 中间件指的是程序员遵守的一套公约，这样他们就可以灵活地创建特定领域的功能管道。这是相当密集的，所以让我们解除密集。我将在本节中讨论灵活的部分，并在\u0026ldquo;文件集合 \u0026ldquo;第 288 页中介绍特定领域的。\n为了理解中间件方法与普通函数组合的不同之处，这里有一个组合日常函数的例子。\n(def strinc (comp str inc)) (strinc 3) ; =\u0026gt; \u0026quot;4\u0026quot; 这个函数组合并没有什么有趣的地方。事实上，这个函数组合是如此的不起眼，以至于我作为一个作家，要对它说些什么都很费劲。有两个函数，各自做自己的事情，现在它们被组成了一个。Whoop-dee-doo!\n中间件为函数组合引入了一个额外的步骤，使你在定义函数管道时有更大的灵活性。假设在前面的例子中，你想对任意的数字返回 \u0026ldquo;我不喜欢这个数字 X\u0026rdquo;，而对其他的东西返回一个字符串化的数字。以下是你如何做到这一点的。\n(defn whiney-str [rejects] {:pre [(set? rejects)]} (fn [x] (if (rejects x) (str \u0026quot;I don't like \u0026quot; x) (str x)))) (def whiney-strinc (comp (whiney-str #{2}) inc)) (whiney-strinc 1) ; =\u0026gt; \u0026quot;I don't like 2\u0026quot; 现在让我们再进一步。如果你想决定是否首先调用inc呢？清单 B-1 显示了你如何做到这一点。\n(defn whiney-middleware [next-handler rejects] {:pre [(set? rejects)]} (fn [x] ➊ (if (= x 1) \u0026quot;I'm not going to bother doing anything to that\u0026quot; (let [y (next-handler x)] (if (rejects y) (str \u0026quot;I don't like \u0026quot; y) (str y)))))) (def whiney-strinc (whiney-middleware inc #{2})) (whiney-strinc 1) ; =\u0026gt; \u0026quot;I'm not going to bother doing anything to that\u0026quot;  B-1. 函数组合的中间件方法让你引入选择权  在这里，你不是用comp来创建你的函数管道，而是将管道中的下一个函数作为第一个参数传递给中间件函数。在这种情况下，你将inc作为第一个参数传递给whiney-middleware作为next-handler。 whiney-middleware然后返回一个匿名函数，该函数关闭了inc并有能力选择是否调用它。你可以在➊看到这个选择。\n我们说，一个中间件把一个 Handler 作为它的第一个参数，并返回一个 Handler。在这个例子中，whiney-middleware将一个 Handler 作为它的第一个参数，inc，它返回另一个 Handler，即匿名函数，x是它唯一的参数。中间件也可以接受额外的参数，如rejects，作为配置。其结果是，中间件返回的 Handler 可以表现得更加灵活（由于配置），而且它对函数管道有更多的控制（因为它可以选择是否调用下一个 Handler）。\n任务是中间件工厂 Boot 通过将中间件的配置与 Handler 的创建分开，将这种使函数组合更加灵活的模式向前推进了一步。首先，你创建一个接受n配置参数的函数。这就是中间件工厂，它返回一个中间件函数。中间件函数希望得到一个参数，即下一个 Handler，并返回一个 Handler，就像前面的例子中一样。下面是一个发牢骚的中间件工厂。\n(defn whiney-middleware-factory [rejects] {:pre [(set? rejects)]} (fn [handler] (fn [x] (if (= x 1) \u0026quot;I'm not going to bother doing anything to that\u0026quot; (let [y (handler x)] (if (rejects y) (str \u0026quot;I don't like \u0026quot; y \u0026quot; :'(\u0026quot;) (str y))))))) (def whiney-strinc ((whiney-middleware-factory #{3}) inc)) 正如你所看到的，这段代码与清单 B-1 几乎相同。变化在于，最上面的函数，whiney-middleware-factory，现在只接受一个参数，rejects。它返回一个匿名函数，即中间件，它希望得到一个参数，即 Handler。其余的代码都是一样的。\n在 Boot 中，任务可以充当中间件工厂。为了说明这一点，让我们把fire任务分成两个任务：what和fire（见清单 B-2）。 what让你指定一个对象以及它是否是复数，而fire则宣布它着火了。这是伟大的模块化软件工程，因为它允许你添加其他任务，如gnomes，宣布一个东西被地精占领了，这在客观上同样有用。(作为一个练习，尝试创建 gnome 任务。它应该和what任务组成，就像fire一样）。\n(deftask what \u0026quot;Specify a thing\u0026quot; [t thing THING str \u0026quot;An object\u0026quot; p pluralize bool \u0026quot;Whether to pluralize\u0026quot;] (fn middleware [next-handler] ➊ (fn handler [fileset] (next-handler (merge fileset {:thing thing :pluralize pluralize}))))) (deftask fire \u0026quot;Announce a thing is on fire\u0026quot; [] (fn middleware [next-handler] ➋ (fn handler [fileset] (let [verb (if (:pluralize fileset) \u0026quot;are\u0026quot; \u0026quot;is\u0026quot;)] (println \u0026quot;My\u0026quot; (:thing fileset) verb \u0026quot;on fire!\u0026quot;) fileset))))  宣布某物着火的可组合 Boot 任务的完整代码  以下是你如何在命令行上运行它。\nboot what -t \u0026quot;pants\u0026quot; -p - fire 下面是在 REPL 中的运行方式。\n(boot (what :thing \u0026quot;pants\u0026quot; :pluralize true) (fire)) 等一下，那个boot'的调用是怎么回事？在➊和➋的fileset又是怎么回事？用Micha的话说，\u0026quot;boot宏负责设置和清理（创建初始文件集合，停止由任务启动的服务器，诸如此类的事情）。任务是函数，所以你可以直接调用它们，但如果它们使用了文件集合，就会失败，除非你通过boot`宏调用它们。\u0026rdquo; 让我们仔细看看文件集合的情况。\n文件集合 前面我提到，中间件是用来创建域特定的函数管道。这意味着每个 Handler 都期望接收特定领域的数据并返回特定领域的数据。以 Ring 为例，每个 Handler 都希望收到一个代表 HTTP 请求的请求 Map，它可能看起来像这样。\n{:server-port 80 :request-method :get :scheme :http} 每个 Handler 可以选择以某种方式修改这个请求 Map，然后再传递给下一个 Handler，例如，添加一个:params键，其中包含所有查询字符串和 POST 参数的漂亮 Clojure Map。环形 Handler 返回一个响应 Map，由:status'、:headers\u0026rsquo;和`:body\u0026rsquo;三个键组成，每个 Handler 可以再次以某种方式转换这些数据，然后再返回给其父 Handler。\n在 Boot 中，每个 Handler 接收并返回一个fileset。文件集合的抽象让你把文件系统上的文件当作不可更改的数据，这对构建工具来说是一项伟大的创新，因为构建项目是以文件为中心的。例如，你的项目可能需要在文件系统上放置临时的、中间的文件。通常，在大多数构建工具中，这些文件被放置在一些特别命名的地方，比如，project/target/tmp。这样做的问题是，project/target/tmp实际上是一个全局变量，其他任务可能会意外地把它搞乱。\nBoot 的文件集合抽象通过在文件系统上增加一层间接性来解决这个问题。比方说，任务 A 创建了文件 X，并告诉文件集合来存储它。在幕后，文件集合将该文件存储在一个匿名的临时目录中。然后，该文件集合被传递给任务 B，任务 B 修改了文件 X 并要求文件集合存储结果。在幕后，一个新的文件，文件 Y，被创建和存储，但文件 X 仍然没有被触动。在任务 B 中，一个更新的文件集合被返回。这相当于用 Map 做 \u0026ldquo;assoc-in\u0026rdquo;。任务 A 仍然可以访问原始文件集合和它引用的文件。\n在清单 B-2 中的what'和fire\u0026rsquo;任务中，你甚至都没有使用这些很酷的文件管理功能。尽管如此，当 Boot 组成任务时，它希望 Handler 能接收并返回 fileset 记录。因此，为了跨任务传达你的数据，你偷偷地用(merge fileset {:thing thing :pluralize pluralize})把它加到文件集合记录中。\n虽然这涵盖了中间件工厂的基本概念，但你还需要学习更多的东西来充分利用文件集合的优势。在 fileset wiki（Filesets - boot-clj/boot Wiki - GitHub）中，对使用 filesets 的机制都有解释。同时，我希望这些信息能给你一个很好的概念性概述!\n接下来的步骤 本附录的重点是解释 Boot 背后的概念。不过，Boot 还有一堆其他的功能，比如set-env!和task-options!，当你真正使用它的时候，会让你的编程生活更轻松。它提供了惊人的神奇功能，比如提供 classpath 隔离，这样你就可以用一个 JVM 运行多个项目，并让你在无需重启 REPL 的情况下向项目添加新的依赖项。如果 Boot 让你心痒难耐，请查看它的 README，了解更多关于实际使用的信息。另外，它的 wiki 提供了一流的文档。\n","permalink":"https://zhenfeng-zhu.github.io/posts/appendixb/","summary":"Boot，花哨的 Clojure 构建框架 Boot 是 Leiningen 的替代品，提供同样的功能。Leiningen 更受欢迎（截至 2015 年夏天），但我个人喜欢用 Boot 工作，因为它更容易扩展。本附录解释了 Boot 的基本概念，并指导你编写你的第一个 Boot 任务。如果你对使用 Boot 构建项目感兴趣，请查看它的 GitHub README（GitHub - boot-clj/boot: Build tooling for Clojure.）和它的 wiki（Home - boot-clj/boot Wiki - GitHub）。\n注意 截至本文写作时，Boot 对 Windows 的支持有限。Boot 团队欢迎大家的贡献!\nBoot 的抽象 Boot 由 Micha Niskin 和 Alan Dipert 创建，是对 Clojure 工具领域的一个有趣而强大的补充。从表面上看，它是构建 Clojure 应用程序和从命令行运行 Clojure 任务的一种便捷方式。深入研究一下，你会发现 Boot 就像 Git 和 Unix 的爱情结晶，它提供的抽象使你在操作系统和应用程序的交叉点上编写代码时更加愉快。\nUnix 提供了我们都很熟悉的抽象，以至于我们认为它们是理所当然的。(偶尔带你的电脑去吃一顿好的餐厅会死吗？) 进程抽象让你把程序推理成独立的逻辑单元，可以通过 STDIN 和 STDOUT 文件描述符轻松地组成一个流处理管道。这些抽象使某些类型的操作，如文本处理，变得非常直接。\n同样，Boot 也提供了一些抽象，使得独立的操作很容易被组合成构建工具最终要做的那种复杂、协调的操作，比如将 ClojureScript 转换为 JavaScript。 Boot 的任务抽象让你可以轻松地定义逻辑单元，通过文件集合进行通信。文件集合抽象可以跟踪不断变化的构建环境，并提供一个定义明确、可靠的任务协调方法。","title":"AppendixB 花哨的 Boot"},{"content":"用 Leiningen 构建和开发 用任何语言编写软件都需要生成工件，即可执行文件或库包，用于部署或共享。它还涉及到管理依赖工件，也称为依赖，以确保它们被加载到你正在构建的项目中。Clojurists 中最流行的管理工件的工具是 Leiningen，本附录将告诉你如何使用它。你还将学习如何使用 Leiningen 来完全增强你的开发经验，使用插件。\nArtifact Ecosystem 因为 Clojure 托管在 Java 虚拟机（JVM）上，所以 Clojure 的工件是以 JAR 文件的形式分发的（在第 12 章有介绍）。Java 地已经有一个处理 JAR 文件的完整的工件生态系统，Clojure 也使用它。神器生态系统并不是一个官方的编程术语；我用它来指代用于识别和分发神器的一套工具、资源和惯例。Java 的生态系统是围绕着 Maven 构建工具发展起来的，由于 Clojure 使用这个生态系统，你会经常看到对 Maven 的引用。Maven 是一个巨大的工具，可以执行各种古怪的项目管理任务。值得庆幸的是，你不需要获得 Maven 学的博士学位就能成为一名有效的 Clojurist。你需要知道的唯一特征是，Maven 规定了一种识别 Clojure 项目所遵守的工件的模式，它还规定了如何在 Maven 仓库中托管这些工件，Maven *仓库只是存储工件以供分发的服务器。\nIdentification Maven 工件需要一个组 ID，一个工件 ID，以及一个版本。你可以在project.clj文件中为你的项目指定这些。以下是你在第一章创建的clojure-noob项目的project.clj第一行的内容。\n(defproject clojure-noob \u0026quot;0.1.0-SNAPSHOT\u0026quot; clojure-noob是你项目的组 ID 和工件 ID，\u0026quot;0.1.0-SNAPSHOT\u0026quot;是其版本。一般来说，版本是永久性的；如果你将一个版本为 0.1.0 的工件部署到存储库，你不能对该工件进行修改并使用相同的版本号进行部署。您需要改变版本号。(许多程序员喜欢 Semantic Versioning 系统，您可以在*Semantic Versioning 2.0.0 | Semantic Versioning.*中阅读到这一系统。） 如果你想表明该版本是一个正在进行的工作，并且你计划不断地更新它，你可以在你的版本号后面加上-SNAPSHOT。\n如果你想让你的组 ID 与你的工件 ID 不同，你可以用斜线将两者分开，像这样。\n(defproject group-id/artifact-id \u0026quot;0.1.0-SNAPSHOT\u0026quot; 通常，开发者会使用他们的公司名称或 GitHub 用户名作为组的 ID。\n依赖 你的project.clj文件还包括一行看起来像这样的内容，它列出了你项目的依赖。\n :dependencies [[org.clojure/clojure \u0026quot;1.9.0\u0026quot;]] 如果你想使用一个库，使用与你命名项目时相同的命名模式将其添加到这个依赖 Vector 中。例如，如果你想轻松地处理日期和时间，你可以添加 clj-time 库，像这样。\n :dependencies [[org.clojure/clojure \u0026quot;1.9.0\u0026quot;] [clj-time \u0026quot;0.9.0\u0026quot;]] 下次你启动你的项目时，无论是通过运行它还是通过启动 REPL，Leiningen 都会自动下载 clj-time 并使其在你的项目中可用。\nClojure 社区创造了大量有用的库，寻找它们的好地方是*http://www.clojure-toolbox.com*的 Clojure 工具箱，它根据项目的目的进行分类。几乎每一个 Clojure 库都在其 README 的顶部提供了它的标识符，使你很容易找出如何把它添加到你的 Leiningen 依赖项中。\n有时你可能想使用一个 Java 库，但标识符并不那么容易获得。例如，如果你想添加 Apache Commons Email，你必须在网上搜索，直到你找到一个包含这样内容的网页。\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.commons\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-email\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.3.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 该 XML 是 Java 项目沟通其 Maven 标识符的方式。要把它添加到 Clojure 项目中，你需要修改:dependenciesVector，使其看起来像这样。\n :dependencies [[org.clojure/clojure \u0026quot;1.9.0\u0026quot;] [clj-time \u0026quot;0.9.0\u0026quot;] [org.apache.commons/commons-email \u0026quot;1.3.3\u0026quot;]] 主要的 Clojure 库是 Clojars（Clojars），主要的 Java 库是 The Central Repository（Maven Central Repository Search），人们通常只把它称为Central，就像旧金山居民把旧金山称为the city一样。你可以使用这些网站来寻找库和它们的标识符。\n要把你自己的项目部署到 Clojars，你所要做的就是在那里创建一个账户，然后在你的项目中运行lein deploy clojars。该任务会生成 Maven 工件所需的一切，包括 POM 文件（我就不多说了）和 JAR 文件，以便储存在仓库中。然后将它们上传到 Clojars。\n插件 Leiningen 让你使用插件，这是一些在你写代码时能帮助你的库。例如，Eastwood 插件是一个 Clojure 检查工具；它可以识别写得不好的代码。你通常要在*$HOME/.lein/profiles.clj文件中指定你的插件。要添加 Eastwood，你要把profiles.clj*改成这样。\n{:user {:plugins [[jonase/eastwood \u0026quot;0.2.1\u0026quot;]] ] 。}} 这就为你的所有项目启用了一个eastwood'Leiningen任务，你可以在项目的根目录下用lein eastwood\u0026rsquo;运行。\nLeiningen 的 GitHub 项目页面有关于如何使用配置文件和插件的优秀文档，它包括一个方便的插件列表。\n总结 本附录着重介绍了项目管理中那些重要但又难以了解的方面，比如什么是 Maven 以及 Clojure 与它的关系。它向你展示了如何使用 Leiningen 来命名你的项目，指定依赖关系，并部署到 Clojars。Leiningen 为软件开发任务提供了很多功能，但并不涉及实际编写代码。如果你想了解更多，请在网上查看 Leiningen 教程*[leiningen/TUTORIAL.md at stable - technomancy/leiningen - GitHub]（https://github.com/technomancy/leiningen/blob/stable/doc/TUTORIAL.md）*.\n","permalink":"https://zhenfeng-zhu.github.io/posts/appendixa/","summary":"用 Leiningen 构建和开发 用任何语言编写软件都需要生成工件，即可执行文件或库包，用于部署或共享。它还涉及到管理依赖工件，也称为依赖，以确保它们被加载到你正在构建的项目中。Clojurists 中最流行的管理工件的工具是 Leiningen，本附录将告诉你如何使用它。你还将学习如何使用 Leiningen 来完全增强你的开发经验，使用插件。\nArtifact Ecosystem 因为 Clojure 托管在 Java 虚拟机（JVM）上，所以 Clojure 的工件是以 JAR 文件的形式分发的（在第 12 章有介绍）。Java 地已经有一个处理 JAR 文件的完整的工件生态系统，Clojure 也使用它。神器生态系统并不是一个官方的编程术语；我用它来指代用于识别和分发神器的一套工具、资源和惯例。Java 的生态系统是围绕着 Maven 构建工具发展起来的，由于 Clojure 使用这个生态系统，你会经常看到对 Maven 的引用。Maven 是一个巨大的工具，可以执行各种古怪的项目管理任务。值得庆幸的是，你不需要获得 Maven 学的博士学位就能成为一名有效的 Clojurist。你需要知道的唯一特征是，Maven 规定了一种识别 Clojure 项目所遵守的工件的模式，它还规定了如何在 Maven 仓库中托管这些工件，Maven *仓库只是存储工件以供分发的服务器。\nIdentification Maven 工件需要一个组 ID，一个工件 ID，以及一个版本。你可以在project.clj文件中为你的项目指定这些。以下是你在第一章创建的clojure-noob项目的project.clj第一行的内容。\n(defproject clojure-noob \u0026quot;0.1.0-SNAPSHOT\u0026quot; clojure-noob是你项目的组 ID 和工件 ID，\u0026quot;0.1.0-SNAPSHOT\u0026quot;是其版本。一般来说，版本是永久性的；如果你将一个版本为 0.1.0 的工件部署到存储库，你不能对该工件进行修改并使用相同的版本号进行部署。您需要改变版本号。(许多程序员喜欢 Semantic Versioning 系统，您可以在*Semantic Versioning 2.0.0 | Semantic Versioning.*中阅读到这一系统。） 如果你想表明该版本是一个正在进行的工作，并且你计划不断地更新它，你可以在你的版本号后面加上-SNAPSHOT。\n如果你想让你的组 ID 与你的工件 ID 不同，你可以用斜线将两者分开，像这样。","title":"AppendixA 用 Leiningen 构建和开发"},{"content":"用 Multimethods、协议和记录创建和扩展抽象概念 花一分钟思考一下，作为大自然的顶级产品之一：人类是多么伟大。作为一个人类，你可以在社交媒体上闲聊，玩龙与地下城，戴帽子。也许更重要的是，你可以用抽象的概念来思考和交流。\n抽象思考的能力确实是人类最好的特征之一。它可以让你规避你的认知极限，将不同的细节捆绑在一起，形成一个整齐的概念包，让你可以在工作记忆中持有。你不需要去想 \u0026ldquo;可挤压的红球鼻子装饰 \u0026ldquo;这种笨重的想法，而只需要 \u0026ldquo;小丑鼻子 \u0026ldquo;这个概念。\n在 Clojure 中，一个抽象是一个操作的集合，而数据类型实现抽象。例如，seq 抽象由 \u0026ldquo;first \u0026ldquo;和 \u0026ldquo;rest \u0026ldquo;等操作组成，而 Vector 数据类型是该抽象的实现；它对所有 seq 操作做出响应。像[:seltzer :water]这样的特定 Vector 是该数据类型的*实例。\n编程语言越是让你以抽象的方式思考和写作，你的生产力就越高。例如，如果你知道一个数据结构是 seq 抽象的一个实例，你就可以立即调用一个大的知识网，了解哪些函数可以与数据结构一起工作。因此，你会花时间去实际使用这个数据结构，而不是不断地去查找关于它如何工作的文档。同样地，如果你扩展一个数据结构，使其与 seq 抽象一起工作，你就可以在上面使用大量的 seq 函数库。\n在第四章中，你了解到 Clojure 是以抽象的方式编写的。这很强大，因为在 Clojure 中，你可以专注于你可以用数据结构实际做的事情，而不用担心实现的细枝末节。本章向你介绍了创建和实现你自己的抽象的世界。你将学习 Multimethods、协议和记录的基础知识。\n多态性 我们在 Clojure 中实现抽象的主要方式是将一个操作名称与一个以上的算法联系起来。这种技术被称为多态性。例如，在列表上执行 \u0026ldquo;conj \u0026ldquo;的算法与 Vector 的算法不同，但我们把它们统一在同一个名字下，以表明它们实现了同一个概念，即向这个数据结构添加一个元素。\n因为 Clojure 的许多数据类型都依赖于 Java 的标准库，所以本章中使用了一点 Java。例如，Clojure 的字符串只是 Java 的字符串，是 Java 类java.lang.String的实例。要在 Java 中定义你自己的数据类型，你要使用类。Clojure 提供了额外的类型结构。 记录和类型。本书只涉及记录。\n在我们学习记录之前，让我们看看 Multimethods，这是我们定义多态行为的第一个工具。\nMultimethods Multimethods为你提供了一种直接的、灵活的方法，将多态性引入你的代码中。使用 Multimethods，你可以通过定义一个调度函数将一个名字与多个实现联系起来，该函数产生调度值，用来决定使用哪个方法。调度函数就像餐厅里的主人。主人会问你一些问题，比如 \u0026ldquo;你有预订吗？\u0026ldquo;和 \u0026ldquo;聚会人数？\u0026quot;，然后给你安排相应的座位。同样，当你调用一个 Multimethods 时，调度函数将询问参数，并将它们发送到正确的方法，正如这个例子所显示的。\n(ns were-creatures) ➊ (defmulti full-moon-behavior (fn [were-creature] (:were-type were-creature))) ➋ (defmethod full-moon-behavior :wolf [were-creature] (str (:name were-creature) \u0026quot; will howl and murder\u0026quot;)) ➌ (defmethod full-moon-behavior :simmons [were-creature] (str (:name were-creature) \u0026quot; will encourage people and sweat to the oldies\u0026quot;)) (full-moon-behavior {:were-type :wolf ➍ :name \u0026quot;Rachel from next door\u0026quot;}) ; =\u0026gt; \u0026quot;Rachel from next door will howl and murder\u0026quot; (full-moon-behavior {:name \u0026quot;Andy the baker\u0026quot; ➎ :were-type :simmons}) ; =\u0026gt; \u0026quot;Andy the baker will encourage people and sweat to the oldies\u0026quot; 这个 Multimethods 显示了你如何定义不同种类的狼人生物的满月行为。大家都知道狼人变成了狼，到处嚎叫着杀人。一种不太知名的狼人，即狼-西蒙斯，变成理查德-西蒙斯，烫着头发，到处跑，鼓励人们做最好的自己，为老人们流汗。你不想被这两种生物咬到，否则你就会变成它们。\n我们在➊处创建 Multimethods。这告诉 Clojure，\u0026ldquo;嘿，创建一个名为full-moon-behavior'的新Multimethods。每当有人调用full-moon-behavior时，在参数上运行调度函数(fn [were-creature] (:were-type were-creature))`。使用该函数的结果，也就是调度值，来决定使用哪个具体方法！\u0026rdquo;\n接下来，我们定义了两个方法，一个是当调度函数返回的值是➋的:wolf时，另一个是当它是➌的:simmons时。方法定义看起来很像函数定义，但主要的区别是，方法名称后面紧跟着dispatch 值。 :wolf和:simmons都是dispatch 值。这与调度*值不同，后者是调度函数的返回值。完整的调度序列是这样的。\n 形式(full-moon-behavior {:wer-type :wolf :name \u0026quot;Rachel from next door\u0026quot;})被评估。 运行full-moon-behavior的调度函数，返回:wolf作为调度值。 Clojure 将调度值:wolf与为full-moon-behavior定义的所有方法的调度值相比较。这些调度值是:wolf和:simmons。 因为调度值:wolf等于调度值:wolf，所以:wolf的算法运行。  不要让术语把你绊倒! 主要的想法是，调度函数返回一些值，这个值被用来决定使用哪个方法定义。\n回到我们的例子! 接下来我们调用该方法两次。在➍处，调度函数返回值\u0026rdquo;:wolf\u0026rdquo;，并使用相应的方法，通知你 \u0026ldquo;隔壁的 Rachel 将嚎叫并杀人\u0026rdquo;。在➏，该函数的行为类似，只是:simmons是调度值。\n你可以定义一个以nil为调度值的方法。\n(defmethod full-moon-behavior nil [were-creature] (str (:name were-creature) \u0026quot; will stay at home and eat ice cream\u0026quot;)) (full-moon-behavior {:were-type nil :name \u0026quot;Martin the nurse\u0026quot;}) ; =\u0026gt; \u0026quot;Martin the nurse will stay at home and eat ice cream\u0026quot; 当你这次调用full-moon-behavior时，你给它的参数:wer-type是nil，所以对应于nil的方法被评估，你被告知`\u0026ldquo;护士 Martin 将呆在家里吃冰淇淋\u0026rdquo;。\n你也可以通过指定:default作为调度值，定义一个默认方法，在没有其他方法匹配的情况下使用。在这个例子中，给出的参数的:were-type与之前定义的方法都不匹配，所以使用了默认方法。\n(defmethod full-moon-behavior :default [were-creature] (str (:name were-creature) \u0026quot; will stay up all night fantasy footballing\u0026quot;)) (full-moon-behavior {:were-type :office-worker :name \u0026quot;Jimmy from sales\u0026quot;}) ; =\u0026gt; \u0026quot;Jimmy from sales will stay up all night fantasy footballing\u0026quot; Multimethods 的一个很酷的地方是，你可以随时添加新的方法。如果你发布了一个包括wer-creatures命名空间的库，其他人可以继续扩展 Multimethods 来处理新的派发值。这个例子显示，你创建了自己的随机命名空间并包括了wer-creatures命名空间，然后为full-moon-behaviorMultimethods 定义了另一个方法。\n(ns random-namespace (:require [were-creatures])) (defmethod were-creatures/full-moon-behavior :bill-murray [were-creature] (str (:name were-creature) \u0026quot; will be the most likeable celebrity\u0026quot;)) (were-creatures/full-moon-behavior {:name \u0026quot;Laura the intern\u0026quot; :were-type :bill-murray}) ; =\u0026gt; \u0026quot;Laura the intern will be the most likeable celebrity\u0026quot; 你的调度函数可以使用它的任何或所有参数返回任意的值。下一个例子定义了一个 Multimethods，它接收两个参数，并返回一个包含每个参数类型的 Vector。它还定义了该方法的一个实现，当每个参数都是字符串时，该方法将被调用。\n(ns user) (defmulti types (fn [x y] [(class x) (class y)])) (defmethod types [java.lang.String java.lang.String] [x y] \u0026quot;Two strings!\u0026quot;) (types \u0026quot;String 1\u0026quot; \u0026quot;String 2\u0026quot;) ; =\u0026gt; \u0026quot;Two strings!\u0026quot; 顺便说一下，这就是为什么它们被称为multimethods：它们允许对多个参数进行调度。我没有经常使用这个功能，但我可以看到它被用于角色扮演游戏中，根据法师的主要魔法学校和他的魔法专长来编写方法。无论如何，有它而不需要它总比需要它而没有它好。\n注意 Multimethods 也允许分层调度。Clojure 可以让你建立自定义的层次结构，我不会介绍这些，但你可以通过阅读http://clojure.org/multimethods/ 的文档来了解它们。\n协议 在大约 93.58%的情况下，你会希望根据参数的类型来调度方法。例如，count需要对 Vector 使用不同的方法，而不是对 map 或 list 使用不同的方法。尽管可以用 Multimethods 进行类型调度，但协议是为类型调度而优化的。它们比 Multimethods 更有效，而且 Clojure 让你很容易简洁地指定协议的实现。\nMultimethods 只是一个多态的操作，而协议是一个集合的一个或多个多态操作。协议操作被称为方法，就像 Multimethods 操作一样。与 Multimethods 不同的是，Multimethods 对调度函数返回的任意值进行调度，而协议方法是根据第一个参数的类型进行调度，如本例所示。\n(ns data-psychology) ➊(defprotocol ➋Psychodynamics ➌\u0026quot;Plumb the inner depths of your data types\u0026quot; ➍(thoughts [x] \u0026quot;The data type's innermost thoughts\u0026quot;) ➎(feelings-about [x] [x y] \u0026quot;Feelings about self or other\u0026quot;)) 首先，在➊有defprotocol。这需要一个名字，Psychodynamics ➋，和一个可选的文件串，\u0026quot;探究你的数据类型的内部深度\u0026quot;➌。接下来是方法签名。一个方法签名由一个名称、一个参数说明和一个可选的文档串组成。第一个方法签名被命名为thoughts➍，只能接受一个参数。第二个名为feelings-about➎，可以接受一个或两个参数。协议有一个限制：方法不能有其余参数。所以像下面这样的行是不允许的。\n(feels-about [x] [x \u0026amp; others]) 通过定义一个协议，你在定义一个抽象，但你还没有定义如何实现这个抽象。这就像你为行为保留了名字（在这个例子中，你保留了思想和感觉-关于），但你还没有定义具体的行为。如果你要评估(thoughts \u0026quot;blorb\u0026quot;)，你会得到一个异常，内容是：\u0026ldquo;没有为 java.lang.String 类找到方法的实现：protocol: data-psychology/psychodynamics 的 thoughts。\u0026rdquo; 协议是根据第一个参数的类型分配的，所以当你调用(thoughts \u0026quot;blorb\u0026quot;)时，Clojure 试图为字符串查找thoughts方法的实现，但失败了。\n你可以通过扩展字符串数据类型来实现Psychodynamics协议来解决这一遗憾。\n➊ (extend-type java.lang.String ➋ Psychodynamics ➌ (thoughts [x] (str x \u0026quot; thinks, 'Truly, the character defines the data type'\u0026quot;) ➍ (feelings-about ([x] (str x \u0026quot; is longing for a simpler way of life\u0026quot;)) ([x y] (str x \u0026quot; is envious of \u0026quot; y \u0026quot;'s simpler way of life\u0026quot;)))) (thoughts \u0026quot;blorb\u0026quot;) ➎ ; =\u0026gt; \u0026quot;blorb thinks, 'Truly, the character defines the data type'\u0026quot; (feelings-about \u0026quot;schmorb\u0026quot;) ; =\u0026gt; \u0026quot;schmorb is longing for a simpler way of life\u0026quot; (feelings-about \u0026quot;schmorb\u0026quot; 2) ; =\u0026gt; \u0026quot;schmorb is envious of 2's simpler way of life\u0026quot; extend-type后面是你想扩展的类或类型的名称和你想让它支持的协议\u0026ndash;在这个例子中，你在➊处指定了类java.lang.String和你想让它支持的协议Psychodynamics，在➋。之后，你在➌为 \u0026ldquo;thoughts \u0026ldquo;方法和➍为 \u0026ldquo;feelings-about \u0026ldquo;方法提供一个实现。如果你要扩展一个类型来实现一个协议，你必须实现协议中的每一个方法，否则 Clojure 会抛出一个异常。在这种情况下，你不能只实现思想'或只实现感觉'；你必须同时实现这两种方法。\n注意，这些方法的实现不像 Multimethods 那样以defmethod开头。事实上，它们看起来类似于函数定义，只是没有defn'。要定义一个方法的实现，你要写一个以方法名称开头的表格，像thoughts'，然后提供一个参数 Vector 和方法的主体。这些方法也允许重载，就像函数一样，你定义多重性的方法实现与多重性的函数类似。你可以在➍的 \u0026ldquo;feelings-about \u0026ldquo;实现中看到这一点。\n在你扩展了java.lang.String类型以实现Psychodynamics协议后，Clojure 知道如何调度调用(thoughts \u0026quot;blorb\u0026quot;)，你会在➎得到字符串`\u0026ldquo;blorb thinks, \u0026lsquo;Truly, the character defines the data type\u0026rsquo;\u0026quot;。\n如果你想提供一个默认的实现，就像你对 multimethods 所做的那样呢？要做到这一点，你可以扩展java.lang.Object。这样做是因为 Java（也就是 Clojure）中的每个类型都是java.lang.Object的后代。如果这不是很有意义（也许是因为你不熟悉面向对象的编程），不要担心，只要知道它是有效的。下面是你如何使用这个技术为Psychodynamics协议提供一个默认实现。\n(extend-type java.lang.Object Psychodynamics (thoughts [x] \u0026quot;Maybe the Internet is just a vector for toxoplasmosis\u0026quot;) (feelings-about ([x] \u0026quot;meh\u0026quot;) ([x y] (str \u0026quot;meh about \u0026quot; y)))) (thoughts 3) ; =\u0026gt; \u0026quot;Maybe the Internet is just a vector for toxoplasmosis\u0026quot; (feelings-about 3) ; =\u0026gt; \u0026quot;meh\u0026quot; (feelings-about 3 \u0026quot;blorb\u0026quot;) ; =\u0026gt; \u0026quot;meh about blorb\u0026quot; 因为我们还没有为数字定义一个心理动力学'的实现，Clojure将对思想\u0026rsquo;和感觉-关于'的调用分派给为java.lang.Object\u0026rsquo;定义的实现。\n你可以使用extend-protocol'来代替多次调用extend-type\u0026rsquo;来扩展多个类型，它可以让你一次为多个类型定义协议实现。下面是你如何定义前面的协议实现。\n(extend-protocol Psychodynamics java.lang.String (thoughts [x] \u0026quot;Truly, the character defines the data type\u0026quot;) (feelings-about ([x] \u0026quot;longing for a simpler way of life\u0026quot;) ([x y] (str \u0026quot;envious of \u0026quot; y \u0026quot;'s simpler way of life\u0026quot;))) java.lang.Object (thoughts [x] \u0026quot;Maybe the Internet is just a vector for toxoplasmosis\u0026quot;) (feelings-about ([x] \u0026quot;meh\u0026quot;) ([x y] (str \u0026quot;meh about \u0026quot; y)))) 你可能会发现这个技术比使用extend-type更方便。然后，你也可能不觉得。extend-type让你感觉如何？extend-protocol怎么样？来坐在这个沙发上，告诉我这一切。\n值得注意的是，一个协议的方法 \u0026ldquo;属于 \u0026ldquo;它们所定义的命名空间。在这些例子中，\u0026ldquo;心理动力学 \u0026ldquo;方法的完全限定名称是 \u0026ldquo;数据-心理学/想法 \u0026ldquo;和 \u0026ldquo;数据-心理学/感觉-关于\u0026rdquo;。如果你有面向对象的背景，这可能看起来很奇怪，因为方法属于 OOP 中的数据类型。但不要吓坏了! 这只是 Clojure 赋予抽象优先权的另一种方式。这个事实的一个后果是，如果你想让两个不同的协议包括具有相同名称的方法，你需要把协议放在不同的命名空间中。\n记录 Clojure 允许你创建records，它是自定义的、类似 Map 的数据类型。它们类似于 Map，因为它们将键和值联系起来，你可以像使用 Map 一样查询它们的值，而且它们像 Map 一样是不可改变的。它们的不同之处在于，你为记录指定*字段。字段是数据的槽；使用它们就像指定一个数据结构应该有哪些键。记录也与 Map 不同，你可以扩展它们来实现协议。\n要创建一个记录，你可以使用defrecord来指定它的名字和字段。\n(ns were-records) (defrecord WereWolf [name title]) 这个记录的名字是WereWolf，它的两个字段是name和title。你可以通过三种方式创建这个记录的实例。\n➊ (WereWolf. \u0026quot;David\u0026quot; \u0026quot;London Tourist\u0026quot;) ; =\u0026gt; #were_records.WereWolf{:name \u0026quot;David\u0026quot;, :title \u0026quot;London Tourist\u0026quot;}. ➋ (-\u0026gt;WereWolf \u0026quot;Jacob\u0026quot; \u0026quot;Lead Shirt Discarder\u0026quot;) ; =\u0026gt; #were_records.WereWolf{:name \u0026quot;Jacob\u0026quot;, :title \u0026quot;Lead Shirt Discarder\u0026quot;}。 ➌ (map-\u0026gt;WereWolf {:name \u0026quot;Lucian\u0026quot; :title \u0026quot;CEO of Melodrama\u0026quot;}) ; =\u0026gt; #were_records.WereWolf{:name \u0026quot;Lucian\u0026quot;, :title \u0026quot;CEO of Melodrama\u0026quot;}. 在➊，我们以创建 Java 对象的方式创建一个实例，使用类实例化的互操作调用。(Interop指的是在 Clojure 中与本地 Java 结构交互的能力)。请注意，参数必须遵循与字段定义相同的顺序。这样做的原因是，记录实际上是被掩盖的 Java 类。\n➋的实例看起来与➊的实例几乎相同，但关键的区别在于-\u0026gt;WereWolf是一个函数。当你创建一条记录时，工厂函数-\u0026gt;RecordName 和map-\u0026gt;RecordName 会自动创建。在➌，map-\u0026gt;WereWolf接收一个 map 作为参数，其关键字与记录类型的字段相对应，并返回一个记录。\n如果你想使用其他命名空间的记录类型，你必须导入它，就像你在第 12 章中对 Java 类所做的那样。请注意将命名空间中的所有破折号替换为下划线。这个简单的例子显示了如何在另一个命名空间导入WereWolf记录类型。\n(ns monster-mash (:import [were_records WereWolf]) (WereWolf. \u0026quot;David\u0026quot; \u0026quot;London Tourist\u0026quot;) ; =\u0026gt; #were_records.WereWolf{:name \u0026quot;David\u0026quot;, :title \u0026quot;London Tourist\u0026quot;} 注意，were_records有一个下划线，而不是破折号。\n你可以用查询 Map 值的方式查询记录值，也可以使用 Java 字段访问互操作。\n(def jacob (-\u0026gt;WereWolf \u0026quot;Jacob\u0026quot; \u0026quot;Lead Shirt Discarder\u0026quot;) ➊ (.name jacob) ; =\u0026gt; \u0026quot;Jacob\u0026quot; ➋ (:name jacob) ; =\u0026gt; \u0026quot;Jacob\u0026quot; ➌ (get jacob :name) ;=\u0026gt; \u0026quot;Jacob\u0026quot; 第一个例子(.name jacob)在➊，使用了 Java 互操作，➋和➌的例子访问:name的方式与使用 map 相同。\n当测试相等时，Clojure 将检查所有字段是否相等，以及两个比较体是否具有相同的类型。\n➊ (= jacob (-\u0026gt;WereWolf \u0026quot;Jacob\u0026quot; \u0026quot;Lead Shirt Discarder\u0026quot;)) ; =\u0026gt; true ➋ (= jacob (WereWolf. \u0026quot;David\u0026quot; \u0026quot;London Tourist\u0026quot;)) ; =\u0026gt; false ➌ (= jacob {:name \u0026quot;Jacob\u0026quot; :title \u0026quot;Lead Shirt Discarder\u0026quot;}) ; =\u0026gt; false ➊处的测试返回true，因为jacob'和新创建的记录是同一类型，并且它们的字段是相等的。➋处的测试返回 \u0026quot;false\u0026quot;，因为字段不相等。最后在➌处的测试返回 \u0026quot;false\u0026quot;，因为两个比较对象的类型不一样。jacob\u0026rsquo;是一个`WereWolf\u0026rsquo;记录，而另一个参数是一个 Map。\n任何你能在 Map 上使用的函数，你也能在记录上使用。\n(assoc jacob :title \u0026quot;Lead Third Wheel\u0026quot;) ; =\u0026gt; #were_records.WereWolf{:name \u0026quot;Jacob\u0026quot;, :title \u0026quot;Lead Third Wheel\u0026quot;}。 然而，如果你dissoc一个字段，结果的类型将是一个普通的\u0026rsquo;Clojure map；它将不会有与原始记录相同的数据类型。\n(dissoc jacob :title) ; =\u0026gt; {:name \u0026quot;Jacob\u0026quot;} \u0026lt;- that's not a were_records.WereWolf 这至少有两个原因：第一，访问 Map 值比访问记录值要慢，所以如果你要建立一个高性能的程序，就要注意了。第二，当你创建一个新的记录类型时，你可以扩展它来实现一个协议，类似于你之前使用extend-type扩展一个类型。如果你dissoc一个记录，然后试图在结果上调用一个协议方法，记录的协议方法就不会被调用。\n下面是你在定义记录时如何扩展一个协议。\n➊ (defprotocol WereCreature ➋ (full-moon-behavior [x])) ➌ (defrecord WereWolf [name title] WereCreature (full-moon-behavior [x] (str name \u0026quot; will howl and murder\u0026quot;))) (full-moon-behavior (map-\u0026gt;WereWolf {:name \u0026quot;Lucian\u0026quot; :title \u0026quot;CEO of Melodrama\u0026quot;})) ; =\u0026gt; \u0026quot;Lucian will howl and murder\u0026quot; 我们创建了一个新的协议，WereCreature ➊，有一个方法，full-moon-behavior ➋。在➌，defrecord为WereWolf实现了WereCreature。在full-moon-behavior实现中最有趣的部分是你可以访问name。你还可以访问title'和任何其他可能为你的记录定义的字段。你也可以使用extend-type和extend-protocol`来扩展记录。\n你什么时候应该使用记录，什么时候应该使用 Map？一般来说，如果你发现自己在创建 Map 时反复使用相同的字段，你应该考虑使用记录。这告诉你，这组数据代表了你的应用程序领域的信息，如果你提供一个基于你试图建模的概念的名称，你的代码将更好地传达其目的。不仅如此，记录访问比 Map 访问更有表现力，所以你的程序会变得更有效率一些。最后，如果你想使用协议，你就需要创建一个记录。\n进一步研究 Clojure 提供了其他的工具来处理抽象和数据类型。这些工具，我认为是高级的，包括deftype，reify，和proxy。如果你有兴趣了解更多，请查看*http://clojure.org/datatypes/*上关于数据类型的文档。\n总结 Clojure 的设计原则之一就是要写到抽象。在本章中，你学到了如何使用 Multimethods 和原型来定义你自己的抽象概念。这些结构提供了多态性，允许同一个操作根据它的参数有不同的表现。你还学会了如何用defrecord创建和使用自己的关联数据类型，以及如何扩展记录来实现协议。\n当我刚开始学习 Clojure 时，我对使用 Multimethods、协议和记录感到很害羞。然而，它们在 Clojure 库中经常被使用，所以了解它们的工作原理是很好的。一旦你掌握了它们，它们会帮助你写出更干净的代码。\n练习  扩展full-moon-behaviorMultimethods，为你自己的 were-creature 类型添加行为。 创建一个WereSimmons记录类型，然后扩展WereCreature协议。 创建你自己的协议，然后使用extend-type和extend-protocol来扩展它。 创建一个角色扮演游戏，使用多重调度来实现行为。  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter13/","summary":"用 Multimethods、协议和记录创建和扩展抽象概念 花一分钟思考一下，作为大自然的顶级产品之一：人类是多么伟大。作为一个人类，你可以在社交媒体上闲聊，玩龙与地下城，戴帽子。也许更重要的是，你可以用抽象的概念来思考和交流。\n抽象思考的能力确实是人类最好的特征之一。它可以让你规避你的认知极限，将不同的细节捆绑在一起，形成一个整齐的概念包，让你可以在工作记忆中持有。你不需要去想 \u0026ldquo;可挤压的红球鼻子装饰 \u0026ldquo;这种笨重的想法，而只需要 \u0026ldquo;小丑鼻子 \u0026ldquo;这个概念。\n在 Clojure 中，一个抽象是一个操作的集合，而数据类型实现抽象。例如，seq 抽象由 \u0026ldquo;first \u0026ldquo;和 \u0026ldquo;rest \u0026ldquo;等操作组成，而 Vector 数据类型是该抽象的实现；它对所有 seq 操作做出响应。像[:seltzer :water]这样的特定 Vector 是该数据类型的*实例。\n编程语言越是让你以抽象的方式思考和写作，你的生产力就越高。例如，如果你知道一个数据结构是 seq 抽象的一个实例，你就可以立即调用一个大的知识网，了解哪些函数可以与数据结构一起工作。因此，你会花时间去实际使用这个数据结构，而不是不断地去查找关于它如何工作的文档。同样地，如果你扩展一个数据结构，使其与 seq 抽象一起工作，你就可以在上面使用大量的 seq 函数库。\n在第四章中，你了解到 Clojure 是以抽象的方式编写的。这很强大，因为在 Clojure 中，你可以专注于你可以用数据结构实际做的事情，而不用担心实现的细枝末节。本章向你介绍了创建和实现你自己的抽象的世界。你将学习 Multimethods、协议和记录的基础知识。\n多态性 我们在 Clojure 中实现抽象的主要方式是将一个操作名称与一个以上的算法联系起来。这种技术被称为多态性。例如，在列表上执行 \u0026ldquo;conj \u0026ldquo;的算法与 Vector 的算法不同，但我们把它们统一在同一个名字下，以表明它们实现了同一个概念，即向这个数据结构添加一个元素。\n因为 Clojure 的许多数据类型都依赖于 Java 的标准库，所以本章中使用了一点 Java。例如，Clojure 的字符串只是 Java 的字符串，是 Java 类java.lang.String的实例。要在 Java 中定义你自己的数据类型，你要使用类。Clojure 提供了额外的类型结构。 记录和类型。本书只涉及记录。\n在我们学习记录之前，让我们看看 Multimethods，这是我们定义多态行为的第一个工具。\nMultimethods Multimethods为你提供了一种直接的、灵活的方法，将多态性引入你的代码中。使用 Multimethods，你可以通过定义一个调度函数将一个名字与多个实现联系起来，该函数产生调度值，用来决定使用哪个方法。调度函数就像餐厅里的主人。主人会问你一些问题，比如 \u0026ldquo;你有预订吗？\u0026ldquo;和 \u0026ldquo;聚会人数？\u0026quot;，然后给你安排相应的座位。同样，当你调用一个 Multimethods 时，调度函数将询问参数，并将它们发送到正确的方法，正如这个例子所显示的。\n(ns were-creatures) ➊ (defmulti full-moon-behavior (fn [were-creature] (:were-type were-creature))) ➋ (defmethod full-moon-behavior :wolf [were-creature] (str (:name were-creature) \u0026quot; will howl and murder\u0026quot;)) ➌ (defmethod full-moon-behavior :simmons [were-creature] (str (:name were-creature) \u0026quot; will encourage people and sweat to the oldies\u0026quot;)) (full-moon-behavior {:were-type :wolf ➍ :name \u0026quot;Rachel from next door\u0026quot;}) ; =\u0026gt; \u0026quot;Rachel from next door will howl and murder\u0026quot; (full-moon-behavior {:name \u0026quot;Andy the baker\u0026quot; ➎ :were-type :simmons}) ; =\u0026gt; \u0026quot;Andy the baker will encourage people and sweat to the oldies\u0026quot; 这个 Multimethods 显示了你如何定义不同种类的狼人生物的满月行为。大家都知道狼人变成了狼，到处嚎叫着杀人。一种不太知名的狼人，即狼-西蒙斯，变成理查德-西蒙斯，烫着头发，到处跑，鼓励人们做最好的自己，为老人们流汗。你不想被这两种生物咬到，否则你就会变成它们。","title":"Chapter13 抽象"},{"content":"与 JVM 一起工作 在每个 Clojurist 的生命中都会有这么一天，她必须从纯函数和不可变数据结构的庇护所冒险进入野蛮的 Java 大陆。这段艰难的旅程是必要的，因为 Clojure 是在 Java 虚拟机（JVM）上托管的，这赋予了它三个基本特性。\n赋予它三个基本特征。首先，你运行 Clojure 应用程序的方式与你运行 Java 应用程序的方式相同。第二，你需要使用 Java 对象来实现核心功能，如读取文件和处理日期。第三，Java 有一个庞大的有用库的生态系统，你需要对 Java 有一定的了解才能使用它们。\n这样一来，Clojure 就有点像一个乌托邦社区，被放置在一个乌托邦国家的中间。显然，你更愿意与其他乌托邦人互动，但偶尔你也需要与当地人交谈，以便完成工作。\n这一章就像一本短语书和 Java 国家的文化介绍之间的交叉。你将了解什么是 JVM，它是如何运行程序的，以及如何为它编译程序。本章还将为你简要介绍常用的 Java 类和方法，并解释如何使用 Clojure 与它们互动。你将学会如何思考和理解 Java，以便将任何 Java 库纳入你的 Clojure 程序中。\n要运行本章的例子，你需要在电脑上安装 1.6 或更高版本的 Java 开发工具包（JDK）。你可以通过在终端运行javac -version来检查。你应该看到类似 \u0026ldquo;java 1.8.0_40 \u0026ldquo;的内容；如果没有，请访问http://www.oracle.com/，下载最新的 JDK。\nJVM 开发人员用 JVM 这个词来指代一些不同的东西。你会听到他们说，\u0026ldquo;Clojure 在the JVM 上运行\u0026rdquo;，你也会听到，\u0026ldquo;Clojure 程序在a JVM 中运行\u0026rdquo;。在第一种情况下，JVM 指的是一个抽象概念\u0026ndash;Java 虚拟机的一般模型。在第二种情况下，它指的是一个进程\u0026ndash;一个正在运行的程序的实例。我们将专注于 JVM 模型，但当我们谈论运行中的 JVM 进程时，我将指出来。\n为了理解 JVM，让我们回头看看普通的计算机是如何工作的。在计算机心脏的深处是它的 CPU，而 CPU 的工作是执行像加和无符号乘法这样的操作。你可能听说过程序员将这些指令编码在打卡机上、灯泡里、乌龟壳的神圣缝隙里，或者什么的，但现在这些操作在汇编语言中用 ADD 和 MUL 这样的记忆符号表示。CPU 架构（X86、ARMv7，等等）决定了哪些操作可以作为该架构的指令集的一部分。\n由于用汇编语言编程并不有趣，人们发明了像 C 和 C++这样的高级语言，将其编译成 CPU 可以理解的指令。大体上说，这个过程是\n 编译器读取源代码。 编译器输出一个包含机器指令的文件。 CPU 执行这些指令。  在图 12-1 中注意到，最终，你必须将程序翻译成 CPU 能够理解的指令，而 CPU 并不关心你用哪种编程语言来产生这些指令。\nJVM 类似于计算机，它也需要将代码翻译成低级别的指令，称为Java 字节码。然而，作为一个虚拟机器，这种翻译是作为软件而不是硬件实现的。运行中的 JVM 通过将字节码实时翻译成主机可以理解的机器代码来执行，这个过程被称为及时**编译。\n图 12-1：C 语言程序如何被翻译成机器码的高级概述\n为了让一个程序在 JVM 上运行，它必须被编译成 Java 字节码。通常，当你编译程序时，产生的字节码被保存在一个*.class文件中。然后你会把这些文件打包在Java 归档*文件（JAR 文件）中。就像 CPU 不关心你用哪种编程语言来生成机器指令一样，JVM 也不关心你如何创建字节码。它不关心你是否使用 Scala、JRuby、Clojure，甚至是 Java 来创建 Java 字节码。一般来说，这个过程就像图 12-2 中所示的那样。\n Java 编译器读取源代码。 编译器输出字节码，通常是在一个 JAR 文件中。 JVM 执行字节码。 VM 向 CPU 发送机器指令。  当有人说 Clojure 在 JVM 上运行时，他们的意思之一是 Clojure 程序被编译成 Java 字节码，JVM 进程执行它们。从操作的角度来看，这意味着你对待 Clojure 程序和 Java 程序是一样的。你把它们编译成 JAR 文件，并使用java命令运行它们。如果客户需要一个在 JVM 上运行的程序，你可以偷偷地用 Clojure 而不是 Java 来编写，他们不会知道的。从外面看，你无法分辨 Java 和 Clojure 程序之间的区别，就像你无法分辨 C 和 C++程序之间的区别一样。Clojure 可以让你变得富有成效，而且是偷偷摸摸的。\n！\n图 12-2：Java 程序产生 JVM 字节码，但 JVM 仍然需要产生机器指令，就像 C 语言编译器一样。\n编写、编译和运行一个 Java 程序 让我们来看看一个真正的 Java 程序是如何工作的。在本节中，你将了解到 Java 所使用的面向对象的范式。然后，你将用 Java 建立一个简单的海盗短语书。这将帮助你对 JVM 感到更加舒适，它将为即将到来的 Java 互操作（编写直接使用 Java 类、对象和方法的 Clojure 代码）一节做好准备，如果有一个恶棍试图在公海上破坏你的战利品，它就会派上用场。为了把所有的信息联系在一起，你将在本章的最后偷看一些 Clojure 的 Java 代码。\n面向对象的编程在世界最微小的果壳中的应用 Java 是一种面向对象的语言，所以如果你想了解你在 Clojure 编程中使用 Java 库或编写 Java 互操作代码时发生了什么，你就需要了解面向对象编程（OOP）是如何工作的。你也会在 Clojure 文档中发现面向对象的术语，所以学习这些概念很重要。如果你精通 OOP，可以随意跳过本节。对于那些需要两分钟了解的人来说，这里是：OOP 的核心角色是类、对象和方法。\n我认为对象是真正的、真正的、可笑的蠢货机器人。它们是那种永远不会引起哲学辩论的机器人，即强迫有知觉的生物进行永久的奴役的伦理。这些机器人只做两件事：他们响应命令和维护数据。在我的想象中，它们通过在小 Hello Kitty 剪贴板上写下东西来做这件事。\n想象一下，一个制造这些机器人的工厂。机器人所理解的命令集和它所维护的数据集都是由制造机器人的工厂决定的。在 OOP 术语中，工厂对应于类，androids 对应于对象，而命令对应于方法。例如，你可能有一个ScaryClown'工厂（类），它生产的androids（对象）响应makeBalloonArt\u0026rsquo;命令（方法）。这个安卓机一直跟踪它所拥有的气球的数量，然后在气球的数量发生变化时更新这个数字。它可以用balloonCount报告这个数字，用receiveBalloons接收任何数量的气球。下面是你如何与代表小丑 Belly Rubs 的 Java 对象进行交互。\nScaryClown bellyRubsTheClown = new ScaryClown(); bellyRubsTheClown.balloonCount(); // =\u0026gt; 0 bellyRubsTheClown.receiveBalloons(2); bellyRubsTheClown.balloonCount(); // =\u0026gt; 2 bellyRubsTheClown.makeBalloonArt(); // =\u0026gt; \u0026quot;Belly Rubs makes a balloon shaped like a clown, because Belly Rubs // =\u0026gt; is trying to scare you and nothing is scarier than clowns.\u0026quot; 这个例子告诉你如何使用ScaryClown类创建一个新的对象bellyRubsTheClown。它还向你展示了如何在该对象上调用方法（如气球计数'、接收气球\u0026rsquo;和`制作气球艺术'），大概是为了让你能吓唬孩子。\n你应该知道 OOP 的最后一个方面，或者至少是它在 Java 中的实现方式，就是你也可以向工厂发送命令。在 OOP 术语中，你会说，类也有方法。例如，内置类Math有许多类方法，包括Math.abs，它返回一个数字的绝对值。\nMath.abs(-50) // =\u0026gt; 50 我希望这些小丑没有给你造成太大的创伤。现在让我们把你的 OOP 知识用在工作上吧!\nAhoy, World 继续前进，创建一个名为phrasebook的新目录。在该目录中，创建一个名为PiratePhrases.java的文件，并编写以下内容。\npublic class PiratePhrases { public static void main(String[] args) { System.out.println(\u0026quot;Shiver me timbers!!\u0026quot;); } } 这个非常简单的程序将在你运行时向你的终端打印 \u0026ldquo;Shiver me timbers!!!\u0026ldquo;这句话。(这就是海盗说 \u0026ldquo;你好，世界！\u0026ldquo;的方式），当你运行它时，它将打印到你的终端。它由一个类PiratePhrases和一个属于该类的静态方法main组成。静态方法本质上是类的方法。\n在你的终端，用 javac PiratePhrases.java 命令编译PiratePhrases源代码。如果你打的字都是正确的，**你的心是纯洁的，你应该看到一个名为PiratePhrases.class的文件。\n$ ls PiratePhrases.class PiratePhrases.java 你刚刚编译了你的第一个 Java 程序，我的朋友! 现在用java PiratePhrases运行它。你应该看到这个。\nShiver me timbers!!! 这里发生的事情是你用 Java 编译器javac创建了一个 Java 类文件，PiratePhrases.class。这个文件包含了大量的 Java 字节码（好吧，对于这么大的程序，也许只有一个字节）。\n当你运行 \u0026ldquo;java PiratePhrases \u0026ldquo;时，JVM 首先查看了你的classpath，寻找一个名为 \u0026ldquo;PiratePhrases \u0026ldquo;的类。classpath 是文件系统的路径列表，JVM 通过搜索来寻找定义类的文件。默认情况下，classpath 包括你运行 java 时所在的目录。试着运行 java -classpath /tmp PiratePhrases，你会得到一个错误，尽管PiratePhrases.class就在你的当前目录中。\n注意 你可以在你的 classpath 上有多个路径，如果你在 Mac 上或运行 Linux，可以用冒号隔开，如果你在使用 Windows，可以用分号。例如，classpath /tmp:/var/maven:.包括/tmp、/var/maven 和.目录。\n在 Java 中，每个文件只允许有一个公有类，而且文件名必须与类名一致。这就是为什么java知道要尝试在PiratePhrases.class中寻找PiratePhrases类的字节码。在java找到PiratePhrases类的字节码后，它执行了该类的main方法。Java 与 C 语言类似，只要你说 \u0026ldquo;运行某些东西，并使用这个类作为入口点\u0026rdquo;，它就会一直运行这个类的main'方法；因此，这个方法必须是public'，你可以在`PiratePhrases\u0026rsquo;的源代码中看到。\n在下一节，你将学习如何处理跨越多个文件的程序代码，以及如何使用 Java 库。\n包和导入 为了了解如何使用多文件程序和 Java 库，我们将编译并运行一个程序。本节对 Clojure 有直接的影响，因为你将使用同样的想法和术语来与 Java 库进行交互。\n让我们从几个定义开始。\n 包与 Clojure 的命名空间类似，包提供了代码组织。包包含类，包名对应于文件系统的目录。如果一个文件中有 \u0026ldquo;package com.shapemaster \u0026ldquo;一行，那么目录com/shapemaster一定存在于你的 classpath 上。在该目录中会有定义类的文件。 import Java 允许你导入类，这基本上意味着你可以不使用它们的命名空间前缀来引用它们。所以如果你在com.shapemaster中有一个名为Square的类，你可以在.java文件的顶部写上import``com.shapemaster.Square;或import com.shapemaster.*;，以便在你的代码中使用Square而不是com.shapemaster.Square。  让我们试试使用package和import。在这个例子中，你将创建一个名为pirate_phrases的包，它有两个类，问候'和告别'。 首先，浏览你的phrasebook，在该目录下创建另一个目录，pirate_phrases。创建pirate_phrases是必要的，因为 Java 包的名称与文件系统的目录相对应。然后，在pirate_phrases目录下创建Greetings.java。\n➊ package pirate_phrases; public class Greetings { public static void hello() { System.out.println(\u0026quot;Shiver me timbers!!!\u0026quot;); } } 在➊，package pirate_phrases;表示这个类将是pirate_phrases包的一部分。现在在pirate_phrases目录下创建Farewells.java。\npackage pirate_phrases; public class Farewells { public static void goodbye() { System.out.println(\u0026quot;A fair turn of the tide ter ye thar, ye magnificent sea friend!!\u0026quot;); } } 现在在phrasebook目录下创建PirateConversation.java。\nimport pirate_phrases.*; public class PirateConversation { public static void main(String[] args) { Greetings greetings = new Greetings(); greetings.hello(); Farewells farewells = new Farewells(); farewells.goodbye(); } } 第一行，import pirate_phrases.*;，导入了pirate_phrases包中的所有类，其中包含问候'和告别\u0026rsquo;类。\n如果你在phrasebook目录下运行javac PirateConversation.java，接着运行java PirateConversation，你应该看到这个。\nShiver me timbers!!! A fair turn of the tide ter ye thar, ye magnificent sea friend!! 亲爱的读者，她在那里吹了起来。她确实在吹。\n注意，当你编译一个 Java 程序时，Java 会在你的 classpath 中搜索包。试着输入以下内容。\ncd pirate_phrases javac ../PirateConversation.java 你会得到这个结果。\n../PirateConversation.java:1: error: package pirate_phrases does not exist import pirate_phrases.*; ^ 轰隆隆! Java 编译器刚刚告诉你，让你羞愧地垂下头来，也许还会哭泣一下。\n为什么？它认为pirate_phrases包不存在。但这很愚蠢，对吗？你是在pirate_phrases目录下！你是在pirate_phrases目录下。\n这里发生的情况是，默认的 classpath 只包括当前的目录，在这种情况下是pirate_phrases。 javac试图找到phrasebook/pirate_phrases/pirate_phrases目录，但该目录并不存在。当你在phrasebook目录下运行javac ../PirateConversation.java时，javac试图找到phrasebook/pirate_phrases目录，该目录确实存在。在不改变目录的情况下，尝试运行 javac -classpath ../ ../PirateConversation.java。吓我一跳，居然成功了! 这是因为你手动将 classpath 设置为pirate_phrases的父目录，也就是phrasebook。从那里，javac可以成功地找到pirate_phrases目录。\n综上所述，包组织了代码，并要求有一个匹配的目录结构。导入类可以让你引用它们，而不需要预留整个类的包名。 javac和 Java 使用 classpath 查找包。\nJAR 文件 JAR 文件允许你将所有的*.class文件捆绑成一个单一的文件。导航到你的phrasebook*目录并运行以下程序。\njar cvfe conversation.jar PirateConversation PirateConversation.class pirate_phrases/*.class java -jar conversation.jar 这样就能正确显示海盗对话了。你把所有的类文件捆绑在conversation.jar中。使用e标志，你还指出PirateConversation类是入口点。入口点是包含 JAR 整体运行时应该执行的main'方法的类，jar\u0026rsquo;将这些信息存储在 JAR 文件中的META-INF/MANIFEST.MF文件中。如果你要阅读该文件，它将包含这一行。\nMain-Class: PirateConversation 顺便说一下，当你执行 JAR 文件时，你不必担心你在哪个目录下，相对于文件而言。你可以换到pirate_phrases目录，然后运行java -jar .../conversation.jar，就可以正常工作了。原因是 JAR 文件维护了目录结构。你可以用 jar tf conversation.jar 查看它的内容，它的输出是这样的。\nMETA-INF/ meta-inf/manifest.mf PirateConversation.class pirate_phrases/Farewells.class Pirate_phrases/Greetings.class 你可以看到，JAR 文件包括pirate_phrases目录。关于 JARs 还有一个有趣的事实：它们实际上只是带有*.jar*扩展名的 ZIP 文件。你可以像对待其他 ZIP 文件一样对待它们。\nclojure.jar 现在你已经准备好看看 Clojure 在引擎盖下是如何工作的了! 下载[1.9.0 稳定版]（http://repo1.maven.org/maven2/org/clojure/clojure/1.7.0/clojure-1.9.0.zip）并运行它。\njava -jar clojure-1.7.0.jar 你应该看到最舒心的景象，Clojure REPL。它究竟是如何启动的呢？让我们看看 JAR 文件中的META-INF/MANIFEST.MF。\nManifest-Version: 1.0 Archiver-Version: Plexus Archiver Created-By: Apache Maven Built-By: hudson Build-Jdk: 1.7.0_20 Main-Class: clojure.main 看起来，clojure.main被指定为入口点。这个类是怎么来的？嗯，看看 GitHub 上的clojure/main.java，网址是*https://github.com/clojure/clojure/blob/master/src/jvm/clojure/main.java*。\n/** * Copyright (c) Rich Hickey. All rights reserved. * The use and distribution terms for this software are covered by the * Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php) * which can be found in the file epl-v10.html at the root of this distribution. * By using this software in any fashion, you are agreeing to be bound by * the terms of this license. * You must not remove this notice, or any other, from this software. **/ package clojure; import clojure.lang.Symbol; import clojure.lang.Var; import clojure.lang.RT; public class main{ final static private Symbol CLOJURE_MAIN = Symbol.intern(\u0026quot;clojure.main\u0026quot;); final static private Var REQUIRE = RT.var(\u0026quot;clojure.core\u0026quot;, \u0026quot;require\u0026quot;); final static private Var LEGACY_REPL = RT.var(\u0026quot;clojure.main\u0026quot;, \u0026quot;legacy-repl\u0026quot;); final static private Var LEGACY_SCRIPT = RT.var(\u0026quot;clojure.main\u0026quot;, \u0026quot;legacy-script\u0026quot;); final static private Var MAIN = RT.var(\u0026quot;clojure.main\u0026quot;, \u0026quot;main\u0026quot;); public static void legacy_repl(String[] args) { REQUIRE.invoke(CLOJURE_MAIN); LEGACY_REPL.invoke(RT.seq(args)); } public static void legacy_script(String[] args) { REQUIRE.invoke(CLOJURE_MAIN); LEGACY_SCRIPT.invoke(RT.seq(args)); } public static void main(String[] args) { REQUIRE.invoke(CLOJURE_MAIN); MAIN.applyTo(RT.seq(args)); } } 正如你所看到的，该文件定义了一个名为main的类。它属于 \u0026ldquo;clojure \u0026ldquo;包，并定义了一个 \u0026ldquo;公共静态 \u0026ldquo;的 \u0026ldquo;main \u0026ldquo;方法，JVM 完全乐意将其作为一个入口点。以这种方式来看，Clojure 是一个 JVM 程序，就像其他程序一样。\n这并不是一个深入的 Java 教程，但我希望它有助于澄清程序员在谈论 Clojure \u0026ldquo;在 JVM 上运行 \u0026ldquo;或成为一种 \u0026ldquo;托管 \u0026ldquo;语言时的意思。在下一节中，你将继续探索 JVM 的魅力，学习如何在你的 Clojure 项目中使用额外的 Java 库。\nClojure 应用程序 JARs\n你现在知道 Java 是如何运行 Java JARs 的，但它是如何运行捆绑为 JARs 的 Clojure 应用程序的呢？毕竟，Clojure 应用程序没有类，不是吗？\n事实证明，你可以通过在命名空间声明中加入(:gen-class)指令，让 Clojure 编译器为一个命名空间生成一个类。(你可以在你创建的第一个 Clojure 程序中看到这一点，即第一章的clojure-noob。还记得那个程序吗，小茶壶？） 这意味着编译器会产生必要的字节码，使 JVM 把命名空间当作定义了一个 Java 类。\n你在程序的project.clj文件中，使用:main属性，为你的程序设置入口点的命名空间。对于clojure-noob，你应该看到:main ^:skip-aot clojure-noob.core。当 Leiningen 编译这个文件时，它将添加一个meta-inf/manifest.mf文件，该文件包含了生成的 JAR 文件的入口点。\n因此，如果你在命名空间中定义了一个-main函数，并包括(:gen-class)指令，同时在你的project.clj文件中设置了:main，你的程序在被编译为 JAR 时，将拥有 Java 运行它所需的一切。你可以在你的终端中试用这个方法，浏览你的clojure-noob目录并运行这个。\nlein uberjar java -jar target/uberjar/clojure-noob-0.1.0-SNAPSHOT-standalone.jar 你应该看到打印出来的两条信息。\u0026ldquo;清洁度仅次于神性 \u0026ldquo;和 \u0026ldquo;I\u0026rsquo;m a little teapot!\u0026rdquo; 注意，你不需要 Leiningen 来运行这个 JAR 文件；你可以把它发送给朋友和邻居，只要他们安装了 Java，就可以运行它。\nJava Interop Rich Hickey 对 Clojure 的设计目标之一是创造一种实用的语言。出于这个原因，Clojure 的设计是为了使你能够轻松地与 Java 类和对象进行交互，这意味着你可以使用 Java 广泛的本地功能和它的巨大生态系统。使用 Java 类、对象和方法的能力被称为Java interop*。在本节中，你将学习如何使用 Clojure 的互操作语法，如何导入 Java 包，以及如何使用最常用的 Java 类。\n互通语法 使用 Clojure 的互操作语法，与 Java 对象和类的交互是很直接的。让我们从对象互操作语法开始。\n你可以使用(.methodName object)来调用一个对象的方法。例如，因为所有的 Clojure 字符串都是作为 Java 字符串实现的，所以你可以对它们调用 Java 方法。\n(.toUpperCase \u0026quot;By Bluebeard's bananas!\u0026quot; ) ; =\u0026gt; \u0026quot;by bluebeard's bananas!\u0026quot; ➊ (.indexOf \u0026quot;Let's synergize our bleeding edges\u0026quot; \u0026quot;y\u0026quot;) ; =\u0026gt; 7 这些等同于这个 Java。\n\u0026quot;By Bluebeard's bananas!\u0026quot;.toUpperCase() \u0026quot;Let's synergize our bleeding edges\u0026quot;.indexOf(\u0026quot;y\u0026quot;) 注意，Clojure 的语法允许你向 Java 方法传递参数。在这个例子中，在➊，你把参数\u0026quot;y\u0026quot;传给了indexOf方法。\n你也可以调用类上的静态方法和访问类的静态字段。观察一下!\n➊ (java.lang.Math/abs -3) ; =\u0026gt; 3 ➋ java.lang.Math/PI ; =\u0026gt; 3.141592653589793 在➊，你调用了java.lang.Math类的abs静态方法，在➋，你访问了该类的PI静态字段。\n所有这些例子（除了java.lang.Math/PI）都使用了扩展到使用*dot 特殊形式的宏。一般来说，你不需要使用点的特殊形式，除非你想写自己的宏来与 Java 对象和类交互。尽管如此，下面是每个例子后面的宏扩展。\n(macroexpand-1 '(.toUpperCase \u0026quot;By Bluebeard's bananas!\u0026quot;)) ; =\u0026gt; (. \u0026quot;By Bluebeard's bananas!\u0026quot; toUpperCase) (macroexpand-1 '(.indexOf \u0026quot;Let's synergize our bleeding edges\u0026quot; \u0026quot;y\u0026quot;)) ; =\u0026gt; (. \u0026quot;Let's synergize our bleeding edges\u0026quot; indexOf \u0026quot;y\u0026quot;) (macroexpand-1 '(Math/abs -3)) ; =\u0026gt; (. Math abs -3) 这是点运算符的一般形式。\n(. object-expr-or-classname-symbol method-or-member-symbol optional-args*) 点运算符还有一些功能，如果你有兴趣进一步探索它，你可以看看 clojure.org 关于 Java 互操作的文档*http://clojure.org/java_interop#Java%20Interop-The%20Dot%20special%20form*。\n创建和变异对象\n上一节告诉你如何调用已经存在的对象的方法。本节向你展示如何创建新的对象以及如何与它们进行交互。\n你可以通过两种方式创建一个新的对象。(new ClassName optional-args)和(ClassName. optional-args)。\n(new String) ; =\u0026gt; \u0026quot;\u0026quot; (String.) ; =\u0026gt; \u0026quot;\u0026quot; (String. \u0026quot;To Davey Jones's Locker with ye hardies\u0026quot;) ; =\u0026gt; \u0026quot;To Davey Jones's Locker with ye hardies\u0026quot; 大多数人使用点的版本，(ClassName.)。\n要修改一个对象，你要像上一节那样调用其上的方法。为了研究这个问题，让我们使用java.util.Stack。这个类代表了一个后进先出（LIFO）的对象堆栈，或者只是堆栈。堆栈是一种常见的数据结构，它们之所以被称为堆栈，是因为你可以把它们想象成一摞实物，比如说，一摞你刚刚掠夺来的金币。当你向你的堆栈添加一个硬币时，你就把它添加到堆栈的顶部。当你取出一枚金币时，你就把它从上面移走。因此，最后添加的对象就是第一个被移除的对象。\n与 Clojure 数据结构不同，Java 堆栈是可变的。你可以向它们添加项目和删除项目，改变对象而不是派生出一个新的值。下面是你如何创建一个堆栈并向其添加一个对象。\n(java.util.Stack.) ; =\u0026gt; [] ➊ (let [stack (java.util.Stack.)] (.push stack \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;) stack) ; =\u0026gt; [\u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;] 这里有几个有趣的细节。首先，你需要为stack创建一个let绑定，就像你在➊看到的那样，并把它作为let形式的最后一个表达式。如果你不这样做，整个表达式的值将是字符串\u0026quot;Game of Thrones, ho!\u0026quot;，因为那是push的返回值。\n第二，Clojure 用方括号来打印堆栈，与它用于 Vector 的文本表示法相同，这可能会让你感到困惑，因为它不是一个 Vector。然而，你可以使用 Clojure 的seq函数来读取堆栈中的数据结构，比如first，。\n(let [stack (java.util.Stack.)] (.push stack \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;) (first stack)) ; =\u0026gt; \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot; 但是你不能使用像conj和into这样的函数来添加元素到栈中。如果你这样做，你会得到一个异常。使用 Clojure 函数读取堆栈是可能的，因为 Clojure 扩展了对java.util.Stack的抽象，这个主题你将在第 13 章学习。\nClojure 提供了doto宏，它允许你更简洁地在同一个对象上执行多个方法。\n(doto (java.util.Stack.) (.push \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;) (.push \u0026quot;Whoops, I meant 'Land, ho!'\u0026quot;)) ; =\u0026gt; [\u0026quot;Latest episode of Game of Thrones, ho!\u0026quot; \u0026quot;Whoops, I meant 'Land, ho!'\u0026quot;] doto宏返回对象，而不是任何方法调用的返回值，它更容易理解。如果你用macroexpand-1展开它，你可以看到它的结构与你刚才在前面的例子中看到的let表达式相同。\n(macroexpand-1 '(doto (java.util.Stack.) (.push \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;) (.push \u0026quot;Whoops, I meant 'Land, ho!'\u0026quot;))) ; =\u0026gt; (clojure.core/let [G__2876 (java.util.Stack.)] (.push G__2876 \u0026quot;Latest episode of Game of Thrones, ho!\u0026quot;) (.push G__2876 \u0026quot;Whoops, I meant 'Land, ho!'\u0026quot;) G__2876) 很方便!\n导入 在 Clojure 中，导入的效果和 Java 中的一样：你可以使用类，而不需要打出整个包的前缀。\n(import java.util.Stack) (Stack.) ; =\u0026gt; [] 你也可以使用这种一般形式一次导入多个类。\n(import [package.name1 ClassName1 ClassName2] [package.name2 ClassName3 ClassName4]) 下面是一个例子。\n(import [java.util Date Stack] [java.net Proxy URI]) (Date.) ; =\u0026gt; #inst \u0026quot;2016-09-19T20:40:02.733-00:00\u0026quot; 但通常情况下，你会在ns宏中做所有的导入工作，像这样。\n(ns pirate.talk (:import [java.util Date Stack]. [java.net Proxy URI]) 这两种不同的导入类的方法有相同的结果，但通常第二种方法更可取，因为对于阅读你的代码的人来说，在ns声明中看到所有涉及命名的代码很方便。\n这就是你导入类的方法! 很简单。为了使生活更加简单，Clojure 自动导入了java.lang中的类，包括java.lang.String和java.lang.Math，这就是为什么你能够使用String而不用前面的包名。\n常用的 Java 类 为了完善本章，让我们快速浏览一下你最可能用到的 Java 类。\n系统类 系统 \u0026ldquo;类具有有用的类字段和方法，可以与程序运行的环境进行交互。你可以用它来获取环境变量，与标准输入、标准输出和错误输出流进行交互。\n最有用的方法和成员是exit、getenv和getProperty。你可能在第 5 章中认识System/exit，在那里你用它来退出 Peg Thing 游戏。`System/exit\u0026rsquo;可以终止当前程序，你可以把状态代码作为参数传给它。如果你对状态代码不熟悉，我推荐维基百科的 \u0026ldquo;退出状态 \u0026ldquo;文章，网址是*退出状态-维基百科*。\nSystem/getenv将以 Map 形式返回所有系统的环境变量。\n(System/getenv) {\u0026quot;USER\u0026quot; \u0026quot;the-incredible-bulk\u0026quot; \u0026quot;JAVA_ARCH\u0026quot; \u0026quot;x86_64\u0026quot; } 环境变量的一个常见用途是配置你的程序。\nJVM 有自己的属性列表，与计算机的环境变量分开，如果需要读取它们，可以使用System/getProperty。\n➊ (System/getProperty \u0026quot;user.dir\u0026quot;) ; =\u0026gt; \u0026quot;/Users/dabulk/projects/dabook\u0026quot; ➋ (System/getProperty \u0026quot;java.version\u0026quot;) ; =\u0026gt; \u0026quot;1.7.0_17\u0026quot; 第一个调用➊返回 JVM 启动的目录，第二个调用➋返回 JVM 的版本。\n日期类 Java 有很好的工具来处理日期问题。我不会对java.util.Date类做太多的介绍，因为在线的 API 文档（可在*Date (Java Platform SE 7 )*)很详尽。作为一个 Clojure 开发者，你应该知道这个date类的三个特点。首先，Clojure 允许你使用这样的形式将日期表示为字面意义。\n#inst \u0026quot;2016-09-19T20:40:02.733-00:00\u0026quot; 第二，如果你想自定义如何将日期转换成字符串，或者你想将字符串转换成日期，你需要使用java.util.DateFormat类。第三，如果你要做的任务是比较日期或试图在日期上添加分钟、小时或其他时间单位，你应该使用极其有用的 clj-time 库（你可以在*GitHub - clj-time/clj-time: 一个用于 Clojure 的日期和时间库，包装了 Joda 时间库。*)。\n文件和输入/输出 在这一节中，你将了解到 Java 的输入/输出（IO）方法，以及 Clojure 如何简化它。clojure.java.io命名空间提供了许多方便的函数来简化 IO（clojure.java.io - Clojure v1.10.3 API 文档）。这很好，因为 Java 的 IO 并不完全是简单的。因为在你的编程生涯中，你可能会在某些时候想要执行 IO，让我们开始把你的思想触角缠绕在它上面。\nIO 涉及到资源，无论是文件、套接字、缓冲区，还是其他什么。Java 有独立的类来读取资源的内容，写入其内容，以及与资源的属性进行交互。\n例如，java.io.File类用于与文件的属性进行交互。\n(let [file (java.io.File. \u0026quot;/\u0026quot;)] ➊ (println (.exists file)) ➋ (println (.canWrite file)) ➌ (println (.getPath file))) ; =\u0026gt; true ; =\u0026gt; false ; =\u0026gt; / 在其他任务中，你可以用它来检查一个文件是否存在，获得文件的读/写/执行权限，并获得其文件系统路径，你可以在➊、➋和➌分别看到。\n在这个能力列表中，明显缺少读和写。要读一个文件，你可以使用java.io.BufferedReader类或者java.io.FileReader。同样地，你可以使用java.io.BufferedWriter或java.io.FileWriter类来写。其他类也可用于读写，你选择哪一个取决于你的具体需求。读取器和写入器类的接口都有相同的基本方法集；读取器实现了读取'、关闭\u0026rsquo;等，而写入器实现了添加'、写入'、关闭'和刷新'。Java 给你提供了各种 IO 工具。一个愤世嫉俗的人可能会说，Java 给你的绳子足以让你上吊，如果你找到这样一个人，我希望你能给他一个拥抱。\n不管怎么说，Clojure 使你的读写更容易，因为它包括了统一不同种类资源的读写的函数。例如，spit写到一个资源，而slurp从一个资源中读出。下面是一个使用它们来写和读一个文件的例子。\n(spit \u0026quot;/tmp/hercules-todo-list\u0026quot; \u0026quot;- kill dat lion brov - chop up what nasty multi-headed snake thing\u0026quot;) (slurp \u0026quot;/tmp/hercules-todo-list\u0026quot;) ; =\u0026gt; \u0026quot;- kill dat lion brov - chop up what nasty multi-headed snake thing\u0026quot; 你也可以对代表文件以外的资源的对象使用这些函数。下一个例子使用了一个StringWriter，它允许你对一个字符串进行 IO 操作。\n(let [s (java.io.StringWriter.)] (spit s \u0026quot;- capture cerynian hind like for real\u0026quot;) (.toString s)) ; =\u0026gt; \u0026quot;- capture cerynian hind like for real\u0026quot; 你也可以使用 \u0026ldquo;slurp \u0026ldquo;从StringReader中读取。\n(let [s (java.io.StringReader. \u0026quot;- get erymanthian pig what with the tusks\u0026quot;)] (slurp s)) ; =\u0026gt; \u0026quot;- get erymanthian pig what with the tusks\u0026quot; 此外，你可以对资源使用读和写方法。使用哪种方法并没有什么区别；spit和slurp很方便，因为它们只需使用一个代表文件系统路径或 URL 的字符串。\nwith-open宏是另一种便利：它在其主体的末尾隐含地关闭一个资源，确保你不会因为忘记手动关闭资源而意外地占用资源。reader函数是一个方便的工具，根据clojure.java.ioAPI 文档，\u0026ldquo;试图将其参数强制到一个开放的java.io.Reader\u0026quot;。当你不想使用slurp时，这很方便，因为你不想尝试完整地读取一个资源，你也不想弄清楚你需要使用哪个 Java 类。如果你想一行一行地读取一个文件，你可以使用reader和with-open以及line-seq函数。下面是如何打印 Hercules 待办事项清单的第一项的。\n(with-open [todo-list-rdr (clojure.java.io/reader \u0026quot;/tmp/hercules-todo-list\u0026quot;)] (println (first (line-seq todo-list-rdr)))) ; =\u0026gt; - kill dat lion brov 这应该足以让你在 Clojure 中开始使用 IO。如果你想做更复杂的任务，一定要看看clojure.java.io docs，[java.nio.file](https://docs.oracle.com/javase/7/docs/api/java/nio/file/package-summary.html)包文档，或[java.io](http://docs.oracle.com/javase/7/docs/api/java/io/package-summary.html)包文档。\n资源  \u0026ldquo;Java 虚拟机和编译器的解释\u0026rdquo;。 Java 虚拟机和编译器的解释\u0026ndash;YouTube clojure.org Java 互操作文档。 Clojure - Java Interop 维基百科的 \u0026ldquo;退出状态 \u0026ldquo;文章。 退出状态 - 维基百科  总结 在本章中，你了解了 Clojure 被托管在 JVM 上的含义。Clojure 程序被编译成 Java 字节码并在 JVM 进程中执行。Clojure 程序也可以访问 Java 库，你可以使用 Clojure 的互操作设施轻松地与它们交互。\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter12/","summary":"与 JVM 一起工作 在每个 Clojurist 的生命中都会有这么一天，她必须从纯函数和不可变数据结构的庇护所冒险进入野蛮的 Java 大陆。这段艰难的旅程是必要的，因为 Clojure 是在 Java 虚拟机（JVM）上托管的，这赋予了它三个基本特性。\n赋予它三个基本特征。首先，你运行 Clojure 应用程序的方式与你运行 Java 应用程序的方式相同。第二，你需要使用 Java 对象来实现核心功能，如读取文件和处理日期。第三，Java 有一个庞大的有用库的生态系统，你需要对 Java 有一定的了解才能使用它们。\n这样一来，Clojure 就有点像一个乌托邦社区，被放置在一个乌托邦国家的中间。显然，你更愿意与其他乌托邦人互动，但偶尔你也需要与当地人交谈，以便完成工作。\n这一章就像一本短语书和 Java 国家的文化介绍之间的交叉。你将了解什么是 JVM，它是如何运行程序的，以及如何为它编译程序。本章还将为你简要介绍常用的 Java 类和方法，并解释如何使用 Clojure 与它们互动。你将学会如何思考和理解 Java，以便将任何 Java 库纳入你的 Clojure 程序中。\n要运行本章的例子，你需要在电脑上安装 1.6 或更高版本的 Java 开发工具包（JDK）。你可以通过在终端运行javac -version来检查。你应该看到类似 \u0026ldquo;java 1.8.0_40 \u0026ldquo;的内容；如果没有，请访问http://www.oracle.com/，下载最新的 JDK。\nJVM 开发人员用 JVM 这个词来指代一些不同的东西。你会听到他们说，\u0026ldquo;Clojure 在the JVM 上运行\u0026rdquo;，你也会听到，\u0026ldquo;Clojure 程序在a JVM 中运行\u0026rdquo;。在第一种情况下，JVM 指的是一个抽象概念\u0026ndash;Java 虚拟机的一般模型。在第二种情况下，它指的是一个进程\u0026ndash;一个正在运行的程序的实例。我们将专注于 JVM 模型，但当我们谈论运行中的 JVM 进程时，我将指出来。\n为了理解 JVM，让我们回头看看普通的计算机是如何工作的。在计算机心脏的深处是它的 CPU，而 CPU 的工作是执行像加和无符号乘法这样的操作。你可能听说过程序员将这些指令编码在打卡机上、灯泡里、乌龟壳的神圣缝隙里，或者什么的，但现在这些操作在汇编语言中用 ADD 和 MUL 这样的记忆符号表示。CPU 架构（X86、ARMv7，等等）决定了哪些操作可以作为该架构的指令集的一部分。","title":"Chapter12 与 Java 的互操作"},{"content":"用 core.async 掌握并发进程 有一天，当你走在大街上时，你会惊讶、好奇，并有点厌恶地发现一台热狗自动贩卖机。你的头皮被有罪的好奇心刺痛，你会忍不住掏出三块钱，看看这个装置是否真的能工作。在 \u0026ldquo;咔嚓 \u0026ldquo;一声接受了你的钱后，它弹出了一个新鲜的热狗，包括面包和所有的东西。\n自动售货机表现出简单的行为：当它收到钱时，它会放出一个热狗，然后为下一次购买做准备。当它的热狗用完时，它就会停止。我们周围的热狗自动售货机以不同的面貌出现，它们是独立的实体，同时对世界上的事件作出反应。你最喜欢的咖啡店的浓缩咖啡机，你小时候喜欢的宠物仓鼠\u0026ndash;所有的东西都可以被分解成一组行为，这些行为遵循一般的形式 \u0026ldquo;当x发生时，做y\u0026quot;。甚至我们写的程序也只是美化的热狗贩卖机，每一个都是独立的进程，等待着下一个事件的发生，无论是击键、超时，还是套接字上的数据到达。\nClojure 的 core.async 库允许你在一个程序中创建多个独立进程。 本章描述了思考这种编程风格的有用模型，以及你在实际编写代码时需要了解的实际细节。你将学习如何使用通道在由 go 块和thread创建的独立进程之间进行通信；了解一些关于 Clojure 如何通过停放和阻塞有效地管理线程；如何使用alts!!；以及一种更直接的创建队列的方法。最后，你将学习如何用进程管道来踢回调的屁股。\n进程的入门 core.async 的核心是*进程，一个并发运行的逻辑单元，对事件做出反应。进程对应于我们对现实世界的心理模型：实体之间的互动和响应是独立的，没有某种中央控制机制的牵制。你把钱放进机器里，就会有一个热狗出来，所有这些都不需要光照派或老大哥来策划整个事情。这与你迄今为止一直在探索的并发性观点不同，在那里，你定义的任务要么只是控制主线程的扩展（例如，用pmap实现数据并行），要么是你没有兴趣与之交流的任务（如用future创建的一次性任务）。\n把自动售货机看成是一个进程可能很奇怪：自动售货机是名词和事物，而进程是动词和行为。为了获得正确的思维方式，可以尝试将现实世界的物体定义为其事件驱动的行为的总和。当一粒种子被浇水时，它就会发芽；当母亲看着她的新生儿时，她就会感受到爱；而当你观看《星战》第一集时，你会充满愤怒和绝望。如果你想变得超级哲学，可以考虑是否有可能将每个事物的本质定义为它所识别的事件的集合，以及它如何做出反应。现实是否只是热狗售卖机的组成？\n总之，我说得够多了! 让我们通过创建一些简单的过程，从理论上走向具体。首先，用 \u0026ldquo;lein new app playsync \u0026ldquo;创建一个新的 Leiningen 项目，名为playsync。然后，打开project.clj文件，将 core.async 添加到:dependenciesVector 中，使其内容如下。\n[[org.clojure/clojure \u0026quot;1.9.0\u0026quot;] [org.clojure/core.async \u0026quot;0.1.346.0-17112a-alpha\u0026quot;]] 注意 自从我写完这篇文章后，core.async 的版本有可能有所进步。关于最新的版本，请查看 core.async 的 GitHub 项目页面。但为了这些练习的目的，请使用这里列出的版本。\n接下来，打开src/playsync/core.clj，使其看起来像这样。\n(ns playsync.core (:require [clojure.core.async :as a :refer [\u0026gt;! \u0026lt;! \u0026gt;!! \u0026lt;!! go chan buffer close! thread alts! alts!! timeout]])) 现在，当你在 REPL 中打开它时，你将拥有最常用的 core.async 函数供你使用。很好! 在创建像热狗售卖机那样复杂和革命性的东西之前，先创建一个进程，简单地打印它收到的消息。\n(def echo-chan (chan)) (go (println (\u0026lt;! echo-chan))) (\u0026gt;!! echo-chan \u0026quot;ketchup\u0026quot;) ; =\u0026gt; true ; =\u0026gt; ketchup 在第一行代码中，你用chan函数创建了一个名为echo-chan的通道。通道传达消息*。你可以把消息放到一个通道上，也可以把消息从一个通道上拿下来。进程等待放和取的完成\u0026ndash;这些是进程所响应的事件。你可以认为进程有两个规则。1）当试图把一个消息放到通道上或从通道上取走一个消息时，等待并不做任何事情，直到放或取成功；2）当放或取成功时，继续执行。\n在下一行，你用go来创建一个新的进程。go表达式中的所有内容都被称为go 块，在一个单独的线程上并发运行。Go 块在一个线程池上运行你的进程，该线程池包含的线程数量等于你的机器上的核心数量的两倍，这意味着你的程序不必为每个进程创建一个新的线程。这通常会带来更好的性能，因为你避免了与创建线程有关的开销。\n在这个例子中，进程(println (\u0026lt;! echo-chan))表达了 \u0026ldquo;当我从`echo-chan\u0026rsquo;那里得到一个消息时，打印它\u0026rdquo;。该进程被分流到另一个线程，释放了当前线程，使你能够继续与 REPL 交互。\n在表达式(\u0026lt;! echo-chan)中，\u0026lt;!是take函数。它监听你给它作为参数的通道，它所属的进程等待，直到另一个进程在该通道上放出一个消息。当\u0026lt;!检索到一个值时，该值被返回并执行println表达式。\n表达式(\u0026gt;!! echo-chan \u0026quot;ketchup\u0026quot;)将字符串\u0026quot;ketchup\u0026quot;放到echo-chan上并返回true。当你把一个消息放在一个通道上时，该进程会阻塞，直到另一个进程接收该消息。在这种情况下，REPL 进程根本不需要等待，因为已经有一个进程在监听该通道，等待从该通道中获取信息。然而，如果你做了以下事情，你的 REPL 将无限期地阻塞。\n(\u0026gt;!! (chan) \u0026quot;mustard\u0026quot;) 你已经创建了一个新的通道，并在上面放了一些东西，但没有进程在监听这个通道。进程不仅仅是等待接收消息，他们也在等待他们放在通道上的消息被接收。\n缓冲 值得注意的是，前面的练习包含两个进程：你用go创建的进程和 REPL 进程。这些进程相互之间没有明确的知识，而且它们独立行动。\n让我们想象一下，这些过程发生在一个餐厅里。REPL 是番茄酱厨师，当他完成一个批次时，他大声说：\u0026ldquo;番茄酱！\u0026rdquo; 完全有可能的是，其他员工都在外面欣赏他们有机花园里最新的一批牛至，而厨师只是坐着等待，直到有人来取他的番茄酱。反过来说，\u0026ldquo;去 \u0026ldquo;的过程代表了其中一个工作人员，他正在耐心地等待着什么回应。可能是什么都没有发生，他只是无限期地等待，直到餐厅关门。\n这种情况似乎有点傻：哪个自尊心强的番茄酱厨师会在制作更多的番茄酱之前，只是坐等别人拿走他最新的一批番茄酱？为了避免这种悲剧的发生，你可以创建缓冲通道。\n(def echo-buffer (chan 2)) (\u0026gt;!! echo-buffer \u0026quot;ketchup\u0026quot;) ; =\u0026gt; true (\u0026gt;!! echo-buffer \u0026quot;ketchup\u0026quot;) ; =\u0026gt; true (\u0026gt;!! echo-buffer \u0026quot;ketchup\u0026quot;) ; This blocks because the channel buffer is full (小心评估最后一个(\u0026gt;! ! echo-buffer \u0026quot;ketchup\u0026quot;)，因为它将阻塞你的 REPL。如果你使用的是 Leiningen REPL，ctrl-C 会解除封锁）。\n在这种情况下，你已经创建了一个缓冲区大小为 2 的通道。这意味着你可以在通道上放两个值而不需要等待，但放第三个值意味着进程将等待，直到另一个进程从通道上取值。你还可以用sliding-buffer创建滑动缓冲区，它以先入先出的方式丢弃数值；用dropping-buffer创建丢弃缓冲区，它以后入先出的方式丢弃数值。这两种缓冲区都不会导致\u0026gt;!!阻塞。\n通过使用缓冲区，番茄酱大师可以继续制作成批令人垂涎欲滴的番茄酱，而不必等待他的员工把它们带走。如果他使用普通的缓冲器，就像他有一个架子，可以把所有的番茄酱批次放在上面；一旦架子满了，他还得等待空间的打开。如果他用的是滑动缓冲器，当架子上的番茄酱满了，他就会把最旧的一批扔掉，把所有的番茄酱滑下来，然后把新的一批放到空出来的地方。如果是跌落式缓冲器，他就会把最新鲜的一批番茄酱从货架上打下来，然后把新的一批番茄酱放在那个空间里。\n缓冲区只是对核心模型的阐述：进程是独立的、并发执行的逻辑单元，对事件作出反应。你可以用 go 块来创建进程，并通过通道来沟通事件。\n堵塞和停车 你可能已经注意到，take 函数\u0026lt;!只使用了一个感叹号，而 put 函数\u0026gt;!则使用了两个感叹号。事实上，put 和 take 都有一个感叹号和两个感叹号的种类。什么时候使用哪个？简单的答案是，你可以在 go 块内使用一个感叹号，但你必须在 go 块外使用两个感叹号。\n    Inside go block Outside go block     put \u0026gt;! or \u0026gt;!! \u0026gt;!!   take \u0026lt;! or \u0026lt;!! \u0026lt;!!    这一切都归结为效率问题。因为 go 块使用一个固定大小的线程池，你可以创建 1000 个 go 进程，但只使用少量的线程。\n(def hi-chan (chan)) (doseq [n (range 1000)]) (go (\u0026gt;! hi-chan (str \u0026quot;hi \u0026quot; n))))) 为了理解 Clojure 是如何做到这一点的，我们需要探索进程如何等待。等待是使用 core.async 进程的一个关键方面：我们已经确定，put会等待到另一个进程在同一通道上做take*，反之亦然。在这个例子中，1,000 个进程在等待另一个进程从 \u0026ldquo;hi-chan \u0026ldquo;中提取。\n有两种类型的等待。 停车和阻塞。阻塞是你熟悉的那种等待：一个线程停止执行，直到一个任务完成。通常这发生在你进行某种 I/O 操作的时候。这个线程仍然活着，但不做任何工作，所以如果你想让你的程序继续工作，你必须创建一个新的线程。在第 9 章中，你学到了如何用 \u0026ldquo;future \u0026ldquo;来做这件事。\n停车释放了线程，这样它就可以继续工作了。假设你有一个线程和两个进程，Process A 和 Process B，Process A 在线程上运行，然后等待放或取。Clojure 将进程 A 移出线程，并将进程 B 移到线程上。如果进程 B 开始等待，而进程 A 的 put 或 take 已经完成，那么 Clojure 将把进程 B 移出线程，把进程 A 放回线程上。停放允许多个进程的指令在一个线程上交错，类似于使用多个线程允许在一个核心上交错的方式。停放的实现并不重要；只需说它只在 go 块内实现，并且只在使用\u0026gt;!和\u0026lt;!，或停放 put和停放 take时实现。\u0026gt;!!和\u0026lt;!!是停放的放和停放的取。\n线程 肯定有一些时候你会想使用阻塞而不是停放，比如你的进程要花很长时间才能放或取，在这些场合你应该使用线程。\n(thread (println (\u0026lt;!! echo-chan))) (\u0026gt;!! echo-chan \u0026quot;mustard\u0026quot;) ; =\u0026gt; true ; =\u0026gt; mustard thread的行为几乎与future完全一样：它创建一个新的线程并在该线程上执行一个进程。与future'不同的是，thread\u0026rsquo;不是返回一个可以反推的对象，而是返回一个通道。当thread的进程停止时，该进程的返回值会被放在thread返回的通道上。\n(let [t (thread \u0026quot;chili\u0026quot;) ] (\u0026lt;!! t)) ; =\u0026gt; \u0026quot;chili\u0026quot; 在这种情况下，进程不等待任何事件；相反，它立即停止。它的返回值是 \u0026ldquo;chili\u0026rdquo;，它被放在与t绑定的通道上。我们从t中获取，返回`\u0026ldquo;chili\u0026rdquo;。\n当你执行一个长期运行的任务时，你应该使用thread而不是 go block，原因是你不会堵塞你的线程池。想象一下，你正在运行四个进程，下载巨大的文件，保存它们，然后把文件的路径放在一个通道上。当这些进程在下载文件和保存这些文件时，Clojure 不能停放它们的线程。它只能在最后一步停放线程，即进程将文件的路径放在通道上时。因此，如果你的线程池只有四个线程，所有四个线程都将被用于下载，在其中一个下载完成之前，不允许其他进程运行。\ngo、thread、chan、\u0026lt;!、\u0026lt;!、\u0026gt;!和\u0026gt;!是你用来创建和与进程通信的核心工具。put 和 take 都会使一个进程等待，直到它的补码在给定的通道上被执行。go允许你使用 put 和 take 的停车变体，这可以提高性能。如果你在 put 和 take 之前执行长期运行的任务，你应该使用阻塞式变体，以及thread。\n这应该能满足你的一切需求，让你实现你的心愿，创造一台把钱变成热狗的机器。\n你一直渴望的热狗机过程 看哪，你的梦想成真了!\n(defn hot-dog-machine [] (let [in (chan) out (chan)] (go (\u0026lt;! in) (\u0026gt;! out \u0026quot;hot dog\u0026quot;)) [in out])) 这个函数创建了一个in通道用于接收钱，一个out通道用于发放热狗。然后用go创建一个异步进程，等待钱，然后发放热狗。最后，它将in和out通道作为一个 Vector 返回。\n是时候吃热狗了!\n(let [[in out] (hot-dog-machine)] (\u0026gt;!! in \u0026quot;pocket lint\u0026quot;) (\u0026lt;!! out)) ; =\u0026gt; \u0026quot;hot dog\u0026quot; 在这个片段中，你用 destructuring（在第三章中讲到）和let将in和out通道绑定到in和out符号。然后你把 \u0026ldquo;pocket lint \u0026ldquo;放在 \u0026ldquo;in \u0026ldquo;通道上。热狗机器进程等待着一些东西，任何东西，到达in通道；一旦\u0026quot;pocket lint\u0026quot;到达，热狗机器进程恢复执行，将\u0026quot;hot dog\u0026quot;放在out通道上。\n等一下……这不对。我的意思是，是的，免费的热狗，但是一定会有人因为机器接受小棉絮作为付款而不高兴。不仅如此，这台机器在关闭前只能发放一个热狗。让我们改变热狗机的功能，让你可以指定它有多少个热狗，并且当你给它数字 3 时，它才会发放一个热狗。\n(defn hot-dog-machine-v2 [hot-dog-count] (let [in (chan) out (chan)] (go (loop [hc hot-dog-count] (if (\u0026gt; hc 0) (let [input (\u0026lt;! in)] ➊(if (= 3 input) (do (\u0026gt;! out \u0026quot;hot dog\u0026quot;) (recur (dec hc))) (do (\u0026gt;! out \u0026quot;wilted lettuce\u0026quot;) (recur hc)))) ➋(do (close! in) (close! out))))) [in out])) 这里有很多代码，但策略是直接的。新函数hot-dog-machine-v2允许你指定hot-dog-count。在➊的 go 块内，只有当数字 3（意思是三块钱）被放在`in\u0026rsquo;通道上时，它才会派发热狗；否则，它派发枯萎的生菜，这绝对不是热狗。一旦一个进程采取了输出，热狗机进程就会带着更新的热狗数量循环回来，并准备再次接收钱。\n当机器进程的热狗用完时，该进程就会在➋处关闭通道。当你关闭一个通道时，你就不能再对它执行 put，而且一旦你从一个关闭的通道上取走所有的值，任何后续的取值都将返回 \u0026ldquo;nil\u0026rdquo;。\n让我们来试试清单 11-1 中的升级版热狗机，把钱和口袋里的棉絮放进去。\n(let [[in out] (hot-dog-machine-v2 2)] (\u0026gt;!! in \u0026quot;pocket lint\u0026quot;) (println (\u0026lt;!! out)) (\u0026gt;!! in 3) (println (\u0026lt;!! out)) (\u0026gt;!! in 3) (println (\u0026lt;!! out)) (\u0026gt;!! in 3) (\u0026lt;!! out)) ; =\u0026gt; wilted lettuce ; =\u0026gt; hotdog ; =\u0026gt; hotdog ; =\u0026gt; nil  清单 11-1. 与一个健壮的热狗售货机进程交互  首先，我们尝试了 \u0026ldquo;口袋里的棉絮 \u0026ldquo;这一招，得到了打蔫的生菜。接下来，我们两次投入 3 美元，两次都得到一个热狗。然后，我们试图再投入 3 美元，但这被忽略了，因为通道已经关闭；数字 3 没有被放在通道上。当我们试图从 \u0026ldquo;出 \u0026ldquo;通道取钱时，我们得到的是 \u0026ldquo;零\u0026rdquo;，这也是因为该通道是关闭的。你可能会注意到hot-dog-machine-v2的几个有趣的细节。首先，它在同一个 go 块中做了一个 put 和一个 take。这并不罕见，这也是创建进程管道的一种方法：只要让一个进程的入通道成为另一个进程的出*通道。下面的例子就是这样做的，把一个字符串通过一系列的进程进行转换，直到最后一个进程打印出这个字符串。\n(let [c1 (chan) c2 (chan) c3 (chan)] (go (\u0026gt;! c2 (clojure.string/upper-case (\u0026lt;! c1)))) (go (\u0026gt;! c3 (clojure.string/reverse (\u0026lt;! c2)))) (go (println (\u0026lt;! c3))) (\u0026gt;!! c1 \u0026quot;redrum\u0026quot;)) ; =\u0026gt; MURDER 在本章的最后，我将会有更多关于进程管道以及如何使用它们来代替回调的内容。\n回到清单 11-1! 另一件需要注意的事情是，热狗机在你处理完它所发放的东西之前，不会接受更多的钱。这允许你建立类似于状态机的行为模型，其中通道操作的完成会触发状态转换。例如，你可以认为自动售货机有两个状态。准备接收钱和发放物品*。插入钱和取走物品会触发这两者之间的转换。\nalts core.async 函数alts!!可以让你使用一个操作集合中第一个成功的通道操作的结果。我们在第 198 页的 \u0026ldquo;延迟 \u0026ldquo;中用延迟和 Future 做了类似的事情。在那个例子中，我们把一组头像上传到一个头像分享网站，并在第一张照片上传时通知头像所有者。下面是你如何用alts!!做同样的事情。\n(defn upload [headshot c] (go (Thread/sleep (rand 100)) (\u0026gt;! c headshot))) ➊ (let [c1 (chan) c2 (chan) c3 (chan)] (upload \u0026quot;serious.jpg\u0026quot; c1) (upload \u0026quot;fun.jpg\u0026quot; c2) (upload \u0026quot;sassy.jpg\u0026quot; c3) ➋ (let [[headshot channel] (alts!! [c1 c2 c3])] (println \u0026quot;Sending headshot notification for\u0026quot; headshot))) ; =\u0026gt; Sending headshot notification for sassy.jpg 在这里，upload函数接收一个头像和一个频道，并创建一个新的进程，该进程将随机睡眠一段时间（模拟上传），然后将头像放到频道上。从➊开始的let绑定和upload函数调用应该是有意义的：我们创建了三个通道，然后用它们来执行上传。\n事情在➋处变得有趣。alts!!函数需要一个通道的 Vector 作为其参数。这就好比说，\u0026ldquo;试着在这些通道上同时做一个阻塞性的拍摄。一旦取值成功，返回一个 Vector，其第一个元素是取值，第二个元素是获胜的通道\u0026rdquo;。在这个例子中，与sassy.jpg相关的通道首先收到了一个值。如果你想获取它们的值并对它们进行处理，其他通道仍然可用。alts!!所做的只是从第一个有值的通道中获取一个值；它并不触及其他通道。\nalts!!的一个很酷的方面是，你可以给它一个timeout 通道，它等待指定的毫秒数，然后关闭。这是一个优雅的机制，可以为并发操作设置一个时间限制。下面是你如何在上传服务中使用它。\n(let [c1 (chan)] (upload \u0026quot;serious.jpg\u0026quot; c1) (let [[headshot channel] (alts!! [c1 (timeout 20)])] (if headshot (println \u0026quot;Sending headshot notification for\u0026quot; headshot) (println \u0026quot;Timed out!\u0026quot;)))) ; =\u0026gt; Timed out! 在这种情况下，我们将超时设置为 20 毫秒。因为上传没有在这个时间段完成，我们得到了一个超时消息。\n你也可以使用alts!!来指定 put 操作。要做到这一点，在你传递给alts!!的 Vector 内放置一个 Vector，就像本例中的➊。\n(let [c1 (chan) c2 (chan)] (go (\u0026lt;! c2)) ➊ (let [[value channel] (alts!! [c1 [c2 \u0026quot;put!\u0026quot;]])] (println value) (= channel c2))) ; =\u0026gt; true ; =\u0026gt; true 这里你创建了两个通道，然后创建了一个进程，等待对c2进行处理。你提供给alts!!的 Vector 告诉它，\u0026ldquo;尝试对c1'进行取舍，并尝试将\u0026ldquo;put!\u0026quot;放在c2\u0026rsquo;上。如果在c1上的取值首先完成，返回其值和通道。如果在c2上的投放先完成，如果投放成功，返回true，否则返回false。\u0026rdquo; 最后，value的结果（是true，因为c2的通道是开放的）打印出来，显示返回的通道确实是c2。\n像\u0026lt;!!和\u0026gt;!!一样，alts!!有一个停车的选择，alts!，你可以在 go 块中使用它。 alts!是一个很好的方法，可以对一组通道中的哪一个进行投入或取出的选择。它仍然执行放和取，所以使用停放或阻塞变量的理由同样适用。\n这就涵盖了 core.async 的基础知识! 本章的其余部分解释了协调进程的两种常见模式。\n队列 在第 202 页的 \u0026ldquo;滚动你自己的队列 \u0026ldquo;中，你写了一个宏，让你对 Future 进行排队。进程让你以一种更直接的方式使用类似的技术。假设你想从一个网站上获得一堆随机的报价，并把它们写到一个文件中。你想确保每次只有一个报价被写入文件，这样文本就不会被交错，所以你把你的报价放在一个队列中。下面是完整的代码。\n(defn append-to-file \u0026quot;Write a string to the end of a file\u0026quot; [filename s] (spit filename s :append true)) (defn format-quote \u0026quot;Delineate the beginning and end of a quote because it's convenient\u0026quot; [quote] (str \u0026quot;=== BEGIN QUOTE ===\\n\u0026quot; quote \u0026quot;=== END QUOTE ===\\n\\n\u0026quot;)) (defn random-quote \u0026quot;Retrieve a random quote and format it\u0026quot; [] (format-quote (slurp \u0026quot;http://www.braveclojure.com/random-quote\u0026quot;))) (defn snag-quotes [filename num-quotes] (let [c (chan)] (go (while true (append-to-file filename (\u0026lt;! c)))) (dotimes [n num-quotes] (go (\u0026gt;! c (random-quote)))))) 函数append-to-file、format-quote和random-quote有文档说明它们的作用。snag-quotes是发生有趣工作的地方。首先，它创建一个通道，在产生报价的进程和消费报价的进程之间共享。然后，它创建了一个使用 \u0026ldquo;while true \u0026ldquo;来创建一个无限循环的进程。在循环的每一次迭代中，它等待一个报价到达c，然后将其追加到一个文件中。最后，snag-quotes创建一个num-quotes数量的进程来获取一个引号，然后把它放在c上。如果你评估(snag-quotes \u0026quot;quotes\u0026quot; 2)并检查你启动 REPL 的目录中的quotes文件，它应该有两个引号。\n=== BEGIN QUOTE === Nobody's gonna believe that computers are intelligent until they start coming in late and lying about it. === END QUOTE === === BEGIN QUOTE === Give your child mental blocks for Christmas. === END QUOTE === 这种排队方式与第 9 章中的例子不同。在那个例子中，每个任务都是按照其创建的顺序来处理的。在这里，每个获取报价的任务是按照它完成的顺序来处理的。在这两种情况下，你都要确保每次只有一个报价被写入文件。\n用进程管道逃离回调地狱 在没有通道的语言中，你需要用 \u0026ldquo;回调 \u0026ldquo;来表达 \u0026ldquo;当x发生时，做y\u0026ldquo;的想法。在像 JavaScript 这样的语言中，回调是一种定义代码的方式，一旦其他代码完成就会异步执行。如果你使用过 JavaScript，你可能已经花了一些时间在回调地狱中沉溺。\n它被称为回调地狱的原因是，在回调层之间很容易产生不明显的依赖关系。它们最终会共享状态，使得在回调被触发时很难推理整个系统的状态。你可以通过创建一个流程管道来避免这种令人沮丧的结果。这样一来，每个逻辑单元都生活在自己独立的进程中，逻辑单元之间的所有通信都通过明确定义的输入和输出通道进行。\n在下面的例子中，我们创建了三个通过通道连接的无限循环进程，将一个进程的输出通道作为管道中下一个进程的输入通道。\n(defn upper-caser [in］ (let [out (chan)] (让 [out (chan)]) (go (while true (\u0026gt;! out (clojure.string/upper-case (\u0026lt;! in)))))) out)) (defn reverser [in］ (let [out (chan)] (go (while true (\u0026gt;! (go (while true (\u0026gt;! out (clojure.string/reverse (\u0026lt;! in)))))) out)) (defn printer [in］ (go (while true (println (\u0026lt;! in)))))) (def in-chan (chan)) (def upper-caser-out (upper-caser in-chan)) (def reverser-out (reverser upper-caser-out)) (Printer reverser-out) (\u0026gt;！！in-chan \u0026quot;redrum\u0026quot;) ; =\u0026gt; MURDER (\u0026gt;!! in-chan \u0026quot;repaid\u0026quot;) ; =\u0026gt; DIAPER 通过使用这样的流程处理事件，推理整个数据转换系统的各个步骤就更容易了。你可以查看每个步骤并理解它的作用，而不必参考之前可能发生的事情或之后可能发生的事情；每个过程就像一个纯函数一样容易推理。\n额外资源 Clojure 的 core.async 库在很大程度上受到 Go 的并发模型的启发，它是基于 Tony Hoare 在Communicating Sequential Processes中的工作，可在*http://www.usingcsp.com/。*\nGo 的共同创造者 Rob Pike 有一个很好的关于并发的演讲，可在*Google I/O 2012 - Go 并发模式 - YouTube*。\nClojureScript，也被称为浏览器的最佳选择，使用 core.async。不再有回调的地狱! 你可以在*https://github.com/clojure/clojurescript*了解 ClojureScript 的情况。\n最后，在*clojure.core.async - core.async 1.2.599-SNAPSHOT API documentation*查看 API 文档。\n总结 在本章中，你了解了 core.async 如何允许你创建并发进程，以响应通道上的 put 和 take 通信事件。你了解了如何使用go和thread来创建并发进程，通过停放和阻塞来等待通信事件。你还学习了如何通过使一个进程的出通道成为另一个进程的入通道来创建进程管道，以及这如何使你写的代码比嵌套回调更容易理解。最后，你思考了你是否只是一台花哨的热狗售货机。\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter11/","summary":"用 core.async 掌握并发进程 有一天，当你走在大街上时，你会惊讶、好奇，并有点厌恶地发现一台热狗自动贩卖机。你的头皮被有罪的好奇心刺痛，你会忍不住掏出三块钱，看看这个装置是否真的能工作。在 \u0026ldquo;咔嚓 \u0026ldquo;一声接受了你的钱后，它弹出了一个新鲜的热狗，包括面包和所有的东西。\n自动售货机表现出简单的行为：当它收到钱时，它会放出一个热狗，然后为下一次购买做准备。当它的热狗用完时，它就会停止。我们周围的热狗自动售货机以不同的面貌出现，它们是独立的实体，同时对世界上的事件作出反应。你最喜欢的咖啡店的浓缩咖啡机，你小时候喜欢的宠物仓鼠\u0026ndash;所有的东西都可以被分解成一组行为，这些行为遵循一般的形式 \u0026ldquo;当x发生时，做y\u0026quot;。甚至我们写的程序也只是美化的热狗贩卖机，每一个都是独立的进程，等待着下一个事件的发生，无论是击键、超时，还是套接字上的数据到达。\nClojure 的 core.async 库允许你在一个程序中创建多个独立进程。 本章描述了思考这种编程风格的有用模型，以及你在实际编写代码时需要了解的实际细节。你将学习如何使用通道在由 go 块和thread创建的独立进程之间进行通信；了解一些关于 Clojure 如何通过停放和阻塞有效地管理线程；如何使用alts!!；以及一种更直接的创建队列的方法。最后，你将学习如何用进程管道来踢回调的屁股。\n进程的入门 core.async 的核心是*进程，一个并发运行的逻辑单元，对事件做出反应。进程对应于我们对现实世界的心理模型：实体之间的互动和响应是独立的，没有某种中央控制机制的牵制。你把钱放进机器里，就会有一个热狗出来，所有这些都不需要光照派或老大哥来策划整个事情。这与你迄今为止一直在探索的并发性观点不同，在那里，你定义的任务要么只是控制主线程的扩展（例如，用pmap实现数据并行），要么是你没有兴趣与之交流的任务（如用future创建的一次性任务）。\n把自动售货机看成是一个进程可能很奇怪：自动售货机是名词和事物，而进程是动词和行为。为了获得正确的思维方式，可以尝试将现实世界的物体定义为其事件驱动的行为的总和。当一粒种子被浇水时，它就会发芽；当母亲看着她的新生儿时，她就会感受到爱；而当你观看《星战》第一集时，你会充满愤怒和绝望。如果你想变得超级哲学，可以考虑是否有可能将每个事物的本质定义为它所识别的事件的集合，以及它如何做出反应。现实是否只是热狗售卖机的组成？\n总之，我说得够多了! 让我们通过创建一些简单的过程，从理论上走向具体。首先，用 \u0026ldquo;lein new app playsync \u0026ldquo;创建一个新的 Leiningen 项目，名为playsync。然后，打开project.clj文件，将 core.async 添加到:dependenciesVector 中，使其内容如下。\n[[org.clojure/clojure \u0026quot;1.9.0\u0026quot;] [org.clojure/core.async \u0026quot;0.1.346.0-17112a-alpha\u0026quot;]] 注意 自从我写完这篇文章后，core.async 的版本有可能有所进步。关于最新的版本，请查看 core.async 的 GitHub 项目页面。但为了这些练习的目的，请使用这里列出的版本。\n接下来，打开src/playsync/core.clj，使其看起来像这样。\n(ns playsync.core (:require [clojure.core.async :as a :refer [\u0026gt;! \u0026lt;! \u0026gt;!! \u0026lt;!! go chan buffer close! thread alts! alts!! timeout]])) 现在，当你在 REPL 中打开它时，你将拥有最常用的 core.async 函数供你使用。很好! 在创建像热狗售卖机那样复杂和革命性的东西之前，先创建一个进程，简单地打印它收到的消息。","title":"Chapter11 core.async"},{"content":"Clojure Metaphysics: 原子、Refs、Vars 和拥抱僵尸 三个并发性的小妖精都是从同一个邪恶的坑里生出来的：对可变状态的共享访问。你可以在第九章的引用单元讨论中看到这一点。当两个线程对引用单元进行不协调的更改时，结果是不可预测的。\nRich Hickey 设计 Clojure 是为了专门解决共享访问易变状态所产生的问题。事实上，Clojure 体现了一种非常清晰的状态概念，使其在本质上比大多数流行的编程语言更安全。它是安全的，一直到它的meta-freakin-physics。\n在本章中，你将了解 Clojure 的底层形而上学，与典型的面向对象（OO）语言的形而上学相比较。学习这种哲学将使你准备好处理 Clojure 剩下的并发工具，atom、ref和var引用类型。(Clojure 还有一个额外的引用类型，agents，本书没有涉及。) 这些类型中的每一个都能让你安全地同时执行状态修改操作。你还会学到一些简单的方法，使你的程序更有效率，而不需要引入状态。\n形而上学试图用最广泛的术语来回答两个基本问题。\n 那里有什么？ 它是什么样子的？  为了引出 Clojure 和 OO 语言之间的差异，我将解释两种不同的拥抱僵尸的建模方式。与普通的僵尸不同，拥抱僵尸并不想要吞噬你的大脑。它只想用勺子舀你，也许还想闻闻你的脖子。这使得它的不死、摇晃、腐烂的状态更加悲惨。你怎么能试图杀死只想要爱的东西呢？谁是这里真正的怪物？\n面向对象的形而上学 OO 形而上学将拥抱僵尸视为存在于世界上的一个对象。这个对象的属性可能会随着时间的推移而改变，但它仍然被当作一个单一的、不变的对象。如果这看起来是一个完全明显的、没有争议的僵尸形而上学的方法，那么你可能没有在哲学入门课上花几个小时来争论一把椅子的存在意味着什么，以及什么真正使它首先成为一把椅子。\n棘手的部分是，拥抱的僵尸总是在变化。它的身体慢慢恶化。随着时间的推移，它对拥抱的不灭渴望越来越强烈。在 OO 术语中，我们会说拥抱僵尸是一个具有可改变状态的对象，它的状态是不断波动的。但是不管这个僵尸有多大的变化，我们仍然把它认定为同一个僵尸。下面是你如何在 Ruby 中对抱团僵尸进行建模和交互。\nclass CuddleZombie # attr_accessor is just a shorthand way for creating getters and # setters for the listed instance variables attr_accessor :cuddle_hunger_level, :percent_deteriorated def initialize(cuddle_hunger_level = 1, percent_deteriorated = 0) self.cuddle_hunger_level = cuddle_hunger_level self.percent_deteriorated = percent_deteriorated end end fred = CuddleZombie.new(2, 3) fred.cuddle_hunger_level # =\u0026gt; 2 fred.percent_deteriorated # =\u0026gt; 3 fred.cuddle_hunger_level = 3 fred.cuddle_hunger_level # =\u0026gt; 3  10-1. 用 Ruby 建立抱团僵尸行为模型  在这个例子中，你创建了一个抱团僵尸，fred，有两个属性。cuddle_hunger_level和percent_deteriorated。fred一开始的cuddle_hunger_level是 2，但是你可以把它改成任何你想要的东西，它仍然是好的\u0026rsquo;Fred，同一个拥抱僵尸。在这种情况下，你把它的`cuddle_hunger_level\u0026rsquo;改为 3。\n你可以看到，这个对象只是一个花哨的引用单元。在多线程环境下，它也会受到同样的非确定性结果的影响。例如，如果两个线程试图用fred.cuddle_hunger_level = fred.cuddle_hunger_level + 1这样的方式来增加 Fred 的饥饿度，其中一个增量可能会丢失，就像《三个小妖精》中两个线程向X写入的例子一样。参考单元格、相互排斥和矮人狂战士 \u0026ldquo;中的例子。\n即使你只在一个单独的线程上进行读取，程序仍将是非确定性的。例如，假设你正在进行关于抱团僵尸行为的研究。你想记录一个僵尸的饥饿程度，只要它达到 50%的恶化程度，但你想在另一个线程上进行，以提高性能，使用类似清单 10-1 中的代码。\nif fred.percent_deteriorated \u0026gt;= 50 Thread.new { database_logger.log(fred.cuddle_hunger_level) } end  这段 Ruby 代码在并发执行时并不安全。  问题是，另一个线程可能在实际写入之前改变fred。\n例如，图 10-1 显示了两个从上到下执行的线程。在这种情况下，将 5 写入数据库是正确的，但 10 却被写入了。\n图 10-1：记录不一致的抱团僵尸数据\n这将是很不幸的。当你试图从拥抱僵尸的启示中恢复时，你不希望你的数据是不一致的。然而，没有办法保留一个对象在某一特定时刻的状态。\n此外，为了同时改变cuddle_hunger_level和percent_deteriorated，你必须特别小心。否则，fred有可能被视为不一致的状态，因为另一个线程可能会在你打算同时进行的两个变化之间读取fred`对象，像这样。\nfred.cuddle_hunger_level = fred.cuddle_hunger_level + 1 # At this time, another thread could read fred's attributes and # \u0026quot;perceive\u0026quot; fred in an inconsistent state unless you use a mutex fred.percent_deteriorated = fred.percent_deteriorated + 1 这是另一个版本的互斥问题。在面向对象编程（OOP）中，你可以用mutex来手动解决这个问题，它可以确保在 mutex 的持续时间内，每次只有一个线程可以访问一个资源（在本例中，就是fred对象）。\n对象永远不稳定的事实并不妨碍我们把它们当作程序的基本构件。事实上，这被认为是 OOP 的一个优势。状态如何变化并不重要；你仍然可以与一个稳定的接口进行交互，一切都会正常工作。这符合我们对世界的直观感觉。一块蜡仍然是同一块蜡，即使它的属性发生了变化：如果我改变了它的颜色，融化了它，然后把它倒在我的敌人的脸上，我仍然会认为它是我开始时的那个蜡对象。\n另外，在 OOP 中，对象也会做事。它们相互作用，在程序运行时改变状态。同样，这也符合我们对世界的直观感觉：变化是对象相互作用的结果。一个人的对象推到一个门的对象上，进入一个房子的对象。\nClojure 形而上学 在 Clojure 形而上学中，我们会说，我们永远不会遇到两次相同的拥抱僵尸。拥抱僵尸并不是一个独立于其变异而存在于世界上的离散事物：它实际上是一连串的价值。\n术语值经常被 Clojurists 使用，其具体含义可能与你的习惯不同。价值是*原子性的，即它们在一个更大的系统中形成一个单一的不可还原的单位或组成部分；它们是不可分割的、不变的、稳定的实体。数字是价值：数字 15 变异为另一个数字是没有意义的。当你从 15 加减时，你并没有改变 15 这个数字；你只是得到了一个不同的数字。Clojure 的数据结构也是价值，因为它们是不可改变的。当你在一个 Map 上使用assoc时，你不会修改原来的 Map；相反，你会派生出一个新的 Map。\n所以一个值不会改变，但是你可以对一个值应用一个过程来产生一个新的值。例如，假设我们从一个值F1开始，然后我们把拥抱僵尸过程应用到F1*，产生值F2。然后这个过程又被应用到F2的值上，产生F3的值，以此类推。\n这导致了对身份的不同概念。Clojure 形而上学不是像 OO 形而上学那样把身份理解为变化的对象所固有的，而是把身份理解为我们人类强加给由一个过程随时间产生的一连串不变的值的东西。我们使用名字来指定身份。名字Fred是指一系列单独的状态F1、F2、F3等等的方便方法。从这个角度来看，不存在所谓的可改变的状态。相反，state指的是某个时间点上的身份值。\nRich Hickey 用电话号码的比喻来解释状态。 Alan 的电话号码已经改变了 10 次，但我们将永远用同一个名字来称呼这些号码，即Alan 的电话号码。艾伦五年前的电话号码与今天的电话号码是不同的数值，两者是艾伦电话号码身份的两种状态。\n当你考虑到在你的程序中你是在处理关于世界的信息时，这是有意义的。与其说信息发生了变化，不如说你收到了新的信息。周五中午 12 点，\u0026ldquo;抱抱僵尸 \u0026ldquo;弗雷德处于 50%的腐烂状态。在下午 1 点，他是 60%的腐烂。这都是你可以处理的事实，引入一个新的事实并不会使以前的事实失效。即使弗雷德的衰变率从 50%增加到 60%，但在下午 12:00 时他处于 50%的衰变状态仍然是事实。\n图 10-2 显示了你可以如何将价值、过程、身份和状态可视化。\n图 10-2：价值、过程、身份和状态\n这些价值不会相互作用，也不能被改变。它们不能*做任何事情。只有在以下情况下才会发生变化：a）一个过程产生了一个新的值；b）我们选择将身份与新的值联系起来。\n为了处理这种变化，Clojure 使用参考类型。参考类型让你在 Clojure 中管理身份。使用它们，你可以命名一个身份并检索其状态。让我们来看看其中最简单的，原子。\n原子 Clojure 的原子引用类型允许你赋予一连串的相关值以身份。下面是你如何创建一个原子。\n(def fred (atom {:cuddle-hunger-level 0 :percent-deteriorated 0})) 这将创建一个新的原子，并将其与名称fred绑定。这个原子*引用了{:cuddle-hunger-level 0 :percent-deteriorated 0}的值，你可以说这是它的当前状态。\n要得到一个原子的当前状态，你要解除对它的引用。下面是 Fred 的当前状态。\n@fred ; =\u0026gt; {:cuddle-hunger-level 0, :percent-deteriorated 0} 与期货、延迟和承诺不同，解除对原子（或任何其他引用类型）的引用将永远不会阻塞。当你解除对期货、延迟和承诺的引用时，就像你在说 \u0026ldquo;我现在需要一个值，我会一直等到我得到它\u0026rdquo;，所以这个操作会阻塞是合理的。然而，当你解除引用类型的引用时，就像你在说 \u0026ldquo;给我我现在引用的值\u0026rdquo;，所以操作不会阻塞是有道理的，因为它不需要等待任何东西。\n在清单 10-1 中的 Ruby 例子中，我们看到当你试图在一个单独的线程上记录数据时，对象数据可能会发生变化。当使用原子来管理状态时就不会发生这种危险，因为每个状态都是不可改变的。下面是你如何用println来记录一个僵尸的状态。\n(let [zombie-state @fred] (if (\u0026gt;= (:percent-deteriorated zombie-state) 50) (future (println (:cuddle-hunger-level zombie-state))))) 清单 10-1 中的 Ruby 例子的问题是，它需要两步来读取僵尸的两个属性，而其他线程可能在这两步之间改变这些属性。然而，通过使用原子来引用不可变的数据结构，你只需要执行一次读取，并且返回的数据结构不会被其他线程改变。\n要更新原子，使其指向一个新的状态，你可以使用swap!。这似乎是矛盾的，因为我说过，原子值是不变的。的确，它们是不变的。但是现在我们正在使用原子的参考类型，一个指向原子值的结构。原子值不会改变，但是引用类型可以被更新并被分配一个新的值。\nswap!接收一个原子和一个函数作为参数。它将函数应用于原子的当前状态以产生一个新的值，然后它更新原子以引用这个新的值。新的值也被返回。下面是你如何将 Fred 的拥抱饥饿度提高 1。\n(swap! fred (fn [current-state] (merge-with + current-state {:cuddle-hunger-level 1}))) ; =\u0026gt; {:cuddle-hunger-level 1, :percent-deteriorated 0} 取消引用fred将返回新的状态。\n@fred ; =\u0026gt; {:cuddle-hunger-level 1, :percent-deteriorated 0} 与 Ruby 不同，fred不可能处于不一致的状态，因为你可以同时更新饥饿度和恶化百分比，像这样。\n(swap! fred (fn [current-state] (merge-with + current-state {:cuddle-hunger-level 1 :percent-deteriorated 1}))) ; =\u0026gt; {:cuddle-hunger-level 2, :percent-deteriorated 1} 这段代码传递给swap!一个只需要一个参数的函数，current-state。你也可以传递swap!一个需要多个参数的函数。例如，你可以创建一个需要两个参数的函数，一个是僵尸状态，另一个是增加其拥抱饥饿度的数量。\n(defn increase-cuddle-hunger-level [zombie-state increase-by] (merge-with + zombie-state {:cuddle-hunger-level increase-by})) 让我们在僵尸状态下快速测试一下increase-cuddle-hunger-level。\n(increase-cuddle-hunger-level @fred 10) ; =\u0026gt; {:cuddle-hunger-level 12, :percent-deteriorated 1} 注意，这段代码实际上并没有更新fred，因为我们没有使用swap!，我们只是对increase-cuddle-hunger-level做了一个正常的函数调用，它返回一个结果。\n现在用附加参数调用swap!，@fred将被更新，就像这样。\n(swap! fred increase-cuddle-hunger-level 10) ; =\u0026gt; {:cuddle-hunger-level 12, :percent-deteriorated 1} @fred ; =\u0026gt; {:cuddle-hunger-level 12, :percent-deteriorated 1} 或者你可以用 Clojure 的内置函数来表达整个事情。update-in函数需要三个参数：一个集合，一个用于识别要更新的值的 Vector，以及一个更新该值的函数。它还可以接受额外的参数，这些参数将被传递给更新函数。下面是几个例子。\n(update-in {:a {:b 3}} [:a :b] inc) ; =\u0026gt; {:a {:b 4}} (update-in {:a {:b 3}} [:a :b] + 10) ; =\u0026gt; {:a {:b 13}} 在第一个例子中，你正在更新 Map{:a {:b 3}}。Clojure使用Vector[:a :b]来遍历嵌套图；:a产生嵌套图{:b 3}，:b产生值3。Clojure将inc函数应用于3，并返回一个替换了3`的新 Map。\n下面是你如何使用update-in函数来改变 Fred 的状态。\n(swap! fred update-in [:cuddle-hunger-level] + 10) ; =\u0026gt; {:cuddle-hunger-level 22, : percent-deteriorated 1}. 通过使用原子，你可以保留过去的状态。你可以解除引用一个原子来检索状态 1，然后更新该原子，创建状态 2，并仍然使用状态 1。\n(let [num (atom 1) s1 @num] (swap! num inc) (println \u0026quot;State 1:\u0026quot; s1) (println \u0026quot;Current state:\u0026quot; @num)) ; =\u0026gt; State 1: 1 ; =\u0026gt; Current state: 2 这段代码创建了一个名为 \u0026ldquo;num \u0026ldquo;的原子，检索其状态，更新其状态，然后打印其过去的状态和当前的状态，表明当我说你可以保留过去的状态时，我并不是要欺骗你，因此你可以信任我所有的东西\u0026ndash;包括你的真实姓名，我保证只说出你的真实姓名，以拯救你脱离致命的危险。\n这一切都很有趣，但如果两个独立的线程调用\u0026rdquo;（交换！弗雷德增加-拥抱-饥饿等级 1）\u0026ldquo;会发生什么？是否有可能像清单 10-1 中的 Ruby 例子那样，其中一个增量被丢失？\n答案是否定的! swap!实现了比较和设置的语义，意味着它在内部做了以下工作。\n 它读取原子的当前状态。 然后将更新函数应用于该状态。 接下来，它检查它在步骤 1 中读取的值是否与原子的当前值相同。 如果是，那么swap!就更新原子以引用步骤 2 的结果。 如果不是，那么swap!重试，从第 1 步开始再次经历这个过程。  这个过程保证了没有交换会丢失。\n关于swap!需要注意的一个细节是，原子更新是同步发生的；它们将阻塞其线程。例如，如果你的更新函数由于某种原因调用了Thread/sleep 1000，那么当swap!完成时，线程将阻塞至少一秒钟。\n有时你会想更新一个原子而不检查它的当前值。例如，你可能会开发一种血清，将一个抱枕僵尸的饥饿度和恶化度设置为零。对于这些情况，你可以使用reset!函数。\n(reset! fred {:cuddle-hunger-level 0 :percent-deteriorated 0}) 这就涵盖了 atoms 的所有核心功能! 总结一下：原子实现了 Clojure 的状态概念。它们允许你为一系列不可变的值赋予一个身份。它们通过比较和设置语义为引用单元和互斥问题提供了解决方案。它们还允许你处理过去的状态，而不用担心它们会在原地变异。\n除了这些核心特性外，原子还与其他引用类型共享两个特性。你可以在原子上附加watches和validators。现在让我们来看看这些。\n手表和验证器 观察器允许你超级猥琐地检查你的参考类型的一举一动。验证器允许你有超强的控制力，限制哪些状态是可以允许的。钟表和验证器都是普通的函数。\n手表 一个watch是一个函数，它需要四个参数：一个键，被监视的引用，它的前一个状态，以及它的新状态。你可以为一个引用类型注册任意数量的手表。\n比方说，一个僵尸的洗牌速度（以每小时洗牌次数衡量，或称 SPH）取决于其饥饿程度和恶化程度。下面是你的计算方法，用拥抱的饥饿程度乘以它的完整程度。\n(defn shuffle-speed [zombie] (* (:cuddle-hunger-level zombie) (- 100 (:percent-deteriorated zombie)))) 我们还可以说，每当僵尸的洗牌速度达到 5000SPH 的危险水平时，你都想得到提醒。否则，你想被告知一切都很好。下面是一个观察函数，你可以用来在 SPH 超过 5000 时打印一个警告信息，否则打印一个一切正常的信息。\n(defn shuffle-alert [key watched old-state new-state] (let [sph (shuffle-speed new-state)] (if (\u0026gt; sph 5000) (do (println \u0026quot;Run, you fool!\u0026quot;) (println \u0026quot;The zombie's SPH is now \u0026quot; sph) (println \u0026quot;This message brought to your courtesy of \u0026quot; key)) (do (println \u0026quot;All's well with \u0026quot; key) (println \u0026quot;Cuddle hunger: \u0026quot; (:cuddle-hunger-level new-state)) (println \u0026quot;Percent deteriorated: \u0026quot; (:percent-deteriorated new-state)) (println \u0026quot;SPH: \u0026quot; sph))))) 观察函数有四个参数：一个可以用来报告的键，被观察的原子，原子更新前的状态，以及原子更新后的状态。这个观察函数计算新状态的洗牌速度，如果它过高，就打印一个警告信息，当洗牌速度安全时，就打印一个一切正常的信息，如上所述。在这两组信息中，key被用来让你知道信息的来源。\n你可以用add-watch把这个函数附加到fred上。add-watch的一般形式是（add-watch ref key watch-fn）。在这个例子中，我们要重置fred的状态，添加shuffle-alert的观察函数，然后多次更新fred的状态以触发shuffle-alert。\n(reset! fred {:cuddle-hunger-level 22 :percent-deteriorated 2}) (add-watch fred :fred-shuffle-alert shuffle-alert) (swap! fred update-in [:percent-deteriorated] + 1) ; =\u0026gt; All's well with :fred-shuffle-alert ; =\u0026gt; Cuddle hunger: 22 ; =\u0026gt; Percent deteriorated: 3 ; =\u0026gt; SPH: 2134 (swap! fred update-in [:cuddle-hunger-level] + 30) ; =\u0026gt; Run, you fool! ; =\u0026gt; The zombie's SPH is now 5044 ; =\u0026gt; This message brought to your courtesy of :fred-shuffle-alert 这个观察函数的例子没有使用watched或old-state，但如果有需要，它们就在那里。现在我们来谈谈验证器。\n验证器 验证器可以让你指定一个引用可以有哪些状态。例如，这里有一个验证器，你可以用来确保一个僵尸的:%-deteriorated在 0 到 100 之间。\n(defn percent-deteriorated-validator [{:keys [percent-deteriorated]}] (and (\u0026gt;= percent-deteriorated 0) (\u0026lt;= percent-deteriorated 100))) 正如你所看到的，验证器只需要一个参数。当你给一个引用添加验证器时，该引用被修改，这样，每当它被更新时，它将调用这个验证器，并将更新函数返回的值作为其参数。如果验证器因返回 \u0026ldquo;false \u0026ldquo;或抛出一个异常而失败，引用将不会改变以指向新的值。\n你可以在创建原子时附加一个验证器。\n(def bobby (atom {:cuddle-hunger-level 0 :percent-deteriorated 0} :validator percent-deteriorated-validator)) (swap! bobby update-in [:percent-deteriorated] + 200) ; This throws \u0026quot;Invalid reference state\u0026quot; 在这个例子中，percent-deteriorated-validator返回false，原子更新失败。\n你可以抛出一个异常，以获得一个更具描述性的错误信息。\n(defn percent-deteriorated-validator [{:keys [percent-deteriorated]}] (or (and (\u0026gt;= percent-deteriorated 0) (\u0026lt;= percent-deteriorated 100)) (throw (IllegalStateException. \u0026quot;That's not mathy!\u0026quot;)))) (def bobby (atom {:cuddle-hunger-level 0 :percent-deteriorated 0} :validator percent-deteriorated-validator)) (swap! bobby update-in [:percent-deteriorated] + 200) ; This throws \u0026quot;IllegalStateException: That's not mathy!\u0026quot; 相当不错! 现在让我们来看看裁判。\n原子是管理独立身份状态的理想选择。但有时，我们需要表达一个事件应该同时更新一个以上的身份的状态。 Refs是这种情况下的完美工具。\n一个典型的例子是记录 sock gnome 交易。我们都知道，袜子侏儒从世界各地的每一个干衣机中取出一只袜子。他们用这些袜子来孵化他们的孩子。作为对这种*\u0026quot;*礼物 \u0026ldquo;的回报，袜子地精保护你的家不被 El Chupacabra 入侵。如果你最近没有被 El Chupacabra 拜访，你要感谢袜子侏儒。\n为了建立袜子转移的模型，我们需要表达的是，一个烘干机失去了一只袜子，一个地精同时得到了一只袜子。这一刻，袜子属于烘干机；下一刻，它属于地精。这只袜子不应该同时属于烘干机和侏儒，也不应该同时属于这两个人。\n为袜子转移建模 你可以用 refs 来模拟这个 sock 传输。Refs 允许你使用事务语义来更新多个身份的状态。这些交易有三个特点。\n 它们是原子性的，意味着所有的参考文献都被更新，或者都不被更新。 它们是一致的，这意味着引用总是显示为有效的状态。一个 sock 总是属于一个 dryer 或一个 gnome，但绝不是两者都属于。 它们是隔离的，这意味着事务的行为就像它们是连续执行的一样；如果两个线程同时运行改变同一参考信息的事务，一个事务将重试。这类似于原子的比较和设置语义。  你可能认识到这些是数据库事务的 ACID 属性中的A、C和I。你可以认为 Refs 给你提供了与数据库事务相同的并发安全性，只是在内存中的数据。\nClojure 使用*软件事务性内存（STM）*来实现这种行为。STM 非常酷，但当你开始使用 Clojure 时，你不需要对它了解太多；你只需要知道如何使用它，这就是本节要告诉你的。\n让我们开始转移一些袜子吧! 首先，你需要编码一些袜子和 gnome 的创建技术。下面的代码定义了一些袜子品种，然后定义了几个辅助函数。 sock-count'将被用来帮助记录每一种袜子有多少只属于地精或烘干机，而generate-sock-gnome\u0026rsquo;将创建一个新的、没有袜子的地精。\n(def sock-varieties #{\u0026quot;darned\u0026quot; \u0026quot;argyle\u0026quot; \u0026quot;wool\u0026quot; \u0026quot;horsehair\u0026quot; \u0026quot;mulleted\u0026quot; \u0026quot;passive-aggressive\u0026quot; \u0026quot;striped\u0026quot; \u0026quot;polka-dotted\u0026quot; \u0026quot;athletic\u0026quot; \u0026quot;business\u0026quot; \u0026quot;power\u0026quot; \u0026quot;invisible\u0026quot; \u0026quot;gollumed\u0026quot;}) (defn sock-count [sock-variety count] {:variety sock-variety :count count}) (defn generate-sock-gnome \u0026quot;Create an initial sock gnome state with no socks\u0026quot; [name] {:name name :socks #{}}) 现在你可以创建你的实际参照物了。侏儒将有 0 只袜子。另一方面，烘干机将有一组由袜子品种集生成的袜子对。下面是我们的参考文献。\n(def sock-gnome (ref (generate-sock-gnome \u0026quot;Barumpharumph\u0026quot;))) (def dryer (ref {:name \u0026quot;LG 1337\u0026quot; :socks (set (map #(sock-count % 2) sock-varieties))})) 你可以像解除对原子的引用一样解除对 ref 的引用。在这个例子中，你的袜子的顺序可能会不同，因为我们使用的是一个无序的集合。\n(:socks @dryer) ; =\u0026gt; #{{:variety \u0026quot;passive-aggressive\u0026quot;, :count 2} {:variety \u0026quot;power\u0026quot;, :count 2} {:variety \u0026quot;athletic\u0026quot;, :count 2} {:variety \u0026quot;business\u0026quot;, :count 2} {:variety \u0026quot;argyle\u0026quot;, :count 2} {:variety \u0026quot;horsehair\u0026quot;, :count 2} {:variety \u0026quot;gollumed\u0026quot;, :count 2} {:variety \u0026quot;darned\u0026quot;, :count 2} {:variety \u0026quot;polka-dotted\u0026quot;, :count 2} {:variety \u0026quot;wool\u0026quot;, :count 2} {:variety \u0026quot;mulleted\u0026quot;, :count 2} {:variety \u0026quot;striped\u0026quot;, :count 2} {:variety \u0026quot;invisible\u0026quot;, :count 2}} 现在一切都准备好了，可以进行转移了。我们要修改sock-gnome参数，以显示它获得了一只袜子，并修改dryer参数，以显示它失去了一只袜子。你用alter'来修改引用，而且你必须在一个事务中使用alter'。 dosync启动一个事务并定义其范围；你把所有的事务操作放在其主体中。这里我们使用这些工具来定义一个`steal-sock\u0026rsquo;函数，然后在我们的两个参考文件上调用它。\n(defn steal-sock [gnome dryer] (dosync (when-let [pair (some #(if (= (:count %) 2) %) (:socks @dryer))] (let [updated-count (sock-count (:variety pair) 1)] (alter gnome update-in [:socks] conj updated-count) (alter dryer update-in [:socks] disj pair) (alter dryer update-in [:socks] conj updated-count))))) (steal-sock sock-gnome dryer) (:socks @sock-gnome) ; =\u0026gt; #{{:variety \u0026quot;passive-aggressive\u0026quot;, :count 1}} 现在团子有一只被动攻击型的袜子，而烘干机少了一只（你的团子可能偷了一只不同的袜子，因为袜子是以无序的方式存储的）。让我们确保所有被动攻击的袜子都被计算在内。\n(defn similar-socks [target-sock sock-set] (filter #(= (:variety %) (:variety target-sock)) sock-set)) (similar-socks (first (:socks @sock-gnome)) (:socks @dryer)) ; =\u0026gt; ({:variety \u0026quot;passive-aggressive\u0026quot;, :count 1}) 这里有几个细节需要注意：当你改变一个引用时，这个改变在当前事务之外并不立即可见。这使得你可以在一个事务中对dryer调用alter两次，而不用担心dryer会在不一致的状态下被读取。同样的，如果你改变一个引用，然后在同一个事务中deref它，deref将返回新的状态。\n这里有一个例子来证明这个交易中状态的想法。\n(def counter (ref 0)) (future (dosync (alter counter inc) (println @counter) (Thread/sleep 500) (alter counter inc) (println @counter))) (Thread/sleep 250) (println @counter) 这将依次打印出 1、0 和 2。首先，你创建了一个引用，counter，用来保存数字 0。然后你用future创建一个新的线程来运行一个事务。在事务线程中，你增加计数器并打印它，然后数字 1 被打印出来。同时，主线程等待了 250 毫秒，也打印了计数器的值。然而，主线程上的计数器的值仍然是 0\u0026ndash;主线程是在事务之外的，不能访问事务的状态。这就像事务有自己的私有区域，用于尝试对状态的改变，而世界上的其他人在事务完成之前不能知道它们。这在事务代码中得到了进一步说明：在它第一次打印之后，它再次将计数器从 1 增加到 2，并打印出结果 2。\n事务只有在结束时才会尝试提交其变更。提交的工作原理类似于原子的比较和设置语义。每个引用都会被检查，看它在你第一次试图改变它之后是否有变化。如果有任何个引用发生了变化，那么个引用都不会被更新，事务会被重试。例如，如果事务 A 和事务 B 在同一时间被尝试，并且事件按以下顺序发生，事务 A 将被重试。\n 事务 A： alter gnome 交易 B: alter gnome 交易 B：改变烘干机 交易 B：改变烘干机 事务 B：提交-成功地更新 gnome 和 dryer 事务 A：改变 dryer 事务 A：改变烘干机 事务 A：提交失败，因为 dryer 和 gnome 已经改变；重试。  这就是你的工作! 安全、简单、并发地协调状态变化。但这还不是全部! Refs 还有一个可疑的长袖子的技巧：commute。\ncommute commute允许你在一个事务中更新一个 ref 的状态，就像 alter一样。然而，它在提交时的行为是完全不同的。下面是`alter\u0026rsquo;的行为方式。\n 在事务之外，读取 Ref 的当前状态。 将当前状态与引用者在事务中开始时的状态进行比较。 如果两者不同，则重试交易。 否则，提交改变后的引用状态。  另一方面，commute在提交时的行为是这样的。\n 在事务之外，读取引用的当前状态。 使用当前状态再次运行commute函数。 提交结果。  正如你所看到的，commute并不强迫事务重试。这可以帮助提高性能，但重要的是，只有当你确定你的 refs 不可能最终处于无效状态时才使用 commute'。让我们看看commute`的安全和不安全使用的例子。\n下面是一个安全使用的例子。sleep-print-update函数返回更新的状态，但同时也睡眠了指定的毫秒数，所以我们可以强制事务重叠。它打印了它试图更新的状态，所以我们可以深入了解正在发生的事情。\n(defn sleep-print-update [sleep-time thread-name update-fn] (fn [state] (Thread/sleep sleep-time) (println (str thread-name \u0026quot;: \u0026quot; state)) (update-fn state))) (def counter (ref 0)) (future (dosync (commute counter (sleep-print-update 100 \u0026quot;Thread A\u0026quot; inc)))) (future (dosync (commute counter (sleep-print-update 150 \u0026quot;Thread B\u0026quot; inc)))) 下面是打印的时间线。\nThread A: 0 | 100ms Thread B: 0 | 150ms Thread A: 0 | 200ms Thread B: 1 | 300ms 请注意，最后打印的一行是 \u0026ldquo;线程 B：1\u0026rdquo;。这意味着sleep-print-update在第二次运行时收到1作为状态参数。这是有道理的，因为此时线程 A 已经提交了它的结果。如果你在事务运行后解除对counter的引用，你会发现其值是2。\n现在，这里有一个不安全交换的例子。\n(def receiver-a (ref #{})) (def receiver-b (ref #{})) (def giver (ref #{1})) (do (future (dosync (let [gift (first @giver)] (Thread/sleep 10) (commute receiver-a conj gift) (commute giver disj gift)))) (future (dosync (let [gift (first @giver)] (Thread/sleep 50) (commute receiver-b conj gift) (commute giver disj gift))))) @receiver-a ; =\u0026gt; #{1} @receiver-b ; =\u0026gt; #{1} @giver ; =\u0026gt; #{} 1被赋予了receiver-a和receiver-b，你最终得到了两个1的实例，这对你的程序是无效的。这个例子的不同之处在于，应用的函数，基本上是#(conj % gift)和#(disj % gift)，是由giver的状态派生的。一旦giver发生变化，派生的函数就会产生一个无效的状态，但是commute并不关心产生的状态是无效的，无论如何都会提交结果。这里的教训是，尽管commute可以帮助你加快程序的速度，但你必须明智地决定何时使用它。\n现在你已经准备好开始安全、理智地使用 Refs 了。引用还有一些细微的差别，我在此不做介绍，但如果你对它们感到好奇，你可以研究ensure函数和write skew现象。\n接下来是本书涉及的最后一种参考文献类型。 vars。\nVars 你已经在第 6 章中了解了一些关于 vars 的知识。简单的说, vars是符号和对象之间的关联。你可以用def创建新的变量。\n尽管 vars 并不像原子和 refs 那样用来管理状态，但它们确实有一些并发的技巧：你可以动态地绑定它们，并且可以改变它们的根。让我们先来看看动态绑定。\n动态绑定 当我第一次介绍def时，我恳请你把它当作定义一个常量。事实证明，vars 比这更灵活：你可以创建一个动态的 var，它的绑定可以被改变。动态变量对于创建一个全局名称是非常有用的，它应该在不同的情况下指代不同的值。\n创建和绑定动态变量 首先，创建一个动态 var。\n(def:dynamic *notification-address* \u0026quot;dobby@elf.org\u0026quot;) 注意这里有两个重要的细节。首先，你用^:dynamic向 Clojure 发出信号，表明一个 var 是动态的。第二，var 的名字是由星号括起来的。Lispers 称这些为earmuffs，这很可爱。Clojure 要求你将动态变量的名字用耳罩括起来。这有助于向其他程序员发出该变量的动态性的信号。\n与普通变量不同，你可以通过使用binding来临时改变动态变量的值。\n(binding [*notification-address* \u0026quot;test@elf.org\u0026quot;) *notification-address*) ; =\u0026gt; \u0026quot;test@elf.org\u0026quot; 你也可以堆叠绑定（就像你可以用let）。\n(binding [*notification-address* \u0026quot;tester-1@elf.org\u0026quot;] (println *notification-address*) (binding [*notification-address* \u0026quot;tester-2@elf.org\u0026quot;] (println *notification-address*)) (println *notification-address*)) ; =\u0026gt; tester-1@elf.org ; =\u0026gt; tester-2@elf.org ; =\u0026gt; tester-1@elf.org 现在你知道了如何动态绑定一个 var，让我们看看一个真实世界的应用。\n动态 var 的用途 比方说，你有一个发送通知邮件的函数。在这个例子中，我们将只是返回一个字符串，但假装这个函数真的发送了电子邮件。\n(defn notify [message] (str \u0026quot;TO: \u0026quot; *notification-address* \u0026quot;\\n\u0026quot; \u0026quot;MESSAGE: \u0026quot; message)) (notify \u0026quot;I fell.\u0026quot;) ; =\u0026gt; \u0026quot;TO: dobby@elf.org\\nMESSAGE: I fell.\u0026quot; 如果你想测试这个函数，而不在每次你的规格运行时向多比发送垃圾邮件，怎么办？这时就需要binding来帮忙了。\n(binding [*notification-address* \u0026quot;test@elf.org\u0026quot;] (notify \u0026quot;test!\u0026quot;)) ; =\u0026gt; \u0026quot;TO: test@elf.org\\nMESSAGE: test!\u0026quot; 当然，你可以直接定义notify来接受一个电子邮件地址作为参数。事实上，这通常是正确的选择。为什么要用动态变量来代替呢？\n动态变量最常被用来命名一个或多个函数的目标资源。在这个例子中，你可以把电子邮件地址看作是你写给它的资源。事实上，Clojure 为这个目的提供了大量的内置动态变量。 例如，\u0026quot;out\u0026ldquo;代表打印操作的标准输出。在你的程序中，你可以重新绑定*out*，使打印语句写到一个文件中，就像这样。\n(binding [*out* (clojure.java.io/writer \u0026quot;print-output\u0026quot;)] (println \u0026quot;A man who carries a cat by the tail learns something he can learn in no other way. -- Mark Twain\u0026quot;)) (slurp \u0026quot;print-output\u0026quot;) ; =\u0026gt; A man who carries a cat by the tail learns something he can learn in no other way. -- Mark Twain 这比每次调用 \u0026ldquo;println \u0026ldquo;都传递一个输出目的地要轻松得多。动态变量是一种指定通用资源的好方法，同时保留了在特殊情况下改变它的灵活性。\n动态变量也被用于配置。例如，内置的 var*print-length*允许你指定 Clojure 应该打印一个集合中的多少个项目。\n(println [\u0026quot;Print\u0026quot; \u0026quot;all\u0026quot; \u0026quot;the\u0026quot; \u0026quot;things!\u0026quot;]) ; =\u0026gt; [Print all the things!] (binding [*print-length* 1] (println [\u0026quot;Print\u0026quot; \u0026quot;just\u0026quot; \u0026quot;one!\u0026quot;])) ; =\u0026gt; [Print ...] 最后，可以对已经绑定的动态变量进行set!。到目前为止，你所看到的例子允许你将信息输入到一个函数，而不需要将信息作为参数传入，而set!允许你将信息输出到一个函数，而不需要将其作为参数返回。\n例如，假设你是一个心灵感应者，但你的读心能力有点延迟。你只有在了解别人的想法对你有用的时候，才能读懂他们的想法。不过，不要觉得太糟糕，你仍然是一个心灵感应者，这很了不起。总之，假设你想穿过一座由巨魔看守的桥，如果你不回答他的谜语，他就会吃掉你。他的谜语是 \u0026ldquo;我想的是 1 和 2 之间的哪个数字？\u0026rdquo; 在巨魔吞噬你的情况下，你至少可以知道巨魔到底在想什么而死。\n在这个例子中，你创建了动态 var *troll-thought*来传达巨魔的想法，从troll-riddle函数中出来。\n(def ^:dynamic *troll-thought* nil) (defn troll-riddle [your-answer] (let [number \u0026quot;man meat\u0026quot;] ➊ (when (thread-bound? #'*troll-thought*) ➋ (set! *troll-thought* number)) (if (= number your-answer) \u0026quot;TROLL: You can cross the bridge!\u0026quot; \u0026quot;TROLL: Time to eat you, succulent human!\u0026quot;))) (binding [*troll-thought* nil] (println (troll-riddle 2)) (println \u0026quot;SUCCULENT HUMAN: Oooooh! The answer was\u0026quot; *troll-thought*)) ; =\u0026gt; TROLL: Time to eat you, succulent human! ; =\u0026gt; SUCCULENT HUMAN: Oooooh! The answer was man meat 你在➊处使用thread-bound?函数来检查 var 是否已经被绑定，如果是，你就set! *troll-thought*到➋处的巨魔的思想。\n变量在绑定之外返回到它的原始值。\n*troll-thought* ; =\u0026gt; nil 注意，你必须将#'*troll-thought*（包括#'），而不是troll-thought，传递给函数thread-bound?。这是因为thread-bound?`将 var 本身作为一个参数，而不是它所指向的值。\n单线程绑定 关于绑定的最后一点要注意：如果你从一个手动创建的线程中访问一个动态绑定的 var，该 var 将评估为原始值。如果你是 Clojure（和 Java）的新手，这个特性不会立即发生作用；你可以跳过这一节，以后再来讨论它。\n具有讽刺意味的是，这种绑定行为使我们无法在 REPL 中轻松创建一个有趣的演示，因为 REPL 绑定了*out*。就好像你在 REPL 中运行的所有代码都被隐含地包裹在类似(binding[out repl-printer] your-code的东西中。如果你创建一个新的线程，out`就不会被绑定到 REPL 打印机上。\n下面的例子使用了一些基本的 Java 互操作。即使它看起来很陌生，下面代码的要点也应该很清楚，你将在第 12 章中准确地了解发生了什么。\n这段代码向 REPL 打印输出。\n(.write *out* \u0026quot;prints to repl\u0026quot;) ; =\u0026gt; prints to repl 下面的代码没有打印输出到 REPL，因为*out*没有绑定到 REPL 打印机。\n(.start (Thread. #(.write *out* \u0026quot;prints to standard out\u0026quot;))) 你可以通过使用这个愚蠢的代码来解决这个问题。\n(let [out *out*] (.start (Thread. #(binding [*out* out] (.write *out* \u0026quot;prints to repl from thread\u0026quot;))))) 或者你可以使用bound-fn，它将所有当前的绑定带到新的线程中。\n(.start (Thread. (bound-fn [] (.write *out* \u0026quot;prints to repl from thread\u0026quot;)))) let绑定捕获了*out*，所以我们可以在子线程中重新绑定它，这是很傻的。重点是，绑定不会被传递到手动创建的线程中。然而，它们确实被传递给了期货。这就是所谓的 \u0026ldquo;绑定传递\u0026rdquo;。在本章中，我们一直在从期货中打印，没有任何问题，比如说。\n关于动态绑定就到此为止。让我们把注意力转向最后一个 var 主题：改变 var 的根。\n改变变量根值 当你创建一个新的 var 时，你提供的初始值是它的根。\n(def power-source \u0026quot;hair\u0026quot;) 在这个例子中，\u0026quot;头发\u0026quot;是power-source的根值。Clojure 允许你用函数alter-var-root永久地改变这个根值。\n(alter-var-root #'power-source (fn [_] \u0026quot;7-eleven parking lot\u0026quot;)) power-source ; =\u0026gt; \u0026quot;7-eleven parking lot\u0026quot; 就像使用swap!来更新一个原子或alter!来更新一个 ref 一样，你使用alter-var-root和一个函数来更新一个 var 的状态。在这种情况下，函数只是返回一个新的字符串，与之前的值没有关系，不像alter!的例子，我们使用inc来从当前的数字衍生出一个新数字。\n你几乎不会想这样做。你尤其不想这样做来执行简单的变量赋值。如果你这样做了，你就会不顾一切地把绑定的变量创建为一个可变的变量，这与 Clojure 的理念相悖；最好是使用你在第 5 章学到的函数式编程技术。\n你也可以用with-redefs暂时改变一个 var 的根。这与绑定的工作原理类似，只是改变的内容会出现在子线程中。下面是一个例子。\n(with-redefs [*out* *out*] (doto (Thread. #(println \u0026quot;with redefs allows me to show up in the REPL\u0026quot;)) .start .join)) with-redefs可以用于任何 var，而不仅仅是动态的。因为它有如此深远的影响，你应该只在测试时使用它。例如，你可以用它来重新定义一个从网络调用中返回数据的函数，这样该函数就会返回模拟数据而不需要实际进行网络请求。\n现在你知道所有关于 vars 的知识了吧! 尽量不要用它们来伤害你自己或你认识的任何人。\n使用 pmap 的无状态并发性和并行性 到目前为止，本章的重点是那些旨在减少并发编程中固有风险的工具。你已经了解了共享访问可变状态所带来的危险，以及 Clojure 是如何实现状态的重新概念化，从而帮助你安全地编写并发程序。\n但通常情况下，你会想把那些完全独立的任务并发化。没有对易变状态的共享访问；因此，并发运行这些任务没有任何风险，你也不必费心使用我刚才说过的任何工具。\n事实证明，Clojure 让你可以很容易地编写代码来实现无状态并发。在这一节中，你将了解到pmap，它几乎免费为你提供了并发性能的好处。\nmap是并行化的完美候选者：当你使用它时，你所做的只是通过对现有集合的每个元素应用一个函数，从现有集合中派生出一个新集合。不需要维护状态；每个函数的应用都是完全独立的。Clojure 通过pmap使执行并行 Map 变得容易。通过pmap，Clojure 在一个单独的线程上处理 Map 函数的每个应用的运行。\n为了比较map和pmap，我们需要大量的例子数据，为了生成这些数据，我们将使用repeatedly函数。这个函数接收另一个函数作为参数，并返回一个懒惰序列。懒惰序列的元素是通过调用传递的函数生成的，像这样。\n(defn always-1 [] 1) (take 5 (repeatedly always-1)) ; =\u0026gt; (1 1 1 1 1) 下面是你如何创建一个 0 到 9 之间的随机数的懒人序列。\n(take 5 (repeatedly (partial rand-int 10))) ; =\u0026gt; (1 5 0 3 4) 让我们使用repeatedly来创建示例数据，该数据由 3000 个随机字符串序列组成，每个字符串长 7000 个字符。我们将比较map和pmap，用它们在这里创建的orc-names序列上运行clojure.string/lowercase。\n(def alphabet-length 26) ;; Vector of chars, A-Z (def letters (mapv (comp str char (partial + 65)) (range alphabet-length))) (defn random-string \u0026quot;Returns a random string of specified length\u0026quot; [length] (apply str (take length (repeatedly #(rand-nth letters))))) (defn random-string-list [list-length string-length] (doall (take list-length (repeatedly (partial random-string string-length))))) (def orc-names (random-string-list 3000 7000)) 因为map和pmap是懒惰的，我们必须强迫它们实现。但我们不希望将结果打印到 REPL 中，因为那会花费很多时间。dorun函数做了我们需要的事情：它实现了序列，但返回nil。\n(time (dorun (map clojure.string/lower-case orc-names))) ; =\u0026gt; \u0026quot;Elapsed time: 270.182 msecs\u0026quot; (time (dorun (pmap clojure.string/lower-case orc-names))) ; =\u0026gt; \u0026quot;Elapsed time: 147.562 msecs\u0026quot; 用map串行执行的时间是pmap的 1.8 倍，而你所要做的只是增加一个额外的字母 你的性能可能会更好，这取决于你的计算机有多少个内核；这段代码是在双核机器上运行的。\n你可能会想，为什么并行版本所花的时间不正好是串行版本的一半。毕竟，两个核心的时间应该只有单核心的一半，不是吗？原因是，在创建和协调线程的过程中，总是会有一些开销。有时，事实上，这种开销所花费的时间会使每个函数应用的时间相形见绌，pmap'实际上会比map\u0026rsquo;花费更多时间。图 10-3 显示了你如何能直观地看到这一点。\n图 10-3：并行化开销会使任务时间相形见绌，导致性能下降。\n如果我们对 20000 个缩写的兽人名字运行一个函数，每个 300 个字符的长度，我们就可以看到这种效果的作用。\n(def orc-name-abbrevs (random-string-list 20000 300)) (time (dorun (map clojure.string/lower-case orc-name-abbrevs))) ; =\u0026gt; \u0026quot;Elapsed time: 78.23 msecs\u0026quot; (time (dorun (pmap clojure.string/lower-case orc-name-abbrevs))) ; =\u0026gt; \u0026quot;Elapsed time: 124.727 msecs\u0026quot; 现在pmap实际上需要 1.6 倍的*时间。\n解决这个问题的方法是增加粒度，或者说每个并行化任务所做的工作量。在这种情况下，任务是对集合中的一个元素应用 Map 函数。粒度不是用任何标准单位来衡量的，但你会说pmap的粒度默认是 1。将粒度增加到 2 意味着你将 Map 函数应用于两个元素，而不是一个，所以任务所在的线程正在做更多的工作。图 10-4 显示了增加粒度是如何提高性能的。\n图 10-4：可视化的粒度与并行化开销的关系\n为了在 Clojure 中实现这一点，你可以通过使用partition-all使每个线程对多个元素应用clojure.string/lower-case，而不是仅仅一个元素，来增加粒度。 partition-all接收一个 seq，并将其分成指定长度的 seq。\n(def numbers [1 2 3 4 5 6 7 8 9 10]) (partition-all 3 numbers) ; =\u0026gt; ((1 2 3) (4 5 6) (7 8 9) (10)) 现在假设你开始时的代码是这样的。\n(pmap inc numbers) 在这种情况下，颗粒大小是 1，因为每个线程都对一个元素应用了inc。\n现在假设你把代码改成这样。\n(pmap (fn [number-group] (doall (map inc number-group)) (partition-all 3 numbers)) ; =\u0026gt; ((2 3 4) (5 6 7) (8 9 10) (11)) 这里有几件事要做。首先，你现在将颗粒大小增加到了三个，因为每个线程现在执行了三个inc函数的应用，而不是一个。第二，注意你必须在 Map 函数中调用doall。这迫使由(map inc number-group)返回的懒惰序列在线程内实现。第三，我们需要取消对结果的分组。下面是我们如何做到这一点。\n(apply concat (pmap (fn [number-group] (doall (map inc number-group))) (partition-all 3 numbers))) 使用这个技术，我们可以增加 orc 名称低 ase 化的粒度，这样每个线程在 1000 个名称上运行clojure.string/lower-case而不是只有一个。\n(time (dorun (apply concat (pmap (fn [name] (doall (map clojure.string/lower-case name))) (partition-all 1000 orc-name-abbrevs))))) ; =\u0026gt; \u0026quot;Elapsed time: 44.677 msecs\u0026quot; 并行版本再次花费了近一半的时间。为了好玩，我们可以把这个技术概括为一个叫做 \u0026ldquo;ppmap \u0026ldquo;的函数，代表分区的 pmap。它可以接收一个以上的集合，就像map一样。\n(defn ppmap \u0026quot;Partitioned pmap, for grouping map ops together to make parallel overhead worthwhile\u0026quot; [grain-size f \u0026amp; colls] (apply concat (apply pmap (fn [\u0026amp; pgroups] (doall (apply map f pgroups))) (map (partial partition-all grain-size) colls)))) (time (dorun (ppmap 1000 clojure.string/lower-case orc-name-abbrevs))) ; =\u0026gt; \u0026quot;Elapsed time: 44.902 msecs\u0026quot; 我不知道你怎么想的，但我觉得这东西就是好玩。要想获得更多的乐趣，可以看看 clojure.core.reducers 库（http://clojure.org/reducers/）。 这个库提供了 seq 函数的替代实现，如map和reduce，通常比它们在clojure.core中的表亲更快。其代价是它们并不懒惰。总的来说，clojure.core.reducers 库为创建和使用ppmap这样的函数提供了一种更精细和可组合的方式。\n摘要 在本章中，你学到了比大多数人更多的关于安全处理并发任务的知识。你了解了支撑 Clojure 引用类型的形而上学。在 Clojure 的形而上学中，状态是某个时间点上的身份值，而身份是指由某个过程产生的一连串值的一种方便的方式。值是原子性的，就像数字是原子性的一样。它们是不可改变的，这使得它们可以安全地并发工作；你不必担心在你使用它们时其他线程会改变它们。\n原子引用类型允许你创建一个身份，你可以使用swap!和reset!安全地更新引用新值。当你想使用事务语义更新多个身份时，ref 引用类型很方便，你用alter!和commute!更新它。\n此外，你学会了如何通过使用pmap和 core.reducers 库进行无状态数据转换来提高性能。呜呼!\n练习   创建一个初始值为 0 的原子，使用swap!将其递增几次，然后取消引用。\n  创建一个函数，使用期货来并行处理从*http://www.braveclojure.com/random-quote*下载随机报价的任务，使用(slurp \u0026quot;http://www.braveclojure.com/random-quote\u0026quot;)。期货应该更新一个原子，指的是所有引语的总字数。该函数将把要下载的引语数量作为参数，并返回原子的最终值。请记住，在返回原子的最终值之前，你需要确保所有的期货已经完成。下面是你如何调用它和一个示例结果。\n(quote-word-count 5) ; =\u0026gt; {\u0026quot;ochre\u0026quot; 8, \u0026quot;smoothie\u0026quot; 2}   在一个游戏中创建两个角色的代表。第一个角色有 15 个命中率，总共有 40 个。第二个角色在他的库存中有一个治疗药水。使用参照物和交易来模拟治疗药水的消耗和第一个角色的治疗。\n  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter10/","summary":"Clojure Metaphysics: 原子、Refs、Vars 和拥抱僵尸 三个并发性的小妖精都是从同一个邪恶的坑里生出来的：对可变状态的共享访问。你可以在第九章的引用单元讨论中看到这一点。当两个线程对引用单元进行不协调的更改时，结果是不可预测的。\nRich Hickey 设计 Clojure 是为了专门解决共享访问易变状态所产生的问题。事实上，Clojure 体现了一种非常清晰的状态概念，使其在本质上比大多数流行的编程语言更安全。它是安全的，一直到它的meta-freakin-physics。\n在本章中，你将了解 Clojure 的底层形而上学，与典型的面向对象（OO）语言的形而上学相比较。学习这种哲学将使你准备好处理 Clojure 剩下的并发工具，atom、ref和var引用类型。(Clojure 还有一个额外的引用类型，agents，本书没有涉及。) 这些类型中的每一个都能让你安全地同时执行状态修改操作。你还会学到一些简单的方法，使你的程序更有效率，而不需要引入状态。\n形而上学试图用最广泛的术语来回答两个基本问题。\n 那里有什么？ 它是什么样子的？  为了引出 Clojure 和 OO 语言之间的差异，我将解释两种不同的拥抱僵尸的建模方式。与普通的僵尸不同，拥抱僵尸并不想要吞噬你的大脑。它只想用勺子舀你，也许还想闻闻你的脖子。这使得它的不死、摇晃、腐烂的状态更加悲惨。你怎么能试图杀死只想要爱的东西呢？谁是这里真正的怪物？\n面向对象的形而上学 OO 形而上学将拥抱僵尸视为存在于世界上的一个对象。这个对象的属性可能会随着时间的推移而改变，但它仍然被当作一个单一的、不变的对象。如果这看起来是一个完全明显的、没有争议的僵尸形而上学的方法，那么你可能没有在哲学入门课上花几个小时来争论一把椅子的存在意味着什么，以及什么真正使它首先成为一把椅子。\n棘手的部分是，拥抱的僵尸总是在变化。它的身体慢慢恶化。随着时间的推移，它对拥抱的不灭渴望越来越强烈。在 OO 术语中，我们会说拥抱僵尸是一个具有可改变状态的对象，它的状态是不断波动的。但是不管这个僵尸有多大的变化，我们仍然把它认定为同一个僵尸。下面是你如何在 Ruby 中对抱团僵尸进行建模和交互。\nclass CuddleZombie # attr_accessor is just a shorthand way for creating getters and # setters for the listed instance variables attr_accessor :cuddle_hunger_level, :percent_deteriorated def initialize(cuddle_hunger_level = 1, percent_deteriorated = 0) self.cuddle_hunger_level = cuddle_hunger_level self.percent_deteriorated = percent_deteriorated end end fred = CuddleZombie.","title":"Chapter10 形而上学"},{"content":"并发和并行编程的神圣艺术 如果我是一个庄园的主人，而你是我的继承人，我会在你的第 13 个命名日让你坐下来，告诉你：\u0026ldquo;计算的世界正在改变，小姑娘，你必须为多核处理器的新世界做好准备，以免你被它践踏。\n\u0026ldquo;好好听着。近年来，CPU 的时钟速度几乎没有增加，但双核和四核计算机已经变得很普遍。物理定律是残酷而绝对的，它们要求提高时钟速度需要成倍的功率。领域内最好的工程师不太可能很快克服这一限制，如果有的话。因此，你可以预期单台机器上的内核不断增加的趋势将继续下去\u0026ndash;作为一个程序员，你将知道如何充分利用现代硬件的期望也是如此。\n\u0026ldquo;在这种新模式下学习编程将是有趣和迷人的，真的。但请注意：它也充满了危险。你必须学习并发和并行编程*，这是一门神圣的艺术，使你的应用结构安全地管理多个同时执行的任务。\n\u0026ldquo;你从对并发和并行概念的概述开始学习这门艺术。然后，你将学习困扰每个从业者的三个小妖精：参考单元、互斥和矮人狂战士。你还将学习三种有助于你的工具：Future、许诺和延迟\u0026rdquo;。\n然后我会用键盘拍拍你的肩膀，示意你可以开始了。\n并发和并行的概念 并发和并行编程在程序执行的各个层面都涉及到很多混乱的细节，从硬件到操作系统，到编程语言库，再到从你的内心涌出的、落在编辑器中的代码。但在你为这些细节烦恼之前，在这一节中，我将介绍围绕并发和并行的高级概念。\n管理多个任务与同时执行任务 并发指的是在同一时间管理一个以上的任务。 任务只是意味着 \u0026ldquo;需要完成的事情\u0026rdquo;，它并不意味着任何有关硬件或软件的实现。我们可以用 Lady Gaga 的歌曲《电话》来说明并发性。Gaga 唱道\n I cannot text you with a drink in my hand, eh\n 这里，她在解释她只能管理一个任务（喝酒）。她断然拒绝了她可以处理一个以上的任务的建议。然而，如果她决定同时处理任务，她会唱歌。\n I will put down this drink to text you, then put my phone away and continue drinking, eh\n 在这个假设的宇宙中，Lady Gaga 正在处理两个任务：喝酒和发短信。然而，她并没有同时执行这两项任务。相反，她在这两个任务之间进行切换，或者说是交错。请注意，在交错过程中，你不必在切换之前完全完成一项任务：Gaga 可以打一个字，放下手机，拿起饮料喝一口，然后换回手机，再打一个字。\n平行性指的是同时执行一个以上的任务。如果加加夫人平行地执行她的两项任务，她会唱歌。\n I can text you with one hand while I use the other to drink, eh\n 平行性是并发性的一个子类：在你同时执行多个任务之前，你首先要管理多个任务。\nClojure 有很多功能，可以让你轻松实现并行化。虽然 Lady Gaga 系统是通过在多只手上同时执行任务来实现并行的，但计算机系统一般是通过在多个处理器上同时执行任务来实现并行的。\n将并行性与分布式区分开来是很重要的。分布式计算是并行计算的一个特殊版本，处理器在不同的计算机中，任务通过网络分布到计算机上。这就像 Lady Gaga 问 Beyoncé，\u0026ldquo;请在我喝酒时给这家伙发短信\u0026rdquo;。尽管你可以借助库在 Clojure 中进行分布式编程，但本书只涉及并行编程，在这里我用parallel只指同居的处理器。如果你对分布式编程感兴趣，可以去看看 Kyle Kingsbury 的Call Me Maybe系列，网址是https://aphyr.com/*。\n阻塞和异步任务 并发编程的主要用例之一是用于阻塞操作。阻塞实际上是指等待一个操作的完成。你最常听到的是与 I/O 操作有关的，比如读取文件或等待 HTTP 请求的完成。让我们用 Lady Gaga 并发的例子来研究这个问题。\n如果 Lady Gaga 给她的对话者发短信，然后拿着手机站在那里，盯着屏幕等待回应，而不喝水，那么你会说读下一条短信操作是阻塞的，这些任务是*同步执行的。\n相反，如果她把手机收起来，这样她就可以喝酒了，直到手机发出哔哔声或振动来提醒她，那么阅读下一条短信任务就不是阻塞的，你会说她是在*异步地处理这个任务。\n并发编程和并行编程 并发编程和并行编程指的是将一个任务分解成可以并行执行的子任务的技术，以及管理程序同时执行多个任务时产生的风险。在本章的其余部分，我将交替使用这两个术语，因为两者的风险几乎是一样的。\n为了更好地理解这些风险以及 Clojure 如何帮助你避免这些风险，让我们来看看 Clojure 中是如何实现并发和并行的。\nClojure 实现。JVM 线程 我一直在抽象地使用*任务这个词，指的是一系列相关的操作，而不考虑计算机可能如何实现任务的概念。例如，发短信就是一个由一系列相关操作组成的任务，它与往你脸上倒饮料的操作完全不同。\n在 Clojure 中，你可以把你正常的、串行的代码看作是任务的序列。你可以通过把任务放在 JVM 的线程*上来表示任务可以并发执行。\n什么是线程 我很高兴你问这个问题! 一个线程是一个子程序。一个程序可以有很多线程，每个线程执行自己的指令集，同时享受对程序状态的共享访问。\n！\n线程管理功能可以存在于计算机的多个层面。例如，操作系统内核通常提供系统调用来创建和管理线程。JVM 提供了自己的独立于平台的线程管理功能，由于 Clojure 程序在 JVM 中运行，所以它们使用 JVM 线程。你将在第 12 章中了解更多关于 JVM 的信息。\n你可以把线程看作是一个实际的、物理的线段，它把一连串的指令串起来。在我看来，这些指令是棉花糖，因为棉花糖很好吃。处理器按顺序执行这些指令。我把这想象成一条鳄鱼在吃这些指令，因为鳄鱼喜欢吃棉花糖（这是事实！）。因此，执行一个程序看起来就像一堆棉花糖串在一条线上，一条鳄鱼沿着这条线逐一吃掉。图 9-1 显示了单核处理器执行单线程程序的这个模型。\n图 9-1：单核处理器执行一个单线程的程序\n一个线程可以*产生一个新的线程来并发地执行任务。在单处理器系统中，处理器在线程之间来回切换（交织）。这里就引入了潜在的并发性问题。尽管处理器按顺序执行每个线程的指令，但它不保证何时在线程之间来回切换。\n图 9-2 显示了两个线程，A 和 B，以及它们的指令如何执行的时间线。我对线程 B 的指令做了阴影处理，以帮助区分它们与线程 A 的指令。\n单核处理器执行两个线程\n请注意，这只是一种可能的指令执行顺序。例如，处理器也可以按照 A1、A2、A3、B1、A4、B2、B3 的顺序执行指令。这使程序变得不确定。你不能事先知道结果是什么，因为你无法知道执行顺序，不同的执行顺序会产生不同的结果。\n这个例子显示了通过交织在单个处理器上的并发执行，而多核系统为每个核分配一个线程，允许计算机同时执行一个以上的线程。每个核心按顺序执行其线程的指令，如图 9-3 所示。\n两个线程，两个处理器。\n与单核上的交织一样，整体执行顺序没有保证，所以程序是不确定的。当你在程序中加入第二个线程时，它就变得不确定了，这使得你的程序有可能成为三种问题的牺牲品。\n三个小妖精。参考单元、互斥和矮人狂战士 并发编程中有三个核心挑战，也被称为 \u0026ldquo;三个并发妖精\u0026rdquo;。要知道为什么这些是可怕的，想象一下图 9-3 中的程序包括表 9-1 中的假指令。\n 非确定结果的程序的指令     ID Instruction     A1 WRITE X = 0   A2 READ X   A3 WRITE X = X + 1   B1 READ X   B2 WRITE X = X + 1    如果处理器遵循 A1, A2, A3, B1, B2 的顺序，那么X的值将是2，正如你所期望的。但是如果它遵循 A1, A2, B1, A3, B2 的顺序，X'的值将是1'，正如你在图 9-4 中看到的那样。\n两个线程与一个引用单元进行交互\n我们把这称为参考单元问题（第一个并发性妖精）。 当两个线程可以对同一个位置进行读写时，就会出现引用单元问题，而该位置的值取决于读写的顺序。\n第二个并发妖精是互斥。想象一下，两个线程，每个人都试图向一个文件写一个咒语。如果没有任何方法可以要求对文件进行独占性的写入访问，那么这个咒语最终会变成乱码，因为写入指令会被交错使用。考虑一下以下两个咒语。\n By the power invested in me\nby the state of California,\nI now pronounce you man and wife Thunder, lightning, wind, and rain,\na delicious sandwich, I summon again\n 如果你把这些写到一个没有相互排斥的文件中，你可能会得到这样的结果。\n By the power invested in me\nby Thunder, lightning, wind, and rain,\nthe state of California,\nI now pronounce you a delicious man sandwich, and wife\nI summon again\n 第三个并发妖精就是我所说的矮人狂战士问题（又称死锁）。想象一下，四个狂暴者围坐在一张粗糙的圆形木桌旁，互相安慰。\u0026ldquo;我知道我对我的孩子很疏远，但我就是不知道如何与他们沟通，\u0026ldquo;一个人咆哮道。其余的人啜饮着咖啡，有意无意地点头，他们的眼角处都有护理纹。\n现在，每个人都知道，矮人狂战士结束舒适的咖啡聚会的仪式是拿起他们的 \u0026ldquo;安慰棒\u0026rdquo;（双刃战斧），互相抓挠对方的背部。每对矮人之间放一把战斧，如图 9-5 所示。\n他们的仪式是这样进行的。\n 拿起左边的战斧，如果有的话。 拿起右边战斧，如果有的话。 用你的 \u0026ldquo;安慰棒 \u0026ldquo;大力挥舞来安慰你的邻居。 释放两把战斧。 重复。  矮人狂热者在舒适的咖啡聚会中\n按照这个仪式，所有的矮人狂战士完全有可能拿起他们左边的安慰棒，然后无限期地阻挡，同时等待他们右边的安慰棒出现，导致僵局。(顺便说一下，如果你想进一步研究这种现象，它通常被称为吃饭的哲学家问题，但这是一个更无聊的场景）。本书没有详细讨论死锁，但了解这个概念和术语是很好的。\n并发编程有它的小妖精，但有了正确的工具，它是可控的，甚至是有趣的。让我们开始看一下正确的工具。\nFutures, Delays, and Promises Future、延迟和 Promise 是用于并发编程的简单、轻便的工具。在这一节中，你将学习每个工具的工作原理，以及如何一起使用它们来抵御引用单元的并发妖精和互斥的并发妖精。你会发现，虽然简单，但这些工具对满足你的并发需求有很大帮助。\n它们通过给予你比串行代码更多的灵活性来做到这一点。当你写串行代码时，你把这三个事件绑定在一起。\n 任务定义 任务执行 要求任务的结果  作为一个例子，看一下这个假设的代码，它定义了一个简单的 API 调用任务。\n(web-api/get :dwarven-beard-waxes) 一旦 Clojure 遇到这个任务定义，它就会执行它。它也需要现在的结果，阻塞直到 API 调用完成。学习并发编程的一部分是学会识别何时不需要这些时间上的联接。Future、延迟和 Promise 允许你把任务定义、任务执行和要求结果分开。继续前进!\nFuture 在 Clojure 中，你可以使用futures来定义一个任务，并把它放在另一个线程上，而不要求立即得到结果。你可以用future宏来创建一个未来。在 REPL 中试试这个。\n(future (Thread/sleep 4000) (println \u0026quot;I'll print after 4 seconds\u0026quot;)) (println \u0026quot;I'll print immediately\u0026quot;) Thread/sleep告诉当前线程在指定的毫秒数内坐着什么都不做。通常情况下，如果你在你的 REPL 中评估了Thread/sleep，你就不能评估任何其他语句，直到 REPL 完成睡眠；执行你的 REPL 的线程将被阻塞。然而，future创建了一个新的线程，并将你传递给它的每个表达式放在新的线程上，包括Thread/sleep，允许 REPL 的线程继续运行，不受阻塞。\n你可以使用 future 在一个单独的线程上运行任务，然后忘记它们，但你经常想使用任务的结果。future函数返回一个引用值，你可以用它来请求结果。参考值就像干洗店给你的票据：在任何时候你都可以用它来请求你的干净衣服，但是如果你的衣服还没有洗干净，你就必须等待。类似地，你可以使用参考值来请求一个未来的结果，但是如果未来还没有完成计算结果，你就必须等待。\n请求一个未来的结果被称为dereferencing未来，你可以用deref函数或@读者宏来做。一个 future 的结果值是其主体中最后一个被评估的表达式的值。一个 future 的主体只执行一次，它的值被缓存起来。试试下面的方法。\n(let [result (future (println \u0026quot;this prints once\u0026quot;) (+ 1 1))] (println \u0026quot;deref: \u0026quot; (deref result)) (println \u0026quot;@: \u0026quot; @result)) ; =\u0026gt; \u0026quot;this prints once\u0026quot; ; =\u0026gt; deref: 2 ; =\u0026gt; @: 2 请注意，\u0026ldquo;this prints once \u0026ldquo;这个字符串确实只打印了一次，尽管你对 future 进行了两次推断。这表明 future 的主体只运行了一次，结果2被缓存了。\n如果未来程序还没有完成运行，解指未来程序就会阻塞，就像这样。\n(let [result (future (Thread/sleep 3000) (+ 1 1))] (println \u0026quot;The result is: \u0026quot; @result) (println \u0026quot;It will be at least 3 seconds before I print\u0026quot;)) ; =\u0026gt; The result is: 2 ; =\u0026gt; It will be at least 3 seconds before I print 有时你想为一个未来的等待时间设置一个时间限制。要做到这一点，你可以给deref一个等待的毫秒数，以及当deref超时时要返回的值。\n(deref (future (Thread/sleep 1000) 0) 10 5) ; =\u0026gt; 5 这段代码告诉deref，如果 future 在 10 毫秒内没有返回一个值，则返回值5。\n最后，你可以使用realized?来询问一个 future，看看它是否已经运行完毕。\n(realized? (future (Thread/sleep 1000))) ; =\u0026gt; false (let [f (future)] @f (realized? f)) ; =\u0026gt; true Future 是一种简单的方法，可以在你的程序中撒上一些并发性。\n就其本身而言，它们让你有能力将任务转移到其他线程上，这可以使你的程序更有效率。它们还可以让你的程序表现得更加灵活，让你控制何时需要一个任务的结果。\n当你解除对一个 future 的引用时，你表明现在需要这个结果，并且在获得这个结果之前应该停止计算。你会看到这如何帮助你处理相互排斥的问题。另外，你也可以忽略这个结果。例如，你可以使用 Future 来异步写入一个日志文件，在这种情况下，你不需要解除对 Future 的引用来获得任何返回值。\nFuture 给你带来的灵活性是非常酷的。Clojure 还允许你用延迟和 Promise 来独立处理任务定义和要求结果。\n延迟 延迟允许你定义一个任务，而不需要立即执行它或要求得到结果。你可以使用delay创建一个延迟。\n(def jackson-5-delay (delay (let [message \u0026quot;Just call my name and I'll be there\u0026quot;] (println \u0026quot;First deref:\u0026quot; message) message))) 在这个例子中，没有任何东西被打印出来，因为我们还没有要求对let形式进行评估。你可以评估延迟，并通过解构它或使用force来获得其结果。 force的行为与deref相同，但它更清楚地表达了你正在使一个任务开始，而不是等待一个任务完成。\n(force jackson-5-delay) ; =\u0026gt; First deref: Just call my name and I'll be there ; =\u0026gt; \u0026quot;Just call my name and I'll be there\u0026quot; 像 Future 一样，延迟只运行一次，其结果被缓存。后续的取消引用将返回 Jackson 5 的信息，而不打印任何东西。\n@jackson-5-delay ; =\u0026gt; \u0026quot;Just call my name and I'll be there\u0026quot; 你可以使用延迟的一种方式是在一组相关的 Future 中的一个 Future 第一次完成时启动一个语句。例如，假设你的应用程序将一组头像上传到一个头像分享网站，并在第一张头像完成后立即通知所有者，如下所示。\n(def gimli-headshots [\u0026quot;serious.jpg\u0026quot; \u0026quot;fun.jpg\u0026quot; \u0026quot;playful.jpg\u0026quot;]) (defn email-user [email-address] (println \u0026quot;Sending headshot notification to\u0026quot; email-address)) (defn upload-document \u0026quot;Needs to be implemented\u0026quot; [headshot] true) (let [notify (delay ➊(email-user \u0026quot;and-my-axe@gmail.com\u0026quot;))] (doseq [headshot gimli-headshots] (future (upload-document headshot) ➋(force notify)))) 在这个例子中，你定义了一个要上传头像的 Vector（gimli-headshots）和两个函数（email-user和upload-document）来假装执行这两个操作。然后你用let将notify绑定到一个延迟。延迟的主体，(email-user \u0026quot;and-my-axe@gmail.com\u0026quot;)➊，在创建延迟的时候并没有被评估。相反，当由doseq表单创建的 Future 之一第一次评估(force notify)➋时，它就被评估了。即使(force notify)将被评估三次，延迟主体只被评估一次。Gimli 会很高兴知道第一张头像什么时候可用，这样他就可以开始调整它并分享它。他也会感谢不被垃圾邮件，而你也会感谢不面对他的矮人之怒。\n这种技术可以帮助你避免相互排斥的并发妖精\u0026ndash;确保每次只有一个线程可以访问特定资源的问题。在这个例子中，延迟守护着电子邮件服务器资源。因为延迟的主体被保证只发射一次，所以你可以确定你永远不会遇到两个线程发送相同邮件的情况。当然，没有线程能够再次使用延迟来发送邮件。对于大多数情况来说，这可能是一个过于激烈的约束，但在像这个例子这样的情况下，它是完美的。\nPromise Promise允许你表达你期望的结果，而不需要定义应该产生结果的任务或该任务应该何时运行。你用promise'创建Promise，用deliver\u0026rsquo;向他们传递一个结果。你通过取消引用来获得结果。\n(def my-promise (promise)) (deliver my-promise (+ 1 2)) @my-promise ; =\u0026gt; 3 这里，你创建了一个 promise，然后向它传递一个值。最后，你通过解除对 Promise 的引用来获得该值。解除引用是你表达你期望一个结果的方式，如果你试图在没有首先传递一个值的情况下解除引用`my-promise'，程序将阻塞，直到一个 Promise 被传递，就像 Future 和延迟一样。你只能向一个 Promise 传递一次结果。\nPromise 的一个用途是在一个数据集合中找到第一个满意的元素。例如，假设你正在收集成分以使你的鹦鹉听起来像詹姆斯-厄尔-琼斯。因为詹姆斯-厄尔-琼斯的声音是世界上最顺畅的，所以其中一种成分是顺畅度达到 97 以上的优质牦牛油。你的预算是 100 美元一磅。\n你是一个现代神奇鸟类学艺术的实践者，因此，与其繁琐地浏览每个牦牛油零售网站，不如创建一个脚本，给你提供第一个符合你需求的牦牛油的 URL。\n下面的代码定义了一些牦牛油产品，创建了一个函数来模拟 API 调用，并创建了另一个函数来测试产品是否满意。\n(def yak-butter-international {:store \u0026quot;Yak Butter International\u0026quot; :price 90 :smoothness 90}) (def butter-than-nothing {:store \u0026quot;Butter Than Nothing\u0026quot; :price 150 :smoothness 83}) ;; This is the butter that meets our requirements (def baby-got-yak {:store \u0026quot;Baby Got Yak\u0026quot; :price 94 :smoothness 99}) (defn mock-api-call [result] (Thread/sleep 1000) result) (defn satisfactory? \u0026quot;If the butter meets our criteria, return the butter, else return false\u0026quot; [butter] (and (\u0026lt;= (:price butter) 100) (\u0026gt;= (:smoothness butter) 97) butter)) 该 API 调用在返回结果前等待一秒钟，以模拟执行实际调用的时间。\n为了说明同步检查网站需要多长时间，我们将使用some对集合中的每个元素应用satisfactory?函数，并返回第一个真实的结果，如果没有，则返回 nil。当你同步检查每个站点时，每个站点可能需要超过一秒钟的时间来获得结果，正如下面的代码所示。\n(time (some (comp satisfactory? mock-api-call) [yak-butter-international butter-than-nothing baby-got-yak])) ; =\u0026gt; \u0026quot;Elapsed time: 3002.132 msecs\u0026quot; ; =\u0026gt; {:store \u0026quot;Baby Got Yak\u0026quot;, :smoothness 99, :price 94} 这里我用comp来组合函数，我用time来打印评估一个表单的时间。你可以使用 promise 和 futures 来在一个单独的线程上执行每个检查。如果你的计算机有多个核心，这可以把时间减少到一秒钟左右。\n(time (let [butter-promise (promise)] (doseq [butter [yak-butter-international butter-than-nothing baby-got-yak]] (future (if-let [satisfactory-butter (satisfactory? (mock-api-call butter))] (deliver butter-promise satisfactory-butter)))) (println \u0026quot;And the winner is:\u0026quot; @butter-promise))) ; =\u0026gt; \u0026quot;Elapsed time: 1002.652 msecs\u0026quot; ; =\u0026gt; And the winner is: {:store Baby Got Yak, :smoothness 99, :price 94} 在这个例子中，你首先创建了一个 Promise，butter-promise，然后创建了三个访问该 Promise 的 Future。每个 Future 的任务是评估一个牦牛黄油网站，如果该网站令人满意，则向 Promise 提供该网站的数据。最后，你解除对butter-promise的引用，导致程序阻塞，直到网站数据被交付。这需要一秒钟而不是三秒钟，因为网站的评估是平行进行的。通过将对结果的要求与结果的实际计算方式脱钩，你可以并行地进行多个计算，并节省一些时间。\n你可以把这看作是一种保护自己不受参考单元格并发性妖精影响的方法。因为 Promise 只能被写入一次，你可以防止非确定性读写产生的那种不一致的状态。\n你可能想知道，如果牦牛油都不满意会怎么样。如果发生这种情况，解除引用将永远阻塞，并绑住线程。为了避免这种情况，你可以加入一个超时。\n(让 [p (promise)] (deref p 100 \u0026quot;timed out\u0026quot;) 这将创建一个 Promise，p'，并试图解除对它的引用。数字100告诉deref等待100毫秒，如果届时没有可用的值，就使用超时值，\u0026ldquo;timed out\u0026rdquo;`。\n我应该提到的最后一个细节是，你也可以使用 Promise 来注册回调，实现与你在 JavaScript 中可能习惯的相同功能。JavaScript 的回调是一种定义代码的方式，一旦其他代码完成，就应该异步执行。下面是如何在 Clojure 中做到这一点。\n(let [ferengi-wisdom-promise (promise)] (future (println \u0026quot;Here's some Ferengi wisdom:\u0026quot; @ferengi-wisdom-promise)) (Thread/sleep 100) (deliver ferengi-wisdom-promise \u0026quot;Whisper your way to success.\u0026quot;)) ; =\u0026gt; Here's some Ferengi wisdom: Whisper your way to success. 这个例子创建了一个立即开始执行的未来。然而，未来的线程是阻塞的，因为它在等待一个值被传递给ferengi-wisdom-promise。100 毫秒后，你交付了值，未来中的`println\u0026rsquo;语句开始运行。\nFuture、延迟和 Promise 是在你的应用程序中管理并发性的伟大而简单的方法。在下一节中，我们将看到一个更有趣的方法来控制你的并发应用程序。\n滚动你自己的队列 到目前为止，你已经看到了一些简单的方法来结合 Future、延迟和 Promise，使你的并发程序更加安全。在这一节中，你将使用一个宏来以一种稍微复杂的方式结合 Future 和 Promise。你可能不一定会用到这段代码，但它会更多地展示这些适度的工具的力量。这个宏需要你在头脑中同时持有运行时逻辑和宏扩展逻辑，以了解正在发生的事情；如果你被卡住了，就跳过前面。\n三个并发妖精的一个共同特点是，它们都涉及到任务以不协调的方式并发地访问一个共享资源\u0026ndash;变量、打印机、矮人战斧。如果你想确保每次只有一个任务会访问一个资源，你可以把任务的资源访问部分放在一个序列执行的队列中。这有点像做蛋糕：你和一个朋友可以分别取回原料（鸡蛋、面粉、蝾螈的眼睛，等等），但有些步骤你必须连续执行。你必须在把面糊放进烤箱之前准备好它。图 9-6 说明了这个策略。\n将任务分为串行部分和并发部分，可以让你安全地使你的代码更有效率。\n为了实现排队宏，你要向英国人致敬，因为他们发明了队列。你将使用一个队列来确保英国人习惯的问候语 \u0026ldquo;Ello, gov\u0026rsquo;na! Pip Pip! Cheerio!\u0026ldquo;的正确顺序进行传递。这个演示将涉及到大量的 \u0026ldquo;睡眠\u0026rdquo;，所以这里有一个宏来更简洁地完成这个任务。\n(defmacro wait \u0026quot;Sleep `timeout` seconds before evaluating body\u0026quot; [timeout \u0026amp; body] `(do (Thread/sleep ~timeout) ~@body)) 这段代码所做的就是接受你给它的任何形式，并在它们之前插入对Thread/sleep的调用，所有这些都被do包裹起来。\n清单 9-1 中的代码将任务分成了并发部分和序列化部分。\n(let [saying3 (promise)] (future (deliver saying3 (wait 100 \u0026quot;Cheerio!\u0026quot;))) @(let [saying2 (promise)] (future (deliver saying2 (wait 400 \u0026quot;Pip pip!\u0026quot;))) ➊ @(let [saying1 (promise)] (future (deliver saying1 (wait 200 \u0026quot;'Ello, gov'na!\u0026quot;))) (println @saying1) saying1) (println @saying2) saying2) (println @saying3) saying3)  9-1. 一个 enqueue 宏调用的扩展  整体策略是为每个任务（在本例中，打印问候语的一部分）创建一个 Promise，以创建一个相应的未来，将并发计算的值交付给该 Promise。这确保了在任何一个 Promise 被解除引用之前，所有的未来都被创建，并且确保序列化的部分以正确的顺序执行。首先打印saying1'的值-\u0026quot;\u0026lsquo;Ello, gov\u0026rsquo;na!\u0026quot;-然后是saying2'的值，最后是saying3\u0026rsquo;。在let块中返回saying1，并在➊处解除对let块的引用，可以确保在代码继续对saying2做任何事情之前，你已经完全完成了saying1，而且这种模式在saying2和saying3上重复。\n解除对let块的引用似乎很傻，但这样做可以让你用一个宏来抽象这段代码。你肯定想使用宏，因为像前面的例子那样写出的代码会让你发疯（英国人会这么说）。理想情况下，这个宏的工作方式如清单 9-2 所示。\n(-\u0026gt; (enqueue ➊saying ➋(wait 200 \u0026quot;'Ello, gov'na!\u0026quot;) ➌(println @saying)) ➍(enqueue saying (wait 400 \u0026quot;Pip pip!\u0026quot;) (println @saying)) (enqueue saying (wait 100 \u0026quot;Cheerio!\u0026quot;) (println @saying)))  这就是你使用 enqueue 的方法。  该宏让你命名被创建的 Promise➊，定义如何获取价值以交付该 Promise➋，并定义如何处理该 Promise➌。这个宏也可以把另一个enqueue宏调用作为它的第一个参数，这样你就可以把它变成线程➍。清单 9-3 显示了你如何定义enqueue宏。定义完enqueue后，清单 9-2 中的代码将扩展为清单 9-1 中的代码，其中包含所有嵌套的let表达式。\n(defmacro enqueue ➊ ([q concurrent-promise-name concurrent serialized] ➋ `(let [~concurrent-promise-name (promise)] (future (deliver ~concurrent-promise-name ~concurrent)) ➌ (deref ~q) ~serialized ~concurrent-promise-name)) ➍ ([concurrent-promise-name concurrent serialized] `(enqueue (future) ~concurrent-promise-name ~concurrent ~serialized))) 1.enqueue 的实现\n首先注意这个宏有两个 arities，以便提供一个缺省值。第一个 arity ➊是真正的工作所在。它有参数q，而第二个 arity 则没有。第二个 arity ➍调用第一个 arity，为q提供了(future)的值；你将在一分钟内看到原因。在➋中，宏返回一个表单，该表单创建了一个 Promise，在一个 future 中传递它的值，取消对提供给q的任何表单的引用，评估序列化代码，最后返回 Promise。q通常是一个嵌套的let表达式，由另一个对enqueue的调用返回，如清单 9-2 所示。如果没有为q提供值，宏会提供一个未来，这样在➌的deref就不会引起异常。\n现在我们已经写好了enqueue宏，让我们试试它是否能减少执行时间\n(time @(-\u0026gt; (enqueue saying (wait 200 \u0026quot;'Ello, gov'na!\u0026quot;) (println @saying)) (enqueue saying (wait 400 \u0026quot;Pip pip!\u0026quot;) (println @saying)) (enqueue saying (wait 100 \u0026quot;Cheerio!\u0026quot;) (println @saying)))) ; =\u0026gt; 'Ello, gov'na! ; =\u0026gt; Pip pip! ; =\u0026gt; Cheerio! ; =\u0026gt; \u0026quot;Elapsed time: 401.635 msecs\u0026quot; 天哪! 问候语是按照正确的顺序传递的，你可以通过耗时看到，睡眠的 \u0026ldquo;工作 \u0026ldquo;是同时进行的。\n总结 对于像你这样的程序员来说，学习并发和并行编程技术很重要，这样你就可以设计出在现代硬件上高效运行的程序。并发是指一个程序能够执行一个以上的任务，在 Clojure 中，你可以通过将任务放在不同的线程上来实现。当计算机有一个以上的 CPU 时，程序就会并行执行，这样就可以在同一时间执行一个以上的线程。\n并发编程指的是用于管理三种并发风险的技术：引用单元、互斥和死锁。Clojure 为你提供了三个基本工具，帮助你减轻这些风险：Future、延迟和 Promise。每个工具都可以让你把定义任务、执行任务和要求任务结果这三个事件解耦。Future 让你定义一个任务并立即执行它，允许你稍后或永远不要求结果。 Future 也会缓存其结果。延迟（Delay）让你定义一个稍后才执行的任务，并且延迟的结果会被缓存起来。许诺让你表达你需要一个结果，而不需要知道产生该结果的任务。你只能向一个 Promise 传递一次值。\n在下一章中，你将探索并发编程的哲学层面，并学习更复杂的工具来管理风险。\n练习  编写一个函数，将一个字符串作为参数，使用slurp函数在 Bing 和 Google 上搜索它。你的函数应该返回搜索到的第一个页面的 HTML。 更新你的函数，使其接受第二个参数，包括要使用的搜索引擎。 创建一个新的函数，将搜索词和搜索引擎作为参数，并从每个搜索引擎的第一页搜索结果中返回一个 URL 的 Vector。  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter9/","summary":"并发和并行编程的神圣艺术 如果我是一个庄园的主人，而你是我的继承人，我会在你的第 13 个命名日让你坐下来，告诉你：\u0026ldquo;计算的世界正在改变，小姑娘，你必须为多核处理器的新世界做好准备，以免你被它践踏。\n\u0026ldquo;好好听着。近年来，CPU 的时钟速度几乎没有增加，但双核和四核计算机已经变得很普遍。物理定律是残酷而绝对的，它们要求提高时钟速度需要成倍的功率。领域内最好的工程师不太可能很快克服这一限制，如果有的话。因此，你可以预期单台机器上的内核不断增加的趋势将继续下去\u0026ndash;作为一个程序员，你将知道如何充分利用现代硬件的期望也是如此。\n\u0026ldquo;在这种新模式下学习编程将是有趣和迷人的，真的。但请注意：它也充满了危险。你必须学习并发和并行编程*，这是一门神圣的艺术，使你的应用结构安全地管理多个同时执行的任务。\n\u0026ldquo;你从对并发和并行概念的概述开始学习这门艺术。然后，你将学习困扰每个从业者的三个小妖精：参考单元、互斥和矮人狂战士。你还将学习三种有助于你的工具：Future、许诺和延迟\u0026rdquo;。\n然后我会用键盘拍拍你的肩膀，示意你可以开始了。\n并发和并行的概念 并发和并行编程在程序执行的各个层面都涉及到很多混乱的细节，从硬件到操作系统，到编程语言库，再到从你的内心涌出的、落在编辑器中的代码。但在你为这些细节烦恼之前，在这一节中，我将介绍围绕并发和并行的高级概念。\n管理多个任务与同时执行任务 并发指的是在同一时间管理一个以上的任务。 任务只是意味着 \u0026ldquo;需要完成的事情\u0026rdquo;，它并不意味着任何有关硬件或软件的实现。我们可以用 Lady Gaga 的歌曲《电话》来说明并发性。Gaga 唱道\n I cannot text you with a drink in my hand, eh\n 这里，她在解释她只能管理一个任务（喝酒）。她断然拒绝了她可以处理一个以上的任务的建议。然而，如果她决定同时处理任务，她会唱歌。\n I will put down this drink to text you, then put my phone away and continue drinking, eh\n 在这个假设的宇宙中，Lady Gaga 正在处理两个任务：喝酒和发短信。然而，她并没有同时执行这两项任务。相反，她在这两个任务之间进行切换，或者说是交错。请注意，在交错过程中，你不必在切换之前完全完成一项任务：Gaga 可以打一个字，放下手机，拿起饮料喝一口，然后换回手机，再打一个字。\n平行性指的是同时执行一个以上的任务。如果加加夫人平行地执行她的两项任务，她会唱歌。\n I can text you with one hand while I use the other to drink, eh","title":"Chapter9 并发的艺术"},{"content":"编写宏程序 当我 18 岁时，我在新墨西哥州圣菲的一家酒店找到了一份夜班审计师的工作，每周工作四个晚上，从晚上 11 点到早上 7 点。经过几个月的这种不眠不休的工作，我的情绪有了自己的变化。一天晚上，大约在\n凌晨 3 点，我正在看一个信息广告，该产品声称可以恢复男人的头发。当我看到一个曾经秃头的人的故事时，我被真诚的喜悦所淹没。\u0026ldquo;终于来了！\u0026ldquo;我的大脑涌动着。\u0026ldquo;这个人得到了他应得的爱和成功! 多么不可思议的产品，给无望的人以希望！\u0026rdquo;\n从那时起，我发现自己一直在想，我是否能以某种方式重新创造因长期睡眠不足而引起的情感放弃和对生命的欣赏。也许是某种药水\u0026ndash;喝上几口，释放我内心的理查德-西蒙斯，但时间不会太长。\n就像药水可以让我暂时改变我的基本性质一样，宏允许你以其他语言无法实现的方式修改 Clojure。有了宏，你可以扩展 Clojure 以适应你的问题空间，建立起语言。\n在这一章中，你将彻底研究如何编写宏，从基本的例子开始，逐步提高复杂性。最后，你将戴上你的假想帽，用宏来验证你想象中的在线药水店的客户订单。\n在本章结束时，你将了解你用来编写宏的所有工具：引号、语法引号、解引号、解引号拼接（又称皮纳塔工具）和 gensym。你还会了解到对毫无戒心的宏作者来说隐藏着的危险：双重评估、变量捕获和宏感染。\n宏是必不可少的 在你开始编写宏之前，我想帮助你把它们放在适当的环境中。是的，宏比北极熊的脚趾甲还要酷，但你不应该把宏看成是一些深奥的工具，当你想对你的代码进行额外的花哨处理时，就把它拿出来。事实上，宏允许 Clojure 从一个很小的函数和特殊形式的核心中获得大量的内置功能。以when为例。 when有这样的一般形式。\n(when boolean-expression expression-1 expression-2 expression-3 ... expression-x) 你可能认为when是一个像if一样的特殊形式。那么你猜怎么着？它不是! 在大多数其他语言中，你只能使用特殊的关键字来创建条件表达式，而没有办法创建你自己的条件运算符。然而，when实际上是一个宏。\n在这个宏扩展中，你可以看到when是用if和do来实现的。\n(macroexpand '(when boolean-expression expression-1 expression-2 expression-3)) ; =\u0026gt; (if boolean-expression (do expression-1 expression-2 expression-3)) 这表明宏是 Clojure 开发中不可或缺的一部分\u0026ndash;它们甚至被用来提供基本操作。宏并不是为奇特的特殊情况而保留的；你应该把写宏看作是你工具包中的另一个工具。当你学会编写自己的宏时，你会发现它们是如何让你进一步扩展语言，使其适合你的特定问题领域的形状。\n解剖巨集 巨集定义看起来很像函数定义。它们有一个名称，一个可选的文档字符串，一个参数列表，以及一个主体。主体几乎总是返回一个列表。这是有道理的，因为宏是将数据结构转化为 Clojure 可以评估的形式的一种方式，而 Clojure 使用列表来表示函数调用、特殊形式调用和宏调用。你可以在宏主体中使用任何函数、宏或特殊形式，你调用宏就像调用函数或特殊形式一样。\n作为一个例子，这里有我们的老朋友infix宏。\n(defmacro infix \u0026quot;Use this macro when you pine for the notation of your childhood\u0026quot; [infixed] (list (second infixed) (first infixed) (last infixed))) 这个宏将一个列表重新排列成正确的 infix 记号顺序。下面是一个例子。\n(infix (1 + 1)) ; =\u0026gt; 2 函数和宏之间的一个关键区别是，函数参数在传递给函数之前被完全评估，而宏是以未评估的数据形式接收参数。你可以在这个例子中看到这一点。如果你试图单独评估(1+1)，你会得到一个异常。然而，因为你在进行一个宏调用，未评估的列表(1 + 1)被传递给infix。然后宏可以使用first、second和last来重新排列列表，这样 Clojure 就可以评估它。\n(macroexpand '(infix (1 + 1)) ; =\u0026gt; (+ 1 1) 通过扩展宏，你可以看到infix将(1 + 1)重新排列成(+ 1 1)。很方便!\n你也可以在宏定义中使用参数重构，就像你可以使用函数一样。\n(defmacro infix-2 [[operand1 op operand2]] (list op operand1 operand2) (list op operand1 operand2)) 解构参数可以让你根据序列参数中的位置简洁地将值与符号绑定。在这里，infix-2将一个顺序数据结构作为参数，并按位置进行解构，因此第一个值被命名为operand1，第二个值被命名为op，第三个值在宏中被命名为operand2。\n你也可以创建多属性的宏，事实上，基本的布尔运算and和or都被定义为宏。下面是and的源代码。\n(defmacro and \u0026quot;Evaluates exprs one at a time, from left to right. If a form returns logical false (nil or false), and returns that value and doesn't evaluate any of the other expressions, otherwise it returns the value of the last expr. (and) returns true.\u0026quot; {:added \u0026quot;1.0\u0026quot;} ([] true) ([x] x) ([x \u0026amp; next] `(let [and# ~x] (if and# (and ~@next) and#)))) 在这个例子中发生了很多事情，包括符号和~@，你很快就会了解到这些。现在重要的是，这里有三个宏体：一个总是返回 \u0026ldquo;true \u0026ldquo;的 0-arity 宏体，一个返回操作数的 1-arity 宏体，以及一个递归调用自身的n-arity 宏体。这是正确的：宏可以是递归的，它们也可以使用其余的参数（n-arity 宏主体中的\u0026amp; next），就像函数一样。\n现在你对宏的解剖已经很熟悉了，现在是时候把你自己绑在你的奥德修斯式思维的桅杆上，学习写宏体了。\n为评估建立列表 编写宏就是要为 Clojure 建立一个列表来进行评估，这需要颠覆你的正常思维方式。首先，你经常需要引用表达式，以便在你的最终列表中获得未评估的数据结构（我们稍后会回到这个问题）。更普遍的是，你需要特别注意符号和值之间的区别。\n区分符号和值 假设你想创建一个宏，它接收一个表达式，并同时打印和返回其值。(这与println'不同，println\u0026rsquo;总是返回`nil'。)你希望你的宏能够返回类似这样的列表。\n(let [result expression] (println result) result) 你的宏的第一个版本可能看起来像这样，使用list函数来创建 Clojure 应该评估的列表。\n (defmacro my-print-whoopsie [expression] (list let [result expression] (list println result) result)) 然而，如果你尝试这样做，你会得到一个异常`不能接受一个宏的值。#\u0026lsquo;clojure.core/let\u0026rsquo;。这到底是怎么回事？\n发生这种情况的原因是，你的宏主体试图获取符号 let所指的*值，而你实际想做的是返回let符号本身。还有其他的问题：你试图获得result的值，这是不绑定的，你试图获得println的值，而不是返回其符号。下面是你如何写宏来做你想要的事情。\n(defmacro my-print [expression] (list 'let ['result expression] (list 'println 'result) 'result)) 在这里，你通过在每个符号前加上单引号\u0026rdquo;\u0026lsquo;\u0026lsquo;来引出你想作为一个符号使用。这告诉 Clojure关闭后面的评估，在这种情况下，防止 Clojure 试图解决这些符号，而只是返回这些符号。使用引号来关闭评估的能力是编写宏的核心，所以让我们给这个主题一个独立的章节。\n简单的引号 你几乎总是在你的宏中使用引号来获得一个未评价的符号。让我们简单地复习一下引号，然后看看你如何在宏中使用它。\n首先，这里是一个没有引号的简单函数调用。\n(+ 1 2) ; =\u0026gt; 3 如果我们在开头加上quote，它就会返回一个未评估的数据结构。\n(quote (+ 1 2)) ; =\u0026gt; (+ 1 2) 这里在返回的列表中，+是一个符号。如果我们评估这个加号，就会产生加号函数。\n+ ; =\u0026gt; #\u0026lt;core$_PLUS_ clojure.core$_PLUS_@47b36583\u0026gt; 而如果我们引用这个加号，它只是产生加号。\n(quote +) ; =\u0026gt; + 评估一个未绑定的符号会引发一个异常。\nsweating-to-the-oldies ; =\u0026gt; Unable to resolve symbol: sweating-to-the-oldies in this context 但是引用符号会返回一个符号，不管这个符号是否有一个与之相关的值。\n(quote sweating-to-the-oldies) ; =\u0026gt; sweating-to-the-oldies 单引号字符是(quotex)的读者宏。\n'(+ 1 2) ; =\u0026gt; (+ 1 2) 'dr-jekyll-and-richard-simmons ; =\u0026gt; dr-jekyll-and-richard-simmons 你可以在when宏中看到引用的工作。这是when的实际源代码。\n(defmacro when \u0026quot;Evaluates test. If logical true, evaluates body in an implicit do.\u0026quot; {:added \u0026quot;1.0\u0026quot;} [test \u0026amp; body] (list 'if test (cons 'do body))) 注意，宏的定义同时引用了if和do。这是因为你想让这些符号出现在`when\u0026rsquo;返回的最终列表中进行计算。下面是一个返回列表的例子，它可能是这样的。\n(macroexpand '(when (the-cows-come :home) (call me :pappy) (slap me :silly))) ; =\u0026gt; (if (the-cows-come :home) (do (call me :pappy) (slap me :silly))) 下面是另一个内置宏的源代码的例子，这次是关于unless的。\n(defmacro unless \u0026quot;Inverted 'if'\u0026quot; [test \u0026amp; branches] (conj (reverse branches) test 'if)) 同样，你必须引用if，因为你想让未评价的符号放在结果列表中，就像这样。\n(macroexpand '(unless (done-been slapped? me) (slap me :silly) (say \u0026quot;I reckon that'll learn me\u0026quot;))) ; =\u0026gt; (if (done-been slapped? me) (say \u0026quot;I reckon that'll learn me\u0026quot;) (slap me :silly)) 在许多情况下，在编写宏时，你会使用这样的简单引号，但大多数情况下你会使用更强大的语法引号。\n语法引用 到目前为止, 你已经看到了通过使用list函数来建立列表的宏，以及对列表进行操作的函数，如first, second, last，等等。事实上，你可以这样写宏，直到奶牛回家。但有时，这将导致繁琐和冗长的代码。\n语法引号返回未评估的数据结构，与普通引号类似。然而，有两个重要的区别。一个区别是，语法引用将返回完全合格的符号（即包括符号的命名空间）。让我们比较一下引号和语法引号。\n如果你的代码中不包括名字空间，那么引用就不包括名字空间。\n'+ ; =\u0026gt; + 写出命名空间，它将被正常的引用所返回。\n'clojure.core/+ ; =\u0026gt; clojure.core/+ 语法引号将总是包括符号的完整命名空间。\n`+ ; =\u0026gt; clojure.core/+ 对一个列表的引用会递归地引用所有的元素。\n'(+ 1 2) ; =\u0026gt; (+ 1 2) 语法引用一个列表递归地引用所有的元素。\n`(+ 1 2) ; =\u0026gt; (clojure.core/+ 1 2) 语法引号包括名字空间的原因是为了帮助你避免名字的碰撞，这个话题在第 6 章中涉及。\n引号和语法引号之间的另一个区别是，后者允许你使用 \u0026ldquo;tilde\u0026rdquo;，即\u0026rdquo;~\u0026quot;，来*解除引号的形式。这有点像氪星石：只要超人在氪星石周围，他的能力就会消失。每当在一个语法引号的表单中出现 tilde，语法引号返回未评价的、完全命名的表单的能力就会消失。这里有一个例子。\n`(+ 1 ~(inc 1)) ; =\u0026gt; (clojure.core/+ 1 2) 因为它在 tilde 之后，(inc 1)被评估而不是被引号。如果没有 unquote，语法引号会返回未评价的形式，并带有完全限定的符号。\n`(+ 1 (inc 1)) ; =\u0026gt; (clojure.core/+ 1 (clojure.core/inc 1)) 如果你熟悉字符串插值，你可以类似地考虑语法引用/非引用的问题。在这两种情况下，你都在创建一种模板，将一些变量放在一个更大的静态结构中。例如，在 Ruby 中，你可以通过连接来创建字符串\u0026quot;Churn your butter, Jebediah!\u0026quot;。\nname = \u0026quot;Jebediah\u0026quot; \u0026quot;Churn your butter, \u0026quot; + name + \u0026quot;!\u0026quot; 或通过内插法。\n\u0026quot;Churn your butter, #{name}!\u0026quot; 就像字符串插值可以使代码更清晰、更简洁一样，语法引号和解引号可以使你更清晰、更简洁地创建列表。比较一下使用list函数和使用语法引号。\n(list '+ 1 (inc 1)) ; =\u0026gt; (+ 1 2) `(+ 1 ~(inc 1)) ; =\u0026gt; (clojure.core/+ 1 2) 正如你所看到的，语法引号版本更加简洁。而且，它的视觉形式更接近列表的最终形式，使其更容易理解。\n在宏中使用语法引语 现在你已经很好地掌握了语法引号的工作原理，来看看code-critic宏。你将使用语法引号编写一个更简洁的版本。\n(defmacro code-critic \u0026quot;Phrases are courtesy Hermes Conrad from Futurama\u0026quot; [bad good] (list 'do (list 'println \u0026quot;Great squid of Madrid, this is bad code:\u0026quot; (list 'quote bad)) (list 'println \u0026quot;Sweet gorilla of Manila, this is good code:\u0026quot; (list 'quote good)))) (code-critic (1 + 1) (+ 1 1)) ; =\u0026gt; Great squid of Madrid, this is bad code: (1 + 1) ; =\u0026gt; Sweet gorilla of Manila, this is good code: (+ 1 1) 仅仅是看着那些乏味的重复的list和单引号，就让我感到害怕。但是如果你用语法引号重写code-critic，你就可以使它变得圆滑简洁。\n(defmacro code-critic \u0026quot;Phrases are courtesy Hermes Conrad from Futurama\u0026quot; [bad good] `(do (println \u0026quot;Great squid of Madrid, this is bad code:\u0026quot; (quote ~bad)) (println \u0026quot;Sweet gorilla of Manila, this is good code:\u0026quot; (quote ~good)))) 在这种情况下，你想引用除符号good和bad以外的所有内容。在原来的版本中，你必须单独引用每一块，并明确地把它放在一个不方便的列表中，只是为了防止这两个符号被引用。有了语法引号，你只需将整个do表达式包裹在一个引号中，并简单地取消你要评估的两个符号的引号。\n宏的编写方法介绍到此结束! 亲爱的西萨摩亚和东萨摩亚的神圣蟒蛇，这是很重要的!\n总而言之，宏接收未经评估的、任意的数据结构作为参数，并返回 Clojure 评估的数据结构。在定义宏的时候，你可以使用参数重构，就像你可以使用函数和let绑定一样。你也可以编写多属性和递归的宏。\n大多数情况下，你的宏会返回列表。你可以通过使用list函数或使用语法引号来建立要返回的列表。语法引号通常会使代码更清晰、更简洁，因为它可以让你创建一个你想返回的数据结构的模板，更容易进行视觉上的解析。无论你使用语法引号还是普通引号，重要的是在建立你的列表时要清楚地了解符号和它所评估的值之间的区别。如果你想让你的宏返回多种形式供 Clojure 评估，一定要用do来包装它们。\n重构一个宏和取消引号拼接 上一节中的 \u0026ldquo;code-critic \u0026ldquo;宏仍然需要一些改进。看看这个重复的地方! 两个 \u0026ldquo;println \u0026ldquo;的调用几乎是一样的。让我们把它清理一下。首先，让我们创建一个函数来生成这些`println\u0026rsquo;列表。函数比宏更容易思考和使用，所以把宏的内容移到辅助函数中通常是个好主意。\n(defn criticize-code [criticism code] `(println ~criticism (quote ~code))) (defmacro code-critic [bad good] `(do ~(criticize-code \u0026quot;Cursed bacteria of Liberia, this is bad code:\u0026quot; bad) ~(criticize-code \u0026quot;Sweet sacred boa of Western and Eastern Samoa, this is good code:\u0026quot; good))) 注意到criticize-code函数如何返回一个语法引号的列表。这就是你如何建立起宏将返回的列表。\n不过，还有更多的改进空间。这段代码仍然有多个几乎相同的函数调用。在这种情况下，你想对一个值的集合应用同一个函数，使用像map这样的 seq 函数是有意义的。\n(defmacro code-critic [bad good] `(do ~(map #(apply criticize-code %) [[\u0026quot;Great squid of Madrid, this is bad code:\u0026quot; bad] [\u0026quot;Sweet gorilla of Manila, this is good code:\u0026quot; good]]))) 这看起来好一点了。你正在 Map 每个批评/代码对，并将 \u0026ldquo;批评-代码 \u0026ldquo;函数应用于该对。让我们试着运行这段代码。\n(code-critic (1 + 1) (+ 1 1)) ; =\u0026gt; NullPointerException 哦，不！这根本就没有用! 发生了什么？问题是，map返回一个列表，在这种情况下，它返回一个println表达式的列表。我们只想得到每个println调用的结果，但是相反，这段代码把两个结果都放在一个列表中，然后试图评估这个列表。\n换句话说，当它评估这段代码时，Clojure 会得到类似这样的结果。\n(do ((clojure.core/println \u0026quot; criticism\u0026quot; ' (1 + 1)) (clojure.core/println \u0026quot;critism\u0026quot; '(+ 1 1))))) 然后评估第一个 \u0026ldquo;println \u0026ldquo;的调用，给我们提供这个。\n(do (nil (clojure.core/println \u0026quot;criticism\u0026quot; '(+ 1 1)))) 并在评估了第二个`println\u0026rsquo;调用后，这样做。\n(do (nil nil)) 这就是导致异常的原因。println评估为nil，所以我们最后得到的结果是(nil nil)。nil是不可调用的，我们得到一个NullPointerException。\n多么不方便啊 但恰恰相反，无引号拼接正是为了处理这种情况而发明的。取消引号拼接是用~@来完成的。如果你只是取消引用一个列表，你会得到这样的结果。\n`(+ ~(list 1 2 3)) ; =\u0026gt; (clojure.core/+ (1 2 3)) 然而，如果你使用 unquote 拼接，你会得到这样的结果。\n`(+ ~@(list 1 2 3)) ; =\u0026gt; (clojure.core/+ 1 2 3) Unquote 拼接将一个可排序的数据结构解开，将其内容直接放在包围的语法引号数据结构中。这就像~@是一把大锤子，后面的东西是一个皮纳塔，其结果是你曾经参加过的最可怕和最棒的聚会。\n总之，如果你在你的代码批评中使用非引号拼接，那么一切都会很顺利。\n(defmacro code-critic [{:keys [good bad]}] `(do ~@(map #(apply criticize-code %) [[\u0026quot;Sweet lion of Zion, this is bad code:\u0026quot; bad] [\u0026quot;Great cow of Moscow, this is good code:\u0026quot; good]]))) (code-critic (1 + 1) (+ 1 1)) ; =\u0026gt; Sweet lion of Zion, this is bad code: (1 + 1) ; =\u0026gt; Great cow of Moscow, this is good code: (+ 1 1) 呜呼! 你已经成功地将重复的代码提取到一个函数中，并使你的宏代码更加简洁。温尼伯的可爱豚鼠，这是很好的代码!\n需要注意的事项 宏有一些偷偷摸摸的问题，你应该注意到。在本节中，你将了解到一些宏的陷阱以及如何避免它们。我希望你还没有把自己从你的思想桅杆上解下来。\n变量捕获 变量捕获发生在一个宏引入了一个绑定，而这个绑定对宏的用户来说是未知的，它使一个现有的绑定黯然失色。例如，在下面的代码中，一个宏顽皮地引入了它自己的let绑定，这就把代码搞乱了。\n(def message \u0026quot;Good job!\u0026quot;) (defmacro with-mischief [\u0026amp; stuff-to-do] (concat (list 'let ['message \u0026quot;Oh, big deal!\u0026quot;]) stuff-to-do)) (with-mischief (println \u0026quot;Here's how I feel about that thing you did: \u0026quot; message)) ; =\u0026gt; Here's how I feel about that thing you did: Oh, big deal! println调用引用了符号message，我们认为它与字符串\u0026quot;好样的！\u0026quot;绑定。然而，with-mischief宏为message创建了一个新的绑定。\n注意，这个宏没有使用语法引号。这样做会导致一个异常。\n(def message \u0026quot;Good job!\u0026quot;) (defmacro with-mischief [\u0026amp; stuff-to-do] `(let [message \u0026quot;Oh, big deal!\u0026quot;] ~@stuff-to-do)) (with-mischief (println \u0026quot;Here's how I feel about that thing you did: \u0026quot; message)) ; Exception: Can't let qualified name: user/message 这个异常是为了你自己好：语法引号的设计是为了防止你在宏中意外地捕捉到变量。如果你想在你的宏中引入let绑定，你可以使用一个gensym。gensym函数在每次连续调用时产生唯一的符号。\n(gensym) ; =\u0026gt; G__655 (gensym) ; =\u0026gt; G__658 你也可以传递一个符号前缀。\n(gensym 'message) ; =\u0026gt; message4760 (gensym 'message) ; =\u0026gt; message4763 下面是你如何改写with-mischief，使之不那么调皮。\n(defmacro without-mischief [\u0026amp; stuff-to-do] (let [macro-message (gensym 'message)] `(let [~macro-message \u0026quot;Oh, big deal!\u0026quot;] ~@stuff-to-do (println \u0026quot;I still need to say: \u0026quot; ~macro-message)))) (without-mischief (println \u0026quot;Here's how I feel about that thing you did: \u0026quot; message)) ; =\u0026gt; Here's how I feel about that thing you did: Good job! ; =\u0026gt; I still need to say: Oh, big deal! 这个例子通过使用gensym来创建一个新的、唯一的符号，然后与macro-message绑定，避免了变量捕获。在语法引用的let表达式中，macro-message没有被引用，被解析为 gensym 的符号。这个源码符号与stuff-to-do中的任何符号都不同，所以你可以避免变量捕获。因为这是一个常见的模式，你可以使用自动源码。自动源码是使用源码的更简洁和方便的方法。\n`(blarg# blarg#) (blarg__2869__auto__ blarg__2869__auto__) `(let [name# \u0026quot;Larry Potter\u0026quot;] name#) ; =\u0026gt; (clojure.core/let [name__2872__auto__ \u0026quot;Larry Potter\u0026quot;] name__2872__auto__) 在这个例子中，你通过在语法引号列表中的一个符号上附加一个哈希标记（或者哈希标记，如果你一定要坚持的话）来创建一个自动源码。Clojure 会自动确保 x#的每个实例在同一个语法引号列表中解析为相同的符号，y#的每个实例也是如此，以此类推。\ngensym和 auto-gensym 在编写宏时经常使用，它们允许你避免变量捕获。\n双重评估 编写宏时要注意的另一个问题是双重评估，当一个作为参数传递给宏的表格被评估了不止一次时，就会出现这种情况。请看下面的例子。\n(defmacro report [to-try] `(if ~to-try (println (quote ~to-try) \u0026quot;was successful:\u0026quot; ~to-try) (println (quote ~to-try) \u0026quot;was not successful:\u0026quot; ~to-try))) ;; Thread/sleep takes a number of milliseconds to sleep for (report (do (Thread/sleep 1000) (+ 1 1))) 这段代码是为了测试其参数的真实性。如果参数是真实的，它被认为是成功的；如果是虚假的，它是不成功的。该宏打印出其参数是否成功。在这种情况下，你实际上会睡两秒钟，因为(Thread/sleep 1000)被评估了两次：一次在if之后，另一次在println被调用时。这是因为(do (Thread/sleep 1000) (+ 1 1))的代码在整个宏扩展中被重复。这就像你写的一样。\n(if (do (Thread/sleep 1000) (+ 1 1)) (println '(do (Thread/sleep 1000) (+ 1 1)) \u0026quot;was successful:\u0026quot; (do (Thread/sleep 1000) (+ 1 1))) (println '(do (Thread/sleep 1000) (+ 1 1)) \u0026quot;was not successful:\u0026quot; (do (Thread/sleep 1000) (+ 1 1)))) \u0026ldquo;大问题！\u0026ldquo;你内心的例子评论家说。好吧，如果你的代码是在银行账户之间转账，这将是一个非常大的问题。以下是你如何避免这个问题的方法。\n(defmacro report [to-try] `(let [result# ~to-try] (if result# (println (quote ~to-try) \u0026quot;was successful:\u0026quot; result#) (println (quote ~to-try) \u0026quot;was not successful:\u0026quot; result#)))) 将 \u0026ldquo;to-try \u0026ldquo;放在一个 \u0026ldquo;let \u0026ldquo;表达式中，你只需评估一次该代码，并将结果绑定到一个自动标示的符号 \u0026ldquo;result#\u0026ldquo;上，现在你可以引用该符号而无需重新评估 \u0026ldquo;to-try \u0026ldquo;代码。\n宏的所有方式 使用宏的一个微妙的缺陷是，你可能最终不得不写越来越多的宏来完成任何事情。这是由于宏的扩展发生在评估之前。\n例如，假设你想用report宏来doseq。而不是多次调用报告。\n(report (= 1 1)) ; =\u0026gt; (= 1 1) was successful: true (report (= 1 2)) ; =\u0026gt; (= 1 2) was not successful: false 让我们进行迭代。\n(doseq [code ['(= 1 1) '(= 1 2)]] (report code)) ; =\u0026gt; code was successful: (= 1 1) ; =\u0026gt; code was successful: (= 1 2) 当我们单独传递函数时，报告宏工作正常，但当我们使用doseq对多个函数进行report迭代时，它是一个毫无价值的失败。下面是其中一个doseq迭代的宏扩展的样子。\n(if code (clojure.core/println 'code \u0026quot;was successful:\u0026quot; code) (clojure.core/println 'code \u0026quot;was not successful:\u0026quot; code)) 正如你所看到的，report在每个迭代中接收未评估的符号code；然而，我们希望它在评估时接收任何code被绑定的内容。但是report在宏扩展时操作，就是不能访问这些值。这就像它有 T.Rex 的手臂，运行时的值永远不在它的掌握之中。\n为了解决这种情况，我们可以再写一个宏，像这样。\n(defmacro doseq-macro [macroname \u0026amp; args] `(do ~@(map (fn [arg] (list macroname arg)) args))) (doseq-macro report (= 1 1) (= 1 2)) ; =\u0026gt; (= 1 1) was successful: true ; =\u0026gt; (= 1 2) was not successful: false 如果你遇到这种情况，请花些时间重新思考你的方法。这很容易使你自己陷入困境，使你无法通过普通的函数调用来完成任何事情。你会被卡住，不得不写更多的宏。宏是非常强大和令人敬畏的，你不应该害怕使用它们。它们把 Clojure 处理数据的设施变成了创造新语言的设施，而这些新语言是根据你的编程问题来设计的。对于某些程序来说，你的代码 90%以上都是宏，这是合适的。尽管它们很棒，但它们也增加了新的组合挑战。它们只是真正的相互组合，所以通过使用它们，你可能会错过 Clojure 中其他类型的组合（函数式、面向对象）。\n我们现在已经涵盖了编写宏的所有机制。拍拍你的背吧! 这是一个相当大的交易!\n在本章的最后，终于到了戴上你的伪装帽，在本章最开始谈到的网上药水店工作的时候了。\n为勇敢和真实的人而酿的酒 在这一章的开头，我透露了一个梦想：找到某种可饮用的东西，一旦摄入，就能暂时让我拥有 80 年代健身大师的力量和气质，把我从抑制和自我意识的牢笼中解放出来。我相信有一天某个地方会有人发明这样的灵丹妙药，所以我们不妨着手建立一个系统来销售这种神话般的药水。让我们把这种假想的混合物称为勇敢和真实的啤酒。这个名字是我无缘无故想到的。\n在订单纷至沓来之前（双关语！击掌！），我们需要有一些验证的地方。本节向你展示了一种在功能上进行验证的方法，以及如何使用你将编写的名为 \u0026ldquo;if-valid \u0026ldquo;的宏更简洁地编写执行验证的代码。这将帮助你了解编写自己的宏的典型情况。如果你只想知道宏的定义，可以跳到\u0026quot;if-valid\u0026rdquo; 第 182 页。\n验证函数 为了简单起见，我们只担心验证每个订单的姓名和电子邮件。对于我们的商店，我想我们希望这些订单的细节能像这样表示。\n(def order-details {:name \u0026quot;Mitchard Blimmons\u0026quot; :email \u0026quot;mitchard.blimmonsgmail.com\u0026quot;}) 这个特殊的 Map 有一个无效的电子邮件地址（缺少@符号），所以这正是我们的验证代码应该捕捉的订单类型 理想情况下，我们希望编写的代码能产生这样的结果。\n(validate order-details order-details-validations) ; =\u0026gt; {:email [\u0026quot;Your email address doesn't look like an email address.\u0026quot;]} 也就是说，我们希望能够调用一个函数，`validate\u0026rsquo;，其中包含需要验证的数据和如何验证的定义。结果应该是一个 Map，其中每个键对应一个无效的字段，每个值是该字段的一个或多个验证信息的 Vector。下面的两个函数完成了这项工作。\n让我们先看看order-details-validations。以下是你如何表示验证信息。\n(def order-details-validations {:name [\u0026quot;Please enter a name\u0026quot; not-empty] :email [\u0026quot;Please enter an email address\u0026quot; not-empty \u0026quot;Your email address doesn't look like an email address\u0026quot; #(or (empty? %) (re-seq #\u0026quot;@\u0026quot; %))]}) 这是一个 Map，每个键都与错误信息和验证函数对的 Vector 相关。例如，:name有一个验证函数，not-empty；如果验证失败，你应该得到\u0026quot;请输入一个名字\u0026quot;的错误信息。\n接下来，我们需要写出validate'函数。validate函数可以分解成两个函数：一个是对单个字段进行验证，另一个是将这些错误信息累积成一个最终的错误信息Map，如{:email [\u0026ldquo;你的邮箱地址看起来不像邮箱地址。\u0026quot;]}。这里有一个叫做error-messages-for`的函数，对一个单一的值进行验证。\n(defn error-messages-for \u0026quot;Return a seq of error messages\u0026quot; [to-validate message-validator-pairs] (map first (filter #(not ((second %) to-validate)) (partition 2 message-validator-pairs)))) 第一个参数，to-validate，是你要验证的字段。第二个参数，message-validator-pairs，应该是一个有偶数元素的序列。这个序列被分组为(partition 2 message-validator-pairs)'的对。对中的第一个元素应该是一个错误信息，对中的第二个元素应该是一个函数（就像在order-details-validations中安排的对）。error-messages-for函数的工作原理是过滤出所有错误信息和验证对，其中验证函数在应用于to-validate时返回true。然后，它使用map first`来获取每对元素的第一个元素，即错误信息。下面是它的操作。\n(error-messages-for \u0026quot;\u0026quot; [\u0026quot;Please enter a name\u0026quot; not-empty]) ; =\u0026gt; (\u0026quot;Please enter a name\u0026quot;) 现在我们需要将这些错误信息积累到一个 Map 中。\n下面是完整的validate函数，以及我们将其应用于order-details和order-details-validations时的输出。\n(defn validate \u0026quot;Returns a map with a vector of errors for each key\u0026quot; [to-validate validations] (reduce (fn [errors validation] (let [[fieldname validation-check-groups] validation value (get to-validate fieldname) error-messages (error-messages-for value validation-check-groups)] (if (empty? error-messages) errors (assoc errors fieldname error-messages)))) {} validations)) (validate order-details order-details-validations) ; =\u0026gt; {:email (\u0026quot;Your email address doesn't look like an email address\u0026quot;)} 成功了! 这个函数是通过减少order-details-validations'并将order-details\u0026rsquo;的每个键的错误信息（如果有的话）关联到一个最终的错误信息 Map。\nif-valid 有了我们的验证代码，我们现在可以随心所欲地验证记录了。大多数情况下，验证会像这样。\n(let [errors (validate order-details order-details-validations)] (if (empty? errors) (println :success) (println :failure errors))) 该模式是做以下工作。\n 验证一条记录并将结果绑定到errors。 检查是否有任何错误 3.如果有，做成功的事情，这里(println :success)。 否则，做失败的事情，这里(println :failure errors)。  我已经在实际生产的网站中使用了这个验证代码。起初，我发现自己不断重复代码的微小变化，这无疑表明我需要引入一个抽象，以隐藏重复的部分：应用validate函数，将结果绑定到一些符号，并检查结果是否为空。为了创建这种抽象，你可能会想写一个这样的函数。\n(defn if-valid [record validations success-code failure-code] (let [errors (validate record validations)] (if (empty? errors) success-code failure-code))) 然而，这不会起作用，因为success-code和failure-code每次都会被评估。宏会起作用，因为宏允许你控制评估。下面是你如何使用宏的方法。\n(if-valid order-details order-details-validations errors (render :success) (render :failure errors)) 这个宏隐藏了重复的细节，帮助你更简洁地表达你的意图。这就像要求别人给你开瓶器，而不是说：\u0026ldquo;请给我手动装置，用于去除玻璃容器中液体的临时密封剂。\u0026rdquo; 下面是实施方法。\n(defmacro if-valid \u0026quot;Handle validation more concisely\u0026quot; [to-validate validations errors-name \u0026amp; then-else] `(let [~errors-name (validate ~to-validate ~validations)] (if (empty? ~errors-name) ~@then-else))) 这个宏需要四个参数。 to-validate, validations, errors-name, 和其余参数then-else. 像这样使用errors-name是一个新的策略。我们想在then-else语句中访问validate函数返回的错误。要做到这一点，我们要告诉宏它应该把结果绑定到什么符号上。下面的宏扩展显示了它是如何工作的。\n (macroexpand '(if-valid order-details order-details-validations my-error-name (println :success) (println :failure my-error-name))) (let* [my-error-name (user/validate order-details order-details-validations)] (if (clojure.core/empty? my-error-name) (println :success) (println :failure my-error-name))) 语法引号抽象了你之前看到的let/validate/if模式的一般形式。然后我们使用 unquote 拼接来解压if分支，这些分支被打包到then-else其余参数中。\n这真是太简单了! 说了这么多关于宏的内容，并详细介绍了它们的机制，我打赌你一定以为会有更复杂的东西。对不起，朋友。如果你对你的失望感到难以接受，我知道有一种饮料可以帮助你。\n总结 在本章中，你学会了如何编写自己的宏。宏的定义与函数非常相似：它们有参数、文件串和主体。它们可以使用参数重构和休息参数，而且可以是递归的。你的宏几乎都会返回列表。你有时会使用list和seq函数来编写简单的宏，但大多数时候你会使用语法引号，，它让你使用安全模板来编写宏。\n当你编写宏时，重要的是要记住符号和值之间的区别：宏在代码被评估之前被展开，因此不能访问评估的结果。双重求值和变量捕获是另外两个微妙的陷阱，但你可以通过明智地使用 \u0026ldquo;let \u0026ldquo;表达式和代词来避免它们。\n宏是一种有趣的工具，可以让你在编码时少一些拘束。通过让你控制评估，宏给你一定程度的自由和表达，这是其他语言所不允许的。在你的 Clojure 旅程中，你可能会听到有人告诫你不要使用宏，说什么 \u0026ldquo;宏是邪恶的 \u0026ldquo;和 \u0026ldquo;你不应该使用宏\u0026rdquo;。不要听这些假正经的人的话\u0026ndash;至少在开始的时候不要听他们的。走出去，享受美好的时光。这是你学习在哪些情况下适合使用宏的唯一途径。你会从另一个角度知道如何有技巧地、潇洒地使用宏。\n练习   编写宏when-valid，使它的行为与when相似。下面是一个调用它的例子。\n(when-valid order-details order-details-validations (println \u0026quot;It's a success!\u0026quot;) (render :success)) 当数据有效时，应该评估println和render形式，如果数据无效，when-valid应该返回nil。\n  你看到and是作为一个宏实现的。把`or\u0026rsquo;作为一个宏来实现。\n  在第 5 章中，你创建了一系列函数（c-int, c-str, c-dex）来读取一个 RPG 字符的属性。写一个宏，用一个宏调用来定义任意数量的属性检索函数。以下是你如何调用它。\n   (defattrs c-int :intelligence c-str :strength c-dex :dexterity)\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter8/","summary":"编写宏程序 当我 18 岁时，我在新墨西哥州圣菲的一家酒店找到了一份夜班审计师的工作，每周工作四个晚上，从晚上 11 点到早上 7 点。经过几个月的这种不眠不休的工作，我的情绪有了自己的变化。一天晚上，大约在\n凌晨 3 点，我正在看一个信息广告，该产品声称可以恢复男人的头发。当我看到一个曾经秃头的人的故事时，我被真诚的喜悦所淹没。\u0026ldquo;终于来了！\u0026ldquo;我的大脑涌动着。\u0026ldquo;这个人得到了他应得的爱和成功! 多么不可思议的产品，给无望的人以希望！\u0026rdquo;\n从那时起，我发现自己一直在想，我是否能以某种方式重新创造因长期睡眠不足而引起的情感放弃和对生命的欣赏。也许是某种药水\u0026ndash;喝上几口，释放我内心的理查德-西蒙斯，但时间不会太长。\n就像药水可以让我暂时改变我的基本性质一样，宏允许你以其他语言无法实现的方式修改 Clojure。有了宏，你可以扩展 Clojure 以适应你的问题空间，建立起语言。\n在这一章中，你将彻底研究如何编写宏，从基本的例子开始，逐步提高复杂性。最后，你将戴上你的假想帽，用宏来验证你想象中的在线药水店的客户订单。\n在本章结束时，你将了解你用来编写宏的所有工具：引号、语法引号、解引号、解引号拼接（又称皮纳塔工具）和 gensym。你还会了解到对毫无戒心的宏作者来说隐藏着的危险：双重评估、变量捕获和宏感染。\n宏是必不可少的 在你开始编写宏之前，我想帮助你把它们放在适当的环境中。是的，宏比北极熊的脚趾甲还要酷，但你不应该把宏看成是一些深奥的工具，当你想对你的代码进行额外的花哨处理时，就把它拿出来。事实上，宏允许 Clojure 从一个很小的函数和特殊形式的核心中获得大量的内置功能。以when为例。 when有这样的一般形式。\n(when boolean-expression expression-1 expression-2 expression-3 ... expression-x) 你可能认为when是一个像if一样的特殊形式。那么你猜怎么着？它不是! 在大多数其他语言中，你只能使用特殊的关键字来创建条件表达式，而没有办法创建你自己的条件运算符。然而，when实际上是一个宏。\n在这个宏扩展中，你可以看到when是用if和do来实现的。\n(macroexpand '(when boolean-expression expression-1 expression-2 expression-3)) ; =\u0026gt; (if boolean-expression (do expression-1 expression-2 expression-3)) 这表明宏是 Clojure 开发中不可或缺的一部分\u0026ndash;它们甚至被用来提供基本操作。宏并不是为奇特的特殊情况而保留的；你应该把写宏看作是你工具包中的另一个工具。当你学会编写自己的宏时，你会发现它们是如何让你进一步扩展语言，使其适合你的特定问题领域的形状。\n解剖巨集 巨集定义看起来很像函数定义。它们有一个名称，一个可选的文档字符串，一个参数列表，以及一个主体。主体几乎总是返回一个列表。这是有道理的，因为宏是将数据结构转化为 Clojure 可以评估的形式的一种方式，而 Clojure 使用列表来表示函数调用、特殊形式调用和宏调用。你可以在宏主体中使用任何函数、宏或特殊形式，你调用宏就像调用函数或特殊形式一样。\n作为一个例子，这里有我们的老朋友infix宏。\n(defmacro infix \u0026quot;Use this macro when you pine for the notation of your childhood\u0026quot; [infixed] (list (second infixed) (first infixed) (last infixed))) 这个宏将一个列表重新排列成正确的 infix 记号顺序。下面是一个例子。","title":"Chapter8 宏"},{"content":"Clojure 炼金术：读取器、评估器和宏 哲学家之石，与生命之药和伟哥一样，是炼金术传说中最著名的标本之一，因其能将铅转化为金而受到追捧。然而，Clojure 提供了一种工具，使哲学家的石头看起来只是一个小饰品：*宏。\n宏允许你将任意的表达式转化为有效的 Clojure，因此你可以扩展语言本身以满足你的需求。而且，你甚至不需要是一个穿长袍的老家伙或老太太来使用它们\n为了获得这种能力，请考虑这个微不足道的宏。\n(defmacro backwards [form] (reverse form)) (backwards (\u0026quot; backwards\u0026quot; \u0026quot; am\u0026quot; \u0026quot;I\u0026quot; str)) ; =\u0026gt; \u0026quot;I am backwards\u0026quot; backwards宏允许 Clojure 成功地 Eval 表达式(\u0026quot; backwards\u0026quot; \u0026quot; am\u0026quot; \u0026quot;I\u0026quot; str)，尽管它没有遵循 Clojure 的内置语法规则，这些规则要求表达式的操作数首先出现（更不用说表达式不能按相反顺序书写的规则）。如果没有 \u0026ldquo;向后\u0026rdquo;，这个表达式会比几千年来的炼金术士用他们的一生来追求不可能实现的长生不老的方法更难失败。有了`向后'，*你就创造了你自己的语法！*你扩展了 Clojure，这样你就可以随心所欲地写代码了 我告诉你，这比把铅变成金子要好得多!\n本章为你提供了编写自己的宏所需的概念基础，使你能够疯狂地编写自己的宏。它解释了 Clojure 评估模型的元素：读取器，评估器，和宏扩展器。这就像 Clojure 元素的周期表。想想周期表是如何揭示原子的特性的：同一列的元素行为相似，因为它们有相同的核电荷。如果没有元素周期表及其基础理论，我们就会像过去的炼金术士一样，随意地把东西混在一起，看看什么东西会爆炸。但是，随着对元素的深入了解，你可以看到为什么东西会爆炸，并学会如何有目的地炸毁东西。\nA Overview of Clojure\u0026rsquo;s Evaluation Model Clojure（像所有的 Lisps）有一个不同于大多数其他语言的评估模型：它有一个两阶段的系统，它读文本源代码，产生 Clojure 数据结构。然后对这些数据结构进行*评估。Clojure 遍历数据结构，并根据数据结构的类型执行函数应用或 var 查找等操作。例如，当 Clojure 读取文本(+ 1 2)时，结果是一个列表数据结构，其第一个元素是一个+符号，后面是数字 1 和 2。这个数据结构被传递给 Clojure 的评估器，评估器查找+对应的函数，并将该函数应用于 1 和 2。\n在源代码、数据和评估之间有这种关系的语言被称为homoiconic（顺便说一句，如果你在浴室的镜子前熄灯说三次homoiconic，约翰-麦卡锡的幽灵就会出现并给你一个小括号）。同源语言使你能够将你的代码作为一组数据结构进行推理，你可以通过程序进行操作。为了说明这一点，让我们在编译的土地上走一圈。\n编程语言需要一个编译器或解释器来将你写的代码（由 Unicode 字符组成）翻译成其他东西：机器指令、其他编程语言的代码，等等。在这个过程中，编译器会构建一个抽象语法树（AST），这是一个代表你的程序的数据结构。你可以把 AST 看作是评价器的输入，你可以把它看作是一个遍历该树的函数，以产生机器代码或其他什么作为其输出。\n到目前为止，这听起来很像我为 Clojure 描述的那样。然而，在大多数语言中，AST 的数据结构在编程语言中是无法访问的；编程语言空间和编译器空间是永远分离的，两者永远不会相遇。图 7-1 显示了在非 Lisp 编程语言中表达式的编译过程的可视化情况。\n图 7-1：非 Lisp 编程语言的评估\n但 Clojure 是不同的，因为 Clojure 是 Lisp，而 Lisps 比偷来的 tamale 更热。Lisps 评估的是本地数据结构，而不是评估表示为某种无法访问的内部数据结构的 AST。Clojure 仍然评估树形结构，但树是用 Clojure 列表结构的，节点是 Clojure 值。\n列表是构建树形结构的理想选择。列表的第一个元素被视为根，每个后续元素被视为一个分支。要创建一个嵌套树，你可以直接使用嵌套列表，如图 7-2 所示。\n图 7-2：列表可以很容易地被当作树来处理。\n首先，Clojure 的读取器将文本(+ 1 (* 6 7))转换为一个嵌套列表。(你将在下一节了解更多关于读取器的信息。)然后，Clojure 的评估器将该数据作为输入并产生一个结果。(它还可以编译 Java 虚拟机（JVM）字节码，你会在第 12 章中了解到。现在，我们只关注概念层面上的评估模型）。\n考虑到这一点，图 7-3 显示了 Clojure 的评估过程是什么样的。\nS-表达式\n在你的 Lisp 冒险中，你会遇到一些资源，它们解释说 Lisp 评估 S-表达式。我在这里避免使用这个术语，因为它有歧义：你会看到它既指被评估的实际数据对象，也指表示该数据的源代码。对 Lisp 评估的两个不同组成部分（代码和数据）使用同一个术语，会掩盖重要的东西：你的文本代表了本地数据结构，而 Lisp 评估本地数据结构，这是独一无二的，令人敬畏的。关于 s-表达式的精彩处理，请查看http://www.gigamonkeys.com/book/syntax-and-semantics.html。\n图 7-3：Clojure 中的评估\n然而，评估器实际上并不关心它的输入来自哪里；它不一定要来自读者。因此，你可以用eval将你的程序的数据结构直接发送给 Clojure 评估器。看哪!\n(def addition-list (list + 1 2)) (eval addition-list) ; =\u0026gt; 3 这就对了，宝贝! 你的程序刚刚评估了一个 Clojure 列表。你很快就会读到关于 Clojure 评估规则的所有内容，但简单地说，这是发生了什么：当 Clojure 评估列表时，它查找了addition-list所指的列表；然后它查找了与+符号对应的函数；然后它用1和2作为参数调用了该函数，返回3。你的运行程序的数据结构和评估器的数据结构生活在同一个空间，结果是你可以使用 Clojure 的全部力量和你写的所有代码来构建数据结构进行评估。\n(eval (concat addition-list [10])) ; =\u0026gt; 13 (eval (list 'def 'lucky-number (concat addition-list [10]))) ; =\u0026gt; #'user/lucky-number lucky-number ; =\u0026gt; 13 图 7-4 显示了你在这两个例子中发送给评估器的列表。\n图 7-4：你评估的列表\n你的程序可以直接与自己的评估器对话，使用自己的函数和数据在运行中修改自己 你是不是已经被权力冲昏了头脑？我希望是这样！我希望你能坚持你的理智。不过，请保持你的理智，因为还有更多的东西要学。\n所以，Clojure 是同源的：它用列表表示抽象的语法树，当你写 Clojure 代码时，你写的是列表的文本表示。因为你写的代码代表了你习惯于操作的数据结构，而评估器则消耗这些数据结构，所以很容易推理出如何以编程方式修改你的程序。\n宏就是让你轻松进行这些操作的东西。本章的其余部分详细介绍了 Clojure 的读取器和评估规则，让你对宏的工作原理有一个准确的理解。\n读取器 读取器将你保存在文件中或在 REPL 中输入的文本源代码转换为 Clojure 数据结构。它就像人类的 Unicode 字符世界和 Clojure 的列表、Vector、Map、符号和其他数据结构世界之间的翻译。在本节中，你将直接与读取器器互动，并学习一个方便的功能，即读取器宏，如何让你更简洁地编写代码。\n读取器 为了理解读取器，让我们首先仔细看看 Clojure 是如何处理你在 REPL 中输入的文本的。首先，REPL 会提示你输入文本。\nuser=\u0026gt; 然后你输入一点文本。也许像这样。\nuser=\u0026gt; (str \u0026quot;To understand what recursion is,\u0026quot; \u0026quot; you must first understand recursion.\u0026quot;) 这段文字实际上只是一串 Unicode 字符，但它是为了表示 Clojure 数据结构的组合。这种数据结构的文本表示法被称为读取器的形式。在这个例子中，该表格代表了一个列表数据结构，其中又包含了三个表格：str符号和两个字符串。\n一旦你在提示符中输入这些字符并按下回车键，这些文本就会进入读取器（记得 REPL 是 read-eval-print-loop 的缩写）。Clojure 读取字符流并在内部产生相应的数据结构。然后它对数据结构进行评估，并打印出结果的文本表示。\n\u0026quot;To understand what recursion is, you must first understand recursion.\u0026quot; 读取和评估是不连续的过程，你可以独立执行。一种直接与读者互动的方法是使用read-string函数。 read-string接收一个字符串作为参数，并使用 Clojure 的读取器进行处理，返回一个数据结构。\n(read-string \u0026quot;(+ 1 2)\u0026quot;) ; =\u0026gt; (+ 1 2) (list? (read-string \u0026quot;(+ 1 2)\u0026quot;)) ; =\u0026gt; true (conj (read-string \u0026quot;(+ 1 2)\u0026quot;) :zagglewag) ; =\u0026gt; (:zagglewag + 1 2) 在第一个例子中，read-string读取了一个包含加号和数字 1 和 2 的列表的字符串表示。返回值是一个实际的列表，正如第二个例子所证明的。最后一个例子使用conj在列表中预置一个关键字。启示是，读取器和评估是相互独立的。你可以读取文本而不对其进行评估，你可以将结果传递给其他函数。如果你愿意，你也可以对结果进行评估。\n(eval (read-string \u0026quot;(+ 1 2)\u0026quot;)) ; =\u0026gt; 3 在到目前为止的所有例子中，读者形式和相应的数据结构之间一直是一对一的关系。下面是更多简单的读取器形式的例子，它们直接 Map 到它们所代表的数据结构。\n () 一个列表的读取形式 *str 一个符号读取器形式 [1 2] 一个 Vector 读取器形式，包含两个数字读取器形式 {:sound \u0026ldquo;hoot\u0026rdquo;} 一个包含关键字读取器形式和字符串读取器形式的 Map 读取器形式  然而，在将文本转换为数据结构时，读取器可以采用更复杂的行为。例如，还记得匿名函数吗？\n(#(+ 1 %) 3) ; =\u0026gt; 4 好吧，试试这个。\n(read-string \u0026quot;#(+ 1 %)\u0026quot;) ; =\u0026gt; (fn* [p1__423#] (+ 1 p1__423#)) 哇! 这不是我们所习惯的一对一的 Map。读取#(+ 1 %)的结果是一个由fn*符号组成的列表，一个包含一个符号的 Vector，和一个包含三个元素的列表。刚刚发生了什么？\n读者宏 我来回答我自己的问题：读者使用了一个读者宏来转换#(+ 1 %)。读者宏是一组将文本转换为数据结构的规则。它们通常允许你以更紧凑的方式表示数据结构，因为它们采用了一个简略的读者形式，并将其扩展为完整的形式。它们由宏字符指定，如'（单引号）、#和@。它们也完全不同于我们后面要讲的宏。为了不把两者混淆，我总是用读者宏这个全称来指代读者宏。\n例如，你可以在这里看到引用读者宏是如何扩展单引号字符的。\n(read-string \u0026quot;'(a b c)\u0026quot;) ; =\u0026gt; (quote (a b c)) 当读取器遇到单引号时，它将其扩展为一个列表，其第一个成员是符号quote，第二个成员是单引号后面的数据结构。读取器的deref宏对@字符的作用与此类似。\n(read-string \u0026quot;@var\u0026quot;) ; =\u0026gt; (clojure.core/deref var) 读取器宏也可以做一些疯狂的事情，比如导致文本被忽略。分号指定了单行注释的读取器宏。\n(read-string \u0026quot;; ignore!\\n(+ 1 2)\u0026quot;) ; =\u0026gt; (+ 1 2) 这就是读取器! 你卑微的伙伴，正在辛苦地将文本转化为数据结构。现在我们来看看 Clojure 是如何评估这些数据结构的。\n评估器 图 7-5：（+ 1 2）的数据结构\n你可以把 Clojure 的求值器看作是一个函数，它接收一个数据结构作为参数，使用与数据结构类型相对应的规则处理该数据结构，并返回一个结果。要评估一个符号，Clojure 会查找该符号所指的内容。要评估一个列表，Clojure 会查看该列表的第一个元素，并调用一个函数、宏或特殊形式。任何其他的值（包括字符串、数字和关键字）只是简单地对其进行评估。\n例如，假设你在 REPL 中输入了(+ 1 2)。图 7-5 显示了一个被发送到评估器的数据结构图。\n因为它是一个列表，评估器从评估列表中的第一个元素开始。第一个元素是加号，评估器通过返回相应的函数来解决这个问题。因为列表中的第一个元素是一个函数，所以评估器对每个操作数进行评估。操作数 1 和 2 评估为自己，因为它们不是列表或符号。然后评估器以 1 和 2 为操作数调用加法函数，并返回结果。\n本节的其余部分将更全面地解释评估器对每种数据结构的规则。为了显示评估器是如何工作的，我们将在 REPL 中运行每个例子。请记住，REPL 首先读取你的文本以获得一个数据结构，然后将该数据结构发送到评估器，然后将结果打印为文本。\n数据\n我在本章中写到 Clojure 如何评估数据结构，但这是不精确的。从技术上讲，数据结构指的是某种集合，如链接列表或 B-树，或其他什么，但我也用这个术语来指标量（单数，非集合）值，如符号和数字。我考虑过使用数据对象这个术语，但不想暗示面向对象的编程，或者只使用数据，但不想将其与数据这个概念混淆。所以，数据结构就是这样，如果你觉得这很冒犯，我会给你一千次的道歉，深思熟虑地组织成一棵 Van Emde Boas 树。\n这些东西都是自己评估的 每当 Clojure 对不是列表或符号的数据结构进行评估时，其结果就是数据结构本身。\ntrue ; =\u0026gt; true false ; =\u0026gt; false {} ; =\u0026gt; {} :huzzah ; =\u0026gt; :huzzah 空的列表也会对自己进行评估。\n() ; =\u0026gt; () 符号 作为一个程序员，你的基本任务之一是通过将名字和值联系起来来创建抽象。你在第 3 章中通过使用def、let和函数定义学会了如何做到这一点。Clojure 使用符号来命名函数、宏、数据和其他任何你可以使用的东西，并通过解析来评估它们。为了解析一个符号，Clojure 会遍历你所创建的任何绑定，然后在命名空间 Map 中查找该符号的条目，这一点你在第 6 章中了解过。最终，一个符号被解析为一个值或一个特殊形式\u0026ndash;一个内置的 Clojure 操作符，提供基本的行为。\n一般来说，Clojure 通过以下方式解析一个符号。\n 查询该符号是否命名了一个特殊形式。如果它没有……。 查询该符号是否对应于一个本地绑定。如果不是的话 . 试图找到由def引入的命名空间 Map。如果没有的话 . . 抛出一个异常  让我们先看看一个符号解析到一个特殊形式。特殊形式，如if，总是在一个操作的上下文中使用；它们总是一个列表中的第一个元素。\n(if true :a :b) ; =\u0026gt; :a 在这种情况下，if是一个特殊的形式，它被作为一个操作符使用。如果你试图引用这个上下文之外的特殊形式，你会得到一个异常。\nif ; =\u0026gt; CompilerException java.lang.RuntimeException: Unable to resolve symbol: if in this context, compiling:(NO_SOURCE_PATH:0:0) 接下来，让我们评估一些本地绑定。本地绑定是指一个符号和一个不是由def创建的值之间的任何关联。在下一个例子中，符号x用let与 5 绑定。当评估器解析x时，它将符号*x解析为值 5。\n(let [x 5] (+ x 3)) ; =\u0026gt; 8 现在，如果我们创建一个x到 15 的命名空间 Map，Clojure 会相应地解决它。\n(def x 15) (+ x 3) ; =\u0026gt; 18 在下一个例子中，x被 Map 到 15，但是我们用let引入了x与 5 的局部绑定。所以x被解析为 5。\n(def x 15) (让 [x 5] (+ x 3)) ; =\u0026gt; 8 你可以对绑定进行嵌套，在这种情况下，最近定义的绑定具有优先权。\n(让 [x 5] (让 [x 6] (+ x 3))) ; =\u0026gt; 9 函数还创建了局部绑定，将参数与函数体中的参数绑定。在下一个例子中，exclaim被 Map 到一个函数。在函数主体中，参数名exclamation被绑定到传递给函数的参数上。\n(defn exclaim [exclamation] (str exclamation \u0026quot;!\u0026quot;)) (exclaim \u0026quot;Hadoken\u0026quot;) ; =\u0026gt; \u0026quot;Hadoken!\u0026quot; 最后，在这最后一个例子中，map和inc都指的是函数。\n(map inc [1 2 3]) ; =\u0026gt; (2 3 4) 当 Clojure 评估这段代码时，它首先评估map符号，查找相应的函数并将其应用于参数。符号map指的是 map 函数，但它不应该与函数本身相混淆。map符号仍然是一个数据结构，就像字符串\u0026quot;fried salad\u0026quot;是一个数据结构一样，但它与函数本身不同。\n(read-string (\u0026quot;+\u0026quot;)) ; =\u0026gt; + (type (read-string \u0026quot;+\u0026quot;)) ; =\u0026gt; clojure.lang.Symbol (list (read-string \u0026quot;+\u0026quot;) 1 2) ; =\u0026gt; (+ 1 2) 在这些例子中，你正在与加号，+，作为一个数据结构进行交互。你并没有与它所指的加法函数进行交互。如果你评估它，Clojure 会查找该函数并应用它。\n(eval (list (read-string \u0026quot;+\u0026quot;) 1 2)) ; =\u0026gt; 3 就其本身而言，符号和它们的参照物实际上不做任何事情；Clojure 通过评估列表执行工作。\n列表 如果数据结构是一个空列表，它就会被评估为一个空列表。\n(eval (read-string \u0026quot;()\u0026quot;)) ; =\u0026gt; () 否则，它被评估为对列表中第一个元素的*调用。执行调用的方式取决于第一个元素的性质。\n函数调用 当执行一个函数调用时，每个操作数都被完全评估，然后作为参数传递给函数。在这个例子中，+符号解析为一个函数。\n(+ 1 2) ; =\u0026gt; 3 Clojure 看到列表的头部是一个函数，所以它继续评估列表中的其他元素。操作数 1 和 2 都对自己进行评估，在评估之后，Clojure 对它们应用加法函数。\n你也可以嵌套函数调用。\n(+ 1 (+ 2 3)) ; =\u0026gt; 6 即使第二个参数是一个列表，Clojure 在这里也遵循同样的过程：查找+符号并评估每个参数。为了评估列表(+ 2 3)，Clojure 将第一个成员解析为加法函数并继续评估每个参数。通过这种方式，评估是递归的。\n特殊形式 你也可以调用*特殊形式。*一般来说，特殊形式是特殊的，因为它们实现了不能用函数实现的核心行为。比如说\n(if true 1 2) ; =\u0026gt; 1 这里，我们要求 Clojure 评估一个以符号if开始的列表。这个if符号被解析为if特殊形式，Clojure 用操作数true、1和2调用这个特殊形式。\n特殊形式不遵循与普通函数相同的评估规则。例如，当你调用一个函数时，每个操作数都被评估。然而，对于if，你不希望每个操作数都被评估。你只希望某些操作数被评估，这取决于条件是真还是假。\n另一个重要的特殊形式是quote。你已经见过这样的列表。\n'(a b c) 正如你在\u0026ldquo;读取器 \u0026ldquo;第 153 页中所看到的，这将调用一个读取器宏，所以我们最终得到这样的结果。\n(quote (a b c)) 通常，Clojure 会尝试解析a符号，然后调用它，因为它是一个列表中的第一个元素。quote的特殊形式告诉评估器，\u0026ldquo;与其像正常一样评估我的下一个数据结构，不如直接返回数据结构本身。\u0026rdquo; 在这种情况下，你最终得到一个由符号a, b, 和c组成的列表。\ndef、let、loop、fn、do和recur也都是特殊形式。你可以看到为什么：它们的评估方式与函数不一样。例如，通常当评估器评估一个符号时，它会解析该符号，但是def和let显然不是这样的行为。它们不是解析符号，而是在符号和值之间建立关联。因此，评估器从读者那里接收到一个数据结构的组合，然后它去解析符号并调用每个列表开头的函数或特殊形式。但还有更多的东西! 你也可以在列表的开头放置一个宏，而不是一个函数或特殊形式，这可以为你提供巨大的权力，让你知道其余的数据结构如何被评估。\n巨集 嗯 . . Clojure 评估数据结构\u0026ndash;与我们在 Clojure 程序中编写和操作的数据结构相同。如果我们能用 Clojure 来操作 Clojure 评估的数据结构，那不是很好吗？是的，是的，会的。你猜怎么着？你可以用宏来做这件事。你的脑袋是不是爆炸了？我的就是这样。\n为了了解宏的作用，让我们看看一些代码。假设我们想写一个函数，让 Clojure 读出 infix 符号（如1 + 1），而不是其正常符号中的运算符优先（+ 1 1）。这个例子不是**一个宏。相反，它只是表明你可以用 infix 符号写代码，然后用 Clojure 来转换它，使其实际执行。首先，创建一个代表 infix 加法的列表。\n(read-string \u0026quot;(1 + 1)\u0026quot; ) ; =\u0026gt; (1 + 1) 如果你试图让它评估这个列表，Clojure 将抛出一个异常。\n(eval (read-string \u0026quot;(1 + 1)\u0026quot;)) ; =\u0026gt; ClassCastException java.lang.Long cannot be cast to clojure.lang.IFn 然而，read-string返回一个列表，你可以用 Clojure 把这个列表重新组织成它可以成功评估的东西。\n(let [infix (read-string \u0026quot;(1 + 1)\u0026quot;)] (list (second infix) (first infix) (last infix))) ; =\u0026gt; (+ 1 1) 如果你评估这个，它返回2，就像你所期望的那样。\n(eval (let [infix (read-string \u0026quot;(1 + 1)\u0026quot;)] (list (second infix) (first infix) (last infix)))) ; =\u0026gt; 2 这很酷，但它也很笨重。这就是宏的作用。宏给了你一个方便的方法，在 Clojure 评估列表之前对其进行操作。宏很像函数：它们接受参数并返回一个值，就像一个函数那样。它们在 Clojure 数据结构上工作，就像函数那样。它们的独特和强大之处在于它们与评估过程的配合。它们在读取器和评估器之间执行\u0026ndash;所以它们可以操作读取器吐出的数据结构，并在将其传递给评估器之前与这些数据结构进行转换。\n让我们看一个例子。\n(defmacro ignore-last-operand [function-call] (butlast function-call)) ➊ (ignore-last-operand (+ 1 2 10)) ; =\u0026gt; 3 ;; This will not print anything (ignore-last-operand (+ 1 2 (println \u0026quot;look at me!!!\u0026quot;))) ; =\u0026gt; 3 在➊，宏 \u0026ldquo;ignore-last-operand \u0026ldquo;接收列表\u0026rdquo;(+ 1 2 10) \u0026ldquo;作为其参数，不是值 \u0026ldquo;13\u0026rdquo;。这与函数调用有很大的不同，因为函数调用总是评估所有传入的参数，所以函数不可能接触到它的一个操作数并改变或忽略它。相比之下，当你调用一个宏时，操作数是不被评估的。特别是，符号不被解析；它们被当作符号传递。列表也不被评估；也就是说，列表中的第一个元素不作为一个函数、特殊形式或宏被调用。相反，未评估的列表数据结构被传入。\n图 7-6: (infix (1 + 2)) 的完整评估过程\n另一个区别是，函数返回的数据结构是不评估的，但是宏返回的数据结构是评估的。确定宏的返回值的过程被称为宏扩展*，你可以使用函数macroexpand来查看宏在评估数据结构之前返回什么数据结构。注意，你必须引用你传递给macroexpand的形式。\n(macroexpand '(ignore-last-operand (+ 1 2 10))) ; =\u0026gt; (+ 1 2) (macroexpand '(ignore-last-operand (+ 1 2 (println \u0026quot;look at me!!!\u0026quot;)))) ; =\u0026gt; (+ 1 2) 正如你所看到的，这两种扩展的结果都是列表(+ 1 2)。当这个列表被评估时，就像前面的例子一样，结果是3。\n为了好玩，这里有一个做简单 infix 符号的宏。\n(defmacro infix [infixed] (list (second infixed) (first infixed) (last infixed))) (infix (1 + 2)) ; =\u0026gt; 3 思考这整个过程的最好方法是想象在读取和评估之间的一个阶段：宏扩展阶段。图 7-6 显示了如何将(infix (1 + 2))的整个评估过程可视化。\n而这就是宏是如何融入评价过程的。但你为什么要这样做呢？原因是宏允许你将任意的数据结构，如(1 + 2)转化为 Clojure 可以评估的结构，即(+ 1 2)。这意味着你可以使用 Clojure 来扩展自己，所以你可以随心所欲地编写程序。换句话说，宏能够实现句法抽象。句法抽象可能听起来有点抽象（哈哈！），所以我们来探讨一下。\n语法抽象和 -\u0026gt; 宏程序 通常，Clojure 代码由一堆嵌套的函数调用组成。例如，我在我的一个项目中使用了下面这个函数。\n(defn read-resource \u0026quot;Read a resource into a string\u0026quot; [path] (read-string (slurp (clojure.java.io/resource path)))) 为了理解函数体，你必须找到最内部的形式，在本例中是(clojure.java.io/resource path)，然后从右到左向外走，看每个函数的结果如何传递给另一个函数。这种从右到左的流程与非 Lisp 程序员所习惯的相反。当你习惯于用 Clojure 写作时，这种代码会越来越容易理解。但如果你想翻译 Clojure 代码，以便你能以更熟悉的、从左到右、从上到下的方式来阅读它，你可以使用内置的-\u0026gt;宏，它也被称为threading或stabby宏。它可以让你像这样重写前面的函数。\n(defn read-resource [path] (-\u0026gt; path clojure.java.io/resource slurp read-string)) 你可以把这理解为一个从上到下的流水线，而不是从内括号到外括号。首先，path被传递给io/resource，然后结果被传递给slurp，最后结果被传递给read-string`。\n这两种定义 \u0026ldquo;read-resource \u0026ldquo;的方式是完全等价的。然而，第二种方式可能更容易理解，因为我们可以从上到下接近它，一个我们习惯的方向。-\u0026gt;也让我们省略了括号，这意味着有更少的视觉噪音需要处理。这是一个句法抽象，因为它可以让你用一种不同于 Clojure 内置语法的语法来写代码，但对于人类的消费来说是比较好的。胜过点石成金!!!\n总结 在本章中，你了解了 Clojure 的评估过程。首先，读取器将文本转换为 Clojure 数据结构。接下来，宏扩展器用宏来转换这些数据结构，将你的自定义语法转换为语法上有效的数据结构。最后，这些数据结构被发送到评估器。评估器根据数据结构的类型对其进行处理：符号被解析为它们的参照物；列表导致函数、宏或特殊形式的调用；其他一切都被评估为自身。\n这个过程最酷的地方是，它允许你使用 Clojure 来扩展它自己的语法。这个过程变得更加容易，因为 Clojure 是同源的：它的文本代表数据结构，而这些数据结构代表抽象的语法树，让你更容易推理出如何构建扩展语法的宏。\n有了所有这些新的概念，你现在就可以像我承诺的那样，故意炸毁东西了。下一章将教你关于编写宏的一切知识。请抓紧你的袜子，否则它们很可能会被打掉!\n练习 这些练习的重点是读取器和评估。第 8 章有关于编写宏的练习。\n 使用list函数, 引用, 和read-string来创建一个列表, 当评估时, 打印出你的名字和你最喜欢的科幻电影. 创建一个 infix 函数，该函数接收一个类似(1 + 3 * 4 - 5)的列表，并将其转换为 Clojure 需要的列表，以便使用运算符优先规则正确评估该表达式。  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter7/","summary":"Clojure 炼金术：读取器、评估器和宏 哲学家之石，与生命之药和伟哥一样，是炼金术传说中最著名的标本之一，因其能将铅转化为金而受到追捧。然而，Clojure 提供了一种工具，使哲学家的石头看起来只是一个小饰品：*宏。\n宏允许你将任意的表达式转化为有效的 Clojure，因此你可以扩展语言本身以满足你的需求。而且，你甚至不需要是一个穿长袍的老家伙或老太太来使用它们\n为了获得这种能力，请考虑这个微不足道的宏。\n(defmacro backwards [form] (reverse form)) (backwards (\u0026quot; backwards\u0026quot; \u0026quot; am\u0026quot; \u0026quot;I\u0026quot; str)) ; =\u0026gt; \u0026quot;I am backwards\u0026quot; backwards宏允许 Clojure 成功地 Eval 表达式(\u0026quot; backwards\u0026quot; \u0026quot; am\u0026quot; \u0026quot;I\u0026quot; str)，尽管它没有遵循 Clojure 的内置语法规则，这些规则要求表达式的操作数首先出现（更不用说表达式不能按相反顺序书写的规则）。如果没有 \u0026ldquo;向后\u0026rdquo;，这个表达式会比几千年来的炼金术士用他们的一生来追求不可能实现的长生不老的方法更难失败。有了`向后'，*你就创造了你自己的语法！*你扩展了 Clojure，这样你就可以随心所欲地写代码了 我告诉你，这比把铅变成金子要好得多!\n本章为你提供了编写自己的宏所需的概念基础，使你能够疯狂地编写自己的宏。它解释了 Clojure 评估模型的元素：读取器，评估器，和宏扩展器。这就像 Clojure 元素的周期表。想想周期表是如何揭示原子的特性的：同一列的元素行为相似，因为它们有相同的核电荷。如果没有元素周期表及其基础理论，我们就会像过去的炼金术士一样，随意地把东西混在一起，看看什么东西会爆炸。但是，随着对元素的深入了解，你可以看到为什么东西会爆炸，并学会如何有目的地炸毁东西。\nA Overview of Clojure\u0026rsquo;s Evaluation Model Clojure（像所有的 Lisps）有一个不同于大多数其他语言的评估模型：它有一个两阶段的系统，它读文本源代码，产生 Clojure 数据结构。然后对这些数据结构进行*评估。Clojure 遍历数据结构，并根据数据结构的类型执行函数应用或 var 查找等操作。例如，当 Clojure 读取文本(+ 1 2)时，结果是一个列表数据结构，其第一个元素是一个+符号，后面是数字 1 和 2。这个数据结构被传递给 Clojure 的评估器，评估器查找+对应的函数，并将该函数应用于 1 和 2。\n在源代码、数据和评估之间有这种关系的语言被称为homoiconic（顺便说一句，如果你在浴室的镜子前熄灯说三次homoiconic，约翰-麦卡锡的幽灵就会出现并给你一个小括号）。同源语言使你能够将你的代码作为一组数据结构进行推理，你可以通过程序进行操作。为了说明这一点，让我们在编译的土地上走一圈。","title":"Chapter7 炼金术"},{"content":"组织你的项目：一个图书管理员的故事 在我们每个人心中都住着一个叫 Melvil 的图书管理员，一个以组织艺术为乐的奇异生物。日日夜夜，Melvil 都渴望为你的代码库带来秩序。幸运的是，Clojure 提供了一套工具，专门用来帮助这个侏儒与混乱的力量不断斗争。\n这些工具通过将相关的函数和数据分组来帮助你组织你的代码。它们还可以防止名称冲突，这样你就不会意外地覆盖别人的代码，反之亦然。在这个充满悬念和神秘的故事中，请和我一起学习如何使用这些工具，并解决一生中的抢劫案吧 在这个传奇故事的最后，你将了解以下内容。\n  `def\u0026rsquo;是做什么的\n  什么是命名空间以及如何使用它们\n  命名空间和文件系统之间的关系\n  如何使用refer、alias、require、use和ns。\n  如何使用文件系统来组织 Clojure 项目\n  我先来介绍一下 Clojure 的组织系统，它的工作原理很像一个库。Melvil 兴奋地颤抖着!\n你的项目是一个库 现实世界中的图书馆存储对象的集合，如书籍、杂志和 DVD。他们使用寻址系统，所以当你得到一个物体的地址时，你可以导航到物理空间并检索到该物体。\n当然，没有人能够直接知道一本书或 DVD 的地址是什么。这就是为什么图书馆要记录一个物体的标题和它的地址之间的联系，并提供工具来搜索这些记录。在计算机之前的旧时代，图书馆提供卡片目录，即装满纸质卡片的柜子，其中包含每本书的标题、作者、\u0026ldquo;地址\u0026rdquo;（杜威十进制或国会图书馆编号）和其他信息。\n例如，要找到《达芬奇密码》，你可以翻阅书名目录（按书名排序的卡片），直到你找到正确的卡片。在那张卡片上，你会看到地址813.54（如果它使用杜威十进制系统），浏览图书馆，找到达芬奇密码所在的书架，并参与你一生中的文学和/或仇恨阅读冒险。\n在 Clojure 中想象一个类似的设置是很有用的。我认为 Clojure 是将对象（如数据结构和函数）存储在一组巨大的编号架上。没有人能够直接知道一个对象被存储在哪个架子上。相反，我们给 Clojure 一个标识符，它用来检索该对象。\n为了使之成功，Clojure 必须维护我们的标识符和货架地址之间的关联。它通过使用namespaces来做到这一点。命名空间包含了人类友好的符号和书架地址的引用之间的 Map，被称为vars，很像卡片目录。\n从技术上讲，命名空间是 \u0026ldquo;clojure.lang.Namespace \u0026ldquo;类型的对象，你可以与它们互动，就像你可以与 Clojure 数据结构互动一样。例如，你可以用*ns*来引用当前的命名空间，你可以用(ns-name *ns*)来获得其名称。\n(ns-name *ns*) ; =\u0026gt; user 例如，当你启动 REPL 时，你在user命名空间中（正如你在这里看到的）。提示符显示当前名称空间，使用user=\u0026gt;。\n当前名字空间的概念意味着你可以有多个名字空间，事实上 Clojure 允许你创建任意多的名字空间（尽管从技术上讲，你可以创建的名字数量可能有一个上限）。在 Clojure 程序中，你总是在个命名空间中。\n至于符号，你一直在使用它们，甚至没有意识到。例如，当你写(map inc [1 2])时，map和inc都是符号。符号是 Clojure 中的数据类型，我将在下一章中彻底解释它们。现在，你需要知道的是，当你给 Clojure 一个像map这样的符号时，它会在当前命名空间中找到相应的 var，得到一个架子上的地址，并为你从那个架子上检索一个对象\u0026ndash;在这里，就是map所指的那个函数。如果你想只使用符号本身，而不是它所指的东西，你必须引用它。引述任何 Clojure 的形式告诉 Clojure 不要评估它，而是把它当作数据。接下来的几个例子显示了当你引用一个表单时会发生什么。\n➊ inc ; =\u0026gt; #\u0026lt;core$inc clojure.core$inc@30132014\u0026gt; ➋ 'inc ; =\u0026gt; inc ➌ (map inc [1 2]) ; =\u0026gt; (2 3) ➍ '(map inc [1 2]) ; =\u0026gt; (map inc [1 2]) 当你在 REPL 中评估 inc 在 ➊ 处时，它会打印出 inc 所指的函数的文本表述。接下来，你在➋引用inc，所以结果是符号inc。然后，你在➌处评估一个熟悉的map应用程序，得到一个熟悉的结果。之后，你在➍处引用整个列表数据结构，结果是一个未评估的列表，包括map符号、inc符号和一个 Vector。\n现在你知道了 Clojure 的组织系统，让我们来看看如何使用它。\n用 def 存储对象 Clojure 中用于存储对象的主要工具是def。其他的工具，如defn，都是使用def。下面是一个 def 的应用实例。\n(def great-books [\u0026quot;East of Eden\u0026quot; \u0026quot;The Glass Bead Game\u0026quot;]) ; =\u0026gt; #'user/great-books great-books ; =\u0026gt; [\u0026quot;East of Eden\u0026quot; \u0026quot;The Glass Bead Game\u0026quot;] 这段代码告诉 Clojure。\n 用great-books和 var 之间的关联更新当前命名空间的 Map。 找到一个空闲的存储架。 将[《伊甸园之东》《玻璃珠游戏》]存放在架子上。 将书架的地址写在 var 上。 5.返回 var（在这个例子中，`#\u0026lsquo;user/great-books\u0026rsquo;）。  这个过程被称为interning一个 var。 你可以使用`ns-interns\u0026rsquo;与命名空间的符号到内含变量的 Map 进行交互。下面是你如何获得一个内部变量的 Map。\n(ns-interns *ns*) ; =\u0026gt; {great-books #'user/great-books}. 你可以使用`get\u0026rsquo;函数来获取一个特定的 var。\n(get (ns-interns *ns*) ' great-books) ; =\u0026gt; #'user/great-books 通过评估(ns-map ns),你也可以得到命名空间在给定一个符号时用来查找 var 的完整 Map。(ns-map *ns*)给你一个非常大的 Map，我不会在这里打印，但可以试试\n#'user/great-books'是var的*读者形式。 我将在第七章解释更多关于读者形式。现在，只需知道你可以使用#\u0026lsquo;\u0026lsquo;来抓取与后面的符号对应的 var；#'user/great-books'让你在user\u0026rsquo;命名空间中使用与符号great-books'相关的var。我们可以deref\u0026rsquo;变量来获得它们所指向的对象。\n(deref #'user/great-books) ; =\u0026gt; [\u0026quot;East of Eden\u0026quot; \u0026quot;The Glass Bead Game\u0026quot;] 这就像告诉 Clojure，\u0026ldquo;从 var 中获取书架号，去那个书架号，抓住上面的东西，然后给我！\u0026rdquo;\n但是通常情况下，你只需要使用符号。\ngreat-books ; =\u0026gt; [\u0026quot;East of Eden\u0026quot; \u0026quot;The Glass Bead Game\u0026quot;] 这就像告诉 Clojure，\u0026ldquo;检索与 great-books 相关的 var，然后取消那个坏的杰克逊\u0026rdquo;。\n到目前为止还不错，对吗？好吧，请做好准备，因为这个田园诗般的组织天堂即将被颠覆 用同样的符号再次调用def。\n(def great-books [\u0026quot;The Power of Bees\u0026quot; \u0026quot;Journey to Upstairs\u0026quot;]) great-books ; =\u0026gt; [\u0026quot;The Power of Bees\u0026quot; \u0026quot;Journey to Upstairs\u0026quot;] var 已经更新了新的矢量的地址。这就像你在卡片目录中的卡片上的地址用了白笔，然后写了一个新地址。其结果是，你不能再要求 Clojure 找到第一个 Vector。这被称为名称碰撞。混乱! 无政府状态!\n你可能在其他编程语言中经历过这种情况。JavaScript 在这方面是臭名昭著的，它也发生在 Ruby 中。这是个问题，因为你可能无意中覆盖了你自己的代码，而且你也不能保证第三方库不会覆盖你的代码。Melvil 惊恐地退缩了! 幸运的是，Clojure 允许你创建任意多的命名空间，这样你就可以避免这些碰撞。\n创建和切换到命名空间 Clojure 有三种创建命名空间的工具：函数create-ns，函数in-ns，以及宏ns。你将在你的 Clojure 文件中主要使用ns宏，但我将推迟几页来解释它，因为它结合了许多工具，而且在我讨论其他工具之后，它更容易理解。\ncreate-ns接收一个符号，如果它不存在，就用这个名字创建一个命名空间，并返回这个命名空间。\nuser=\u0026gt; (create-ns 'cheese.taxonomy) ; =\u0026gt; #\u0026lt;Namespace cheese.taxonomy\u0026gt; 你可以使用返回的名字空间作为函数调用的参数。\nuser=\u0026gt; (ns-name (create-ns 'cheese.taxonomy)) ; =\u0026gt; cheese-taxonomy 在实践中，你可能永远不会在你的代码中使用create-ns，因为创建一个命名空间而不移入它并不是非常有用。使用in-ns更常见，因为如果命名空间不存在，它会创建命名空间，并**切换到它，如清单 6-1 所示。\nuser=\u0026gt; (in-ns 'cheese.analysis) ; =\u0026gt; #\u0026lt;Namespace cheese.analysis\u0026gt;  6-1. 使用 in-ns 创建一个命名空间并切换到该空间  注意你的 REPL 提示符现在是cheese.analysis\u0026gt;，表明你确实在你刚刚创建的新命名空间中。现在当你使用def时，它将在cheese.analysis命名空间中存储命名对象。\n但是如果你想使用其他命名空间的函数和数据怎么办？要做到这一点，你可以使用一个完全合格的符号。一般的形式是 namespace/name。\ncheese.analysis=\u0026gt; (in-ns 'cheese.taxonomy) cheese.taxonomy=\u0026gt; (def cheddars [\u0026quot;mild\u0026quot; \u0026quot;medium\u0026quot; \u0026quot;strong\u0026quot; \u0026quot;sharp\u0026quot; \u0026quot;extra sharp\u0026quot;]) cheese.taxonomy=\u0026gt; (in-ns 'cheese.analysis) cheese.analysis=\u0026gt; cheddars ; =\u0026gt; Exception: Unable to resolve symbol: cheddars in this context 这创建了一个新的命名空间，cheese.taxonomy，在该命名空间中定义了cheddars，然后切换回cheese.analysis命名空间。如果你试图在cheese.analysis中引用cheese.taxonomy命名空间的cheddars，你会得到一个异常，但是使用完全合格的符号可以。\ncheese.analysis=\u0026gt; cheese.taxonomy/cheddars ; =\u0026gt; [\u0026quot;mild\u0026quot; \u0026quot;medium\u0026quot; \u0026quot;strong\u0026quot; \u0026quot;sharp\u0026quot; \u0026quot;extra sharp\u0026quot;] 输入这些完全合格的符号很快就会成为一种困扰。 比如说，我是一个极不耐烦的学者，专门研究符号学-au-fromage，或者研究与奶酪有关的符号。\n突然间，可能发生的最糟糕的事情发生了！在全世界范围内，神圣的和有可能发生的事情都发生了。在世界各地，神圣的、具有历史意义的奶酪都失踪了。威斯康星州的标准切达干酪：不见了! 图坦卡蒙的大奶酪罐：被偷了! 都灵奶酪：被骗取的奶酪所取代! 这有可能使世界因某种原因而陷入完全的混乱! 自然，作为一个杰出的奶酪研究者，我有责任解开这个谜团。与此同时，我正被光明会、共济会和足部族追捕！因为我是一名学者，所以我必须为他们提供帮助。\n因为我是一个学者，我试图用我知道的最好的方式来解决这个谜团\u0026ndash;去图书馆研究这个狗屎。我可靠的助手 Clojure 陪着我。当我们从一个名字空间到另一个名字空间忙忙碌碌时，我喊着让 Clojure 把一个又一个东西交给我。\n但 Clojure 有点笨，很难弄清楚我指的是什么。在user命名空间中，我大声说：\u0026quot;join! 给我join'！\u0026quot;--我嘴里的唾沫星子飞了出来。\u0026quot;RuntimeException: Unable to resolve symbol: join,\u0026quot; Clojure抱怨着回应。\u0026quot;看在布里的份上，把clojure.string/join`交给我吧！\u0026rdquo; 我反驳道，Clojure 尽职尽责地把我要找的函数交给我。\n我的声音变得沙哑了。我需要一些方法来告诉 Clojure 要给我什么对象，而不必每次都使用完全合格的符号。\n幸运的是，Clojure 提供了 \u0026ldquo;refer \u0026ldquo;和 \u0026ldquo;alias \u0026ldquo;工具，让我可以更简洁地对它吼叫。\n引用 refer使你能够精细地控制你如何引用其他命名空间的对象。启动一个新的 REPL 会话并尝试以下操作。请记住，在 REPL 中这样玩命名空间是可以的，但你不希望你的 Clojure 文件看起来像这样；正确的文件结构方式在\u0026ldquo;真正的项目组织 \u0026ldquo;第 133 页中涉及。\nuser=\u0026gt; (in-ns 'cheese.taxonomy) cheese.taxonomy=\u0026gt; (def cheddars [\u0026quot;mild\u0026quot; \u0026quot;medium\u0026quot; \u0026quot;strong\u0026quot; \u0026quot;sharp\u0026quot; \u0026quot;extra sharp\u0026quot;]) cheese.taxonomy=\u0026gt; (def bries [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;]) cheese.taxonomy=\u0026gt; (in-ns 'cheese.analysis) cheese.analysis=\u0026gt; (clojure.core/refer 'cheese.taxonomy) cheese.analysis=\u0026gt; bries ; =\u0026gt; [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;] cheese.analysis=\u0026gt; cheddars ; =\u0026gt; [\u0026quot;mild\u0026quot; \u0026quot;medium\u0026quot; \u0026quot;strong\u0026quot; \u0026quot;sharp\u0026quot; \u0026quot;extra sharp\u0026quot;] 这段代码创建了一个 \u0026ldquo;cheese.taxonomy \u0026ldquo;命名空间和其中的两个 Vector。 cheddars和bries。然后它创建并移动到一个新的命名空间，称为cheese.analysis。用命名空间的符号调用refer可以让你引用相应的命名空间的对象，而不需要使用完全限定的符号。它通过更新当前命名空间的符号/对象 Map 来实现这一目的。你可以看到像这样的新条目。\ncheese.analysis=\u0026gt; (clojure.core/get (clojure.core/ns-map clojure.core/*ns*) 'bries) ; =\u0026gt; #'cheese.taxonomy/bries cheese.analysis=\u0026gt; (clojure.core/get (clojure.core/ns-map clojure.core/*ns*) 'cheddars) ; =\u0026gt; #'cheese.taxonomy/cheddars 这就好像 Clojure\n 在cheese.taxonomy命名空间上调用ns-interns。 将其与当前命名空间的ns-map合并。 将结果作为当前命名空间的新的`ns-map\u0026rsquo;。  当你调用refer时，你也可以把过滤器:only, :exclude, 和:rename传递给它。正如名字所暗示的，:only和:exclude限制了哪些符号/变量 Map 被合并到当前命名空间的ns-map。 :rename允许你使用不同的符号来表示被合并的变量。如果我们将前面的例子修改为使用:only，会发生以下情况。\ncheese.analysis=\u0026gt; (clojure.core/refer 'cheese.taxonomy :only ['bries]) cheese.analysis=\u0026gt; bries ; =\u0026gt; [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;] cheese.analysis=\u0026gt; cheddars ; =\u0026gt; RuntimeException: 无法解决符号：cheddars 下面是:exclude的操作。\ncheese.analysis=\u0026gt; (clojure.core/refer 'cheese.taxonomy :only ['bries]) cheese.analysis=\u0026gt; bries ; =\u0026gt; [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;] cheese.analysis=\u0026gt; cheddars ; =\u0026gt; RuntimeException: Unable to resolve symbol: cheddars 最后，一个:rename的例子。\ncheese.analysis=\u0026gt; (clojure.core/refer 'cheese.taxonomy :rename {'bries 'yummy-bries}) cheese.analysis=\u0026gt; bries ; =\u0026gt; RuntimeException: Unable to resolve symbol: bries cheese.analysis=\u0026gt; yummy-bries ; =\u0026gt; [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;] 注意，在这些最后的例子中，我们必须使用clojure.core中所有对象的完全合格名称，如clojure.core/ns-map和clojure.core/refer。我们不需要在user命名空间中这样做。这是因为 REPL 在user命名空间中自动引用clojure.core。当你创建一个新的命名空间时，你可以通过评估(clojure.core/refer-clojure)来简化你的生活；这将引用 clojure.core 命名空间，从现在起我将使用它。在例子中你不会看到clojure.core/refer，而只会看到refer。\n另一件需要注意的事情是，你可以完全自由地组织你的函数和数据，跨越命名空间。这让你可以合理地将相关的函数和数据归入同一命名空间。\n有时你可能希望一个函数只对同一命名空间内的其他函数有效。Clojure 允许你使用defn-来定义私有的函数。\n(in-ns 'cheese.analysis) ;; Notice the dash after \u0026quot;defn\u0026quot; (defn- private-function \u0026quot;Just an example function that does nothing\u0026quot; []) 如果你试图从其他命名空间调用这个函数或引用它，Clojure 将抛出一个异常。你可以在评估➊和➋的代码时看到这一点。\ncheese.analysis=\u0026gt; (in-ns 'cheese.taxonomy) cheese.taxonomy=\u0026gt; (clojure.core/refer-clojure) ➊ cheese.taxonomy=\u0026gt; (cheese.analysis/private-function) ➋ cheese.taxonomy=\u0026gt; (refer 'cheese.analysis :only ['private-function]) 正如你所看到的，即使你明确地 \u0026ldquo;引用 \u0026ldquo;这个函数，你也不能使用其他命名空间的函数，因为你把它变成了私有的。(如果你想狡猾一点，你仍然可以使用神秘的语法`@#\u0026lsquo;some/private-var\u0026rsquo;来访问私有变量，但你很少想这样做)。\nalias 与refer相比，alias相对简单。它所做的只是让你缩短一个命名空间的名称，以便使用完全合格的符号。\ncheese.analysis=\u0026gt; (clojure.core/alias 'taxonomy 'cheese.taxonomy) cheese.analysis=\u0026gt; taxonomy/bries ; =\u0026gt; [\u0026quot;Wisconsin\u0026quot; \u0026quot;Somerset\u0026quot; \u0026quot;Brie de Meaux\u0026quot; \u0026quot;Brie de Melun\u0026quot;] 这段代码让我们使用来自cheese.taxonomy命名空间的调用符号，并使用较短的别名taxonomy。\nrefer和alias是你引用当前命名空间以外的对象的两个基本工具! 它们是 REPL 开发的好帮手。\n然而，你不可能在 REPL 中创建整个程序。在下一节中，我将介绍你需要知道的一切，以组织一个真正的项目，使源代码在文件系统中生存。\n真正的项目组织 现在我已经介绍了 Clojure 组织系统的构建模块，我将向你展示如何在实际项目中使用它们。我将讨论文件路径和命名空间名称之间的关系，解释如何用require和use加载文件，并展示如何使用ns来设置一个命名空间。\n文件路径和命名空间名称之间的关系 为了一石二鸟（或者用一颗种子喂养两只鸟，这取决于你是多么的嬉皮士），我将介绍更多关于命名空间的内容，同时我们将通过绘制国际奶酪大盗的抢劫地点来抓捕这个讨厌的大盗。运行以下程序。\nlein new app the-divine-cheese-code 这应该创建一个目录结构，看起来像这样。\n| .gitignore | doc | | intro.md | project.clj | README.md | resources | src | | the_divine_cheese_code | | | core.clj | test | | the_divine_cheese_code | | | core_test.clj 现在，打开src/the_divine_cheese_code/core.clj。你应该在第一行看到这个。\n(ns the-divine-cheese-code.core (:gen-class)) ns是在 Clojure 中创建和管理命名空间的主要方式。我很快就会对它进行全面的解释。不过现在，只需知道这一行与我们在清单 6-1 中使用的in-ns函数非常相似。如果一个命名空间不存在，它就创建一个命名空间，然后切换到它。我在第 12 章也详细介绍了(:gen-class)。\n命名空间的名字是the-divine-cheese-code.core。在 Clojure 中，命名空间的名称和声明命名空间的文件路径之间有一个一对一的 Map，根据以下约定。\n 当你用lein创建一个目录时（就像你在这里做的那样），源代码的根默认为src。 名称空间中的破折号对应于文件系统中的下划线。所以the-divine-cheese-code在文件系统中被 Map 为the_divine_cheese_code。 命名空间名称中的句号（.）前面的成分对应于一个目录。例如，由于the-divine-cheese-code.core是命名空间的名称，the_divine_cheese_code是一个目录。 命名空间的最后一个组成部分对应于扩展名为*.clj的文件；core被 Map 到core.clj*。  你的项目将有一个命名空间，the-divine-cheese-code.visualization.svg。现在继续为它创建文件。\nmkdir src/the_divine_cheese_code/visualization touch src/the_divine_cheese_code/visualization/svg.clj 注意，文件系统的路径遵循这些惯例。有了命名空间和文件系统之间的关系，我们来看看require和use。\n要求和使用命名空间 在the-divine-cheese-code.core命名空间的代码将使用the-divine-cheese-code.visualization.svg命名空间的函数来创建 SVG 标记。为了使用svg的函数，core将不得不要求它。但首先，让我们在svg.clj*中添加一些代码。让它看起来像这样（你以后会添加更多）。\n(ns the-divine-cheese-code.visualization.svg) (defn latlng-\u0026gt;point \u0026quot;Convert lat/lng map to comma-separated string\u0026quot; [latlng] (str (:lat latlng) \u0026quot;,\u0026quot; (:lng latlng))) (defn points [locations] (clojure.string/join \u0026quot; \u0026quot; (map latlng-\u0026gt;point locations))) 这定义了两个函数，latlng-\u0026gt;point和points，你将用它们来把一串经纬度坐标转换成一串点。 要使用core.clj文件中的这段代码，你必须require它。require接收一个指定命名空间的符号，并确保该命名空间存在并准备使用；在这种情况下，当你调用(require 'the-divine-cheese-code.visualization.svg)，Clojure读取并评估相应的文件。通过评估该文件，它创建了the-divine-cheese-code.visualization.svg命名空间，并在该命名空间中定义了函数latlng-\u0026gt;point和points`。即使文件svg.clj在你的项目目录中，Clojure 在运行你的项目时也不会自动评估它；你必须明确告诉 Clojure 你想使用它。\n在要求命名空间之后，你可以参考它，这样你就不必使用完全合格的名称来引用函数。继续要求the-divine-cheese-code.visualization.svg，并添加heists序列，使core.clj与列表相符。\n(ns the-divine-cheese-code.core) ;; Ensure that the SVG code is evaluated (require 'the-divine-cheese-code.visualization.svg) ;; Refer the namespace so that you don't have to use the ;; fully qualified name to reference svg functions (refer 'the-divine-cheese-code.visualization.svg) (def heists [{:location \u0026quot;Cologne, Germany\u0026quot; :cheese-name \u0026quot;Archbishop Hildebold's Cheese Pretzel\u0026quot; :lat 50.95 :lng 6.97} {:location \u0026quot;Zurich, Switzerland\u0026quot; :cheese-name \u0026quot;The Standard Emmental\u0026quot; :lat 47.37 :lng 8.55} {:location \u0026quot;Marseille, France\u0026quot; :cheese-name \u0026quot;Le Fromage de Cosquer\u0026quot; :lat 43.30 :lng 5.37} {:location \u0026quot;Zurich, Switzerland\u0026quot; :cheese-name \u0026quot;The Lesser Emmental\u0026quot; :lat 47.37 :lng 8.55} {:location \u0026quot;Vatican City\u0026quot; :cheese-name \u0026quot;The Cheese of Turin\u0026quot; :lat 41.90 :lng 12.45}]) (defn -main [\u0026amp; args] (println (points heists))) 现在你有一连串的 heist 位置可以使用，你可以使用visualization.svg命名空间的函数。main函数只是将points函数应用于heists。如果你用lein run运行该项目，你应该看到这个。\n50.95,6.97 47.37,8.55 43.3,5.37 47.37,8.55 41.9,12.45 万岁! 你离抓到那个偷窃发酵乳的人又近了一步! 使用require成功加载了the-divine-cheese-code.visualization.svg以供使用。\nrequire的细节实际上有点复杂，但为了实用，你可以认为require是告诉 Clojure 以下内容。\n 如果你已经用这个符号（the-divine-cheese-code.visualization.svg）调用了require，则不做任何事情。 否则，使用\u0026ldquo;文件路径和命名空间名称之间的关系 \u0026ldquo;第 133 页中描述的规则找到与该符号对应的文件。在这种情况下，Clojure 找到src/the_divine_cheese_code/visualization/svg.clj。  读取并评估该文件的内容。Clojure 希望该文件声明一个与它的路径相对应的命名空间（我们的文件就是如此）。\nrequire也可以让你在需要一个命名空间时使用:as或alias来别名它。这样。\n(require '[the-divine-cheese-code.visualization.svg :as svg] ) 相当于这样。\n(require 'the-divine-cheese-code.visualization.svg) (alias 'svg 'the-divine-cheese-code.visualization.svg) 现在你可以使用别名的命名空间了。\n(svg/points heists) ; =\u0026gt; \u0026quot;50.95,6.97 47.37,8.55 43.3,5.37 47.37,8.55 41.9,12.45\u0026quot; Clojure 提供了另一种捷径。函数use不需要单独调用require和refer，而是同时调用。在生产代码中使用use是不可取的，但当你在 REPL 中做实验，想快速获得一些函数时，它就很方便。例如，这个。\n(require 'the-divine-cheese-code.visualization.svg) (refer 'the-divine-cheese-code.visualization.svg) 相当于这样。\n(use 'the-divine-cheese-code.visualization.svg) 你可以用use来别名一个命名空间，就像你可以用require一样。这样。\n(require 'the-divine-cheese-code.visualization.svg) (refer 'the-divine-cheese-code.visualization.svg) (alias 'svg 'the-divine-cheese-code.visualization.svg) 相当于清单 6-2 中的代码，其中也显示了函数调用中使用的别名空间。\n(use '[the-divine-cheese-code.visualization.svg :as svg]) (= svg/points points) ; =\u0026gt; true (= svg/latlng-\u0026gt;point latlng-\u0026gt;point) ; =\u0026gt; true  6-2. 有时，既使用又别名一个命名空间是很方便的。  在这里用use别名命名空间似乎是多余的，因为use已经引用了命名空间（这让你可以简单地调用points而不是svg/points）。但在某些情况下，这很方便，因为use和refer有相同的选项（:only, :exclude, :as, 和:rename）。当你跳过引用一个符号时，你可能想用use来别名一个命名空间。你可以这样使用。\n(require 'the-divine-cheese-code.visualization.svg) (refer 'the-divine-cheese-code.visualization.svg :as :only ['point]) 或者你可以使用清单 6-3 中的use形式（其中还包括如何调用函数的例子）。\n(use '[the-divine-cheese-code.visualization.svg :as svg :only [points]]) (refer 'the-divine-cheese-code.visualization.svg :as :only ['points]) (= svg/points points) ; =\u0026gt; true ;; We can use the alias to reach latlng-\u0026gt;point svg/latlng-\u0026gt;point ; This doesn't throw an exception ;; But we can't use the bare name latlng-\u0026gt;point ; This does throw an exception!  在你使用一个命名空间后将其别名化，可以让你参考你排除的符号。  如果你在 REPL 中尝试清单 6-3，并且latlng-\u0026gt;point没有抛出一个异常，这是因为你在清单 6-2 中引用了latlng-\u0026gt;point。你需要重新启动你的 REPL 会话，使代码表现得如清单 6-3 所示。\n这里的启示是，require和use加载文件，并可选择alias或refer其命名空间。当你写 Clojure 程序和阅读别人写的代码时，你可能会遇到更多的require'和use\u0026rsquo;的写法，这时，阅读 Clojure 的 API 文档（http://clojure.org/libs/）来了解发生了什么是有意义的。然而，到目前为止，你所学到的关于require和use的内容应该能满足你 95.3%的需求。\n＃＃＃NS 宏 现在是时候看看ns宏了。到目前为止所涉及的工具\u0026ndash;in-ns, refer, alias, require, 和 use\u0026ndash;最常在你使用 REPL 时使用。在你的源代码文件中，你通常会使用ns宏，因为它允许你简洁地使用迄今为止描述的工具，并提供其他有用的功能。在本节中，你将了解一个ns调用如何结合require、use、in-ns、alias和refer。\nns做的一个有用的任务是默认引用clojure.core命名空间。这就是为什么你可以从the-divine-cheese-code.core中调用println，而不使用完全限定的名称clojure.core/println。\n你可以用:refer-clojure来控制从clojure-core引用的内容，它的选项与refer相同。\n(ns the-divine-cheese-code.core (:refer-clojure :exclude [println]) 如果你在divine_cheese_code.core.clj的开头调用这个，会破坏你的代码，迫使你在-main'函数中使用clojure.core/println\u0026rsquo;。\n在ns中，(:refer-clojure)`的形式被称为reference。这对你来说可能看起来很奇怪。这个引用是一个函数调用？一个宏？它是什么？你将在第 7 章中了解更多关于底层机器的知识。现在，你只需要了解每个引用如何 Map 到函数调用。例如，前面的代码就相当于这样。\n(in-ns 'the-divine-cheese-code.core) (refer 'clojure.core :exclude ['println]) 在 \u0026ldquo;ns \u0026ldquo;中，有六种可能的引用。\n (:refer-clojure). \u0026ldquo;(:require)\u0026quot;。 (:use) (:import) (:load) (:gen-class)。  (:import)和(:gen-class)将在第 12 章介绍。我将不介绍(:load)，因为它很少被使用。\n(:require)的工作方式很像require函数。例如，这样。\n(ns the-divine-cheese-code.core (:require the-divine-cheese-code.visualization.svg)) 相当于这样。\n(in-ns 'the-divine-cheese-code.core) (require 'the-divine-cheese-code.visualization.svg) 注意，在 \u0026ldquo;ns \u0026ldquo;形式中（与 \u0026ldquo;in-ns \u0026ldquo;函数调用不同），你不需要用\u0026rdquo;\u0026lsquo;\u0026lsquo;来引用你的符号。在 \u0026ldquo;ns \u0026ldquo;中，你从来不需要引用符号。\n你也可以alias一个你在ns内require的库，就像你调用函数时一样。这样。\n(ns the-divine-cheese-code.core (:require [the-divine-cheese-code.visualization.svg :as svg]) 相当于这样。\n(in-ns 'the-divine-cheese-code.core) (require ['the-divine-cheese-code.visualization.svg :as 'svg]) 你可以在一个(:require)引用中要求多个库，如下所示。 这样。\n(ns the-divine-cheese-code.core (:require [the-divine-cheese-code.visualization.svg :as svg]) [clojure.java.browse :as browse])) 相当于这样。\n(in-ns 'the-divine-cheese-code.core) (require ['the-divine-cheese-code.visualization.svg :as 'svg]) (require ['clojure.java.browse :as 'browse]) 然而，(:require)引用和require函数之间的一个区别是，引用也允许你引用名字。这一点。\n(ns the-divine-cheese-code.core (:require [the-divine-cheese-code.visualization.svg :refer [point])) 相当于这样。\n(in-ns 'the-divine-cheese-code.core) (require 'the-divine-cheese-code.visualization.svg) (refer 'the-divine-cheese-code.visualization.svg :only ['point]) 你也可以引用所有的符号（注意:all关键字）。\n(ns the-divine-cheese-code.core (:require [the-divine-cheese-code.visualization.svg :refer :all])) 这就相当于这样做了。\n(in-ns 'the-divine-cheese-code.core) (require 'the-divine-cheese-code.visualization.svg) (refer 'the-divine-cheese-code.visualization.svg) 这是要求代码、别名命名空间和引用符号的首选方式。建议你不要使用(:use)，但由于你很可能会遇到它，所以知道它是如何工作的很好。你知道该怎么做。这个。\n(ns the-divine-cheese-code.core (:use clojure.java.browse)) 这样做。\n(in-ns 'the-divine-cheese-code.core) (use 'clojure.java.browse) 而这一点。\n(ns the-divine-cheese-code.core (:use [clojure.java browse io]) 这样做。\n(in-ns 'the-divine-cheese-code.core) (use 'clojure.java.browse) (use 'clojure.java.io) 注意，当你在:use后面加上一个矢量时，它把第一个符号作为base，然后用后面的每个符号调用use。\n哦，我的天哪，就是这样! 现在你可以像专家一样使用ns了! 你需要这样做，该死的，因为那个voleur des fromages（他们可能在法语中这样说）仍然在肆意妄为。还记得他/她吗？\n∮∮抓小偷\n我们不能让这个掠夺帕尔马干酪的人带着更多的干酪离开！是时候完成根据坐标画线的工作了。现在是时候根据盗窃案的坐标来完成画线了！这肯定会发现一些问题。这肯定会发现一些问题!\n使用每个抢劫案的纬度坐标，你将在一个 SVG 图像中连接这些点。但是，如果你用给定的坐标画线，结果看起来就不对了，原因有二。首先，纬度坐标是由南向北上升的，而 SVG 的 Y 坐标是由上向下上升的。换句话说，你需要翻转坐标，否则绘图就会颠倒过来。\n第二，绘图会非常小。为了解决这个问题，你将通过平移和缩放来放大它。这就像把一张看起来像图 6-1a 的图变成图 6-1b。\n图 6-1：通过翻转、平移和缩放纬度坐标来制作一张 SVG 图片。\n说实话，这些都是完全随意的，它已经与代码组织没有直接关系了，但是它很有趣，我想你会有一个很好的时间来浏览这些代码的 使你的svg.clj文件与清单 6-4 一致。\n(ns the-divine-cheese-code.visualization.svg (:require [clojure.string :as s]) (:refer-clojure :exclude [min max]) ➊ （defn comparator-over-maps [比较-fn ks］ (fn [maps] ➋ (zipmap ks ➌ (map (fn [k] (apply comparison-fn (map k maps))) ks)))) ➍ (def min (comparator-over-maps clojure.core/min [:lat :lng]) (def max (comparator-over-maps clojure.core/max [:lat :lng]))  6-3. 构建 Map 比较函数  你在➊处定义了comparator-over-maps函数。这可能是最棘手的部分，所以请忍受一下。 comparator-over-maps是一个返回一个函数的函数。返回的函数使用所提供的比较函数comparison-fn对参数ks提供的键值进行比较。\n你使用comparator-over-map来构造min和max函数➍，你将用它们来寻找我们图形的左上角和右下角。下面是`min\u0026rsquo;的操作。\n(min [{:a 1 :b 3} {:a 5 :b 0}] ) ; =\u0026gt; {:a 1 :b 0} 当你调用min时，它调用zipmap，它接受两个参数，都是 seq，并返回一个新的 map。第一个序列的元素成为键，第二个序列的元素成为值。\n(zipmap [:a :b] [1 2]) ; =\u0026gt; {:a 1 :b 2}。 在 ，zipmap的第一个参数是ks，所以ks的元素将是返回 Map 的键。第二个参数是在➌的 Map 调用的结果。那个 Map 调用实际上是在进行比较。\n最后，在➍，你使用comparator-over-maps来创建比较函数。如果你把图纸看作是刻在一个矩形里，那么min是矩形中最接近（0，0）的角，max是离它最远的角。\n下面是代码的下一部分。\n (defn translate-to-00 [locations] (let [mincoords (min locations)] (map #(merge-with - % mincoords) locations))) (defn scale [width height locations] (let [maxcoords (max locations) ratio {:lat (/ height (:lat maxcoords)) :lng (/ width (:lng maxcoords))}] (map #(merge-with * % ratio) locations))) translate-to-00，定义在 ，工作原理是找到我们位置的min'，然后从每个位置减去这个值。它使用merge-with`，其工作原理如下。\n(merge-with - {:lat 50 :lng 10} {:lat 5 :lng 5}) ; =\u0026gt; {:lat 45 :lng 5} 然后我们定义函数scale，它将每个点乘以最大经纬度与所需高度和宽度之间的比率。\n下面是svg.clj的其余代码。\n(defn latlng-\u0026gt;point \u0026quot;Convert lat/lng map to comma-separated string\u0026quot; [latlng] (str (:lat latlng) \u0026quot;,\u0026quot; (:lng latlng))) (defn points \u0026quot;Given a seq of lat/lng maps, return string of points joined by space\u0026quot; [locations] (s/join \u0026quot; \u0026quot; (map latlng-\u0026gt;point locations))) (defn line [points] (str \u0026quot;\u0026lt;polyline points=\\\u0026quot;\u0026quot; points \u0026quot;\\\u0026quot; /\u0026gt;\u0026quot;)) (defn transform \u0026quot;Just chains other functions\u0026quot; [width height locations] (-\u0026gt;\u0026gt; locations translate-to-00 (scale width height))) (defn xml \u0026quot;svg 'template', which also flips the coordinate system\u0026quot; [width height locations] (str \u0026quot;\u0026lt;svg height=\\\u0026quot;\u0026quot; height \u0026quot;\\\u0026quot; width=\\\u0026quot;\u0026quot; width \u0026quot;\\\u0026quot;\u0026gt;\u0026quot; ;; These two \u0026lt;g\u0026gt; tags change the coordinate system so that ;; 0,0 is in the lower-left corner, instead of SVG's default ;; upper-left corner \u0026quot;\u0026lt;g transform=\\\u0026quot;translate(0,\u0026quot; height \u0026quot;)\\\u0026quot;\u0026gt;\u0026quot; \u0026quot;\u0026lt;g transform=\\\u0026quot;rotate(-90)\\\u0026quot;\u0026gt;\u0026quot; (-\u0026gt; (transform width height locations) points line) \u0026quot;\u0026lt;/g\u0026gt;\u0026lt;/g\u0026gt;\u0026quot; \u0026quot;\u0026lt;/svg\u0026gt;\u0026quot;)) 这里的函数非常简单明了。它们只是接收{:lat x :lng y}Map，并对其进行转换，以便创建一个 SVG。latlng-\u0026gt;point返回一个字符串，可用于在 SVG 标记中定义一个点。points将lat/lngMap 的序列转换为一个以空格分隔的点的字符串。 line返回连接所有给定空间分隔的点字符串的 SVG 标记。 transform接收一个位置序列，将它们翻译成从(0, 0)开始的点，并将它们缩放到给定的宽度和高度。最后，xml产生标记，用 SVG 显示给定的位置。\n有了svg.clj的所有代码，现在让core.clj看起来像这样。\n(ns the-divine-cheese-code.core (:require [clojure.java.browse :as browse] [the-divine-cheese-code.visualization.svg :refer [xml]]) (:gen-class)) (def heists [{:location \u0026quot;Cologne, Germany\u0026quot; :cheese-name \u0026quot;Archbishop Hildebold's Cheese Pretzel\u0026quot; :lat 50.95 :lng 6.97} {:location \u0026quot;Zurich, Switzerland\u0026quot; :cheese-name \u0026quot;The Standard Emmental\u0026quot; :lat 47.37 :lng 8.55} {:location \u0026quot;Marseille, France\u0026quot; :cheese-name \u0026quot;Le Fromage de Cosquer\u0026quot; :lat 43.30 :lng 5.37} {:location \u0026quot;Zurich, Switzerland\u0026quot; :cheese-name \u0026quot;The Lesser Emmental\u0026quot; :lat 47.37 :lng 8.55} {:location \u0026quot;Vatican City\u0026quot; :cheese-name \u0026quot;The Cheese of Turin\u0026quot; :lat 41.90 :lng 12.45}]) (defn url [filename] (str \u0026quot;file:///\u0026quot; (System/getProperty \u0026quot;user.dir\u0026quot;) \u0026quot;/\u0026quot; filename)) (defn template [contents] (str \u0026quot;\u0026lt;style\u0026gt;polyline { fill:none; stroke:#5881d8; stroke-width:3}\u0026lt;/style\u0026gt;\u0026quot; contents)) (defn -main [\u0026amp; args] (let [filename \u0026quot;map.html\u0026quot;] (-\u0026gt;\u0026gt; heists (xml 50 100) template (spit filename)) (browse/browse-url (url filename)))) 这里没有太复杂的事情发生。在 \u0026ldquo;main \u0026ldquo;中，你使用 \u0026ldquo;xml \u0026ldquo;和 \u0026ldquo;template \u0026ldquo;函数建立绘图，用 \u0026ldquo;spit \u0026ldquo;将绘图写入一个文件，然后用 \u0026ldquo;browse/browse-url \u0026ldquo;打开它。你现在应该试试! 运行lein run，你会看到类似图 6-2 的东西。\n图 6-2: 抢劫模式的最终 SVG!\n等一下 ……这看起来很像 ……这看起来很像一个 lambda。Clojure 的标志是一个 lambda . ……哦，我的天啊! Clojure，一直以来都是你!\n总结 在本章中你学到了很多东西。在这一点上，你应该拥有所有你需要的工具来开始组织你的项目。你现在知道命名空间组织了符号和 vars 之间的 Map，vars 是对 Clojure 对象（数据结构、函数等）的引用。 def存储一个对象，并用符号和指向该对象的 var 之间的 Map 来更新当前命名空间。你可以用defn-创建私有函数。\nClojure 允许你用create-ns创建命名空间，但通常使用in-ns更有用，它也会切换到命名空间。你可能只在 REPL 中使用这些函数。当你在 REPL 中时，你总是在当前命名空间中。当你在文件中而不是在 REPL 中定义名字空间时，你应该使用 ns 宏，名字空间和它在文件系统中的路径之间是一对一的关系。\n你可以通过使用完全限定的名称来引用其他命名空间中的对象，如cheese.taxonomy/cheddars。 refer可以让你使用其他命名空间的名字，而不需要完全限定它们，alias可以让你在写出完全限定的名字时，使用一个更短的名字来命名空间。\nrequire和use确保一个名字空间的存在并准备好被使用，并且可以选择让你refer和alias相应的名字空间。你应该使用ns在你的源文件中调用require和use。*Clojure ns syntax cheat-sheet - GitHub*是使用ns的所有变化的一个很好的参考。\n最后，也是最重要的一点，做一个俗气的人并不容易。\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter6/","summary":"组织你的项目：一个图书管理员的故事 在我们每个人心中都住着一个叫 Melvil 的图书管理员，一个以组织艺术为乐的奇异生物。日日夜夜，Melvil 都渴望为你的代码库带来秩序。幸运的是，Clojure 提供了一套工具，专门用来帮助这个侏儒与混乱的力量不断斗争。\n这些工具通过将相关的函数和数据分组来帮助你组织你的代码。它们还可以防止名称冲突，这样你就不会意外地覆盖别人的代码，反之亦然。在这个充满悬念和神秘的故事中，请和我一起学习如何使用这些工具，并解决一生中的抢劫案吧 在这个传奇故事的最后，你将了解以下内容。\n  `def\u0026rsquo;是做什么的\n  什么是命名空间以及如何使用它们\n  命名空间和文件系统之间的关系\n  如何使用refer、alias、require、use和ns。\n  如何使用文件系统来组织 Clojure 项目\n  我先来介绍一下 Clojure 的组织系统，它的工作原理很像一个库。Melvil 兴奋地颤抖着!\n你的项目是一个库 现实世界中的图书馆存储对象的集合，如书籍、杂志和 DVD。他们使用寻址系统，所以当你得到一个物体的地址时，你可以导航到物理空间并检索到该物体。\n当然，没有人能够直接知道一本书或 DVD 的地址是什么。这就是为什么图书馆要记录一个物体的标题和它的地址之间的联系，并提供工具来搜索这些记录。在计算机之前的旧时代，图书馆提供卡片目录，即装满纸质卡片的柜子，其中包含每本书的标题、作者、\u0026ldquo;地址\u0026rdquo;（杜威十进制或国会图书馆编号）和其他信息。\n例如，要找到《达芬奇密码》，你可以翻阅书名目录（按书名排序的卡片），直到你找到正确的卡片。在那张卡片上，你会看到地址813.54（如果它使用杜威十进制系统），浏览图书馆，找到达芬奇密码所在的书架，并参与你一生中的文学和/或仇恨阅读冒险。\n在 Clojure 中想象一个类似的设置是很有用的。我认为 Clojure 是将对象（如数据结构和函数）存储在一组巨大的编号架上。没有人能够直接知道一个对象被存储在哪个架子上。相反，我们给 Clojure 一个标识符，它用来检索该对象。\n为了使之成功，Clojure 必须维护我们的标识符和货架地址之间的关联。它通过使用namespaces来做到这一点。命名空间包含了人类友好的符号和书架地址的引用之间的 Map，被称为vars，很像卡片目录。\n从技术上讲，命名空间是 \u0026ldquo;clojure.lang.Namespace \u0026ldquo;类型的对象，你可以与它们互动，就像你可以与 Clojure 数据结构互动一样。例如，你可以用*ns*来引用当前的命名空间，你可以用(ns-name *ns*)来获得其名称。\n(ns-name *ns*) ; =\u0026gt; user 例如，当你启动 REPL 时，你在user命名空间中（正如你在这里看到的）。提示符显示当前名称空间，使用user=\u0026gt;。\n当前名字空间的概念意味着你可以有多个名字空间，事实上 Clojure 允许你创建任意多的名字空间（尽管从技术上讲，你可以创建的名字数量可能有一个上限）。在 Clojure 程序中，你总是在个命名空间中。\n至于符号，你一直在使用它们，甚至没有意识到。例如，当你写(map inc [1 2])时，map和inc都是符号。符号是 Clojure 中的数据类型，我将在下一章中彻底解释它们。现在，你需要知道的是，当你给 Clojure 一个像map这样的符号时，它会在当前命名空间中找到相应的 var，得到一个架子上的地址，并为你从那个架子上检索一个对象\u0026ndash;在这里，就是map所指的那个函数。如果你想只使用符号本身，而不是它所指的东西，你必须引用它。引述任何 Clojure 的形式告诉 Clojure 不要评估它，而是把它当作数据。接下来的几个例子显示了当你引用一个表单时会发生什么。","title":"Chapter6 组织你的项目"},{"content":"函数式编程 到目前为止，你已经专注于熟悉 Clojure 提供的工具：不可变的数据结构、函数、抽象，等等。在这一章中，你将学习如何思考你的编程任务，以最好的方式利用这些工具。你将开始把你的经验整合到一个新的函数式编程思维中。\n你将学到的核心概念包括：什么是纯函数，为什么它们很有用；如何使用不可变的数据结构，为什么它们比可变的表亲更有优势；如何将数据和函数分开，给你带来更多的力量和灵活性；以及为什么对一小部分数据抽象进行编程会很强大。一旦你把所有这些知识塞进你的大脑，你就会有一个全新的解决问题的方法\n在学习了这些主题之后，你将通过编写一个基于终端的游戏来运用你所学到的一切，这个游戏的灵感来自于美国各地 Cracker Barrel 餐馆中的一种古老而神秘的思维训练装置。Peg Thing!\n纯函数：什么和为什么 除了 \u0026ldquo;println \u0026ldquo;和 \u0026ldquo;rand\u0026rdquo;，到目前为止，你所使用的所有函数都是纯函数。是什么使它们成为纯函数，为什么会有这样的问题？如果一个函数符合两个条件，它就是纯函数。\n 如果给出相同的参数，它总是返回相同的结果。这被称为引用透明度，你可以把它添加到你的 5 美元编程术语列表中。 它不能引起任何副作用。也就是说，该函数不能做出任何在函数本身之外可以观察到的改变\u0026ndash;例如，通过改变一个外部可访问的可改变对象或写到一个文件。  这些特性使你更容易推理你的程序，因为这些函数是完全隔离的，无法影响你系统的其他部分。当你使用它们时，你不必问自己，\u0026ldquo;我调用这个函数会破坏什么？\u0026rdquo; 它们也是一致的：你永远不需要搞清楚为什么给一个函数传递相同的参数会导致不同的返回值，因为这永远不会发生。\n纯函数和算术一样稳定，没有问题（你最后一次为两个数字相加而烦恼是什么时候？） 它们是巨大的函数小砖块，你可以自信地将其作为你程序的基础。让我们更详细地看看引用透明性和无副作用，看看它们到底是什么，以及它们是如何发挥作用的。\n纯函数是引用透明的 为了在调用相同参数时返回相同的结果，纯函数只依靠 1）自己的参数和 2）不可变的值来决定其返回值。例如，数学函数是引用透明的。\n(+ 1 2) ; =\u0026gt; 3 如果一个函数依赖于一个不可变的值，那么它就是引用透明的。字符串`\u0026rdquo;, Daniel-san \u0026ldquo;是不可变的，所以下面的函数也是引用透明的。\n(defn wisdom [words] (str words \u0026#34;, Daniel-san\u0026#34;)) (wisdom \u0026#34;Always bathe on Fridays\u0026#34;) ; =\u0026gt; \u0026#34;Always bathe on Fridays, Daniel-san\u0026#34; 相比之下，下面的函数在相同的参数下不会产生相同的结果；因此，它们在指称上是不透明的。任何依赖随机数生成器的函数都不可能是指称透明的。\n(defn year-end-evaluation [] (if (\u0026gt; (rand) 0.5) \u0026#34;You get a raise!\u0026#34; \u0026#34;Better luck next year!\u0026#34;)) 如果你的函数从一个文件中读出，它就不是引用透明的，因为文件的内容可以改变。下面的函数analyze-file不是引用透明的，但函数analysis是透明的。\n(defn analyze-file [filename] (analysis (slurp filename))) (defn analysis [text] (str \u0026#34;Character count: \u0026#34; (count text))) 当使用一个引用透明的函数时，你永远不必考虑哪些可能的外部条件会影响函数的返回值。如果你的函数在多个地方被使用，或者它被深深地嵌套在一个函数调用链中，这一点就特别重要。在这两种情况下，你可以高枕无忧地知道，外部条件的变化不会导致你的代码中断。\n另一种思考方式是，现实在很大程度上是引用透明的。如果你把重力看作一个函数，那么引力就是在两个物体上调用该函数的返回值。因此，当你下次参加编程面试时，你可以通过把面试官桌上的东西打掉来证明你的函数式编程知识（这也证明你知道如何在一个集合上应用一个函数）。\n纯函数没有副作用 执行副作用就是在一个给定的范围内改变一个名字和它的值之间的关联。下面是一个 JavaScript 的例子。\nvar haplessObject = { emotion: \u0026#34;Carefree!\u0026#34; }; var evilMutator = function(object){ object.emotion = \u0026#34;So emo :\u0026#39;(\u0026#34;; } evilMutator(haplessObject); haplessObject.emotion; // =\u0026gt; \u0026#34;So emo :\u0026#39;(\u0026#34; 当然，你的程序必须要有一些副作用。它写入磁盘，改变了文件名和磁盘扇区集合之间的关联；它改变了显示器像素的 RGB 值；等等。否则，运行它就没有意义了。\n然而，副作用是潜在的有害的，因为它们带来了关于你的代码中的名称所指的不确定性。这就导致了很难追踪为什么以及如何将一个名字与一个值联系起来的情况，这就使程序的调试变得非常困难。当你调用一个没有副作用的函数时，你只需要考虑输入和输出之间的关系。你不必担心其他可能在你的系统中出现的变化。\n另一方面，有副作用的函数给你的思想葡萄带来了更多的负担：现在你必须担心当你调用这个函数时，世界是如何受到影响的。不仅如此，每一个依赖于副作用函数的函数都会被这种担忧所感染；它也会成为你在构建程序时需要格外小心和思考的另一个组件。\n如果你有使用 Ruby 或 JavaScript 等语言的重要经验，你可能已经遇到了这个问题。当一个对象被传来传去的时候，它的属性不知不觉地发生了变化，而你却不知道为什么。然后你不得不买一台新的电脑，因为你把你的电脑扔到了窗外。如果你读过任何关于面向对象设计的文章，你就会知道，很多文章都是关于管理状态和减少副作用的策略，正是因为这个原因。\n由于所有这些原因，在你的代码中寻找限制使用副作用的方法是个好主意。幸运的是，Clojure 通过不遗余力地限制副作用来使你的工作变得更容易\u0026ndash;它的所有核心数据结构都是不可改变的。无论你如何努力，你都无法在原地改变它们。然而，如果你不熟悉不可变的数据结构，你可能会觉得你最喜欢的工具被剥夺了。你怎么能*做没有副作用的事情呢？好吧，这就是下一节要讲的内容! 这段话怎么样，嗯？诶？\n与不可变的数据结构共处 不可变的数据结构确保你的代码不会有副作用。正如你现在衷心知道的，这是一件好事。但你如何在没有副作用的情况下完成任何事情呢？\n递归而不是 for/while 如果你曾经在 JavaScript 中写过这样的东西，请举手。\nvar wrestlers = getAlligatorWrestlers(); var totalBites = 0; var l = wrestlers.length; for(var i=0; i \u0026lt; l; i++){ totalBites += wrestlers[i].timesBitten; } 或者这样。\nvar allPatients = getArkhamPatients(); var analyzedPatients = []; var l = allPatients.length; for(var i=0; i \u0026lt; l; i++){ if(allPatients[i].analyzed){ analyzedPatients.push(allPatients[i]); } } 注意这两个例子都对循环变量i以及循环外的一个变量（第一个例子中的totalBites和第二个例子中的analyzedPatients）产生了副作用。以这种方式使用副作用\u0026ndash;改变***内部的变量\u0026ndash;是相当无害的。你在创造新的值，而不是改变你从程序中其他地方得到的对象。\n但是 Clojure 的核心数据结构甚至不允许这些无害的变异。那么，你能做什么呢？首先，忽略一个事实，你可以很容易地使用map和reduce来完成前面的工作。在这些情况下\u0026ndash;对一些集合进行迭代以建立一个结果\u0026ndash;替代突变的函数是递归。\n让我们看一下第一个例子，建立一个总和。Clojure 没有赋值运算符。如果不创建一个新的作用域，你就无法将一个新的值与一个名字联系起来。\n(def great-baby-name \u0026#34;Rosanthony\u0026#34;) great-baby-name ; =\u0026gt; \u0026#34;Rosanthony\u0026#34; (let [great-baby-name \u0026#34;Bloodthunder\u0026#34;] great-baby-name) ; =\u0026gt; \u0026#34;Bloodthunder\u0026#34; great-baby-name ; =\u0026gt; \u0026#34;Rosanthony\u0026#34; 在这个例子中，你首先在全局作用域中将 \u0026ldquo;great-baby-name \u0026ldquo;与 \u0026ldquo;Rosanthony \u0026ldquo;绑定。接下来，你用let引入一个新的作用域。在这个作用域中，你将great-baby-name绑定到\u0026quot;Bloodthunder\u0026quot;。一旦 Clojure 完成了对let表达式的评估，你就回到了全局范围，great-baby-name再次被评估为\u0026quot;Rosanthony\u0026quot;。\nClojure 让你用递归来解决这个明显的限制。下面的例子显示了解决递归问题的一般方法。\n(defn sum ➊ ([vals] (sum vals 0)) ([vals accumulating-total] ➋ (if (empty? vals) accumulating-total (sum (rest vals) (+ (first vals) accumulating-total))))) 这个函数需要两个参数，一个要处理的集合（vals）和一个累加器（accumulating-total），它使用了 arity 重载（在第三章有介绍），在➊为accumulating-total提供一个默认值0。\n像所有的递归解决方案一样，这个函数根据一个基本条件检查它所处理的参数。在这种情况下，我们检查vals在➋是否为空。如果是，我们知道我们已经处理了集合中的所有元素，所以我们返回`累计-总数'。\n如果vals不是空的，意味着我们还在处理这个序列，所以我们递归调用sum，给它传递两个参数：用(其余的vals)表示 vals 的*尾部，用(+(第一个vals)累加总数)表示vals的第一个元素与累加总数之和。通过这种方式，我们建立了累积总数，同时减少vals，直到它达到空集合的基本情况。\n下面是递归函数调用的情况，如果我们把它每次递归的情况分开，就会是这样的。\n(sum [39 5 1]) ; single-arity body calls two-arity body (sum [39 5 1] 0) (sum [5 1] 39) (sum [1] 44) (sum [] 45) ; base case is reached, so return accumulating-total ; =\u0026gt; 45 对sum的每次递归调用都会创建一个新的作用域，其中vals和accumulating-total被绑定到不同的值上，所有这些都不需要改变最初传递给函数的值或执行任何内部变异。正如你所看到的，你可以在没有突变的情况下顺利完成。\n请注意，出于性能的考虑，在进行递归时，你一般应该使用recur。原因是 Clojure 不提供尾部调用的优化，这个话题我不会再提了！（请查看这个网址）。(查看这个网址以了解更多信息。http://en.wikipedia.org/wiki/Tail_call）。所以你可以用recur来做这个。\n(defn sum ([vals] (sum vals 0)) ([vals accumulating-total] (if (empty? vals) accumulating-total (recur (rest vals) (+ (first vals) accumulating-total))))) 如果你在一个小的集合上进行递归操作，使用recur并不重要，但如果你的集合包含数千或数百万个值，你肯定需要使用recur，这样你就不会因为堆栈溢出而使程序爆炸。\n最后一件事! 你可能会说，\u0026ldquo;等一下，如果我最终创造了成千上万的中间值怎么办？这不会因为垃圾收集或其他原因导致程序崩溃吗？\u0026rdquo;\n非常好的问题，鹰眼的读者! 答案是否定的。原因是，在幕后，Clojure 的不可变数据结构是使用结构共享实现的，这完全超出了本书的范围。这有点像 Git! 如果你想了解更多，请阅读这篇伟大的文章。http://hypirion.com/musings/understanding-persistent-vector-pt-1。\n函数组合而不是属性突变 你可能习惯于使用突变的另一种方式是建立起一个对象的最终状态。在下面的 Ruby 例子中，GlamourShotCaption对象使用突变来清理输入，删除尾部的空格并将`\u0026ldquo;lol \u0026ldquo;大写。\nclass GlamourShotCaption attr_reader :text def initialize(text) @text = text clean! end private def clean! text.trim! text.gsub!(/lol/, \u0026#34;LOL\u0026#34;) end end best = GlamourShotCaption.new(\u0026#34;My boa constrictor is so sassy lol! \u0026#34;) best.text ; =\u0026gt; \u0026#34;My boa constrictor is so sassy LOL!\u0026#34; 在这段代码中，GlamourShotCaption类封装了如何清理魅力镜头标题的知识。在创建GlamourShotCaption对象时，你将文本分配给一个实例变量，并逐步改变它。\n清单 5-1 显示了你如何在 Clojure 中做到这一点。\n(require \u0026#39;[clojure.string :as s]) (defn clean [text] (s/replace (s/trim text) #\u0026#34;lol\u0026#34; \u0026#34;LOL\u0026#34;)) (clean \u0026#34;My boa constrictor is so sassy lol! \u0026#34;) ; =\u0026gt; \u0026#34;My boa constrictor is so sassy LOL!\u0026#34;  5-1. 使用函数组合来修改一个迷人的镜头标题  在第一行，我们使用require来访问字符串函数库（我将在第六章讨论这个函数和相关概念）。除此之外，这段代码很简单。不需要变异。clean函数的工作方式是将一个不可变的值text传递给一个纯函数s/trim，该函数返回一个不可变的值（\u0026quot;我的蟒蛇真时髦 lol!\u0026quot;；字符串末尾的空格已经被修剪）。然后，该值被传递给纯函数s/replace，该函数返回另一个不可变的值（\u0026ldquo;我的蟒蛇是如此的时髦 LOL！\u0026quot;）。\n像这样组合函数\u0026ndash;使一个函数的返回值作为参数传递给另一个函数\u0026ndash;被称为函数组合。事实上，这与之前使用递归的例子并没有什么不同，因为递归不断地将一个函数的结果传递给另一个函数；它只是碰巧是同一个函数。一般来说，函数式编程鼓励你通过组合更简单的函数来建立更复杂的函数。\n这种比较也开始揭示了面向对象编程（OOP）的一些限制。在 OOP 中，类的主要目的之一是防止对私有数据进行不必要的修改\u0026ndash;这在不可变的数据结构中是没有必要的。你还必须将方法与类紧密结合，从而限制了方法的可重用性。在 Ruby 的例子中，你必须做额外的工作来重复使用clean!方法。在 Clojure 中，`clean\u0026rsquo;可以对任何字符串起作用。通过 a）将函数和数据解耦，以及 b）根据一组小的抽象进行编程，你最终会得到更多可重用的、可组合的代码。你获得了力量，却没有损失。\n除了直接的实际问题之外，你写面向对象的代码和函数式代码的方式之间的差异指向了两种思维方式之间更深层次的差异。编程是为了你自己邪恶的目的而操纵数据（就像你可以说它是关于任何东西）。在 OOP 中，你把数据看成是可以体现在一个对象中的东西，你戳戳点点，直到它看起来合适。在这个过程中，你的原始数据会永远丢失，除非你非常小心地保存它。相比之下，在函数式编程中，你认为数据是不变的，你从现有的数据中导出新的数据。在这个过程中，原始数据仍然安全无恙。在前面的 Clojure 例子中，原始标题不会被修改。它是安全的，就像当你把数字加在一起时是安全的一样；当你把 3 加进去时，你不会以某种方式把 4 变成 7。\n一旦你有信心使用不可变的数据结构来完成工作，你会感到更加自信，因为你不必担心有什么肮脏的代码会在你宝贵的、可变的变量上沾上油腻的爪子。这将是很好的!\n用纯函数做的酷事 你可以从现有的函数中派生出新的函数，就像你从现有的数据中派生出新的数据一样。你已经看到了一个函数，partial，它可以创建新的函数。本节将向你介绍另外两个函数, comp和memoize, 它们依赖于引用透明性, 不变性, 或两者兼有.\ncomp 像我们在上一节中所做的那样，对纯函数进行组合总是安全的，因为你只需要担心它们的输入/输出关系。组合函数是如此的普遍，以至于 Clojure 提供了一个函数comp，用于从任意数量的函数组合中创建一个新的函数。下面是一个简单的例子。\n((comp inc *) 2 3) ; =\u0026gt; 7 在这里，你通过组合inc和*函数来创建一个匿名函数。然后，你立即将这个函数应用于参数2和3。该函数将数字 2 和 3 相乘，然后将结果递增。使用数学符号，你会说，一般来说，对函数f1, f2, \u0026hellip; fn，创建一个新的函数g，使得g(x1, x2, \u0026hellip; xn)等于f1( f2( fn(x1, x2, \u0026hellip; xn))。这里需要注意的一个细节是，第一个应用的函数\u0026ndash;这里显示的代码中的*\u0026ndash;可以接受任何数量的参数，而其余的函数必须只能接受一个参数。\n下面是一个例子，说明如何使用comp来检索角色扮演游戏中的角色属性。\n(def character {:name \u0026#34;Smooches McCutes\u0026#34; :attributes {:intelligence 10 :strength 4 :dexterity 5}}) (def c-int (comp :intelligence :attributes)) (def c-str (comp :strength :attributes)) (def c-dex (comp :dexterity :attributes)) (c-int character) ; =\u0026gt; 10 (c-str character) ; =\u0026gt; 4 (c-dex character) ; =\u0026gt; 5 在这个例子中，你创建了三个函数来帮助你查询一个角色的属性。你可以不使用comp，而是为每个属性写成这样的东西。\n(fn [c] (:strength (:attributes c))) 但comp更优雅，因为它用更少的代码来表达更多的意思。当你看到 comp时，你立即知道所产生的函数的目的是以一种众所周知的方式组合现有的函数。\n如果你想组合的一个函数需要接受一个以上的参数，你会怎么做？你把它包在一个匿名函数中。请看下面这个片段，它根据你的角色的智力属性来计算她的法术槽的数量。\n(defn spell-slots [char］ (int (inc (/ (c-int char) 2)))) (spell-slots character) ; =\u0026gt; 6 首先，你用智力除以 2，然后加 1，然后用int函数来取整。下面是你如何用comp做同样的事情。\n(def spell-slots-comp (comp int inc #(/ % 2) c-int)) 要除以 2，你所要做的就是把除法包在一个匿名函数中。\nClojure 的comp函数可以组成任何数量的函数。为了了解它是如何做到这一点的，这里有一个实现，它只组合了两个函数。\n(defn two-comp [f g]. (fn [\u0026amp; args] (f (apply g args)))) 我鼓励你评估这段代码，并使用two-comp来组合两个函数! 另外，尝试重新实现 Clojure 的comp函数，这样你就可以组成任何数量的函数。\n记忆化 你可以用纯函数做的另一件很酷的事情是对它们进行备忘，这样 Clojure 就会记住某个特定函数调用的结果。你可以这样做，因为正如你前面所学到的，纯函数在指代上是透明的。例如，+是指代透明的。你可以把\n(+ 3 (+ 5 8)) 替换为\n(+ 3 13) 或\n16 而程序会有相同的行为。\nMemoization 让你通过存储传递给函数的参数和函数的返回值来利用引用的透明度。这样一来，以后用相同的参数调用该函数就可以立即返回结果。这对于需要大量时间运行的函数特别有用。例如，在这个没有备忘录的函数中，结果在一秒钟后被返回。\n(defn sleepy-identity \u0026#34;Returns the given value after 1 second\u0026#34; [x] (Thread/sleep 1000) x) (sleepy-identity \u0026#34;Mr. Fantastico\u0026#34;) ; =\u0026gt; \u0026#34;Mr. Fantastico\u0026#34; after 1 second (sleepy-identity \u0026#34;Mr. Fantastico\u0026#34;) ; =\u0026gt; \u0026#34;Mr. Fantastico\u0026#34; after 1 second 然而，如果你用memoize创建一个新的、记忆化的sleepy-identity版本，只有第一次调用会等待一秒钟；随后的每个函数调用会立即返回。\n(def memo-sleepy-identity (memoize sleepy-identity)) (memo-sleepy-identity \u0026#34;Mr. Fantastico\u0026#34;) ; =\u0026gt; \u0026#34;Mr. Fantastico\u0026#34; after 1 second (memo-sleepy-identity \u0026#34;Mr. Fantastico\u0026#34;) ; =\u0026gt; \u0026#34;Mr. Fantastico\u0026#34; immediately 很酷啊! 从这里开始，memo-sleepy-identity在调用`\u0026ldquo;Mr.Fantastico \u0026ldquo;时将不会产生最初的一秒钟的费用。这个实现对于那些计算密集型的函数或者提出网络请求的函数很有用。\nPeg Thing 是时候了! 是时候用你到目前为止所学到的一切来构建 Peg Thing 的终端实现了：不可变的数据结构、懒惰序列、纯函数、递归\u0026ndash;一切！这将有助于你理解如何将这些概念和技术结合起来解决更大的问题。这样做将帮助你理解如何结合这些概念和技术来解决更大的问题。最重要的是，你将学会如何对玩家的每一次移动所产生的变化进行建模，而不必像在 OOP 中那样对对象进行变异。\n为了构建游戏，你将首先学习游戏的机制以及如何启动和播放程序。然后，我将解释代码的组织。最后，我将对每个函数进行讲解。\n你可以在*https://www.nostarch.com/clojure/*找到 Peg Thing 的完整代码库。\n播放 如前所述，Peg Thing 是基于从古至今流传下来的秘密思维磨练工具，现在由 Cracker Barrel 发行。\n如果你不熟悉这个游戏，以下是游戏的机制。你开始时有一个三角形的棋盘，上面布满了钉子的孔，其中一个孔缺少一个钉子，如图 5-1 所示。\n图 5-1：Peg Thing 的初始设置\n游戏的目的是尽可能多地移除钉子。你通过*跳过钉子来实现这一目标。在图 5-2 中，图钉 A 跳过图钉 B 进入空洞，你就把图钉 B 从棋盘上移走。\nimg\n图 5-2：跳过一个钉子，把它从棋盘上移走。\n要启动 Peg Thing，请下载代码，然后在pegthing目录下的终端运行lein run。出现一个提示，看起来像这样。\nGet ready to play Peg Thing! How many rows? [5] 现在你可以输入棋盘的行数，使用5作为默认值。如果你想要五行，就按回车键（否则，输入一个数字并按回车键）。然后你会看到这个。\nHere\u0026#39;s your board: a0 b0 c0 d0 e0 f0 g0 h0 i0 j0 k0 l0 m0 n0 o0 Remove which peg? [e] 每个字母代表棋盘上的一个位置。数字0（应该是蓝色的，但如果不是，也没什么大不了的）表示一个位置被填满。在游戏开始之前，必须有一个钉子是空的，所以提示要求你输入第一个要移除的钉子的位置。默认是中间的钉子，`e'，但你可以选择一个不同的位置。移走棋子后，你会看到这个。\nHere\u0026#39;s your board: a0 b0 c0 d0 e- f0 g0 h0 i0 j0 k0 l0 m0 n0 o0 Move from where to where? Enter two letters: 注意，e位置现在有一个破折号，-（应该是红色的，但如果不是，也没什么大不了的）。这个破折号表示这个位置是空的。要移动，你要输入你想*拿起的棋子的位置，然后是你想把它放在的空位置的位置。例如，如果你输入`le'，你会得到这样的结果。\nHere\u0026#39;s your board: a0 b0 c0 d0 e0 f0 g0 h- i0 j0 k0 l- m0 n0 o0 Move from where to where? Enter two letters: 你把棋子从l移到e，跳过h，根据图 5-2 所示的规则移走它的棋子。游戏继续提示你走棋，直到没有棋子可用为止，这时它就会提示你再次下棋。\n代码组织 该程序必须处理四个主要任务，源代码也相应地组织起来，每个任务的函数都归为一组。\n 创建一个新的棋盘 返回一个带有棋手行动结果的棋盘 用文字表示棋盘 处理用户互动  关于组织结构还有两点。首先，代码有一个基本的架构，或概念性的组织，由两层组成。顶层由处理用户交互的函数组成。这些函数产生了程序的所有副作用，打印出棋盘并为玩家的互动提供提示。这一层的函数使用底层的函数来创建一个新的棋盘，进行移动，并创建一个文本表述，但底层的函数完全不使用顶层的函数。即使是这么小的程序，一个小小的架构也有助于使代码更容易管理。\n第二，我尽可能地将任务分解成小的函数，以便每个函数都做一个微小的、可理解的任务。其中一些函数只被另外一个函数使用。我发现这很有帮助，因为它可以让我为每个微小的子任务命名，使我能够更好地表达代码的意图。\n但在所有的架构之前，还有这个。\n(ns pegthing.core (require [clojure.set :as set]) (:gen-class)) (declare successful-move prompt-move game-over query-rows) 我将在第六章详细解释这里的函数。如果你好奇这是怎么回事，简短的解释是：(require [clojure.set :as set])允许你轻松使用clojure.set命名空间的函数，(:gen-class)允许你从命令行运行程序，(declaration successful-move prompt-move game-over query-rows)允许函数在被定义之前引用这些名称。如果这还不太明白，相信我很快就会解释。\n创建棋盘 你用来表示棋盘的数据结构应该使你能够很容易地打印棋盘，检查棋手是否下了一步有效的棋，实际执行一步棋，以及检查游戏是否结束。你可以用很多方式来构造棋盘，以实现这些任务。在这种情况下，你将用一个 Map 来表示棋盘，Map 上有对应于每个棋盘位置的数字键和包含该位置连接信息的值。该 Map 还将包含一个:rows键，存储行的总数。图 5-3 显示了一个有每个位置编号的棋盘。\n图 5-3：有编号的钉子板\n下面是为表示它而建立的数据结构。\n{1 {:pegged true, :connections {6 3, 4 2}}, 2 {:pegged true, :connections {9 5, 7 4}}, 3 {:pegged true, :connections {10 6, 8 5}}, 4 {:pegged true, :connections {13 8, 11 7, 6 5, 1 2}}, 5 {:pegged true, :connections {14 9, 12 8}}, 6 {:pegged true, :connections {15 10, 13 9, 4 5, 1 3}}, 7 {:pegged true, :connections {9 8, 2 4}}, 8 {:pegged true, :connections {10 9, 3 5}}, 9 {:pegged true, :connections {7 8, 2 5}}, 10 {:pegged true, :connections {8 9, 3 6}}, 11 {:pegged true, :connections {13 12, 4 7}}, 12 {:pegged true, :connections {14 13, 5 8}}, 13 {:pegged true, :connections {15 14, 11 12, 6 9, 4 8}}, 14 {:pegged true, :connections {12 13, 5 9}}, 15 {:pegged true, :connections {13 14, 6 10}}, :rows 5} 你可能会想，为什么在你玩游戏的时候，每个位置都用字母表示，而在这里，位置却用数字表示。使用数字作为内部表示，可以让你在验证和下棋时利用棋盘布局的一些数学特性。另一方面，字母则更适合于显示，因为它们只占用一个字符空间。一些转换函数在第 120 页的 \u0026ldquo;渲染和打印棋盘\u0026rdquo;中有所介绍。\n在数据结构中，每个位置都与一个 Map 相关联，其内容是这样的。\n{:pegged true, :connection {6 3, 4 2}}. pegged \u0026ldquo;的含义很清楚；它表示该位置是否有一个钉子。`:connections\u0026rsquo;就比较隐蔽了。它是一个 Map，每个键标识一个合法的目的地，每个值代表将被跳过的位置。例如，位置 1 的棋子可以跳到*位置 6，越过位置 3。这可能看起来很落后，但当你看到棋步验证是如何实现的时候，你就会明白其中的道理。\n现在你已经看到了代表棋盘的最终 Map 应该是什么样子的，我们可以开始探索在程序中实际建立这个 Map 的函数了。你不会简单地开始随意地分配可变状态来表示每个位置以及它是否被钉住。相反，你将使用嵌套的递归函数调用来逐个建立最终的棋盘位置。这类似于你之前创建魅力镜头标题的方式，通过将参数传递给一连串的函数，从输入中获得新的数据，从而得到最终结果。\n本节代码中的前几个表达式是关于三角形数的。三角形数是由前n个自然数相加产生的。第一个三角数是 1，第二个是 3（1+2），第三个是 6（1+2+3），以此类推。这些数字很好地与棋盘上每一行末尾的位置数字相一致，这将成为一个非常有用的属性。首先，你定义了函数tri*，它可以创建一个三角形数字的懒散序列。\n(defn tri* \u0026#34;Generates lazy sequence of triangular numbers\u0026#34; ([] (tri* 0 1)) ([sum n] (let [new-sum (+ sum n)] (cons new-sum (lazy-seq (tri* new-sum (inc n))))))) 快速回顾一下工作原理，调用没有参数的tri*会递归调用(tri* 0 1)。这将返回一个懒惰列表，其元素是 \u0026ldquo;new-sum\u0026rdquo;，在本例中它的值为 \u0026ldquo;1\u0026rdquo;。懒惰列表包括一个配方，用于在请求时生成列表的下一个元素，如第四章所述。\n下一个表达式调用tri*，实际上是创建懒惰序列并将其绑定到tri。\n(def tri (tri*)) 你可以验证它是否真的有效。\n(take 5 tri) ; =\u0026gt; (1 3 6 10 15) 接下来的几个函数对三角形数的序列进行操作。triangular?找出它的参数是否在tri懒惰序列中。它通过使用take-while创建一个三角形数列，其最后一个元素是一个小于或等于参数的三角形数。然后它将最后一个元素与参数进行比较。\n(defn triangular? \u0026#34;Is the number triangular? e.g. 1, 3, 6, 10, 15, etc\u0026#34; [n] (= n (last (take-while #(\u0026gt;= n %) tri)))) (triangular? 5) ; =\u0026gt; false (triangular? 6) ; =\u0026gt; true 接下来是row-tri，它接收一个行号，并给出该行末尾的三角形数字。\n(defn row-tri \u0026#34;The triangular number at the end of row n\u0026#34; [n] (last (take n tri))) (row-tri 1) ; =\u0026gt; 1 (row-tri 2) ; =\u0026gt; 3 (row-tri 3) ; =\u0026gt; 6 最后，还有row-num，它接收一个棋盘位置，并返回它所属的行。\n(defn row-num \u0026#34;Returns row number the position belongs to: pos 1 in row 1, positions 2 and 3 in row 2, etc\u0026#34; [pos] (inc (count (take-while #(\u0026gt; pos %) tri)))) (row-num 1) ; =\u0026gt; 1 (row-num 5) ; =\u0026gt; 3 之后是connect，它被用来在两个位置之间实际形成相互连接。\n(defn connect \u0026#34;Form a mutual connection between two positions\u0026#34; [board max-pos pos neighbor destination] (if (\u0026lt;= destination max-pos) (reduce (fn [new-board [p1 p2]] (assoc-in new-board [p1 :connections p2] neighbor)) board [[pos destination] [destination pos]]) board)) (connect {} 15 1 2 4) ; =\u0026gt; {1 {:connections {4 2}} 4 {:connections {1 2}}} connect做的第一件事是检查目的地是否真的是棋盘上的一个位置，确认它是否小于棋盘的最大位置。例如，如果你有五行，最大位置是 15。然而，当游戏棋盘被创建时，connect函数将被调用，参数为(connect {} 15 7 16 22)。connect开头的if语句确保你的程序不允许这种离谱的连接，当你要求它做一些愚蠢的事情时，它只是返回未修改的棋盘。\n接下来，connect通过reduce使用递归，逐步建立起棋盘的最终状态。在这个例子中，你正在减少嵌套 Vector[[1 4] [4 1]]。这就是允许你返回一个更新的棋盘，pos\u0026rsquo;和`destination'（1 和 4）在它们的连接中都指向对方。\n传给reduce的匿名函数使用了一个你以前没有见过的函数assoc-in。函数get-in可以让你在嵌套的 Map 中查找值，而assoc-in可以让你在指定的嵌套中返回一个带有给定值的新 Map。下面是几个例子。\n(assoc-in {} [:cookie :monster :vocals] \u0026#34;Finntroll\u0026#34;) ; =\u0026gt; {:cookie {:monster {:vocals \u0026#34;Finntroll\u0026#34;}}} (get-in {:cookie {:monster {:vocals \u0026#34;Finntroll\u0026#34;}}} [:cookie :monster]) ; =\u0026gt; {:vocals \u0026#34;Finntroll\u0026#34;} (assoc-in {} [1 :connections 4] 2) ; =\u0026gt; {1 {:connections {4 2}}} 在这些例子中，你可以看到，新的、嵌套的 Map 被创建，以适应所有提供的键。\n现在我们有了一个连接两个位置的方法，但程序首先应该如何选择两个位置来连接呢？这由connect-right、connect-down-left和connect-down-right来处理。\n(defn connect-right [board max-pos pos] (let [neighbor (inc pos) destination (inc neighbor)] (if-not (or (triangular? neighbor) (triangular? pos)) (connect board max-pos pos neighbor destination) board))) (defn connect-down-left [board max-pos pos] (let [row (row-num pos) neighbor (+ row pos) destination (+ 1 row neighbor)] (connect board max-pos pos neighbor destination))) (defn connect-down-right [board max-pos pos] (let [row (row-num pos) neighbor (+ 1 row pos) destination (+ 2 row neighbor)] (connect board max-pos pos neighbor destination))) 这些函数分别取了棋盘的最大位置和一个棋盘的位置，并使用一个小的三角形数学来计算出哪些数字要送入connect。例如，connect-down-left将试图连接位置 1 和位置 4。如果你想知道为什么没有定义connect-left、connect-up-left和connect-up-right函数，原因是现有的函数实际上涵盖了这些情况。connect返回一个建立了相互连接的棋盘；当 4向右连接到 6 时，6向左连接到 4。 下面是几个例子。\n(connect-down-left {} 15 1) ; =\u0026gt; {1 {:connections {4 2} 4 {:connections {1 2}}}} (connect-down-right {} 15 3) ; =\u0026gt; {3 {:connections {10 6}} 10 {:connections {3 6}}} 在第一个例子中，connect-down-left接收一个最大位置为15的空棋盘，并返回一个新的棋盘，该棋盘上有1和它下面及左边的位置之间的相互连接。connect-down-right做了类似的事情，返回一个由 3 和它下面及右边的位置之间的相互连接组成的棋盘。\n下一个函数，`add-pos'，很有趣，因为它实际上是在一个函数的 Vector 上进行还原，依次应用每个函数来建立结果的棋盘。但它首先更新棋盘，以表示一个棋子在给定的位置上。\n(defn add-pos \u0026#34;Pegs the position and performs connections\u0026#34; [board max-pos pos] (let [pegged-board (assoc-in board [pos :pegged] true)] (reduce (fn [new-board connection-creation-fn] (connection-creation-fn new-board max-pos pos)) pegged-board [connect-right connect-down-left connect-down-right]))) (add-pos {} 15 1) {1 {:connections {6 3, 4 2}, :pegged true} 4 {:connections {1 2}} 6 {:connections {1 3}}} 就像这个函数首先在pegged-board绑定中说：\u0026ldquo;在棋盘的 X 位置添加一个钉子。\u0026rdquo; 然后，在 \u0026ldquo;reduce \u0026ldquo;中，它说：\u0026ldquo;在 X 的位置上采取新钉子的棋盘，并尝试将 X 的位置连接到一个合法的、向右的位置。取该操作产生的棋盘，并尝试将位置 X 连接到一个合法的、向左下方的位置。最后，取该*操作产生的棋盘，并尝试将位置 X 连接到合法的右下位置。返回所得到的棋盘\u0026rdquo;。\n像这样对函数进行还原是组成函数的另一种方式。为了说明这一点，下面是清单 5-1（第 103 页）中定义clean函数的另一种方式。\n(defn clean [text] (reduce (fn [string string-fn] (string-fn string)) text [s/trim #(s/replace % #\u0026#34;lol\u0026#34; \u0026#34;LOL\u0026#34;)])) 这个对clean的重新定义减少了一个函数 Vector，将第一个函数s/trim应用于初始字符串，然后将下一个函数，匿名函数#(s/replace % #\u0026quot;lol\u0026quot; \u0026quot;LOL\u0026quot;)，应用于结果。\n对一个函数集合进行缩减并不是一个你经常使用的技术，但它偶尔会很有用，而且它显示了函数式编程的多函数性。\n最后一个创建棋盘的函数是new-board。\n(defn new-board \u0026#34;Creates a new board with the given number of rows\u0026#34; [rows] (let [initial-board {:rows rows} max-pos (row-tri rows)] (reduce (fn [board pos] (add-pos board max-pos pos)) initial-board (range 1 (inc max-pos))))) 这段代码首先创建了初始的、空的棋盘，并得到了最大的位置。假设你使用的是 5 行，最大位置将是 15。接下来，该函数使用(range 1 (inc max-pos))得到一个从 1 到 15 的数字列表，也就是棋盘的位置。最后，它对位置列表进行还原。缩减的每一次迭代都会调用(add-pos board max-pos pos)，正如你前面所看到的，它获取一个现有的棋盘，并返回一个新的棋盘，并添加位置。\n移动图钉 下一节代码将验证并执行钉子的移动。许多函数（pegged?, remove-peg, place-peg, move-peg）都是简单的、不言自明的单行代码。\n(defn pegged? \u0026#34;Does the position have a peg in it?\u0026#34; [board pos] (get-in board [pos :pegged])) (defn remove-peg \u0026#34;Take the peg at given position out of the board\u0026#34; [board pos] (assoc-in board [pos :pegged] false)) (defn place-peg \u0026#34;Put a peg in the board at given position\u0026#34; [board pos] (assoc-in board [pos :pegged] true)) (defn move-peg \u0026#34;Take peg out of p1 and place it in p2\u0026#34; [board p1 p2] (place-peg (remove-peg board p1) p2)) 让我们花点时间来欣赏一下这段代码是多么的整洁。在面向对象的程序中，你通常会在这里进行突变；毕竟，你还能如何改变棋盘？然而，这些都是纯函数，而且它们很好地完成了工作。我还喜欢你不需要类的开销来使用这些小家伙。这样的编程感觉更轻松。\n接下来是valid-moves。\n(defn valid-moves \u0026#34;Return a map of all valid moves for pos, where the key is the destination and the value is the jumped position\u0026#34; [board pos] (into {} (filter (fn [[destination jumped]] (and (not (pegged? board destination)) (pegged? board jumped))) (get-in board [pos :connections])))) 这段代码浏览了给定位置的每个连接，并测试目的地位置是否为空，跳转的位置是否有钉子。为了看到这个动作，你可以创建一个 4 号位置为空的棋盘。\n(def my-board (assoc-in (new-board 5) [4 :pegged] false)) 图 5-4 显示了这个棋盘的样子。\n图 5-4：4 号位置为空的钉子板\n考虑到这个棋盘，1、6、11 和 13 位有有效的棋步，但其他位置都没有。\n(valid-moves my-board 1) ; =\u0026gt; {4 2} (valid-moves my-board 6) ; =\u0026gt; {4 5} (valid-moves my-board 11) ; =\u0026gt; {4 7} (valid-moves my-board 5) ; =\u0026gt; {} (valid-moves my-board 8) ; =\u0026gt; {} 你可能想知道为什么valid-moves会返回一个 Map 而不是一个集合或 Vector。原因是，返回 Map 允许你轻松地查找目标位置，以检查特定的棋步是否有效，这就是valid-move?（下一个函数）的作用。\n(defn valid-move? \u0026#34;Return jumped position if the move from p1 to p2 is valid, nil otherwise\u0026#34; [board p1 p2] (get (valid-moves board p1) p2)) (valid-move? my-board 8 4) ; =\u0026gt; nil (valid-move? my-board 1 4) ; =\u0026gt; 2 注意，valid-move?从 Map 上查找目标位置，然后返回将被跳过的钉子的位置。这是让valid-moves返回 Map 的另一个很好的好处，因为从 Map 中获取的跳跃位置正是我们想要传递给下一个函数make-move的东西。当你花时间构建一个丰富的数据结构时，执行有用的操作会更容易。\n(defn make-move \u0026#34;Move peg from p1 to p2, removing jumped peg\u0026#34; [board p1 p2] (if-let [jumped (valid-move? board p1 p2)] (move-peg (remove-peg board jumped) p1 p2))) if-let是一种很好的方式，表示 \u0026ldquo;如果一个表达式评估为一个真实的值，那么就把这个值绑定到一个名字上，就像我在let表达式中一样。否则，如果我提供了一个 \u0026ldquo;else \u0026ldquo;子句，就执行该 \u0026ldquo;else \u0026ldquo;子句；如果我没有提供 \u0026ldquo;else \u0026ldquo;子句，就返回 \u0026ldquo;nil\u0026rdquo;。在这种情况下，测试表达式是(valid-move? board p1 p2)，如果结果是真实的，你要把结果分配给jumped这个名字。这将用于调用move-peg，它将返回一个新棋盘。你没有提供 \u0026ldquo;else \u0026ldquo;子句，所以如果移动无效，整个表达式的返回值为 \u0026ldquo;nil\u0026rdquo;。\n最后，函数`can-move? 是用来确定游戏是否结束的，方法是找到第一个有棋步的钉子位置。\n(defn can-move? \u0026#34;Do any of the pegged positions have valid moves?\u0026#34; [board] (some (comp not-empty (partial valid-moves board)) (map first (filter #(get (second %) :pegged) board)))) 这个函数名称末尾的问号表明它是一个谓词函数，这个函数是为了在布尔表达式中使用。谓词取自谓词逻辑，它关注的是确定一个语句是真还是假。(你已经看到了一些内置的谓词函数，如empty?和every?。)\ncan-move?的工作原理是通过(map first (filter #(get (second %) :pegged) board))获得一个所有挂点的序列。你可以将其进一步分解为filter'和map\u0026rsquo;的函数调用：因为filter'是一个seq函数，它将board'，一个 Map，转换成一个两元素 Vector 的 seq（也称为tuples），看起来像这样。\n([1 {:connection {6 3, 4 2}, :pegged true}) [2 {:connections {9 5, 7 4}, :pegged true}]) 元组的第一个元素是一个位置号，第二个元素是该位置的信息。filter然后将匿名函数#(get (second %) :pegged)应用于这些元组中的每一个，过滤掉那些位置信息表明该位置目前没有挂点的元组。最后，结果被传递给map，它在每个元组上调用first，只从元组中抓取位置号。\n当你得到一连串的钉子位置号码后，你对每个位置调用一个谓词函数，找到第一个返回真值的位置。这个谓词函数是用(comp not-empty (partial valid-moves board))创建的。我们的想法是首先返回一个位置的所有有效棋步的 Map，然后测试该 Map 是否为空。\n首先，表达式(partial valid-moves board)从valid-moves派生出一个匿名函数，第一个参数board用partial填入（因为你每次调用valid-moves时使用的是同一个棋盘）。这个新函数可以接受一个位置，并返回它在当前棋盘上的所有有效棋步的 Map。\n第二，你用comp将这个函数与not-empty组成。这个函数是自述的；如果给定的集合是空的，它返回 \u0026ldquo;true\u0026rdquo;，否则返回 \u0026ldquo;false\u0026rdquo;。\n这段代码最有趣的地方在于，你在使用一个函数链来推导一个新的函数，类似于你使用函数链来推导新的数据。在第三章中，你了解到 Clojure 将函数视为数据，因为函数可以接收函数作为参数并返回。希望这能说明为什么这个函数是有趣和有用的。\n渲染和打印棋盘 在棋盘表示和打印部分的前几个表达式只是定义常数。\n(def alpha-start 97) (def alpha-end 123) (def letters (map (comp str char) (range alpha-start alpha-end) )) (def pos-chars 3) 绑定 \u0026ldquo;alpha-start \u0026ldquo;和 \u0026ldquo;alpha-end \u0026ldquo;为字母a到z设定了数值的开始和结束。我们用这些来建立一个 \u0026ldquo;字母 \u0026ldquo;的序列。char，当应用于一个整数时，返回该整数对应的字符，str将char变成一个字符串。pos-chars被函数row-padding使用，以确定在每一行的开头增加多少间距。接下来的几个定义，ansi-styles，ansi，和colorize向终端输出彩色文本。\n函数render-pos, row-positions, row-padding, 和render-row创建字符串来表示棋盘。\n(defn render-pos [board pos] (str (nth letters (dec pos)) (if (get-in board [pos :pegged]) (colorize \u0026#34;0\u0026#34; :blue) (colorize \u0026#34;-\u0026#34; :red)))) (defn row-positions \u0026#34;Return all positions in the given row\u0026#34; [row-num] (range (inc (or (row-tri (dec row-num)) 0)) (inc (row-tri row-num)))) (defn row-padding \u0026#34;String of spaces to add to the beginning of a row to center it\u0026#34; [row-num rows] (let [pad-length (/ (* (- rows row-num) pos-chars) 2)] (apply str (take pad-length (repeat \u0026#34; \u0026#34;))))) (defn render-row [board row-num] (str (row-padding row-num (:rows board)) (clojure.string/join \u0026#34; \u0026#34; (map (partial render-pos board) (row-positions row-num))))) 如果你从下往上看，你可以看到render-row调用它上面的每个函数来返回给定行的字符串表示。注意表达式(map (partial render-pos board) (row-positions row-num))。这展示了部分函数的一个很好的用例，即多次应用同一函数，并填入一个或多个参数，就像前面展示的can-move?函数一样。\n还请注意，`render-pos\u0026rsquo;使用字母而不是数字来标识每个位置。这在棋盘显示时节省了一点空间，因为它允许每个位置只有一个字符来表示一个五行棋盘。\n最后，print-board只是用doseq遍历每一行的编号，打印该行的字符串表示。\n(defn print-board [board] (doseq [row-num (range 1 (inc (:rows board)))] (println (render-row board row-num)))) 当你想对一个集合中的元素进行副作用的操作（比如打印到终端）时，你可以使用doseq。紧跟在名字doseq后面的 Vector 描述了如何将一个集合中的所有元素逐一绑定到一个名字上，以便你可以对它们进行操作。在这个例子中，你要把数字 1 到 5（假设有五行）分配给row-num这个名字，这样你就可以打印每一行。\n虽然打印棋盘在技术上属于交互，但我想在这里用渲染函数来展示它。当我第一次开始写这个游戏时，print-board函数也生成了棋盘的字符串表示。然而，现在print-board将所有的渲染工作推迟到纯函数，这使得代码更容易理解，并减少了我们不纯函数的表面积。\n玩家互动 下一个函数集合处理玩家互动。首先，有letter-\u0026gt;pos，它将字母（这是玩家显示和识别位置的方式）转换为相应的位置编号。\n(defn letter-\u0026gt;pos \u0026#34;Converts a letter string to the corresponding position number\u0026#34; [letter] (inc (- (int (first letter)) alpha-start))) 接下来，辅助函数get-input允许你读取和清理玩家的输入。你也可以提供一个默认值，如果玩家没有输入任何东西就按下回车键，就会使用这个值。\n(defn get-input \u0026#34;Waits for user to enter text and hit enter, then cleans the input\u0026#34; ([] (get-input nil)) ([default] (let [input (clojure.string/trim (read-line))] (if (empty? input) default (clojure.string/lower-case input))))) 下一个函数，characters-as-strings，是一个很小的辅助函数，被prompt-move用来接收一个字符串并返回一个字母集合，所有非字母的输入都被丢弃。\n(characters-as-strings \u0026#34;a b\u0026#34;) ; =\u0026gt; (\u0026#34;a\u0026#34; \u0026#34;b\u0026#34;) (characters-as-strings \u0026#34;a cb\u0026#34;) ; =\u0026gt; (\u0026#34;a\u0026#34; \u0026#34;c\u0026#34; \u0026#34;b\u0026#34;) 接下来，prompt-move读取玩家的输入，并对其采取行动。\n(defn prompt-move [board] (println \u0026#34;\\nHere\u0026#39;s your board:\u0026#34;) (print-board board) (println \u0026#34;Move from where to where? Enter two letters:\u0026#34;) (let [input (map letter-\u0026gt;pos (characters-as-strings (get-input)))] (if-let [new-board (make-move➊ board (first input) (second input))] (user-entered-valid-move new-board) (user-entered-invalid-move board)))) 在➊，如果棋手的棋步无效，make-move返回nil，你用user-entered-invalid-move函数来通知她的错误。你将未经修改的棋盘传递给user-entered-invalid-move，这样它就可以用棋盘再次提示棋手。下面是函数的定义。\n(defn user-entered-invalid-move \u0026#34;Handles the next step after a user has entered an invalid move\u0026#34; [board] (println \u0026#34;\\n!!! That was an invalid move :(\\n\u0026#34;) (prompt-move board)) 然而，如果这步棋是有效的，\u0026ldquo;new-board \u0026ldquo;将被传递给 \u0026ldquo;user-entered-valid-move\u0026rdquo;，如果还有棋步要走，它将控制权交还给 \u0026ldquo;prompt-move\u0026rdquo;。\n(defn user-entered-valid-move \u0026#34;Handles the next step after a user has entered a valid move\u0026#34; [board] (if (can-move? board) (prompt-move board) (game-over board))) 在我们的棋盘创建函数中，我们看到递归是如何使用不可变的数据结构来建立一个值的。同样的事情也发生在这里，只是它涉及两个相互递归的函数和一些用户输入。没有看到可变的属性!\n游戏结束后会发生什么？这就是所发生的事情。\n(defn game-over \u0026#34;Announce the game is over and prompt to play again\u0026#34; [board] (let [remaining-pegs (count (filter :pegged (vals board)))] (println \u0026#34;Game over! You had\u0026#34; remaining-pegs \u0026#34;pegs left:\u0026#34;) (print-board board) (println \u0026#34;Play again? y/n [y]\u0026#34;) (let [input (get-input \u0026#34;y\u0026#34;)] (if (= \u0026#34;y\u0026#34; input) (prompt-rows) (do (println \u0026#34;Bye!\u0026#34;) (System/exit 0)))))) 这里发生的所有事情是，游戏告诉你你的表现，打印出最后的棋盘，并提示你再玩一次。如果你选择y，游戏就会调用prompt-rows，这就给我们带来了最后一组函数，用来开始新的游戏。\n(defn prompt-empty-peg [board] (println \u0026#34;Here\u0026#39;s your board:\u0026#34;) (print-board board) (println \u0026#34;Remove which peg? [e]\u0026#34;) (prompt-move (remove-peg board (letter-\u0026gt;pos (get-input \u0026#34;e\u0026#34;))))) (defn prompt-rows [] (println \u0026#34;How many rows? [5]\u0026#34;) (let [rows (Integer. (get-input 5)) board (new-board rows)] (prompt-empty-peg board))) 你使用prompt-rows开始游戏，让玩家输入要包括多少行。然后你把控制权交给prompt-empty-peg，这样玩家就可以告诉游戏要先移除哪个钉子。从这里开始，程序提示你走棋，直到没有任何棋步。\n尽管这个程序的所有副作用都是相对无害的（你所做的只是提示和打印），但像这样将它们封存在自己的函数中是函数式编程的最佳实践。一般来说，如果你能确定哪些函数是透明的、无副作用的，并将这些函数放在自己的函数中，你将从函数式编程中获得更多的好处。这些函数不可能在你的程序的不相关部分引起奇怪的错误。它们更容易在 REPL 中测试和开发，因为它们只依赖于你传递给它们的参数，而不是一些复杂的隐藏状态对象。\n总结 纯函数在本质上是透明的，并且没有副作用，这使得它们很容易被推理。为了从 Clojure 中获得最大的收益，请尽量减少不纯函数的使用。在一个不可变的世界里，你可以使用递归而不是for/while循环，使用函数组合而不是连续的突变。纯函数允许强大的技术，如函数组合函数和备忘化。它们也是超级有趣的!\n练习 发展函数式编程技能的最好方法之一是尝试实现现有的函数。为此，下面的大多数练习都建议你实现一个函数，但不要止步于此；通过 Clojure 小抄（http://clojure.org/cheatsheet/），可以挑选更多的函数\n 你用(comp :intelligence :attribute)创建了一个函数来返回一个角色的智力。创建一个新的函数，attr，你可以像(attr :intelligence)那样调用它，做同样的事情。 实现comp函数。 实现assoc-in函数。提示：使用assoc函数并将其参数定义为[m [k \u0026amp; ks] v]。 查阅并使用update-in函数。 实现 \u0026ldquo;update-in\u0026rdquo;。  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter5/","summary":"函数式编程 到目前为止，你已经专注于熟悉 Clojure 提供的工具：不可变的数据结构、函数、抽象，等等。在这一章中，你将学习如何思考你的编程任务，以最好的方式利用这些工具。你将开始把你的经验整合到一个新的函数式编程思维中。\n你将学到的核心概念包括：什么是纯函数，为什么它们很有用；如何使用不可变的数据结构，为什么它们比可变的表亲更有优势；如何将数据和函数分开，给你带来更多的力量和灵活性；以及为什么对一小部分数据抽象进行编程会很强大。一旦你把所有这些知识塞进你的大脑，你就会有一个全新的解决问题的方法\n在学习了这些主题之后，你将通过编写一个基于终端的游戏来运用你所学到的一切，这个游戏的灵感来自于美国各地 Cracker Barrel 餐馆中的一种古老而神秘的思维训练装置。Peg Thing!\n纯函数：什么和为什么 除了 \u0026ldquo;println \u0026ldquo;和 \u0026ldquo;rand\u0026rdquo;，到目前为止，你所使用的所有函数都是纯函数。是什么使它们成为纯函数，为什么会有这样的问题？如果一个函数符合两个条件，它就是纯函数。\n 如果给出相同的参数，它总是返回相同的结果。这被称为引用透明度，你可以把它添加到你的 5 美元编程术语列表中。 它不能引起任何副作用。也就是说，该函数不能做出任何在函数本身之外可以观察到的改变\u0026ndash;例如，通过改变一个外部可访问的可改变对象或写到一个文件。  这些特性使你更容易推理你的程序，因为这些函数是完全隔离的，无法影响你系统的其他部分。当你使用它们时，你不必问自己，\u0026ldquo;我调用这个函数会破坏什么？\u0026rdquo; 它们也是一致的：你永远不需要搞清楚为什么给一个函数传递相同的参数会导致不同的返回值，因为这永远不会发生。\n纯函数和算术一样稳定，没有问题（你最后一次为两个数字相加而烦恼是什么时候？） 它们是巨大的函数小砖块，你可以自信地将其作为你程序的基础。让我们更详细地看看引用透明性和无副作用，看看它们到底是什么，以及它们是如何发挥作用的。\n纯函数是引用透明的 为了在调用相同参数时返回相同的结果，纯函数只依靠 1）自己的参数和 2）不可变的值来决定其返回值。例如，数学函数是引用透明的。\n(+ 1 2) ; =\u0026gt; 3 如果一个函数依赖于一个不可变的值，那么它就是引用透明的。字符串`\u0026rdquo;, Daniel-san \u0026ldquo;是不可变的，所以下面的函数也是引用透明的。\n(defn wisdom [words] (str words \u0026#34;, Daniel-san\u0026#34;)) (wisdom \u0026#34;Always bathe on Fridays\u0026#34;) ; =\u0026gt; \u0026#34;Always bathe on Fridays, Daniel-san\u0026#34; 相比之下，下面的函数在相同的参数下不会产生相同的结果；因此，它们在指称上是不透明的。任何依赖随机数生成器的函数都不可能是指称透明的。\n(defn year-end-evaluation [] (if (\u0026gt; (rand) 0.5) \u0026#34;You get a raise!\u0026#34; \u0026#34;Better luck next year!","title":"Chapter5 函数式编程"},{"content":"核心函数的深入研究 如果你像我一样是焦虑的、以青少年为中心的准肥皂剧*《吸血鬼日记》的超级粉丝，你一定记得主角埃琳娜开始质疑她苍白的、神秘的暗恋者的行为的那一集。\u0026ldquo;为什么当我的膝盖被刮伤时，他立刻消失得无影无踪？\u0026ldquo;和 \u0026ldquo;为什么当我的手指被划破时，他的脸变成了一个怪异的死亡面具？\u0026ldquo;等等。\n如果你已经开始玩 Clojure 的核心函数，你可能也会问自己类似的问题。\u0026ldquo;为什么map'会返回一个列表，而我给它的是一个Vector？\u0026quot;和 \u0026quot;为什么reduce\u0026rsquo;会把我的 map 当成一个 Vector 列表？\u0026ldquo;等等。(不过，有了 Clojure，你至少可以免于思考作为一个 17 岁孩子的深刻的存在恐惧，直到永远）。\n在这一章中，你将了解到 Clojure 的深邃、黑暗、嗜血、超自然的****，我的意思是，在这一章中，你将了解到 Clojure 的编程到抽象的基本概念以及序列和集合的抽象。你还会了解到疯狂的序列*。这将为你提供所需的基础，使你能够阅读你以前没有使用过的函数的文档，并理解当你试着使用它们时发生了什么。\n接下来，你将获得更多关于你最需要使用的函数的经验。你将学习如何用函数map、reduce、into、conj、concat、some、filter、take、drop、sort、sort-by和identity来处理列表、Vector、Map 和集合。你还将学习如何用apply、partial和complement创建新的函数。所有这些信息将帮助你了解如何以 Clojure 的方式做事，它将为你编写自己的代码以及阅读和学习他人的项目打下坚实的基础。\n最后，你将学会如何解析和查询 CSV 中的吸血鬼数据，以确定在你的家乡潜伏着哪些诺斯费拉图。\n从编程到抽象 为了理解对抽象的编程，让我们把 Clojure 与一种没有考虑到这个原则的语言进行比较。Emacs Lisp（elisp）。在 elisp 中，你可以使用mapcar函数来导出一个新的列表，这与你在 Clojure 中使用map的方式相似。然而，如果你想在 elisp 中 Map 一个哈希图（类似于 Clojure 的 map 数据结构），你需要使用maphash函数，而在 Clojure 中你仍然可以只使用map。换句话说，elisp 使用两个不同的、针对数据结构的函数来实现map操作，而 Clojure 只使用一个。你也可以在 Clojure 中对 map 调用reduce，而 elisp 并没有提供一个函数来减少散列 map。\n原因是 Clojure 在*序列抽象方面定义了map和reduce函数，而不是在具体的数据结构方面。只要数据结构响应核心序列操作（函数first'、rest\u0026rsquo;和cons'，我们稍后会仔细研究），它就能与map'、`reduce\u0026rsquo;以及其他大量的序列函数免费工作。这就是 Clojurists 所说的抽象编程，也是 Clojure 哲学的一个核心原则。\n我认为抽象是操作的命名集合。如果你能在一个对象上执行一个抽象的所有操作，那么这个对象就是该抽象的一个实例。我甚至在编程之外也是这样想的。例如，电池抽象包括 \u0026ldquo;将导电介质连接到其阳极和阴极 \u0026ldquo;的操作，而该操作的输出是电流。电池是用锂还是用土豆做的并不重要。只要它对定义电池的一系列操作做出反应，它就是一个电池。\n同样地，map并不关心列表、Vector、集合和 Map 是如何实现的。它只关心它是否能对它们进行序列操作。让我们看看map是如何在序列抽象中定义的，这样你就能理解一般的抽象编程。\n把列表、Vector、集合和 Map 当作序列对待 如果你把map操作独立于任何编程语言，甚至是编程，它的基本行为是用一个函数ƒ从现有的序列x导出一个新的序列y，这样y1 = ƒ(x1), y2 = ƒ(x2), . . yn = ƒ(xn)。图 4-1 说明了你如何将应用于序列的 Map 可视化。\n! img\n图 4-1：Map 的可视化\n术语序列在这里指的是以线性顺序组织的元素集合，而不是无序集合或节点之间没有*前后关系的图。图 4-2 显示了你如何将一个序列可视化，与上述其他两个集合形成对比。\n图 4-2：序列和非序列集合\n在这个关于 Map 和序列的描述中，没有提到列表、Vector 或其他具体的数据结构。Clojure 的设计是让我们尽可能地用这种抽象的术语来思考和编程，它通过用数据结构的抽象来实现函数。在这个例子中，map'是根据序列抽象来定义的。在对话中，你会说map、reduce`和其他序列函数取一个序列或甚至取一个seq*。事实上，Clojurists 通常使用seq而不是sequence，使用seq 函数和seq 库等术语来指代执行顺序操作的函数。无论你使用sequence还是seq，你都表明有关的数据结构将被视为一个序列，在这种情况下，它实际上是什么最真实的心态并不重要。\n如果核心序列函数 \u0026ldquo;first\u0026rdquo;、\u0026ldquo;rest \u0026ldquo;和 \u0026ldquo;cons \u0026ldquo;在一个数据结构上工作，你可以说这个数据结构实现了序列的抽象性。列表、Vector、集合和 Map 都实现了序列抽象，所以它们都与map一起工作，如图所示。\n(defn titleize [topic] (str topic \u0026quot; for the Brave and True\u0026quot;)) (map titleize [\u0026quot;Hamsters\u0026quot; \u0026quot;Ragnarok\u0026quot;]) ; =\u0026gt; (\u0026quot;Hamsters for the Brave and True\u0026quot; \u0026quot;Ragnarok for the Brave and True\u0026quot;) (map titleize '(\u0026quot;Empathy\u0026quot; \u0026quot;Decorating\u0026quot;)) ; =\u0026gt; (\u0026quot;Empathy for the Brave and True\u0026quot; \u0026quot;Decorating for the Brave and True\u0026quot;) (map titleize #{\u0026quot;Elbows\u0026quot; \u0026quot;Soap Carving\u0026quot;}) ; =\u0026gt; (\u0026quot;Elbows for the Brave and True\u0026quot; \u0026quot;Soap Carving for the Brave and True\u0026quot;) (map #(titleize (second %)) {:uncomfortable-thing \u0026quot;Winking\u0026quot;}) ; =\u0026gt; (\u0026quot;Winking for the Brave and True\u0026quot;) 前两个例子表明map对 Vector 和列表的工作方式是相同的。第三个例子显示map可以与未排序的集合一起工作。在第四个例子中，你必须在匿名函数的参数上调用`second'，然后再将其标题化，因为参数是一个 map。我将很快解释原因，但首先让我们看看定义序列抽象的三个函数。\nfirst, rest, and cons 在这一节中，我们将快速迂回到 JavaScript 中，实现一个链表和三个核心函数。first',rest', 和cons'。在这三个核心函数实现之后，我将展示如何用它们来构建map`。\n重点是要理解 Clojure 中的 seq 抽象和链接列表的具体实现之间的区别。如何实现一个特定的数据结构并不重要：当涉及到在一个数据结构上使用 seq 函数时，Clojure 所问的是 \u0026ldquo;我可以first、rest和cons吗？\u0026rdquo; 如果答案是肯定的，你就可以在该数据结构上使用 seq 库。\n在一个链接列表中，节点是以线性顺序链接的。下面是你如何在 JavaScript 中创建一个。在这个片段中，next是空的，因为它是列表中的最后一个节点。\nvar node3 = { value: \u0026quot;last\u0026quot;, next: null }; 在这个片段中，node2的next指向node3，而node1的next指向node2；这就是 \u0026ldquo;链表 \u0026ldquo;中的 \u0026ldquo;链接\u0026rdquo;。\nvar node2 = { value: \u0026quot;middle\u0026quot;, next: node3 }; var node1 = { value: \u0026quot;first\u0026quot;, next: node2 }; 从图形上看，你可以如图 4-3 所示表示这个列表。\n图 4-3: 一个链接列表\n你可以在一个链表上执行三个核心函数。first, rest, 和cons. first返回请求的节点的值，rest返回请求的节点之后的剩余值，cons在列表的开头添加一个具有给定值的新节点。在这些实现之后，你可以在它们之上实现map、reduce、filter和其他 seq 函数。\n下面的代码显示了我们如何用我们的 JavaScript 节点例子实现和使用first、rest和cons，以及如何使用它们来返回特定的节点并导出一个新的列表。请注意，first和rest的参数被命名为node。这可能会让人感到困惑，因为你可能会说：\u0026ldquo;我不是在获取一个列表的第一个元素吗？\u0026rdquo; 好吧，你一次对列表中的元素进行操作，是一个节点一个节点地操作\nvar first = function(node) { return node.value; }; var rest = function(node) { return node.next; }; var cons = function(newValue, node) { return { value: newValue, next: node }; }; first(node1); // =\u0026gt; \u0026quot;first\u0026quot; first(rest(node1)); // =\u0026gt; \u0026quot;middle\u0026quot; first(rest(rest(node1))); // =\u0026gt; \u0026quot;last\u0026quot; var node0 = cons(\u0026quot;new first\u0026quot;, node1); first(node0); // =\u0026gt; \u0026quot;new first\u0026quot; first(rest(node0)); // =\u0026gt; \u0026quot;first\u0026quot; 如前所述，你可以用first、rest和cons来实现map。\nvar map = function (list, transform) { if (list === null) { return null; } else { return cons(transform(first(list)), map(rest(list), transform)); } } 这个函数转换了 list 的第一个元素，然后在 list 的其余部分再次调用自己，直到到达结尾（一个空值）。让我们看看它的运行情况 在这个例子中，你对以 node1 开始的列表进行 Map，返回一个新的列表，字符串 \u0026quot; mapped!\u0026quot; 被附加到每个节点的值上。然后你用first来返回第一个节点的值。\nfirst( map(node1, function (val) { return val + \u0026quot; mapped!\u0026quot;}) ); // =\u0026gt; \u0026quot;first mapped!\u0026quot; 这里有件很酷的事：因为map是完全用cons、first和rest实现的，你实际上可以把任何数据结构传给它，只要cons、first和rest对该数据结构起作用，它就能工作。\n下面是它们对一个数组的作用。\nvar first = function (array) { return array[0]; } var rest = function (array) { var sliced = array.slice(1, array.length); if (sliced.length == 0) { return null; } else { return sliced; } } var cons = function (newValue, array) { return [newValue].concat(array); } var list = [\u0026quot;Transylvania\u0026quot;, \u0026quot;Forks, WA\u0026quot;]; map(list, function (val) { return val + \u0026quot; mapped!\u0026quot;}) // =\u0026gt; [\u0026quot;Transylvania mapped!\u0026quot;, \u0026quot;Forks, WA mapped!\u0026quot;] 这个代码片段用 JavaScript 的数组函数定义了first、rest和cons。同时，map继续引用名为first、rest和cons的函数，所以现在它在array上工作。所以，如果你能实现first、rest和cons，你就能免费得到map和前面提到的大量其他函数。\n通过定向进行抽象 在这一点上，你可能会反对我只是在踢皮球，因为我们仍然面临着像first这样的函数如何能够与不同的数据结构一起工作的问题。Clojure 使用两种形式的指示来实现这一目标。在编程中，indirection是一个通用术语，指的是一种语言所采用的机制，这样一个名字可以有多种相关的含义。在这个例子中，\u0026ldquo;first \u0026ldquo;这个名字有多种数据结构的含义。方向性是使抽象化成为可能的原因。\n多态性是 Clojure 提供间接性的一种方式。我不想在细节上迷失方向，但基本上，多态函数根据提供的参数类型分配给不同的函数体。(这与多态函数根据你提供的参数数量派发到不同的函数体并无太大区别）。\n注意 Clojure 有两种结构来定义多态调度：主机平台的接口结构和平台独立的协议。但在你刚开始的时候，没有必要了解这些东西是如何工作的。我将在第 13 章介绍协议。\n当涉及到序列时，Clojure 也通过做一种轻量级的类型转换来创造间接性，产生一种数据结构，与抽象的函数一起工作。每当 Clojure 期望一个序列\u0026ndash;例如，当你调用map、first、rest或cons时，它就会调用相关数据结构上的seq函数，以获得一个允许first、rest和cons的数据结构。\n(seq '(1 2 3)) ; =\u0026gt; (1 2 3) (seq [1 2 3]) ; =\u0026gt; (1 2 3) (seq #{1 2 3}) ; =\u0026gt; (1 2 3) (seq {:name \u0026quot;Bill Compton\u0026quot; :occupation \u0026quot;Dead mopey guy\u0026quot;}) ; =\u0026gt; ([:name \u0026quot;Bill Compton\u0026quot;] [:occupation \u0026quot;Dead mopey guy\u0026quot;]) 这里有两个值得注意的细节。首先，seq总是返回一个看起来像列表的值；你会把这个值称为sequence或seq。第二，Map 的 seq 由两个元素的键值 Vector 组成。这就是为什么map把你的 Map 当作 Vector 列表的原因! 你可以在 \u0026ldquo;Bill Compton \u0026ldquo;的例子中看到这一点。我想特别指出这个例子，因为它可能是令人惊讶和困惑的。在我刚开始使用 Clojure 的时候就是这样。了解这些底层机制将使你不至于像试图保留人性的男性吸血鬼那样，经常表现出挫折感和普遍的拖沓感。\n你可以通过使用into将 seq 转换回 Map，将结果粘到一个空的 Map 中（后面你会仔细看into）。\n(into {} (seq {:a 1 :b 2 :c 3}) ; =\u0026gt; {:a 1, :c 3, :b 2} 所以，Clojure 的序列函数在其参数上使用seq。序列函数是根据序列抽象定义的，使用first、rest和cons。只要一个数据结构实现了序列抽象，它就可以使用广泛的 seq 库，其中包括诸如reduce、filter、distinct、group-by等超级明星函数。\n这里的启示是，把注意力集中在我们能对一个数据结构做什么，并尽可能地忽略它的实现，是非常有力的。实现本身并不重要。它们只是达到目的的一种手段。一般来说，抽象编程可以让你在不同的数据结构上使用函数库，不管这些数据结构是如何实现的。\nSeq 函数实例 Clojure 的 seq 库中有很多有用的函数，你会经常用到。现在你已经对 Clojure 的序列抽象有了更深的了解，让我们来详细看看这些函数。如果你是 Lisp 和函数式编程的新手，这些例子将是令人惊讶和愉快的。\nMap 你现在已经看过很多map的例子了，但是这一节展示了map做了两个新的任务：把多个集合作为参数，以及把一个函数集合作为参数。它还强调了一个常见的map模式：使用关键字作为 Map 函数。\n到目前为止，你只看到了map在一个集合上操作的例子。在下面的代码中，这个集合是 Vector[1 2 3]。\n(map inc [1 2 3]) ; =\u0026gt; (2 3 4) 然而，你也可以给map多个集合。下面是一个简单的例子来说明这个方法的作用。\n(map str [\u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot;] [\u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;] ) ; =\u0026gt; (\u0026quot;aA\u0026quot; \u0026quot;bB\u0026quot; \u0026quot;cC\u0026quot;) 这就好像map做了以下的事情。\n(list (str \u0026quot;a\u0026quot; \u0026quot;A\u0026quot;) (str \u0026quot;b\u0026quot; \u0026quot;B\u0026quot;) (str \u0026quot;c\u0026quot; \u0026quot;C\u0026quot;)) 当你传递给map多个集合时，第一个集合的元素（[\u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot;]）将作为 Map 函数（str）的第一个参数传递，第二个集合的元素（[\u0026quot;A\u0026quot; \u0026quot;B\u0026quot; \u0026quot;C\u0026quot;）将作为第二个参数传递，以此类推。只要确保你的 Map 函数可以接受的参数数量与你传递给map的集合数量相等。\n下面的例子显示了如果你是一个试图抑制人类消费的吸血鬼，你可以如何使用这种能力。你有两个 Vector，一个代表人类摄入的升数，另一个代表过去四天的小动物摄入量。unify-diet-data \u0026ldquo;函数获取人类和动物的单日数据，并将两者统一为一张 Map。\n(def human-consumption [8.1 7.3 6.6 5.0]) (def critter-consumption [0.0 0.2 0.3 1.1]) (defn unify-diet-data [human critter] {:human human :critter critter}) (map unify-diet-data human-consumption critter-consumption) ; =\u0026gt; ({:human 8.1, :critter 0.0} {:human 7.3, :critter 0.2} {:human 6.6, :critter 0.3} {:human 5.0, :critter 1.1}) 好样的，把人裁掉了!\n你可以用map做的另一件有趣的事是把一个函数集合传给它。如果你想对不同的数字集合进行一系列的计算，你可以使用这个方法，就像这样。\n(def sum #(reduce + %)) (def avg #(/ (sum %) (count %))) (defn stats [numbers] (map #(% numbers) [sum count avg])) (stats [3 4 10]) ; =\u0026gt; (17 3 17/3) (stats [80 1 44 13 6]) ; =\u0026gt; (144 5 144/5) 在这个例子中，stats函数遍历了一个函数的 Vector，将每个函数应用于numbers。\n此外，Clojurists 经常使用map从 map 数据结构的集合中检索与一个关键词相关的值。因为关键字可以作为函数使用，你可以简洁地做到这一点。下面是一个例子。\n(def identities [{:alias \u0026quot;Batman\u0026quot; :real \u0026quot;Bruce Wayne\u0026quot;} {:alias \u0026quot;Spider-Man\u0026quot; :real \u0026quot;Peter Parker\u0026quot;} {:alias \u0026quot;Santa\u0026quot; :real \u0026quot;Your mom\u0026quot;} {:alias \u0026quot;Easter Bunny\u0026quot; :real \u0026quot;Your dad\u0026quot;}]) (map :real identities) ; =\u0026gt; (\u0026quot;Bruce Wayne\u0026quot; \u0026quot;Peter Parker\u0026quot; \u0026quot;Your mom\u0026quot; \u0026quot;Your dad\u0026quot;) (如果你是五岁，那么我深表歉意）。\nreduce 第 3 章展示了reduce如何处理序列中的每个元素来建立一个结果。本节展示了其他一些可能不明显的使用方法。\n第一种用法是转换一个 Map 的值，产生一个新的 Map，其键值相同，但数值更新。\n(reduce (fn [new-map [key val]] (assoc new-map key (inc val))) {} {:max 30 :min 10}) ; =\u0026gt; {:max 31, :min 11} 在这个例子中，reduce将参数{:max 30 :min 10}视为一个 Vector 序列，如([:max 30] [:min 10])。然后，它从一个空图（第二个参数）开始，用第一个参数，一个匿名函数来建立它。就像reduce这样做。\n(assoc (assoc {} :max (inc 30)) :min (inc 10)) 函数assoc需要三个参数：一个 Map，一个键，和一个值。它通过关联给定的键和给定的值，从你给它的 Map 中派生出一个新的 Map。例如，(assoc {:a 1} :b 2)将返回{:a 1 :b 2}。\n重组 \u0026ldquo;的另一个用途是根据键值从 Map 中过滤出来。在下面的例子中，匿名函数检查一个键值对的值是否大于 4，如果不是，那么这个键值对就被过滤掉了。在 Map{:human 4.1 :critter 3.9}中，3.9 小于 4，所以:critter键和它的 3.9 值被过滤掉了。\n(reduce (fn [new-map [key val]] (if (\u0026gt; val 4) (assoc new-map key val) new-map)) {} {:human 4.1 :critter 3.9}) ; =\u0026gt; {:human 4.1} 这里的启示是，reduce'是一个比最初看起来更灵活的函数。每当你想从一个seqable数据结构中得到一个新的值时，reduce通常能够满足你的需要。如果你想做一个真正能让你的头发倒竖的练习，试着用reduce实现map，然后在本章后面的内容中对filter和some`做同样的练习。\ntake, drop, take-while, and drop-while take和drop都接受两个参数：一个数字和一个序列。take'返回序列的前n个元素，而drop\u0026rsquo;返回除去前 n 个元素的序列。\n(take 3 [1 2 3 4 5 6 7 8 9 10]) ; =\u0026gt; (1 2 3) (drop 3 [1 2 3 4 5 6 7 8 9 10]) ; =\u0026gt; (4 5 6 7 8 9 10) 它们的表亲take-while和drop-while更有趣一些。每一个都需要一个谓词函数（一个其返回值被评估为真或假的函数）来决定它何时应该停止取舍。例如，假设你有一个 Vector，代表你 \u0026ldquo;食物 \u0026ldquo;日记中的条目。每个条目都有月份和日期，以及你吃了什么。为了保留空间，我们将只包括几个条目。\n(def food-journal [{:month 1 :day 1 :human 5.3 :critter 2.3} {:month 1 :day 2 :human 5.1 :critter 2.0} {:month 2 :day 1 :human 4.9 :critter 2.1} {:month 2 :day 2 :human 5.0 :critter 2.5} {:month 3 :day 1 :human 4.2 :critter 3.3} {:month 3 :day 2 :human 4.0 :critter 3.8} {:month 4 :day 1 :human 3.7 :critter 3.9} {:month 4 :day 2 :human 3.7 :critter 3.6}]) 使用take-while，你可以只检索一月和二月的数据。take-while遍历给定的序列（在本例中是food-journal），对每个元素应用谓词函数。\n这个例子使用匿名函数#(\u0026lt; (:month %) 3)来测试日记条目的月份是否超出范围。\n(take-while #(\u0026lt; (:month %) 3) food-journal) ; =\u0026gt; ({:month 1 :day 1 :human 5.3 :critter 2.3} {:month 1 :day 2 :human 5.1 :critter 2.0} {:month 2 :day 1 :human 4.9 :critter 2.1} {:month 2 :day 2 :human 5.0 :critter 2.5}) 当take-while到达第一个 March 条目时，匿名函数返回false，而take-while返回它在这之前测试的每个元素的序列。\n同样的想法也适用于drop-while，只是它一直在丢弃元素，直到有一个测试为真。\n(drop-while #(\u0026lt; (:month %) 3) food-journal) ; =\u0026gt; ({:month 3 :day 1 :human 4.2 :critter 3.3} {:month 3 :day 2 :human 4.0 :critter 3.8} {:month 4 :day 1 :human 3.7 :critter 3.9} {:month 4 :day 2 :human 3.7 :critter 3.6}) 通过同时使用take-while和drop-while，你可以只获得 2 月和 3 月的数据。\n(take-while #(\u0026lt; (:month %) 4) (drop-while #(\u0026lt; (:month %) 2) food-journal)) ; =\u0026gt; ({:month 2 :day 1 :human 4.9 :critter 2.1} {:month 2 :day 2 :human 5.0 :critter 2.5} {:month 3 :day 1 :human 4.2 :critter 3.3} {:month 3 :day 2 :human 4.0 :critter 3.8}) 这个例子使用 \u0026ldquo;drop-while \u0026ldquo;去掉 1 月份的条目，然后对结果使用 \u0026ldquo;take-while \u0026ldquo;继续取条目，直到到达 4 月份的第一个条目。\n过滤和一些 使用filter来返回一个序列中对一个谓词函数测试为真的所有元素。这里是人类消费少于 5 升的日记条目。\n(filter #(\u0026lt; (:human %) 5) food-journal) ; =\u0026gt; ({:month 2 :day 1 :human 4.9 :critter 2.1} {:month 3 :day 1 :human 4.2 :critter 3.3} {:month 3 :day 2 :human 4.0 :critter 3.8} {:month 4 :day 1 :human 3.7 :critter 3.9} {:month 4 :day 2 :human 3.7 :critter 3.6}) 你可能想知道为什么我们不在前面的 \u0026ldquo;take-while \u0026ldquo;和 \u0026ldquo;drop-while \u0026ldquo;例子中使用filter。事实上，filter也可以用于此。这里我们要抓取 1 月和 2 月的数据，就像在take-while例子中一样。\n(filter #(\u0026lt; (:month %) 3) food-journal) ; =\u0026gt; ({:month 1 :day 1 :human 5.3 :critter 2.3} {:month 1 :day 2 :human 5.1 :critter 2.0} {:month 2 :day 1 :human 4.9 :critter 2.1} {:month 2 :day 2 :human 5.0 :critter 2.5}) 这种用法完全没有问题，但是filter最终会处理你的所有数据，这并不总是必要的。因为食物日记已经按日期排序，我们知道take-while会返回我们想要的数据，而不需要检查任何我们不需要的数据。因此，take-while可以更有效率。\n通常情况下，你想知道一个集合是否包含对一个谓词函数测试为真的任何值。some函数就是这样做的，它返回由一个谓词函数返回的第一个真值（任何不是false或nil的值）。\n(some #(\u0026gt; (:critter %) 5) food-journal) ; =\u0026gt; nil (some #(\u0026gt; (:critter %) 3) food-journal) ; =\u0026gt; true 你没有任何食物日记条目显示你从小动物来源中消耗了超过 5 升的食物，但是你至少有一条显示你消耗了超过 3 升的食物。请注意，第二个例子中的返回值是true，而不是产生真值的实际条目。原因是匿名函数#(\u0026gt; (:critter %) 3)返回true或false。下面是你如何返回该条目。\n(some #(and (\u0026gt; (:critter %) 3) %) food-journal) ; =\u0026gt; {:month 3 :day 1 :human 4.2 :critter 3.3}。 这里，一个稍有不同的匿名函数使用and首先检查条件(\u0026gt; (:critter %) 3)是否为真，然后在条件确实为真时返回条目。\nsort and sort-by 你可以用sort将元素按升序排序。\n(sort [3 1 2]) ; =\u0026gt; (1 2 3) 如果你的排序需求更复杂，你可以使用sort-by，它允许你将一个函数（有时称为键函数）应用于一个序列的元素，并使用它返回的值来决定排序顺序。在下面的例子中，取自*http://clojuredocs.org/*，count是关键函数。\n(sort-by count [\u0026quot;aaa\u0026quot; \u0026quot;c\u0026quot; \u0026quot;bb\u0026quot;] ) ; =\u0026gt; (\u0026quot;c\u0026quot; \u0026quot;bb\u0026quot; \u0026quot;aaa\u0026quot;) 如果你使用sort进行排序，元素将按字母顺序进行排序，返回(\u0026quot;aaa\u0026quot; \u0026quot;bb\u0026quot; \u0026quot;c\u0026quot;)。相反，结果是(\u0026quot;c\u0026quot; \u0026quot;bb\u0026quot; \u0026quot;aaa\u0026quot;)，因为你是按count排序，而\u0026quot;c \u0026quot;的计数是1，\u0026ldquo;bb \u0026ldquo;是 2，`\u0026ldquo;aaa \u0026ldquo;是 3。\n协程 最后, concat简单地将一个序列的成员附加到另一个序列的末尾:\n(concat [1 2] [3 4]) ; =\u0026gt; (1 2 3 4) Lazy Seqs 正如你之前看到的，map首先在你传递给它的集合上调用seq。但这并不是故事的全部。许多函数，包括map和filter，都返回一个lazy seq。lazy seq 是一个 seq，它的成员在你试图访问它们时才被计算。计算一个 seq 的成员被称为实现seq。将计算推迟到需要的时候，可以使你的程序更有效率，而且它还有一个令人惊讶的好处，就是允许你构建无限的序列。\n演示懒惰序列的效率 为了看到懒惰序列的作用，假装你是一个现代任务组的成员，其目的是为了识别吸血鬼。你的情报人员告诉你，在你的城市里只有一个活跃的吸血鬼，而且他们已经帮助你把嫌疑人的名单缩小到一百万人。你的老板给了你一份一百万个社会安全号码的名单，并喊道：\u0026ldquo;搞定它，麦克菲斯维奇！\u0026rdquo;\n值得庆幸的是，你拥有一台 Vampmatic 3000 计算机，这是用于识别吸血鬼的最先进的设备。由于这种猎杀吸血鬼的技术的源代码是专有的，我把它存根出来，模拟执行这项任务所需的时间。这里是一个吸血鬼数据库的子集。\n(def vampire-database {0 {:makes-blood-puns? false, :has-pulse? true :name \u0026quot;McFishwich\u0026quot;} 1 {:makes-blood-puns? false, :has-pulse? true :name \u0026quot;McMackson\u0026quot;} 2 {:makes-blood-puns? true, :has-pulse? false :name \u0026quot;Damon Salvatore\u0026quot;} 3 {:makes-blood-puns? true, :has-pulse? true :name \u0026quot;Mickey Mouse\u0026quot;}}) (defn vampire-related-details [social-security-number] (Thread/sleep 1000) (get vampire-database social-security-number)) (defn vampire? [record] (and (:makes-blood-puns? record) (not (:has-pulse? record)) record)) (defn identify-vampire [social-security-numbers] (first (filter vampire? (map vampire-related-details social-security-numbers)))) 你有一个函数，vampire-related-details，它需要一秒钟从数据库中查找一个条目。接下来，你有一个函数，vampire?，如果它通过了吸血鬼测试，就返回一条记录；否则，就返回false。最后，identify-vampire将社会安全号码 Map 到数据库记录，然后返回第一条表明有吸血鬼的记录。\n为了显示运行这些函数需要多少时间，你可以使用time操作。当你使用time时，你的代码的行为与你不使用time时完全一样，但有一个例外：会打印出一份经过时间的报告。下面是一个例子。\n(time (vampire-related-details 0)) ; =\u0026gt; \u0026quot;Elapsed time: 1001.042 msecs\u0026quot; ; =\u0026gt; {:name \u0026quot;McFishwich\u0026quot;, :makes-blood-puns? false, :has-pulse? true} 第一个打印行报告了给定操作所花费的时间\u0026ndash;本例是 1,001.042 毫秒。第二行是返回值，在本例中是你的数据库记录。返回值与没有使用time的情况下完全相同。\n一个不笨的map的实现首先要对social-security-numbers的每个成员应用vampire-related-details，然后再把结果传给filter`。因为你有一百万个嫌疑人，这将需要一百万秒，也就是 12 天，到那时你的一半城市都会死掉！\u0026quot;。当然，如果结果是唯一的吸血鬼是记录中的最后一个嫌疑人，用懒人版本还是会花那么多时间，但至少有一个很好的机会，它不会。\n因为map是懒惰的，在你试图访问 Map 的元素之前，它实际上并没有将吸血鬼相关的细节'应用于社会安全号码。事实上，map`几乎立刻就会返回一个值。\n第一个打印行报告了给定操作所花费的时间\u0026ndash;本例中是 1,001.042 毫秒。第二行是返回值，在这个例子中是你的数据库记录。返回值与没有使用time的情况下完全相同。\n一个不笨的map的实现首先要对social-security-numbers的每个成员应用vampire-related-details，然后再把结果传给filter`。因为你有一百万个嫌疑人，这将需要一百万秒，也就是 12 天，到那时你的一半城市都会死掉！\u0026quot;。当然，如果结果是唯一的吸血鬼是记录中的最后一个嫌疑人，用懒人版本还是会花那么多时间，但至少有一个很好的机会，它不会。\n因为map是懒惰的，在你试图访问 Map 的元素之前，它实际上并没有将吸血鬼相关的细节'应用于社会安全号码。事实上，map`几乎马上就会返回一个值。\n(time (def mapped-details (map vampire-related-details (range 0 1000000)))) ; =\u0026gt; \u0026quot;Elapsed time: 0.049 msecs\u0026quot; ; =\u0026gt; #'user/mapped-details 在这个例子中，range返回一个由 0 到 999,999 的整数组成的懒惰序列。然后，map返回一个与名称mapped-details相关的懒惰序列。因为map实际上没有对range返回的任何元素应用vampire-related-details，整个操作几乎没有花费任何时间，当然，少于 12 天。\n你可以认为懒人序列是由两部分组成的：一个关于如何实现序列元素的配方和到目前为止已经实现的元素。当你使用map时，它返回的懒人序列不包括任何已实现的元素，但它确实有生成其元素的配方。每当你试图访问一个未实现的元素时，懒人序列将使用它的配方来生成所请求的元素。\n在前面的例子中，mapped-details是未实现的。一旦你试图访问mapped-details的一个成员，它将使用它的配方来生成你所请求的元素，你将产生每秒钟的数据库查询费用。\n在这个例子中，range返回一个由 0 到 999,999 的整数组成的懒惰序列。然后，map返回一个与mapped-details名称相关的懒惰序列。因为map实际上没有对range返回的任何元素应用vampire-related-details，整个操作几乎没有花费任何时间，当然，少于 12 天。\n你可以认为懒人序列由两部分组成：一个关于如何实现序列元素的配方和到目前为止已经实现的元素。当你使用map时，它返回的懒惰序列不包括任何已实现的元素，但它确实有生成其元素的配方。每当你试图访问一个未实现的元素时，懒人序列将使用它的配方来生成所请求的元素。\n在前面的例子中，mapped-details是未实现的。一旦你试图访问mapped-details的一个成员，它将使用它的配方来生成你所请求的元素，你将产生每秒钟的数据库查询费用。\n(time (first mapped-details)) ; =\u0026gt; \u0026quot;Elapsed time: 32030.767 msecs\u0026quot; ; =\u0026gt; {:name \u0026quot;McFishwich\u0026quot;, :makes-blood-puns? false, :has-pulse? true} 这个操作花了大约 32 秒。这比一百万秒好得多，但还是比我们预期的多了 31 秒。毕竟，你只是试图访问第一个元素，所以它应该只花一秒钟。\n花了 32 秒的原因是 Clojurechunks它的懒惰序列，这只是意味着每当 Clojure 要实现一个元素时，它也会预先实现一些下一个元素的实现。在这个例子中，你只想要`mapped-details\u0026rsquo;的第一个元素，但 Clojure 继续前进，也准备了后面的 31 个元素。Clojure 这样做是因为它几乎总是能带来更好的性能。\n值得庆幸的是，懒惰的 seq 元素只需要实现一次。再次访问mapped-details的第一个元素几乎不需要时间。\n(time (first mapped-details)) ; =\u0026gt; \u0026quot;Elapsed time: 0.022 msecs\u0026quot; ; =\u0026gt; {:name \u0026quot;McFishwich\u0026quot;, :makes-blood-puns? false, :has-pulse? true} 有了这些新发现的知识，你就可以有效地挖掘吸血鬼数据库，找到带獠牙的罪魁祸首。\n(time (identify-vampire (range 0 1000000))) \u0026quot;Elapsed time: 32019.912 msecs\u0026quot; ; =\u0026gt; {:name \u0026quot;Damon Salvatore\u0026quot;, :makes-blood-puns? true, :has-pulse? false} 哦！这就是为什么达蒙会做出那些令人毛骨悚然的双关语的原因。\n无限序列 lazy seqs 给你的一个很酷、很有用的能力是构建无限序列的能力。到目前为止，你只处理过从 Vector 或列表中生成的懒惰序列，这些序列是终止的。然而，Clojure 自带了一些函数来创建无限序列。创建无限序列的一个简单方法是使用repeat，它创建一个序列，其每个成员都是你传递的参数。\n(concat (take 8 (repeat \u0026quot;na\u0026quot;)) [\u0026quot;Batman!\u0026quot;]) ; =\u0026gt; (\u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;na\u0026quot; \u0026quot;Batman!\u0026quot;) 在这种情况下，你创建了一个无限的序列，其中每个元素都是字符串 \u0026ldquo;na\u0026rdquo;，然后用它来构建一个可能引起或不引起怀旧情绪的序列。\n你也可以使用repeatedly，它将调用提供的函数来生成序列中的每个元素。\n(take 3 (repeatedly (fn [] (rand-int 10)))) ; =\u0026gt; (1 4 0) 这里，由repeatedly返回的懒惰序列通过调用匿名函数(fn [] (rand-int 10))生成每个新元素，该函数返回一个 0 到 9 之间的随机整数。如果你在你的 REPL 中运行这个，你的结果很可能与此不同。\nlazy seq 的配方不需要指定一个端点。像first和take这样的函数实现了懒惰序列，它们没有办法知道序列的下一步是什么，如果序列一直提供元素，那么它们就会一直取走它们。如果你构建你自己的无限序列，你就可以看到这一点。\n(defn even-numbers ([] (even-numbers 0)) ([n] (cons n (lazy-seq (even-numbers (+ n 2)))))) (take 10 (even-numbers)) ; =\u0026gt; (0 2 4 6 8 10 12 14 16 18) 这个例子有点令人费解，因为它使用了递归。记住cons返回一个新的列表，并将一个元素追加到给定的列表中，会有所帮助。\n(cons 0 '(2 4 6)) ; =\u0026gt; (0 2 4 6) (顺便说一下，Lisp 程序员在使用cons函数时称它为consing)。\n在 \u0026ldquo;偶数 \u0026ldquo;中，你是在对一个懒惰列表进行 consing，其中包括一个关于下一个元素的配方（一个函数）（而不是对一个完全实现的列表进行 consing）。\n这就涵盖了懒惰序列! 现在你知道了关于序列抽象的所有知识，我们可以转向集合抽象了。\n集合抽象 集合的抽象与序列的抽象密切相关。所有 Clojure 的核心数据结构\u0026ndash;Vector、Map、列表和集合\u0026ndash;都参与了这两个抽象。\n序列抽象是关于对成员的单独操作，而集合抽象是关于数据结构的整体。例如，集合函数 count, empty?, 和 every? 不是关于任何单独的元素；它们是关于整体的。\n(empty?[]) ; =\u0026gt; true (empty? [\u0026quot;no!\u0026quot;]) ; =\u0026gt; false 实际上，你很少会有意识的说：\u0026ldquo;好的，自己！\u0026quot;。你现在是在和整个集合一起工作。从集合抽象的角度来考虑！\u0026rdquo; 尽管如此，了解这些作为你所使用的函数和数据结构基础的概念还是很有用的。\n现在我们来研究两个常见的集合函数\u0026ndash;into和conj，它们的相似性可能会让人有点困惑。\ninto 最重要的集合函数之一是into。正如你现在所知，许多 seq 函数返回一个 seq，而不是原始数据结构。你可能想把返回值转换成原始值, into让你做到这一点:\n(map identity {:sunlight-reaction \u0026quot;Glitter!\u0026quot;}) ; =\u0026gt; ([:sunlight-reaction \u0026quot;Glitter!\u0026quot;]) (into {} (map identity {:sunlight-reaction \u0026quot;Glitter!\u0026quot;})) ; =\u0026gt; {:sunlight-reaction \u0026quot;Glitter!\u0026quot;}. 在这里，map函数在得到一个 map 数据结构后返回一个顺序数据结构，并将 seq 转换回 map。\n这也适用于其他数据结构。\n(map identity [:garlic :sesame-oil :fried-eggs]) ; =\u0026gt; (:garlic :sesame-oil :fried-eggs) (into [] (map identity [:garlic :sesame-oil :fried-eggs])) ; =\u0026gt; [:garlic :sesame-oil :fried-eggs] 这里，在第一行，map返回一个序列，我们在第二行使用into将结果转换为一个 Vector。\n在下面的例子中，我们从一个有两个相同条目的 Vector 开始，map把它转换为一个列表，然后我们用into把值粘到一个集合中。\n(map identity [:garlic-clove :garlic-clove]) ; =\u0026gt; (:garlic-clove :garlic-clove) (into #{} (map identity [:garlic-clove :garlic-clove])) ; =\u0026gt; #{:garlic-clove} 因为集合只包含唯一的值，所以集合中最终只有一个值。\ninto的第一个参数不一定是空的。这里，第一个例子显示了如何使用into向 Map 添加元素，第二个例子显示了如何向矢量添加元素。\n(into {:favorite-emotion \u0026quot;gloomy\u0026quot;} [[:sunlight-reaction \u0026quot;Glitter!\u0026quot;]]) ; =\u0026gt; {:favorite-emotion \u0026quot;gloomy\u0026quot; :sunlight-reaction \u0026quot;Glitter!\u0026quot;} (into [\u0026quot;cherry\u0026quot;] '(\u0026quot;pine\u0026quot; \u0026quot;spruce\u0026quot;)) ; =\u0026gt; [\u0026quot;cherry\u0026quot; \u0026quot;pine\u0026quot; \u0026quot;spruce\u0026quot;] 当然，两个参数也可以是同一类型。在下一个例子中，两个参数都是 Map，而之前所有的例子都有不同类型的参数。它的工作原理和你所期望的一样，返回一个新的 Map，将第二个 Map 的元素添加到第一个 Map 中。\n(into {:favorite-animal \u0026quot;kitty\u0026quot;} {:least-favorite-smell \u0026quot;dog\u0026quot; :relationship-with-teenager \u0026quot;creepy\u0026quot;}) ; =\u0026gt; {:favorite-animal \u0026quot;kitty\u0026quot; :relationship-with-teenager \u0026quot;creepy\u0026quot; :least-favorite-smell \u0026quot;dog\u0026quot;} 如果into在求职面试中被要求描述它的优势，它会说：\u0026ldquo;我很擅长处理两个集合，并将第二个集合中的所有元素添加到第一个集合中。\u0026rdquo;\nconj conj也是向一个集合添加元素，但它的方式略有不同。\n(conj [0] [1]) ; =\u0026gt; [0 [1]] 呜呜呜! 看起来它把整个 Vector[1]添加到[0]。与into比较。\n(into [0] [1]) ; =\u0026gt; [0 1] 下面是我们如何用conj做同样的事情。\n(conj [0] 1) ; =\u0026gt; [0 1] 注意，数字 1 是作为标量（单数，非集合）值传递的，而into的第二个参数必须是一个集合。\n你可以提供尽可能多的元素与conj一起添加，你也可以添加到其他集合中，如 map。\n(conj [0] 1 2 3 4) ; =\u0026gt; [0 1 2 3 4] (conj {:time \u0026quot;midnight\u0026quot;} [:place \u0026quot;ye olde cemetarium\u0026quot;]) ; =\u0026gt; {:place \u0026quot;ye olde cemetarium\u0026quot; :time \u0026quot;midnight\u0026quot;} conj和into如此相似，你甚至可以用into来定义conj。\n(defn my-conj [target \u0026amp; additions] (into target additions)) (my-conj [0] 1 2 3) ; =\u0026gt; [0 1 2 3] 功能函数 学习利用 Clojure 的接受函数作为参数和返回函数作为值的能力是非常有趣的，即使它需要一些适应性。\nClojure 的两个函数，apply和partial，可能看起来特别奇怪，因为它们都接受和返回函数。让我们来解开它们的疑惑。\n应用 apply explodes一个 seqable 数据结构，所以它可以被传递给一个期望有其余参数的函数。例如，max接受任何数量的参数，并返回所有参数中最大的一个。这里是你如何找到最大的数字。\n(max 0 1 2) ; =\u0026gt; 2 但如果你想找到一个 Vector 的最大元素，怎么办？你不能只把 Vector 传给max。\n(max [0 1 2]) ; =\u0026gt; [0 1 2] 这不会返回 Vector 中最大的元素，因为max返回所有传递给它的参数中最大的，在这种情况下，你只是传递给它一个包含所有你想比较的数字的 Vector，而不是把数字作为单独的参数传递进去。apply是这种情况的完美选择。\n(apply max [0 1 2]) ; =\u0026gt; 2 通过使用apply，就像你调用(max 0 1 2)一样。你经常会像这样使用apply，对一个集合的元素进行分解，使它们作为单独的参数被传递给一个函数。\n还记得我们之前是如何用 \u0026ldquo;into \u0026ldquo;来定义 \u0026ldquo;conj \u0026ldquo;的吗？那么，我们也可以通过使用apply在conj的基础上定义into。\n(defn my-into [target additions] (apply conj target additions)) (my-into [0] [1 2 3]) ; =\u0026gt; [0 1 2 3] 对my-into的调用相当于调用(conj [0] 1 2 3)。\n部分 partial接收一个函数和任意数量的参数。然后它返回一个新的函数。当你调用返回的函数时，它用你提供的原参数和新参数一起调用原函数。\n这里有一个例子。\n(def add10 (partial + 10)) (add10 3) ; =\u0026gt; 13 (add10 5) ; =\u0026gt; 15 (def add-missing-elements (partial conj [\u0026quot;water\u0026quot; \u0026quot;earth\u0026quot; \u0026quot;air\u0026quot;])) (add-missing-elements \u0026quot;unobtainium\u0026quot; \u0026quot;adamantium\u0026quot;) ; =\u0026gt; [\u0026quot;water\u0026quot; \u0026quot;earth\u0026quot; \u0026quot;air\u0026quot; \u0026quot;unobtainium\u0026quot; \u0026quot;adamantium\u0026quot;] 所以当你调用add10'时，它会调用原始函数和参数（+ 10'），并附加你调用add10'的任何参数。为了帮助澄清partial\u0026rsquo;的工作原理，下面是你如何定义它。\n(defn my-partial [partialized-fn \u0026amp; args] (fn [\u0026amp; more-args] (apply partialized-fn (into args more-args)))) (def add20 (my-partial + 20)) (add20 3) ; =\u0026gt; 23 在这个例子中，add20'的值是由my-partial\u0026rsquo;返回的匿名函数。这个匿名函数是这样定义的。\n(fn [\u0026amp; more-args] (apply + (into [20] more-args))) 一般来说，当你发现你在许多不同的情况下重复相同的函数和参数组合时，你会想使用 partials。这个玩具例子显示了你如何使用partial来专门化一个记录器，创建一个warn函数。\n(defn lousy-logger [log-level message] (condp = log-level :warn (clojure.string/lower-case message) :emergency (clojure.string/upper-case message))) (def warn (partial lousy-logger :warn)) (warn \u0026quot;Red light ahead\u0026quot;) ; =\u0026gt; \u0026quot;red light ahead\u0026quot; 在这里调用(warning \u0026quot;Red light ahead\u0026quot;)与调用(lousy-logger :warning \u0026quot;Red light ahead\u0026quot;)是相同的。\n补充 早些时候，你创建了`识别吸血鬼\u0026rsquo;函数，以便在一百万人中找到一个吸血鬼。如果你想创建一个函数来寻找所有的人类呢？也许你想给他们发送感谢卡，因为他们没有成为不死的掠夺者。这里是你可以做的。\n(defn identify-humans [social-security-numbers] (filter #(not (vampire? %)) (map vampire-related-details social-security-numbers))) 看看filter的第一个参数，#(not (vampire? %))。想要得到一个布尔函数的complement（否定）是很常见的，所以有一个函数，complement，用于此。\n(def not-vampire? (complement vampire?)) (defn identify-humans [social-security-numbers] (filter not-vampire? (map vampire-related-details social-security-numbers))) 下面是你如何实现 \u0026ldquo;补充 \u0026ldquo;的方法。\n(defn my-complement [fun] (fn [\u0026amp; args] (not (apply fun args)))) (def my-pos? (complement neg?)) (my-pos? 1) ; =\u0026gt; true (my-pos? -1) ; =\u0026gt; false 正如你所看到的，complement'是一个不起眼的函数。它只做一件小事，而且做得很好。complement使创建一个不吸血\u0026rsquo;的函数变得微不足道，而且任何阅读代码的人都能理解代码的意图。\n这不会为你提供数兆字节的数据的 MapReduce 或类似的东西，但它确实证明了高阶函数的力量。它们允许你以一种在某些语言中不可能实现的方式建立起实用函数库。总的来说，这些实用函数使你的生活变得更加轻松。\nA Vampire Data Analysis Program for the FWPD 为了把所有的事情联系起来，让我们为华盛顿州福克斯警察局（FWPD）编写一个复杂的吸血鬼数据分析程序的雏形。\nFWPD 有一个花哨的新数据库技术，叫做CSV （逗号-**分隔的值）。你的工作是解析这个最先进的 CSV，并分析它是否有潜在的吸血鬼。我们将通过过滤每个嫌疑人的闪光指数*来做到这一点，这是一个由某个少女开发的对嫌疑人的吸血鬼性的 0-10 预测。继续并为你的工具创建一个新的 Leiningen 项目。\nlein new app fwpd 在新的fwpd目录下，创建一个名为suspects.csv的文件，输入如下内容。\nEdward Cullen,10 Bella Swan,0 Charlie Swan,0 Jacob Black,3 Carlisle Cullen,6 现在是时候通过建立fwpd/src/fwpd/core.clj文件来弄脏你的手了。我建议你启动一个新的 REPL 会话，这样你就可以边走边试。在 Emacs 中，你可以通过打开fwpd/**src/fwpd/core.clj并运行M-x cider-restart 来实现。一旦 REPL 启动，删除core.clj的内容，然后加入以下内容。\n(ns fwpd.core) (def filename \u0026quot;suspects.csv\u0026quot;) 第一行建立了命名空间，第二行只是使你创建的 CSV 更容易被引用。你可以通过编译你的文件（Emacs 中的C-c C-k）并运行以下程序，在你的 REPL 中做一个快速的理智检查。\n(slurp filename) ; =\u0026gt; \u0026quot;Edward Cullen,10\\nBella Swan,0\\nCharlie Swan,0\\nJacob Black, 3\\nCarlisle Cullen, 6\u0026quot; 如果slurp函数没有返回前面的字符串，试着在core.clj打开的情况下重新启动你的 REPL 会话。\n接下来，在core.clj中添加这个内容。\n➊ (def vamp-keys [:name :glitter-index]) ➋ (defn str-\u0026gt;int [str] (Integer. str)) ➌ (def conversions {:name identity :glitter-index str-\u0026gt;int}) ➍ (defn convert [vamp-key value] ((get conversions vamp-key) value)) 最终，你会得到一串看起来像{:name \u0026quot;Edward Cullen\u0026quot; :glitter-index 10}的 Map，前面的定义可以帮助你达到目的。首先，vamp-keys➊是一个键的 Vector，你很快会用它来创建吸血鬼 Map。接下来，函数str-\u0026gt;int➋将一个字符串转换为一个整数。Mapconversions➌将一个转换函数与每个吸血鬼键相关联。你根本不需要转换名字，所以它的转换函数是identity，它只是返回传递给它的参数。熠熠生辉的索引被转换为一个整数，所以它的转换函数是str-\u0026gt;int。最后，convert函数➍接收一个 vamp 键和一个值，并返回转换后的值。下面是一个例子。\n(convert :glitter-index \u0026quot;3\u0026quot;) ; =\u0026gt; 3 现在把这个添加到你的文件中。\n(defn parse \u0026quot;Convert a CSV into rows of columns\u0026quot; [string] (map #(clojure.string/split % #\u0026quot;,\u0026quot;) (clojure.string/split string #\u0026quot;\\n\u0026quot;))) parse函数接收一个字符串，首先在换行符上进行分割，创建一个字符串的序列。接下来，它对字符串序列进行 Map，在逗号字符上分割每一个字符串。试着在你的 CSV 上运行parse。\n(parse (slurp filename)) ; =\u0026gt; ([\u0026quot;Edward Cullen\u0026quot; \u0026quot;10\u0026quot;] [\u0026quot;Bella Swan\u0026quot; \u0026quot;0\u0026quot;] [\u0026quot;Charlie Swan\u0026quot; \u0026quot;0\u0026quot;] [\u0026quot;Jacob Black\u0026quot; \u0026quot;3\u0026quot;] [\u0026quot;Carlisle Cullen\u0026quot; \u0026quot;6\u0026quot;]) 接下来的代码将 Vector 序列与你的吸血鬼钥匙结合起来，创建 Map。\n(defn mapify \u0026quot;Return a seq of maps like {:name \\\u0026quot;Edward Cullen\\\u0026quot; :glitter-index 10}\u0026quot; [rows] (map (fn [unmapped-row] (reduce (fn [row-map [vamp-key value]] (assoc row-map vamp-key (convert vamp-key value))) {} (map vector vamp-keys unmapped-row))) rows)) 在这个函数中，map通过使用reduce将每一行 Vector 如[\u0026quot;Bella Swan\u0026quot; 0]转化为一个 Map，其方式与上面\u0026rdquo;reduce\u0026ldquo;中的第一个例子相似。首先，map创建一个键值对序列，如([:name \u0026quot;Bella Swan\u0026quot;] [:glitter-index 0])。然后，\u0026ldquo;reduce \u0026ldquo;通过将一个 vamp 键和一个转换后的 vamp 值关联到 \u0026ldquo;row-map \u0026ldquo;来建立一个 Map。下面是第一行的 Map。\n(first (mapify (parse (slurp filename)))) ; =\u0026gt; {:glitter-index 10, :name \u0026quot;Edward Cullen\u0026quot; } 最后，添加这个glitter-filter函数。\n(defn glitter-filter [minimum-glitter records] (filter #(\u0026gt;= (:glitter-index %) minimum-glitter) records)) 这需要完全 Map 的吸血鬼记录，并过滤掉那些:glitter-index小于所提供的minimum-glitter的记录。\n(glitter-filter 3 (mapify (parse (slurp filename)))) ({:name \u0026quot;Edward Cullen\u0026quot;, :glitter-index 10} {:name \u0026quot;Jacob Black\u0026quot;, :glitter-index 3} {:name \u0026quot;Carlisle Cullen\u0026quot;, :glitter-index 6}) Et voilà! 你现在离实现你的梦想又近了一步，即成为一名猎杀超自然生物的义务警员。你最好去围捕那些粗略的人物!\n摘要 在本章中，你了解到 Clojure 强调对抽象的编程。序列抽象处理的是对序列中各个元素的操作，而 seq 函数通常将其参数转换为 seq，并返回一个懒惰的 seq。懒惰评估通过将计算推迟到需要时再进行，从而提高性能。你所学到的另一个抽象，即集合抽象，处理的是整个数据结构。最后，你学到的最重要的东西是，你不应该相信那些在阳光下闪光的人。\n练习 你现在拥有的吸血鬼分析程序已经领先于市场上的任何其他程序几十年了。但你怎样才能使它变得更好呢？我建议尝试以下几点。\n 把你的闪光过滤器的结果变成一个名字的列表。 写一个函数，`append'，它将把一个新的嫌疑人追加到你的嫌疑人列表中。 写一个函数，validate'，它将在你append\u0026rsquo;时检查:name'和:glitter-index\u0026rsquo;是否存在。validate函数应该接受两个参数：一个类似于conversions的验证函数的关键词 Map，以及要验证的记录。 编写一个函数，将你的 Map 列表转换为 CSV 字符串。你需要使用clojure.string/join函数。  祝你好运，McFishwich!\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter4/","summary":"核心函数的深入研究 如果你像我一样是焦虑的、以青少年为中心的准肥皂剧*《吸血鬼日记》的超级粉丝，你一定记得主角埃琳娜开始质疑她苍白的、神秘的暗恋者的行为的那一集。\u0026ldquo;为什么当我的膝盖被刮伤时，他立刻消失得无影无踪？\u0026ldquo;和 \u0026ldquo;为什么当我的手指被划破时，他的脸变成了一个怪异的死亡面具？\u0026ldquo;等等。\n如果你已经开始玩 Clojure 的核心函数，你可能也会问自己类似的问题。\u0026ldquo;为什么map'会返回一个列表，而我给它的是一个Vector？\u0026quot;和 \u0026quot;为什么reduce\u0026rsquo;会把我的 map 当成一个 Vector 列表？\u0026ldquo;等等。(不过，有了 Clojure，你至少可以免于思考作为一个 17 岁孩子的深刻的存在恐惧，直到永远）。\n在这一章中，你将了解到 Clojure 的深邃、黑暗、嗜血、超自然的****，我的意思是，在这一章中，你将了解到 Clojure 的编程到抽象的基本概念以及序列和集合的抽象。你还会了解到疯狂的序列*。这将为你提供所需的基础，使你能够阅读你以前没有使用过的函数的文档，并理解当你试着使用它们时发生了什么。\n接下来，你将获得更多关于你最需要使用的函数的经验。你将学习如何用函数map、reduce、into、conj、concat、some、filter、take、drop、sort、sort-by和identity来处理列表、Vector、Map 和集合。你还将学习如何用apply、partial和complement创建新的函数。所有这些信息将帮助你了解如何以 Clojure 的方式做事，它将为你编写自己的代码以及阅读和学习他人的项目打下坚实的基础。\n最后，你将学会如何解析和查询 CSV 中的吸血鬼数据，以确定在你的家乡潜伏着哪些诺斯费拉图。\n从编程到抽象 为了理解对抽象的编程，让我们把 Clojure 与一种没有考虑到这个原则的语言进行比较。Emacs Lisp（elisp）。在 elisp 中，你可以使用mapcar函数来导出一个新的列表，这与你在 Clojure 中使用map的方式相似。然而，如果你想在 elisp 中 Map 一个哈希图（类似于 Clojure 的 map 数据结构），你需要使用maphash函数，而在 Clojure 中你仍然可以只使用map。换句话说，elisp 使用两个不同的、针对数据结构的函数来实现map操作，而 Clojure 只使用一个。你也可以在 Clojure 中对 map 调用reduce，而 elisp 并没有提供一个函数来减少散列 map。\n原因是 Clojure 在*序列抽象方面定义了map和reduce函数，而不是在具体的数据结构方面。只要数据结构响应核心序列操作（函数first'、rest\u0026rsquo;和cons'，我们稍后会仔细研究），它就能与map'、`reduce\u0026rsquo;以及其他大量的序列函数免费工作。这就是 Clojurists 所说的抽象编程，也是 Clojure 哲学的一个核心原则。\n我认为抽象是操作的命名集合。如果你能在一个对象上执行一个抽象的所有操作，那么这个对象就是该抽象的一个实例。我甚至在编程之外也是这样想的。例如，电池抽象包括 \u0026ldquo;将导电介质连接到其阳极和阴极 \u0026ldquo;的操作，而该操作的输出是电流。电池是用锂还是用土豆做的并不重要。只要它对定义电池的一系列操作做出反应，它就是一个电池。\n同样地，map并不关心列表、Vector、集合和 Map 是如何实现的。它只关心它是否能对它们进行序列操作。让我们看看map是如何在序列抽象中定义的，这样你就能理解一般的抽象编程。\n把列表、Vector、集合和 Map 当作序列对待 如果你把map操作独立于任何编程语言，甚至是编程，它的基本行为是用一个函数ƒ从现有的序列x导出一个新的序列y，这样y1 = ƒ(x1), y2 = ƒ(x2), .","title":"Chapter4 深入研究核心函数"},{"content":"做事情：Clojure 速成班 是时候学习如何用 Clojure 真正地做事了! 该死的! 尽管你无疑已经听说过 Clojure 令人敬畏的并发支持和其他了不起的功能，但 Clojure 最突出的特点是它是一种 Lisp 语言。在本章中，你将探索构成这个 Lisp 核心的元素：语法、函数和数据。它们将共同为你在 Clojure 中表示和解决问题打下坚实的基础。\n在打下这个基础之后，你将能够编写一些超级重要的代码。在最后一节中，你将通过创建一个霍比特人的模型，并编写一个函数将其打在一个随机的位置上，从而将一切联系起来。超级! 重要的!\n当你阅读本章时，我建议你在 REPL 中输入例子并运行它们。用一种新的语言编程是一种技能，就像约德尔舞或花样游泳一样，你必须通过练习来学习它。 请留意它!\n语法 Clojure 的语法很简单。像所有的 Lisp 一样，它采用了统一的结构、少量的特殊运算符，以及从藏在麻省理工学院下面的小括号矿井中不断提供的小括号，Lisp 就是在那里诞生的。\n形式 所有的 Clojure 代码都是以统一结构编写的。Clojure 可以识别两种结构。\n 数据结构的字面表示（如数字、字符串、Map 和 Vector） 操作  我们使用术语form来指代有效的代码。我有时也会用表达式来指代 Clojure 形式。但不要太纠结于术语。Clojure 评价每一个表单，以产生一个值。这些字面表达都是有效的形式。\n1 \u0026quot;a string\u0026quot; [\u0026quot;a\u0026quot; \u0026quot;vector\u0026quot; \u0026quot;of\u0026quot; \u0026quot;strings\u0026quot;] 当然，你的代码很少包含自由浮动的字元，因为它们本身实际上并不做什么。相反，你会在操作中使用字面符号。操作是你做事情的方式。所有操作的形式都是：*开括号，*操作符，*操作数，闭括号。\n(operator operand1 operand2 ... operandn) 请注意，这里没有逗号。Clojure 使用空格来分隔操作数，它将逗号视为空格。下面是一些操作的例子。\n(+ 1 2 3) ; =\u0026gt; 6 (str \u0026quot;It was the panda \u0026quot; \u0026quot;in the library \u0026quot; \u0026quot;with a dust buster\u0026quot;) ; =\u0026gt; \u0026quot;It was the panda in the library with a dust buster\u0026quot; 在第一个操作中，运算符+将操作数1、2和3相加。在第二个操作中，运算符str将三个字符串连接起来，形成一个新的字符串。这两种形式都是有效的。这里有一个不是形式的东西，因为它没有一个结束的小括号。\n(+ Clojure 的结构统一性可能与你所习惯的不同。在其他语言中，不同的操作可能有不同的结构，这取决于操作符和操作数。例如，JavaScript 采用的是 infix 符号、点运算符和小括号的大杂烩。\n1 + 2 + 3 \u0026quot;It was the panda \u0026quot;.concat(\u0026quot;in the library \u0026quot;, \u0026quot;with a dust buster\u0026quot;) 相比之下，Clojure 的结构是非常简单和一致的。无论你使用哪种运算符，或对哪种数据进行操作，其结构都是一样的。\n控制流 让我们来看看三个基本的控制流操作符。if, do, 和when。在本书中，你会遇到更多的操作，但这些操作可以让你开始。\nif 这是一个 \u0026ldquo;if \u0026ldquo;表达式的一般结构。\n(if boolean-form then-form optional-else-form) 布尔形式只是一个评估为真值或假值的形式。你会在下一节中了解到真实性和虚假性。下面是几个`if\u0026rsquo;的例子。\n(if true \u0026quot;By Zeus's hammer!\u0026quot; \u0026quot;By Aquaman's trident!\u0026quot;) ; =\u0026gt; \u0026quot;By Zeus's hammer!\u0026quot; (if false \u0026quot;By Zeus's hammer!\u0026quot; \u0026quot;By Aquaman's trident!\u0026quot;) ; =\u0026gt; \u0026quot;By Aquaman's trident!\u0026quot; 第一个例子返回 \u0026ldquo;靠宙斯的锤子！\u0026quot;，因为其布尔形式评估为 \u0026ldquo;true\u0026rdquo;，是一个真实的值；第二个例子返回 \u0026ldquo;靠阿卡曼的三叉戟！\u0026quot;，因为其布尔形式 \u0026ldquo;false\u0026rdquo;，评估为一个错误的值。\n你也可以省略else分支。如果你这样做，并且布尔表达式是假的，Clojure 会返回nil，就像这样。\n(if false \u0026quot;By Odin's Elbow!\u0026quot;) ; =\u0026gt; nil 注意if使用操作数位置将操作数与then和else分支联系起来：第一个操作数是then分支，第二个操作数是（可选）else分支。因此，每个分支只能有一种形式。这与大多数语言不同。例如，你可以在 Ruby 中这样写。\nif true doer.do_thing(1) doer.do_thing(2) else other_doer.do_thing(1) other_doer.do_thing(2) end 为了绕过这个明显的限制，你可以使用do操作符。\ndo do操作符可以让你在括号中包裹起多个表单，并运行其中的每一个。在你的 REPL 中尝试以下操作。\n(if true (do (println \u0026quot;Success!\u0026quot;) \u0026quot;By Zeus's hammer!\u0026quot;) (do (println \u0026quot;Failure!\u0026quot;) \u0026quot;By Aquaman's trident!\u0026quot;)) ; =\u0026gt; Success! ; =\u0026gt; \u0026quot;By Zeus's hammer!\u0026quot; 这个操作符让你在if表达式的每个分支中做多件事情。在这种情况下，会发生两件事。成功！被打印在 REPL 中，\u0026quot;通过宙斯的锤子！\u0026quot;被作为整个if表达式的值返回。\nwhen when操作符就像if和do的组合，但没有else分支。下面是一个例子。\n(when true (println \u0026quot;Success!\u0026quot;) \u0026quot;abra cadabra\u0026quot;) ; =\u0026gt; Success! ; =\u0026gt; \u0026quot;abra cadabra\u0026quot; 如果你想在某个条件为真时做多件事，而你总是想在条件为假时返回nil'，请使用when`。\nnil, true, false, Truthiness, Equality, and Boolean Expressions Clojure 有true和false值。nil在 Clojure 中用来表示没有值。你可以用适当命名的nil?函数来检查一个值是否为nil。\n(nil? 1) ; =\u0026gt; false (nil? nil) ; =\u0026gt; true nil和false都是用来表示逻辑上的虚假性，而所有其他的值都是逻辑上的真实性。Truthy和falsey指的是在布尔表达式中如何处理一个值，比如传递给if的第一个表达式。\n(if \u0026quot;bears eat beets\u0026quot; \u0026quot;bears beets Battlestar Galactica\u0026quot;) ; =\u0026gt; \u0026quot;bears beets Battlestar Galactica\u0026quot; (if nil \u0026quot;This won't be the result because nil is falsey\u0026quot; \u0026quot;nil is falsey\u0026quot;) ; =\u0026gt; \u0026quot;nil is falsey\u0026quot; 在第一个例子中，字符串\u0026quot;熊吃甜菜\u0026quot;被认为是真实的，所以if表达式评估为\u0026quot;熊吃甜菜Battlestar Galactica\u0026quot;。第二个例子显示一个假值是假的。\nClojure 的平等运算符是=。\n(= 1 1) ; =\u0026gt; true (= nil nil) ; =\u0026gt; true (= 1 2) ; =\u0026gt; false 其他一些语言要求你在比较不同类型的值时使用不同的运算符。例如，你可能不得不使用某种专门为字符串制作的特殊字符串平等运算符。但在使用 Clojure 的内置数据结构时，你不需要像这样奇怪或繁琐的东西来测试平等性。\nClojure 使用布尔运算符or和and。or返回第一个真值或最后一个值。and返回第一个错误的值，如果没有错误的值，则返回最后一个真实的值。让我们先看一下or。\n(or false nil :large_I_mean_venti :why_cant_I_just_say_large) ; =\u0026gt; :large_I_mean_venti (or (= 0 1) (= \u0026quot;yes\u0026quot; \u0026quot;no\u0026quot;)) ; =\u0026gt; false (or nil) ; =\u0026gt; nil 在第一个例子中，返回值是:large_I_mean_venti，因为它是第一个真值。第二个例子没有真值，所以or返回最后一个值，即false。在最后一个例子中，同样没有真值存在，or返回最后一个值，即nil。现在我们来看看and。\n(and :free_wifi :hot_coffee) ; =\u0026gt; :hot_coffee (and :feelin_super_cool nil false) ; =\u0026gt; nil 在第一个例子中，and返回最后一个真值，:hot_coffee。在第二个例子中, and返回nil, 这是第一个错误的值.\n用 def 命名数值 在 Clojure 中, 你可以使用def将一个名字与一个值结合起来:\n(def failed-protagonist-names [\u0026quot;Larry Potter\u0026quot; \u0026quot;Doreen the Explorer\u0026quot; \u0026quot;The Incredible Bulk\u0026quot;]) failed-protagonist-names ; =\u0026gt; [\u0026quot;Larry Potter\u0026quot; \u0026quot;Doreen the Explorer\u0026quot; \u0026quot;The Incredible Bulk\u0026quot;] 在这个例子中，你把名字failed-protagonist-names绑定到一个包含三个字符串的 Vector（你将在\u0026ldquo;Vector \u0026ldquo;第 45 页中了解 Vector）。\n请注意，我使用的是 \u0026ldquo;绑定 \u0026ldquo;一词，而在其他语言中，你会说你是在给一个变量赋值。那些其他语言通常鼓励你对同一个变量进行多次赋值。\n例如，在 Ruby 中，你可以对一个变量进行多次赋值，以建立它的值。\nseverity = :mild error_message = \u0026quot;OH GOD! IT'S A DISASTER! WE'RE \u0026quot; if severity == :mild error_message = error_message + \u0026quot;MILDLY INCONVENIENCED!\u0026quot; else error_message = error_message + \u0026quot;DOOOOOOOMED!\u0026quot; end 你可能想在 Clojure 中做类似的事情。\n(def severity :mild) (def error-message \u0026quot;OH GOD! IT'S A DISASTER! WE'RE \u0026quot;) (if (= severity :mild) (def error-message (str error-message \u0026quot;MILDLY INCONVENIENCED!\u0026quot;)) (def error-message (str error-message \u0026quot;DOOOOOOOMED!\u0026quot;))) 然而，像这样改变与名字相关的值会使你更难理解你的程序的行为，因为更难知道哪个值是与名字相关的，或者为什么这个值可能已经改变了。Clojure 有一套处理变化的工具，你会在第 10 章中了解到。随着你对 Clojure 的学习，你会发现你很少需要改变一个名字/值的关联。下面是你写前面代码的一种方式。\n(defn error-message [severity] (str \u0026quot;OH GOD! IT'S A DISASTER! WE'RE \u0026quot; (if (= severity :mild) \u0026quot;MILDLY INCONVENIENCED!\u0026quot; \u0026quot;DOOOOOOOMED!\u0026quot;))) (error-message :mild) ; =\u0026gt; \u0026quot;OH GOD! IT'S A DISASTER! WE'RE MILDLY INCONVENIENCED!\u0026quot; 这里，你创建了一个函数，error-message，它接受一个参数，severity，并使用它来决定返回哪个字符串。然后你用:mild作为严重程度来调用这个函数。你将在\u0026ldquo;函数 \u0026ldquo;第 48 页中学习所有关于创建函数的知识；与此同时，你应该把def当作定义常量。在接下来的几章中，你将学习如何通过接受函数式编程范式来处理这个明显的限制。\n数据结构 Clojure 带有少量的数据结构，你在大多数时候都会用到。如果你来自面向对象的背景，你会惊讶于你可以用这里介绍的看似基本的类型做很多事情。\nClojure 的所有数据结构都是不可改变的，这意味着你不能在原地改变它们。例如，在 Ruby 中，你可以做以下事情来重新分配索引为 0 的失败主角的名字。\nfailed_protagonist_names = [ \u0026quot;Larry Potter\u0026quot;, \u0026quot;Doreen the Explorer\u0026quot;, \u0026quot;The Incredible Bulk\u0026quot; ] failed_protagonist_names[0] = \u0026quot;Gary Potter\u0026quot; failed_protagonist_names # =\u0026gt; [ # \u0026quot;Gary Potter\u0026quot;, # \u0026quot;Doreen the Explorer\u0026quot;, # \u0026quot;The Incredible Bulk\u0026quot; # ] Clojure 没有与之对应的东西。你会在第 10 章中了解到更多关于 Clojure 这样实现的原因，但现在只学习如何做事情，而不考虑所有的哲学问题，这很有趣。不多说了，让我们来看看 Clojure 中的数字。\n数字 Clojure 有相当复杂的数字支持。我不会花太多时间纠缠于无聊的技术细节（比如强制和传染），因为那会妨碍做事情。如果你对这些枯燥的细节感兴趣，请查看*http://clojure.org/data_**structures#Data%20Structures-Numbers*的文档。可以说，Clojure 会很高兴地处理你扔给它的几乎所有东西。\n在此期间，我们将使用整数和浮点数。我们还将使用比率，Clojure 可以直接表示这些比率。下面分别是一个整数、一个浮点数和一个比率。\n93 1.2 1/5 字符串 字符串代表文本。这个名字来自于古代腓尼基人，他们在一次涉及纱线的事故后，有一天发明了字母表。下面是一些字符串字面的例子。\n\u0026quot;Lord Voldemort\u0026quot; \u0026quot;\\\u0026quot;He who must not be named\\\u0026quot;\u0026quot; \u0026quot;\\\u0026quot;Great cow of Moscow!\\\u0026quot; - Hermes Conrad\u0026quot; 注意，Clojure 只允许用双引号来划分字符串。例如，\u0026ldquo;Lord Voldemort \u0026ldquo;就不是一个有效的字符串。还要注意，Clojure 没有字符串插值。它只允许通过str函数进行连接。\n(def name \u0026quot;Chewbacca\u0026quot;) (str \u0026quot;\\\u0026quot;Uggllglglglglglll\\\u0026quot; - \u0026quot; name) ; =\u0026gt; \u0026quot;Uggllglglglglglll\u0026quot; - Chewbacca Map Map 类似于其他语言中的字典或哈希值。它们是一种将一些值与另一些值联系起来的方式。Clojure 中的两种 Map 是哈希 Map 和排序 Map。我将只介绍更基本的哈希图。让我们来看看 Map 字面的一些例子。这里有一个空 Map。\n{} 在这个例子中，:first-name和:last-name是关键字（我将在下一节介绍这些）。\n{:first-name \u0026quot;Charlie\u0026quot; :last-name \u0026quot;McFishwich\u0026quot;} 这里我们把\u0026quot;string-key\u0026quot;和+函数联系起来。\n{\u0026quot;string-key\u0026quot; +} Map 可以被嵌套。\n{:name {:first \u0026quot;John\u0026quot; :middle \u0026quot;Jacob\u0026quot; :last \u0026quot;Jingleheimerschmidt\u0026quot;}}. 注意，Map 的值可以是任何类型\u0026ndash;字符串、数字、Map、Vector，甚至函数。Clojure 并不关心这个问题。\n除了使用 map 字面，你还可以使用hash-map函数来创建一个 map。\n(hash-map :a 1 :b 2) ; =\u0026gt; {:a 1 :b 2}. 你可以用get函数在 Map 中查询数值。\n(get {:a 0 :b 1} :b) ; =\u0026gt; 1 (get {:a 0 :b {:c \u0026quot;ho hum\u0026quot;}} :b) ; =\u0026gt; {:c \u0026quot;ho hum\u0026quot;} 在这两个例子中，我们向get询问给定 Map 中:b键的值\u0026ndash;在第一个例子中，它返回1，而在第二个例子中，它返回嵌套 Map{:c \u0026quot;ho hum\u0026quot;}。\n如果没有找到你的键，get将返回nil'，或者你可以给它一个默认值，例如\u0026ldquo;独角兽？\u0026quot;`。\n(get {:a 0 :b 1} :c) ; =\u0026gt; nil (get {:a 0 :b 1} :c \u0026quot;unicorns?\u0026quot;) ; =\u0026gt; \u0026quot;unicorns?\u0026quot; get-in函数可以让你在嵌套 Map 中查询数值。\n(get-in {:a 0 :b {:c \u0026quot;ho hum\u0026quot;}} [:b :c]) ; =\u0026gt; \u0026quot;ho hum\u0026quot; 另一种在 Map 中查询数值的方法是把 Map 当作一个以键为参数的函数。\n({:name \u0026quot;The Human Coffeepot\u0026quot;} :name) ; =\u0026gt; \u0026quot;The Human Coffeepot\u0026quot; 你可以用 Map 做的另一件很酷的事情是把 Keywords 作为函数来查询它们的值，这就引出了下一个主题，Keywords。\nKeywords 了解 Clojure 关键字的最好方法是看它们是如何被使用的。正如你在上一节中所看到的，它们主要是作为 Map 中的键来使用。下面是一些 Keywords 的例子。\n:a :rumplestiltsken :34 :_? Keywords 可以作为函数使用，在数据结构中查找相应的值。例如，你可以在一个 Map 中查找:a。\n(:a {:a 1 :b 2 :c 3}) ; =\u0026gt; 1 这相当于。\n(get {:a 1 :b 2 :c 3} :a) ; =\u0026gt; 1 你可以提供一个默认值，和get一样。\n(:d {:a 1 :b 2 :c 3} \u0026quot;No gnome knows homes like Noah knows\u0026quot;) ; =\u0026gt; \u0026quot;No gnome knows homes like Noah knows\u0026quot; 使用关键字作为一个函数是令人愉快的简洁，Real Clojurists 一直在这样做。你也应该这样做!\n矢量 Vector 类似于数组, 它是一个以 0 为索引的 Set。例如, 下面是一个 Vector 的字面意思:\n[3 2 1] 这里我们要返回一个 Vector 的第 0 个元素。\n(get [3 2 1] 0) ; =\u0026gt; 3 下面是另一个按索引获取的例子。\n(get [\u0026quot;a\u0026quot; {:name \u0026quot;Pugsley Winterbottom\u0026quot;} \u0026quot;c\u0026quot;] 1) ; =\u0026gt; {:name \u0026quot;Pugsley Winterbottom\u0026quot;} 你可以看到，Vector 元素可以是任何类型，而且你可以混合类型。还注意到我们使用的get函数与我们在 Map 中查找数值时使用的相同。\n你可以用vector函数来创建 Vector。\n(vector \u0026quot;creepy\u0026quot; \u0026quot;full\u0026quot; \u0026quot;moon\u0026quot;) ; =\u0026gt; [\u0026quot;creepy\u0026quot; \u0026quot;full\u0026quot; \u0026quot;moon\u0026quot;] 你可以使用conj函数来添加额外的元素到 Vector 中。元素被添加到 Vector 的*端。\n(conj [1 2 3] 4) ; =\u0026gt; [1 2 3 4] Vector 不是存储序列的唯一方法；Clojure 还有列表。\nLists Lists 与 Vector 类似，它们都是数值的线性 Set。但也有一些区别。例如，你不能用get检索列表元素。要写一个列表的字面意思, 只需将元素插入括号内, 并在开头使用单引号:\n'(1 2 3 4) ; =\u0026gt; (1 2 3 4) 注意，当 REPL 打印出列表时，它不包括单引号。我们将在后面的第 7 章中再来讨论为什么会这样。如果你想从一个列表中检索一个元素，你可以使用 nth 函数。\n(nth '(:a :b :c) 0) ; =\u0026gt; :a (nth '(:a :b :c) 2) ; =\u0026gt; :c 我在本书中没有详细介绍性能，因为我认为在你熟悉一种语言之后再关注它是没有用的。然而，知道使用nth从列表中检索一个元素比使用get从 Vector 中检索一个元素要慢一些是很好的。这是因为 Clojure 必须遍历一个列表中的所有n个元素才能到达n个，而通过索引访问一个 Vector 元素最多只需要几跳。\n列表值可以有任何类型，你可以用list函数创建列表。\n(list 1 \u0026quot;two\u0026quot; {3 4}) ; =\u0026gt; (1 \u0026quot;二\u0026quot; {3 4}) 元素被添加到一个列表的开头。\n(conj '(1 2 3) 4) ; =\u0026gt; (4 1 2 3) 什么时候应该使用列表，什么时候应该使用 Vector？一个好的经验法则是，如果你需要很容易地把项目添加到一个序列的开头，或者你正在写一个宏，你应该使用一个列表。否则，你应该使用矢量。随着你学习的深入，你会对何时使用哪种方法有很好的感觉。\nSet Set 是唯一值的 Set。Clojure 有两种类型的 Set：哈希 Set 和排序 Set。我将专注于哈希集，因为它们更经常被使用。下面是一个哈希集的文字符号。\n#{\u0026quot;kurt vonnegut\u0026quot; 20 :icicle}. 你也可以用hash-set来创建一个 Set:\n(hash-set 1 1 2 2) ; =\u0026gt; #{1 2} 注意，一个值的多个实例在 Set 中成为一个唯一的值，所以我们只剩下一个1和一个2。如果你试图将一个值添加到一个已经包含该值的 Set 中（比如下面代码中的:b），它仍然只有一个该值。\n( conj #{:a :b} :b) ; =\u0026gt; #{:a :b} 你也可以通过使用set函数从现有的 Vector 和列表中创建 Set。\n(set [3 3 3 4 4]) ; =\u0026gt; #{3 4} 你可以使用contains?函数来检查 Set 的成员资格，通过使用get，或通过使用关键字作为函数，以 Set 为参数。contains?返回true或false，而get和关键字查找将返回存在的值，如果不存在，则返回nil。\n下面是你如何使用contains?。\n(contains? #{:a :b} :a) ; =\u0026gt; true (contains? #{:a :b} 3) ; =\u0026gt; false (contains? #{nil} nil) ; =\u0026gt; true 下面是你如何使用关键字。\n(:a #{:a :b}) ; =\u0026gt; :a 这里是你如何使用get的方法。\n(get #{:a :b} :a) ; =\u0026gt; :a (get #{:a nil} nil) ; =\u0026gt; nil (get #{:a :b} \u0026quot;kurt vonnegut\u0026quot;) ; =\u0026gt; nil 注意，使用get来测试一个 Set 是否包含nil，将总是返回nil，这令人困惑。当你专门测试 Set 成员时，contains?可能是更好的选择。\n简单性 你可能已经注意到，到目前为止，对数据结构的处理并不包括对如何创建新类型或类的描述。原因是 Clojure 对简单性的强调鼓励你首先去接触内置的数据结构。\n如果你来自面向对象的背景，你可能会认为这种方法很奇怪而且落后。然而，你会发现，你的数据不一定非要和一个类紧密地捆绑在一起，才是有用和可理解的。这里有一个被 Clojurists 喜爱的寓言故事，暗示了 Clojure 的哲学。\n 让 100 个函数操作一个数据结构比让 10 个函数操作 10 个数据结构要好。 -Alan Perlis\n 在接下来的章节中，你会了解到更多关于 Clojure 哲学的这个方面。现在，请留意你通过坚持使用基本数据结构来获得代码重用性的方法。\n我们的 Clojure 数据结构入门课程到此结束。现在，是时候深入到函数中去，学习如何使用这些数据结构了\n函数 人们为 Lisps 疯狂的原因之一是，这些语言可以让你建立起行为复杂的程序，但主要的构件\u0026ndash;函数\u0026ndash;却是如此简单。本节通过解释以下内容，让你开始了解 Lisp 函数的美丽和优雅。\n 调用函数 函数与宏和特殊形式有什么不同 定义函数 匿名函数 返回函数  调用函数 现在你已经看到了许多函数调用的例子。\n(+ 1 2 3 4) (* 1 2 3 4) (first [1 2 3 4]) 请记住，所有的 Clojure 操作都有相同的语法：开括号、操作符、操作数、闭括号。函数**调用只是操作的另一个术语，其中运算符是一个函数或一个函数**表达式（一个返回函数的表达式）。\n这可以让你写出一些相当有趣的代码。下面是一个函数表达式，它返回+（加法）函数。\n(or + -) ; =\u0026gt; #\u0026lt;core$_PLUS_ clojure.core$_PLUS_@76dace31\u0026gt; 该返回值是加法函数的字符串表示。因为or的返回值是第一个真值，而这里的加法函数是真值，所以返回的是加法函数。你也可以在另一个表达式中使用这个表达式作为运算符。\n((or + -) 1 2 3) ; =\u0026gt; 6 因为(or + -)返回+，这个表达式被评估为1、2和3之和，返回6。\n下面是几个有效的函数调用，它们都返回`6'。\n((and (= 1 1) +) 1 2 3) ; =\u0026gt; 6 ((first [+ 0]) 1 2 3) ; =\u0026gt; 6 在第一个例子中，and的返回值是第一个假值或最后一个真值。在这个例子中，+被返回，因为它是最后一个真值，然后被应用于参数1 2 3，返回6。在第二个例子中，first的返回值是一个序列中的第一个元素，在这个例子中是+。\n然而，这些都不是有效的函数调用，因为数字和字符串都不是函数。\n(1 2 3 4) (\u0026quot;test\u0026quot; 1 2 3) 如果你在 REPL 中运行这些，你会得到这样的结果。\nClassCastException java.lang.String cannot be cast to clojure.lang.IFn user/eval728 (NO_SOURCE_FILE:1) 当你继续使用 Clojure 时，你可能会多次看到这个错误。 cannot be cast to clojure.lang.IFn只是意味着你试图将某个东西作为一个函数使用，而它并不是。\n函数的灵活性并没有随着函数表达式的出现而结束! 在语法上，函数可以接受任何表达式作为参数\u0026ndash;包括其他函数*。可以接受一个函数作为参数或返回一个函数的函数被称为高阶函数*。具有高阶函数的编程语言被称为支持第一类函数*，因为你可以像对待数字和 Vector 等更熟悉的数据类型一样，将函数作为值来处理。\n以map函数（不要与 map 数据结构混淆）为例。map通过对一个集合的每个成员应用一个函数来创建一个新的列表。这里，inc函数将一个数字增加 1。\n(inc 1.1) ; =\u0026gt; 2.1 (map inc [0 1 2 3]) ; =\u0026gt; (1 2 3 4) (注意map并不返回一个 Vector，尽管我们提供了一个 Vector 作为参数。你将在第四章中了解原因。现在，请相信这是好的，也是预期的）。\nClojure 对一级函数的支持使你能够建立比没有一级函数的语言更强大的抽象概念。那些不熟悉这种编程方式的人认为函数允许你对数据实例进行泛化操作。例如，+函数对任何特定数字的加法进行了抽象。\n相比之下，Clojure（以及所有 Lisps）允许你创建泛化进程的函数。map允许你通过在任何集合上应用一个函数\u0026ndash;任何函数\u0026ndash;来概括转换一个集合的过程。\n你需要知道的关于函数调用的最后一个细节是，Clojure 在将所有函数参数传递给函数之前，会递归地评估这些参数。下面是 Clojure 如何评估一个参数也是函数调用的函数调用。\n(+ (inc 199) (/ 100 (- 7 2))) (+ 200 (/ 100 (- 7 2))) ; evaluated \u0026quot;(inc 199)\u0026quot; (+ 200 (/ 100 5)) ; evaluated (- 7 2) (+ 200 20) ; evaluated (/ 100 5) 220 ; final evaluation 函数调用启动了评估过程，在应用+函数之前，所有的子表格都被评估了。\n函数调用、宏调用和特殊形式 在上一节中，你了解到函数调用是以函数表达式为操作符的表达式。另外两种表达式是宏调用和特殊形式。你已经看到了几种特殊形式：定义和if表达式。\n你将在第 7 章中学习关于宏调用和特殊形式的所有知识。现在，使特殊形式 \u0026ldquo;特殊 \u0026ldquo;的主要特征是，与函数调用不同，它们不总是评估所有**它们的操作数。\n以 \u0026ldquo;if \u0026ldquo;为例。这是它的一般结构。\n(if boolean-form then-form optional-else-form) 现在想象一下你有一个这样的if语句。\n(if good-mood (tweet walking-on-sunshine-lyrics) (tweet mopey-country-song-lyrics)) 显然，在这样的if表达中，我们希望 Clojure 只评估两个分支中的一个。如果 Clojure 同时评估两个`tweet\u0026rsquo;函数调用，你的 Twitter 粉丝们最终会非常困惑。\n另一个区别于特殊形式的特征是，你不能把它们作为函数的参数。一般来说，特殊形式实现了 Clojure 的核心功能，只是不能用函数实现。Clojure 只有少量的特殊形式，而如此丰富的语言是用如此小的一组构建块来实现的，这是很令人惊讶的。\n宏与特殊形式类似，它们对操作数的评估与函数调用不同，而且它们也不能作为参数传递给函数。但这段弯路已经走得够长了；现在是学习如何定义函数的时候了!\n定义函数 函数的定义由五个主要部分组成。\n defn 函数名称 描述该函数的 docstring(可选) 括号中列出的参数 函数主体  下面是一个函数定义的例子和函数的调用示例。\n➊ (defn too-enthusiastic ➋ \u0026quot;Return a cheer that might be a bit too enthusiastic\u0026quot; ➌ [name] ➍ (str \u0026quot;OH. MY. GOD! \u0026quot; name \u0026quot; YOU ARE MOST DEFINITELY LIKE THE BEST \u0026quot; \u0026quot;MAN SLASH WOMAN EVER I LOVE YOU AND WE SHOULD RUN AWAY SOMEWHERE\u0026quot;)) (too-enthusiastic \u0026quot;Zelda\u0026quot;) ; =\u0026gt; \u0026quot;OH. MY. GOD! Zelda YOU ARE MOST DEFINITELY LIKE THE BEST MAN SLASH WOMAN EVER I LOVE YOU AND WE SHOULD RUN AWAY SOMEWHERE\u0026quot; 在➊处，too-enthusiastic是函数的名称，在➋处有一个描述性的 docstring。参数 \u0026ldquo;name \u0026ldquo;在➌处给出，函数体在➍处接受参数，并做了它所描述的事情\u0026ndash;返回一个可能有点过于热情的欢呼。\n让我们更深入地了解 docstring、参数和函数体。\ndocstring docstring*是一种描述和记录你的代码的有用方法。你可以在 REPL 中用 (docfn-name)查看一个函数的 docstring，例如 (doc map)。如果你使用一个工具为你的代码生成文档，那么 docstring 也会发挥作用。\n参数和 Arity Clojure 函数可以用零个或多个参数来定义。你传递给函数的值被称为arguments，参数可以是任何类型。参数的数量就是函数的*特性。下面是一些具有不同性质的函数定义。\n(defn no-params [] \u0026quot;I take no parameters!\u0026quot;) (defn one-param [x] (str \u0026quot;I take one parameter: \u0026quot; x)) (defn two-params [x y] (str \u0026quot;Two parameters! That's nothing! Pah! I will smoosh them \u0026quot; \u0026quot;together to spite you! \u0026quot; x y)) 在这些例子中，no-params是一个 0-arity 函数，one-param是 1-arity，two-params是 2-arity。\n函数也支持 arity overloading。这意味着你可以定义一个函数，使不同的函数体根据不同的 arity 来运行。下面是一个多义性函数定义的一般形式。请注意，每个数位定义都被括在括号里，并且有一个参数列表。\n(defn multi-arity ;; 3-arity arguments and body ([first-arg second-arg third-arg] (do-things first-arg second-arg third-arg)) ;; 2-arity arguments and body ([first-arg second-arg] (do-things first-arg second-arg)) ;; 1-arity arguments and body ([first-arg] (do-things first-arg))) Arity 重载是为参数提供默认值的一种方法。在下面的例子中，\u0026quot;karate\u0026quot;是chop-type参数的默认参数。\n(defn x-chop \u0026quot;Describe the kind of chop you're inflicting on someone\u0026quot; ([name chop-type] (str \u0026quot;I \u0026quot; chop-type \u0026quot; chop \u0026quot; name \u0026quot;! Take that!\u0026quot;)) ([name] (x-chop name \u0026quot;karate\u0026quot;))) 如果你用两个参数调用x-chop，该函数的工作原理和它不是一个多义性函数时一样。\n(x-chop \u0026quot;Kanye West\u0026quot; \u0026quot;slap\u0026quot;) ; =\u0026gt; \u0026quot;I slap chop Kanye West! Take that!\u0026quot; 如果你调用x-chop时只有一个参数，x-chop实际上会在提供第二个参数\u0026quot;空手道\u0026quot;时调用自己。\n(x-chop \u0026quot;Kanye East\u0026quot;) ; =\u0026gt; \u0026quot;I karate chop Kanye East! Take that!\u0026quot; 像这样用函数本身来定义一个函数，可能显得不寻常。如果是这样，那就好了! 你正在学习一种新的方法来做事!\n你也可以让每个 arity 做一些完全不相关的事情。\n(defn weird-arity ([] \u0026quot;Destiny dressed you this morning, my friend, and now Fear is trying to pull off your pants. If you give up, if you give in, you're gonna end up naked with Fear just standing there laughing at your dangling unmentionables! - the Tick\u0026quot;) ([number] (inc number))) 0-arity 主体返回一个明智的引号，1-arity 主体增加一个数字。最有可能的是，你不会想写一个这样的函数，因为有两个完全不相关的函数体会让人困惑。\nClojure 还允许你通过包括一个rest 参数来定义可变极性函数，就像 \u0026ldquo;把这些参数的其余部分放在一个列表中，名称如下\u0026rdquo;。休息参数用安培号（\u0026amp;）表示，如➊所示。\n(defn codger-communication [whippersnapper] (str \u0026quot;Get off my lawn, \u0026quot; whippersnapper \u0026quot;!!!\u0026quot;)) (defn codger ➊ [\u0026amp; whippersnappers] (map codger-communication whippersnappers)) (codger \u0026quot;Billy\u0026quot; \u0026quot;Anne-Marie\u0026quot; \u0026quot;The Incredible Bulk\u0026quot;) ; =\u0026gt; (\u0026quot;Get off my lawn, Billy!!!\u0026quot; \u0026quot;Get off my lawn, Anne-Marie!!!\u0026quot; \u0026quot;Get off my lawn, The Incredible Bulk!!!\u0026quot;) 正如你所看到的，当你为变量性质的函数提供参数时，参数被当作一个列表来处理。你可以把休息参数和普通参数混在一起，但休息参数必须放在最后。\n(defn favorite-things [name \u0026amp; things] (str \u0026quot;Hi, \u0026quot; name \u0026quot;, here are my favorite things: \u0026quot; (clojure.string/join \u0026quot;, \u0026quot; things))) (favorite-things \u0026quot;Doreen\u0026quot; \u0026quot;gum\u0026quot; \u0026quot;shoes\u0026quot; \u0026quot;kara-te\u0026quot;) ; =\u0026gt; \u0026quot;Hi, Doreen, here are my favorite things: gum, shoes, kara-te\u0026quot; 最后，Clojure 有一种更复杂的定义参数的方法，叫做destructuring，这值得有自己的小节。\n解构 解构的基本思想是，它可以让你在一个集合中简洁地将名字与值绑定。让我们看看一个基本的例子。\n;; Return the first element of a collection (defn my-first [[first-thing]] ; Notice that first-thing is within a vector first-thing) (my-first [\u0026quot;oven\u0026quot; \u0026quot;bike\u0026quot; \u0026quot;war-axe\u0026quot;]) ; =\u0026gt; \u0026quot;oven\u0026quot; 这里，my-first函数将符号first-thing与作为参数传入的 Vector 中的第一个元素联系起来。你告诉my-first这样做，就是把符号first-thing放在一个 Vector 中。\n矢量就像一个巨大的牌子，对 Clojure 说：\u0026ldquo;嘿！这个函数将收到一个列表或矢量作为参数。让我的生活更轻松，为我拆开参数的结构，并将有意义的名字与参数的不同部分联系起来！\u0026rdquo; 当对一个 Vector 或列表进行解构时，你可以随意命名你想要的元素，也可以使用其他参数。\n(defn chooser [[first-choice second-choice \u0026amp; unimportant-choices]] (println (str \u0026quot;Your first choice is: \u0026quot; first-choice)) (println (str \u0026quot;Your second choice is: \u0026quot; second-choice)) (println (str \u0026quot;We're ignoring the rest of your choices. \u0026quot; \u0026quot;Here they are in case you need to cry over them: \u0026quot; (clojure.string/join \u0026quot;, \u0026quot; unimportant-choices)))) (chooser [\u0026quot;Marmalade\u0026quot;, \u0026quot;Handsome Jack\u0026quot;, \u0026quot;Pigpen\u0026quot;, \u0026quot;Aquaman\u0026quot;]) ; =\u0026gt; Your first choice is: Marmalade ; =\u0026gt; Your second choice is: Handsome Jack ; =\u0026gt; We're ignoring the rest of your choices. Here they are in case \\ you need to cry over them: Pigpen, Aquaman 这里，其余的参数unimportant``-choices处理用户在第一和第二选择之后的任何数量的额外选择。\n你也可以对 Map 进行去结构化。就像你告诉 Clojure 通过提供一个 Vector 作为参数来解除 Vector 或列表的结构一样，你可以通过提供一个 Map 作为参数来解除 Map 的结构。\n(defn announce-treasure-location ➊ [{lat :lat lng :lng}] (println (str \u0026quot;Treasure lat: \u0026quot; lat)) (println (str \u0026quot;Treasure lng: \u0026quot; lng))) (announce-treasure-location {:lat 28.22 :lng 81.33}) ; =\u0026gt; Treasure lat: 28.22 ; =\u0026gt; Treasure lng: 81.33 让我们更详细地看看➊的那一行。这就像告诉 Clojure，\u0026ldquo;哟！Clojure! 为我做一件事，把lat这个名字与键:lat对应的值联系起来。对lng和:lng做同样的事情，好吗？\u0026rdquo;\n我们经常想直接把关键词从 Map 中分离出来，所以有一个更短的语法。这和前面的例子有相同的结果。\n(defn announce-treasure-location [{:keys [lat lng]}] 。 (println (str \u0026quot;Treasure lat: \u0026quot; lat)) (println (str \u0026quot;Treasure lng: \u0026quot; lng))) 你可以通过使用:as关键字保留对原始 Map 参数的访问。在下面的例子中，原始 Map 是用treasure-location来访问的。\n(defn receive-treasure-location [{:keys [lat lng] :as treasure-location}] (println (str \u0026quot;Treasure lat: \u0026quot; lat)) (println (str \u0026quot;Treasure lng: \u0026quot; lng)) ;; One would assume that this would put in new coordinates for your ship (steer-ship! treasure-location)) 一般来说，你可以把重构看作是指示 Clojure 如何将名字与列表、Map、集合或 Vector 中的值联系起来。现在，我们来看看函数中真正起作用的部分：函数体!\n函数体 函数主体可以包含任何形式的表单。Clojure 会自动返回最后评估的形式。这个函数体只包含三种形式，当你调用这个函数时，它会吐出最后一种形式，\u0026quot;joe\u0026quot;。\n(defn illustrative-function [] (+ 1 304) 30 \u0026quot;joe\u0026quot;) (exstrative-function) ; =\u0026gt; \u0026quot;joe\u0026quot; 下面是另一个函数体，它使用一个if表达式。\n(defn number-comment [x] (if (\u0026gt; x 6) \u0026quot;Oh my gosh! What a big number!\u0026quot; \u0026quot;That number's OK, I guess\u0026quot;)) (number-comment 5) ; =\u0026gt; \u0026quot;That number's OK, I guess\u0026quot; (number-comment 7) ; =\u0026gt; \u0026quot;Oh my gosh! What a big number!\u0026quot; 所有函数都是平等的 最后说明一下：Clojure 没有特权函数。+只是一个函数，-只是一个函数，而inc和map也只是函数。它们并不比你自己定义的函数好。所以，不要让他们给你任何口实!\n更重要的是，这个事实有助于证明 Clojure 的底层简单性。在某种程度上，Clojure 是非常愚蠢的。当你进行函数调用时，Clojure 只是说，\u0026quot;map？当然，不管怎样! 我只是应用这个并继续前进\u0026rdquo;。它并不关心这个函数是什么，或者它来自哪里；它对所有的函数都一视同仁。在它的核心，Clojure 并不关心加法、乘法或 Map 的问题。它只关心函数的应用。\n当你继续用 Clojure 编程时，你会发现这种简单性是很理想的。你不必为处理不同的函数而担心特殊的规则或语法。它们的工作原理都是一样的!\n匿名函数 在 Clojure 中，函数不需要有名字。事实上，你会一直使用匿名函数。多么神秘啊! 你可以通过两种方式创建匿名函数。第一种是使用fn形式。\n(fn [param-list] function body) 看起来很像defn，不是吗？让我们试一试几个例子。\n(map (fn [name] (str \u0026quot;Hi, \u0026quot; name)) [\u0026quot;Darth Vader\u0026quot; \u0026quot;Mr. Magoo\u0026quot;] ) ; =\u0026gt; (\u0026quot;Hi, Darth Vader\u0026quot; \u0026quot;Hi, Mr. Magoo\u0026quot;) ((fn [x] (* x 3)) 8) ; =\u0026gt; 24 你可以用处理fn的方式来处理defn，这几乎是相同的。参数列表和函数体的工作原理完全相同。你可以使用参数重构，休息参数，等等。你甚至可以将你的匿名函数与一个名字联系起来，这不应该是一个惊喜（如果这确实是一个惊喜，那么 \u0026hellip; \u0026hellip; 惊喜！）。\n(def my-special-multiplier (fn [x] (* x 3)) (my-special-multiplier 12) ; =\u0026gt; 36 Clojure 还提供了另一种更紧凑的方式来创建匿名函数。下面是一个匿名函数的样子。\n#(* % 3) 哇，这看起来很奇怪。来吧，应用这个看起来很奇怪的函数。\n(#(* % 3) 8) ; =\u0026gt; 24 下面是一个将匿名函数作为参数传递给 map 的例子。\n(map #(str \u0026quot;Hi, \u0026quot; %) [\u0026quot;Darth Vader\u0026quot; \u0026quot;Mr. Magoo\u0026quot;]) ; =\u0026gt; (\u0026quot;Hi, Darth Vader\u0026quot; \u0026quot;Hi, Mr. Magoo\u0026quot;) 这种看起来很奇怪的匿名函数的编写方式是由一个叫做reader**macros的函数实现的。你会在第 7 章中了解到这些。现在，只学习如何使用这些匿名函数就可以了。\n你可以看到，这种语法肯定更紧凑，但也有点奇怪。让我们把它分解一下。这种匿名函数看起来很像函数调用，只是它前面有一个哈希标记，#。\n;; Function call (* 8 3) ;; Anonymous function #(* % 3) 这种相似性使你能更快地看到应用这个匿名函数时将发生什么。\u0026ldquo;哦，\u0026ldquo;你可以对自己说，\u0026ldquo;这是要把它的参数乘以 3\u0026rdquo;。\n现在你可能已经猜到了，百分号%，表示传递给函数的参数。如果你的匿名函数需要多个参数，你可以像这样区分它们。%1, %2, %3, 以此类推。%相当于%1。\n(#(str %1 \u0026quot; and \u0026quot; %2) \u0026quot;cornbread\u0026quot; \u0026quot;butter beans\u0026quot;) ; =\u0026gt; \u0026quot;cornbread and butter beans\u0026quot; 你也可以用%\u0026amp;传递其余参数。\n(#(identity %\u0026amp;) 1 \u0026quot;blarg\u0026quot; :yip) ; =\u0026gt; (1 \u0026quot;blarg\u0026quot; :yip) 在这种情况下，你将身份函数应用于其余参数。Identity 返回它所给的参数而不改变它。休息参数是以列表形式存储的，所以函数应用返回所有参数的列表。\n如果你需要写一个简单的匿名函数，使用这种风格是最好的，因为它在视觉上很紧凑。另一方面，如果你要写一个更长、更复杂的函数，它很容易变得不可读。如果是这种情况，请使用fn。\n返回函数 现在你已经看到，函数可以返回其他函数。返回的函数是closures，这意味着它们可以访问函数创建时在范围内的所有变量。下面是一个标准的例子。\n(defn inc-maker \u0026quot;Create a custom incrementor\u0026quot; [inc-by] #(+ % inc-by)) (def inc3 (inc-maker 3)) (inc3 7) ; =\u0026gt; 10 这里，inc-by在范围内，所以即使返回的函数在inc-maker之外使用，也可以访问它。\n把这一切拉到一起 好了! 是时候把你新发现的知识用于一个崇高的目的了：打倒霍比特人! 要打一个霍比特人，你首先要建立它的身体部位模型。每个身体部位都将包括其相对大小，以表明该部位被击中的可能性有多大。为了避免重复，霍比特人的模型将只包括左**脚，左**耳的条目，以此类推。因此，你需要一个函数来完全对称该模型，创建右**脚，右**耳，等等。最后，你将创建一个函数，迭代身体各部分，并随机选择击中的部分。在这一过程中，你将了解到一些新的 Clojure 工具。let表达式，循环，和正则表达式。有趣的是!\n夏尔的下一个顶级模型 对于我们的霍比特人模型，我们将避开霍比特人的特征，如活泼和调皮，只关注霍比特人的小身板。下面是霍比特人的模型。\n(def asym-hobbit-body-parts [{:name \u0026quot;head\u0026quot; :size 3} {:name \u0026quot;left-eye\u0026quot; :size 1} {:name \u0026quot;left-ear\u0026quot; :size 1} {:name \u0026quot;mouth\u0026quot; :size 1} {:name \u0026quot;nose\u0026quot; :size 1} {:name \u0026quot;neck\u0026quot; :size 2} {:name \u0026quot;left-shoulder\u0026quot; :size 3} {:name \u0026quot;left-upper-arm\u0026quot; :size 3} {:name \u0026quot;chest\u0026quot; :size 10} {:name \u0026quot;back\u0026quot; :size 10} {:name \u0026quot;left-forearm\u0026quot; :size 3} {:name \u0026quot;abdomen\u0026quot; :size 6} {:name \u0026quot;left-kidney\u0026quot; :size 1} {:name \u0026quot;left-hand\u0026quot; :size 2} {:name \u0026quot;left-knee\u0026quot; :size 2} {:name \u0026quot;left-thigh\u0026quot; :size 4} {:name \u0026quot;left-lower-leg\u0026quot; :size 3} {:name \u0026quot;left-achilles\u0026quot; :size 1} {:name \u0026quot;left-foot\u0026quot; :size 2}]) 这是一个 Map 的 Vector。每个 Map 都有身体部位的名称和身体部位的相对大小。(我知道只有动漫人物的眼睛是头部的三分之一大小，但就这样吧，好吗？)\n明显缺少的是霍比特人的右侧。让我们来解决这个问题。清单 3-1 是到目前为止你看到的最复杂的代码，它引入了一些新的想法。但是不要担心，因为我们将详细地研究它。\n(defn matching-part [part] {:name (clojure.string/replace (:name part) #\u0026quot;^left-\u0026quot; \u0026quot;right-\u0026quot;) :size (:size part)}) (defn symmetrize-body-parts \u0026quot;Expects a seq of maps that have a :name and :size\u0026quot; [asym-body-parts] (loop [remaining-asym-parts asym-body-parts final-body-parts []] (if (empty? remaining-asym-parts) final-body-parts (let [[part \u0026amp; remaining] remaining-asym-parts] (recur remaining (into final-body-parts (set [part (matching-part part)])))))))  3-1. 匹配-部分和对称-身体-部分的函数  当我们对asym-hobbit-body-parts调用函数symmetriz-body-parts时，我们得到一个完全对称的霍比特人。\n(symmetrize-body-parts asym-hobbit-body-parts) ; =\u0026gt; [{:name \u0026quot;head\u0026quot;, :size 3} {:name \u0026quot;left-eye\u0026quot;, :size 1} {:name \u0026quot;right-eye\u0026quot;, :size 1} {:name \u0026quot;left-ear\u0026quot;, :size 1} {:name \u0026quot;right-ear\u0026quot;, :size 1} {:name \u0026quot;mouth\u0026quot;, :size 1} {:name \u0026quot;nose\u0026quot;, :size 1} {:name \u0026quot;neck\u0026quot;, :size 2} {:name \u0026quot;left-shoulder\u0026quot;, :size 3} {:name \u0026quot;right-shoulder\u0026quot;, :size 3} {:name \u0026quot;left-upper-arm\u0026quot;, :size 3} {:name \u0026quot;right-upper-arm\u0026quot;, :size 3} {:name \u0026quot;chest\u0026quot;, :size 10} {:name \u0026quot;back\u0026quot;, :size 10} {:name \u0026quot;left-forearm\u0026quot;, :size 3} {:name \u0026quot;right-forearm\u0026quot;, :size 3} {:name \u0026quot;abdomen\u0026quot;, :size 6} {:name \u0026quot;left-kidney\u0026quot;, :size 1} {:name \u0026quot;right-kidney\u0026quot;, :size 1} {:name \u0026quot;left-hand\u0026quot;, :size 2} {:name \u0026quot;right-hand\u0026quot;, :size 2} {:name \u0026quot;left-knee\u0026quot;, :size 2} {:name \u0026quot;right-knee\u0026quot;, :size 2} {:name \u0026quot;left-thigh\u0026quot;, :size 4} {:name \u0026quot;right-thigh\u0026quot;, :size 4} {:name \u0026quot;left-lower-leg\u0026quot;, :size 3} {:name \u0026quot;right-lower-leg\u0026quot;, :size 3} {:name \u0026quot;left-achilles\u0026quot;, :size 1} {:name \u0026quot;right-achilles\u0026quot;, :size 1} {:name \u0026quot;left-foot\u0026quot;, :size 2} {:name \u0026quot;right-foot\u0026quot;, :size 2}] 让我们来分析一下这段代码!\nlet 在清单 3-1 的大量疯狂中，你可以看到结构(let ...)的形式。让我们通过一个例子来建立对let的理解，当我们熟悉了所有的部分后，再来检查程序中的完整例子。\nlet将名字与值绑定。你可以认为let是let it be的缩写，这也是披头士乐队关于编程的一首优美的歌曲。这里有一个例子。\n(让 [x 3] x) ; =\u0026gt; 3 (def dalmatian-list [\u0026quot;Pongo\u0026quot; \u0026quot;Perdita\u0026quot; \u0026quot;Puppy 1\u0026quot; \u0026quot;Puppy 2\u0026quot;] ) (让 [dalmatians (take 2 dalmatian-list)]) 达尔马提亚人) ; =\u0026gt; (\u0026quot;Pongo\u0026quot; \u0026quot;Perdita\u0026quot;) 在第一个例子中，你将名字x与值3绑定。在第二个例子中，你把名字dalmatians绑定到表达式(取2dalmatian-list)的结果，也就是列表(\u0026quot;Pongo\u0026quot; \u0026quot;Perdita\u0026quot;)。let还引入了一个新的*范围。\n(def x 0) (let [x 1] x) ; =\u0026gt; 1 这里，你首先使用def将名字x绑定到值0上。然后，let创建了一个新的作用域，在这个作用域中，名字x被绑定到值1上。我认为范围是指事物的上下文。例如，在 \u0026ldquo;请清理这些烟头 \u0026ldquo;这句话中，烟头的含义是不同的，这取决于你是在产科病房工作还是在香烟制造商大会的监管人员工作。在这个代码片段中，你在说：\u0026ldquo;我希望x'在全局上下文中是0'，但在这个let'表达式的上下文中，它应该是1'。\u0026rdquo;\n你可以在你的let绑定中引用现有的绑定。\n(def x 0) (let [x (inc x)] x) ; =\u0026gt; 1 在这个例子中，(inc x)中的x是指由(def x 0)创建的绑定。结果是1'，然后在let\u0026rsquo;创建的新作用域中与名称x'绑定。在let表单的范围内，x指的是1，而不是0`。\n你也可以在let中使用休息参数，就像你在函数中一样。\n(let [[Pongo \u0026amp; dalmatians] dalmatian-list] [Pongo dalmatians]) [Pongo dalmatians]) ; =\u0026gt; [\u0026quot;Pongo\u0026quot; (\u0026quot;Perdita\u0026quot; \u0026quot;Puppy 1\u0026quot; \u0026quot;Puppy 2\u0026quot;) ] 注意，let表单的值是其主体中最后被评估的表单。let形式遵循所有在\u0026ldquo;调用函数 \u0026ldquo;第 48 页中介绍的析构规则。在这个例子中，[pongo \u0026amp; dalmatians]解构了dalmatian-list'，将字符串\u0026ldquo;Pongo \u0026ldquo;绑定到名称pongo'上，将其余的dalmatians列表绑定到dalmatians上。Vector[pongo dalmatians]是let的最后一个表达式，所以它是let`形式的值。\nlet形式有两个主要用途。首先，它们通过允许你对事物进行命名来提供清晰度。其次，它们允许你只评估一个表达式，并重复使用其结果。当你需要重复使用一个昂贵的函数调用的结果时，这一点特别重要，比如网络 API 调用。当表达式有副作用时，这也很重要。\n让我们再看一下我们的对称函数中的let形式，这样我们就能明白到底发生了什么。\n(let [[part \u0026amp; remaining] remaining-asym-parts]) (recur remaining (in into final-body-parts (set [part (matching-part part part)])))) 这段代码告诉 Clojure，\u0026ldquo;创建一个新的范围。在它里面，将part与remaining-asym-parts的第一个元素相关联。将remaining与remaining-asym-parts中的其他元素联系起来\u0026rdquo;。\n至于let表达式的主体，你将在下一节中了解到recur的含义。函数调用\n(in into final-body-parts (set [part (matching-part part part)] )) 首先告诉 Clojure, \u0026ldquo;使用set'函数创建一个由part\u0026rsquo;和它的匹配部分组成的集合。然后使用函数into将该集合的元素添加到 Vectorfinal-body-parts中\u0026rdquo;。你在这里创建一个集合，以确保你向final-body-parts添加唯一的元素，因为part和(matching-part part)有时是同一个东西，正如你将在接下来的正则表达式部分看到的。下面是一个简化的例子。\n(into [] (set [:a :a])) ; =\u0026gt; [:a] 首先，(set [:a :a])返回集合#{:a}，因为集合不包含重复的元素。然后(into [] #{:a})返回 Vector[:a]。\n回到let'：注意part\u0026rsquo;在let'的主体中被多次使用。如果我们使用原来的表达式，而不是使用part和remaining`的名字，那将是一个混乱的局面! 下面是一个例子。\n(recur (rest remaining-asym-parts) (in into final-body-parts (set [(first remaining-asym-parts) (matching-part (first remaining-asym-parts)) ])) 所以，let是一种方便的方法，可以为值引入本地名称，这有助于简化代码。\n循环 在我们的symmetrize-body-parts函数中，我们使用了loop，它提供了另一种在 Clojure 中进行递归的方法。让我们看看一个简单的例子。\n(loop [iteration 0] (println (str \u0026#34;Iteration \u0026#34; iteration)) (if (\u0026gt; iteration 3) (println \u0026#34;Goodbye!\u0026#34;) (recur (inc iteration)))) ; =\u0026gt; Iteration 0 ; =\u0026gt; Iteration 1 ; =\u0026gt; Iteration 2 ; =\u0026gt; Iteration 3 ; =\u0026gt; Iteration 4 ; =\u0026gt; Goodbye! 第一行，loop [iteration 0]，开始了循环并引入了一个初始值的绑定。在循环的第一次传递中，iteration的值为 0.接下来，它打印一个短消息。然后，它检查iteration的值。如果该值大于 3，那么是时候说再见了。否则，我们就 \u0026ldquo;重来\u0026rdquo;。这就好比loop创建了一个匿名函数，其参数名为iteration，而recur允许你从其内部调用该函数，传递参数(inc iteration)。\n事实上，你可以通过使用一个普通的函数定义来完成同样的事情。\n(defn recursive-printer ([] (recursive-printer 0)) ([iteration] (println iteration) (if (\u0026gt; iteration 3) (println \u0026#34;Goodbye!\u0026#34;) (recursive-printer (inc iteration))))) (recursive-printer) ; =\u0026gt; Iteration 0 ; =\u0026gt; Iteration 1 ; =\u0026gt; Iteration 2 ; =\u0026gt; Iteration 3 ; =\u0026gt; Iteration 4 ; =\u0026gt; Goodbye! 但正如你所看到的，这是个比较啰嗦的方法。而且，loop有更好的性能。在我们的对称化函数中，我们将使用loop遍历不对称的身体部位列表中的每个元素。\n正则表达式 正则表达式是对文本进行模式匹配的工具。正则表达式的文字符号是将表达式放在哈希标记后的引号中。\n#\u0026quot;regular-expression\u0026quot; 在清单 3-1 中的函数matching-part中，clojure.string/replace使用正则表达式#\u0026quot;^left-\u0026quot;来匹配以\u0026quot;left-\u0026quot;开头的字符串，以便用\u0026quot;right-\u0026quot;替换\u0026quot;left-\u0026quot;。卡特，^，是正则表达式发出的信号，即只有当文本\u0026quot;left-\u0026quot;位于字符串的开头时，它才会匹配，这就确保了像\u0026quot;cleft-chin\u0026quot;这样的字符串不会匹配。你可以用re-find来测试，它检查一个字符串是否与正则表达式描述的模式相匹配，如果不匹配，则返回匹配的文本或nil。\n(re-find #\u0026#34;^left-\u0026#34; \u0026#34;left-eye\u0026#34;) ; =\u0026gt; \u0026#34;left-\u0026#34; (re-find #\u0026#34;^left-\u0026#34; \u0026#34;cleft-chin\u0026#34;) ; =\u0026gt; nil (re-find #\u0026#34;^left-\u0026#34; \u0026#34;wongleblart\u0026#34;) ; =\u0026gt; nil 下面是几个matching-part'的例子，使用一个重词将\u0026ldquo;left-\u0026ldquo;替换为`\u0026ldquo;right-\u0026quot;。\n(defn matching-part [part] {:name (clojure.string/replace (:name part) #\u0026#34;^left-\u0026#34; \u0026#34;right-\u0026#34;) :size (:size part)}) (matching-part {:name \u0026#34;left-eye\u0026#34; :size 1}) ; =\u0026gt; {:name \u0026#34;right-eye\u0026#34; :size 1}] (matching-part {:name \u0026#34;head\u0026#34; :size 3}) ; =\u0026gt; {:name \u0026#34;head\u0026#34; :size 3}] 请注意，名称 \u0026ldquo;head\u0026rdquo; \u0026ldquo;是原样返回的。\n对称器 现在让我们回到完整的对称器，对其进行更详细的分析。\n(def asym-hobbit-body-parts [{:name \u0026#34;head\u0026#34; :size 3} {:name \u0026#34;left-eye\u0026#34; :size 1} {:name \u0026#34;left-ear\u0026#34; :size 1} {:name \u0026#34;mouth\u0026#34; :size 1} {:name \u0026#34;nose\u0026#34; :size 1} {:name \u0026#34;neck\u0026#34; :size 2} {:name \u0026#34;left-shoulder\u0026#34; :size 3} {:name \u0026#34;left-upper-arm\u0026#34; :size 3} {:name \u0026#34;chest\u0026#34; :size 10} {:name \u0026#34;back\u0026#34; :size 10} {:name \u0026#34;left-forearm\u0026#34; :size 3} {:name \u0026#34;abdomen\u0026#34; :size 6} {:name \u0026#34;left-kidney\u0026#34; :size 1} {:name \u0026#34;left-hand\u0026#34; :size 2} {:name \u0026#34;left-knee\u0026#34; :size 2} {:name \u0026#34;left-thigh\u0026#34; :size 4} {:name \u0026#34;left-lower-leg\u0026#34; :size 3} {:name \u0026#34;left-achilles\u0026#34; :size 1} {:name \u0026#34;left-foot\u0026#34; :size 2}]) (defn matching-part [part] {:name (clojure.string/replace (:name part) #\u0026#34;^left-\u0026#34; \u0026#34;right-\u0026#34;) :size (:size part)}) ➊ (defn symmetrize-body-parts \u0026#34;Expects a seq of maps that have a :name and :size\u0026#34; [asym-body-parts] ➋ (loop [remaining-asym-parts asym-body-parts final-body-parts []] ➌ (if (empty? remaining-asym-parts) final-body-parts ➍ (let [[part \u0026amp; remaining] remaining-asym-parts] ➎ (recur remaining (into final-body-parts (set [part (matching-part part)]))))))) symmetriz-body-parts函数（从➊开始）采用了函数式编程中常见的一般策略。给定一个序列（在本例中，是一个身体部位及其尺寸的 Vector），该函数连续地将该序列分割成head和尾。然后，它处理头部，将其添加到某个结果中，并使用递归来继续处理尾部的过程。\n我们在➋处开始循环处理主体部分。序列的尾部将被绑定到remaining-asym-parts。最初，它被绑定到传递给函数的完整序列：asym-body-parts'。我们还创建了一个结果序列，final-body-parts`；它的初始值是一个空 Vector。\n如果remaining-asym-parts在➌处是空的，这意味着我们已经处理了整个序列，可以返回结果，final-body-parts。否则，在➍，我们将列表分成头，部分，和尾，剩余。\n在➎处，我们用remaining进行循环，这个列表在循环的每一次迭代中都会缩短一个元素，还有(in)表达式，它建立了对称的身体部分的 Vector。\n如果你是这种编程的新手，这段代码可能需要一些时间来解决。请坚持下去! 一旦你理解了正在发生的事情，你会觉得自己像个百万富翁!\n更好的对称器与 reduce 处理********************************************的模式非常普遍，以至于有一个内置的函数叫做reduce。下面是一个简单的例子。\n;; sum with reduce (reduce + [1 2 3 4]) ; =\u0026gt; 10 这就像告诉 Clojure 这样做。\n(+ (+ (+ 1 2) 3) 4) reduce函数按照以下步骤工作。\n 将给定的函数应用于一个序列的前两个元素。这就是(+ 1 2)的由来。 将给定的函数应用于结果和序列的下一个元素。在本例中，步骤 1 的结果是3，序列的下一个元素也是3。所以最后的结果是`(+3 3)'。 对序列中剩下的每个元素重复第 2 步。  reduce也需要一个可选的初始值。这里的初始值是15。\n(reduce + 15 [1 2 3 4]) 如果你提供了一个初始值，reduce就会开始对初始值和序列的第一个元素应用给定的函数，而不是序列的前两个元素。\n需要注意的一个细节是，在这些例子中，reduce接收一个元素的集合，[1 2 3 4]，并返回一个单一的数字。虽然程序员经常这样使用reduce，但你也可以使用reduce来返回一个比你开始时更大的集合，就像我们在symmetrize-body-parts中尝试做的那样。reduce抽象了 \u0026quot;处理一个集合并建立一个结果 \u0026quot;的任务，它对返回的结果类型是不确定的。为了进一步了解reduce`的工作原理，这里有一种方法可以实现它。\n(defn my-reduce ([f initial coll] (loop [result initial remaining coll] (if (empty? remaining) result (recur (f result (first remaining)) (rest remaining))))) ([f [head \u0026amp; tail]] (my-reduce f head tail))) 我们可以重新实现我们的对称器，如下所示。\n(defn better-symmetrize-body-parts \u0026#34;Expects a seq of maps that have a :name and :size\u0026#34; [asym-body-parts] (reduce (fn [final-body-parts part] (into final-body-parts (set [part (matching-part part)]))) [] asym-body-parts)) 真棒! 使用reduce的一个显而易见的好处是，你写的代码总体上更少。你传递给reduce的匿名函数只专注于处理一个元素和建立一个结果。原因是reduce处理了底层的机制，即跟踪哪些元素已经被处理，并决定是否返回一个最终结果或递归。\n使用reduce也更有表现力。如果你的代码的读者遇到 \u0026ldquo;loop\u0026rdquo;，如果不阅读所有的代码，他们将不能确定这个循环到底在做什么。但是如果他们看到reduce，他们会立即知道代码的目的是处理一个集合的元素以建立一个结果。\n最后，通过将 \u0026ldquo;reduce \u0026ldquo;过程抽象为一个以另一个函数为参数的函数，你的程序变得更有可塑性。例如，你可以将reduce函数作为一个参数传递给其他函数。你还可以创建一个更通用的 \u0026ldquo;对称体-部件 \u0026ldquo;版本，例如 \u0026ldquo;扩展体-部件\u0026rdquo;。除了身体部位的列表外，它还可以接受一个扩展器函数，并让你的模型不仅仅是霍比特人。例如，你可以有一个蜘蛛扩展器，可以增加眼睛和腿的数量。我会让你自己来写，因为我是邪恶的。\n霍比特人的暴力 我的话，这真是为勇敢和真实的人准备的 Clojure! 为了给你的工作画上句号，这里有一个函数可以确定霍比特人的哪个部分被击中。\n(defn hit [asym-body-parts] (let [sym-parts (➊better-symmetrize-body-parts asym-body-parts) ➋body-part-size-sum (reduce + (map :size sym-parts)) target (rand body-part-size-sum)] ➌(loop [[part \u0026amp; remaining] sym-parts accumulated-size (:size part)] (if (\u0026gt; accumulated-size target) part (recur remaining (+ accumulated-size (:size (first remaining)))))))) hit的工作原理是取一个不对称的身体部位的 Vector，在➊处对称，然后在➋处将各部位的大小相加。一旦我们将这些尺寸相加，就好像从 1 到身体部位尺寸之和的每个数字都对应于一个身体部位；1 可能对应于左眼，而 2、3、4 可能对应于头部。这使得当你击中一个身体部位时（通过在这个范围内选择一个随机数字），特定身体部位被击中的可能性将取决于身体部位的大小。\n图 3-1：身体部位与数字的范围相对应，如果目标在这个范围内，就会被击中。\n最后，这些数字中的一个被随机选择，然后我们在➌处使用loop来寻找并返回与该数字对应的身体部位。循环是通过跟踪我们已经检查过的部分的累计大小，并检查累计大小是否大于目标值来实现的。我把这个过程想象成用一排编号的槽来排列身体部位。在我排完一个身体部位后，我问自己：\u0026ldquo;我已经达到目标了吗？\u0026rdquo; 如果我达到了，这意味着我刚刚排好的身体部位就是被击中的那个部位。否则，我就继续排查这些部位。\n例如，假设你的零件清单是头、左眼和左手，如图 3-1。在取完第一个部分，即头部后，累计大小为 3。当累计大小超过目标时，身体部分就被击中，所以如果目标小于 3，那么头部就被击中了。否则，你取下下一个部分，即左眼，并将累积大小增加到 4，如果目标大于或等于 3 且小于 4，则产生一个命中。\n下面是一些hit函数的运行样本。\n(hit asym-hobbit-body-parts) ; =\u0026gt; {:name \u0026#34;right-upper-arm\u0026#34;, :size 3} (hit asym-hobbit-body-parts) ; =\u0026gt; {:name \u0026#34;chest\u0026#34;, :size 10} (hit asym-hobbit-body-parts) ; =\u0026gt; {:name \u0026#34;left-eye\u0026#34;, :size 1} 哦，我的上帝，那个可怜的霍比特人！你这个怪物！\u0026quot;。你这个怪物!\n总结 本章让你对如何在 Clojure 中做事有了一个旋风式的了解。你现在知道了如何用字符串、数字、Map、关键字、Vector、列表和集合来表示信息，以及如何用def和let来命名这些表示法。你已经了解了函数的灵活性以及如何创建你自己的函数。此外，你还了解了 Clojure 的简洁哲学，包括其统一的语法和强调在原始数据类型上使用大型函数库。\n第 4 章将带你详细考察 Clojure 的核心函数，第 5 章解释了函数式编程的思维模式。本章向你展示了如何编写 Clojure 代码\u0026ndash;接下来的两章将向你展示如何编写 Clojure*好。\n在这一点上，我建议你开始写代码，我的每一根纤维都是这样。没有比这更好的方法来巩固你的 Clojure 知识了。Clojure Cheat Sheet（http://clojure.org/api/cheatsheet）是一个很好的参考资料，它列出了所有在本章中涉及的数据结构上操作的内置函数。\n下面的练习会让你的大脑非常兴奋。如果你想更多地测试你的新技能，可以在*http://www.projecteuler.net/尝试一些 Project Euler 挑战。你还可以看看 4Clojure（http://www.4clojure.com/problems/*），这是一套在线的 Clojure 问题，旨在测试你的知识。写点什么吧!\n练习 这些练习是为了测试你的 Clojure 知识和学习更多的 Clojure 函数，是一种有趣的方式。前三个可以只用本章介绍的信息来完成，但后三个需要你使用到目前为止还没有涉及的函数。如果你真的很想写更多的代码并探索 Clojure 的标准库，那么就去解决后三个问题。如果你觉得这些练习太难了，可以在读完第 4 章和第 5 章后再来看看，你会发现它们要容易得多。\n  使用str, vector, list, hash-map, 和hash-set函数。\n  编写一个函数，接收一个数字，并向其添加 100。\n  写一个函数。\ndec-maker ，其工作原理与函数\ninc-maker 除了用减法。\n(def dec9 (dec-maker 9)) (dec9 10) ; =\u0026gt; 1   写一个函数。\nmapset ，它的工作原理是\nmap 除了返回值是一个集合。\n(mapset inc [1 1 2 2]) ; =\u0026gt; #{2 3}   创建一个类似于symmetriz-body-parts的函数，只是它必须与具有径向对称性的奇怪的太空外星人一起工作。他们没有两只眼睛、胳膊、腿等等，而是有五只。\n  创建一个函数，将`symmetriz-body-parts\u0026rsquo;和你在练习 5 中创建的函数通用化。这个新的函数应该接受一个身体部位的集合，以及要增加的匹配身体部位的数量。如果你对 Lisp 语言和函数式编程是完全陌生的，那么如何做到这一点可能并不明显。如果你被卡住了，只需转到下一章，以后再重温这个问题。\n  ","permalink":"https://zhenfeng-zhu.github.io/posts/chapter3/","summary":"做事情：Clojure 速成班 是时候学习如何用 Clojure 真正地做事了! 该死的! 尽管你无疑已经听说过 Clojure 令人敬畏的并发支持和其他了不起的功能，但 Clojure 最突出的特点是它是一种 Lisp 语言。在本章中，你将探索构成这个 Lisp 核心的元素：语法、函数和数据。它们将共同为你在 Clojure 中表示和解决问题打下坚实的基础。\n在打下这个基础之后，你将能够编写一些超级重要的代码。在最后一节中，你将通过创建一个霍比特人的模型，并编写一个函数将其打在一个随机的位置上，从而将一切联系起来。超级! 重要的!\n当你阅读本章时，我建议你在 REPL 中输入例子并运行它们。用一种新的语言编程是一种技能，就像约德尔舞或花样游泳一样，你必须通过练习来学习它。 请留意它!\n语法 Clojure 的语法很简单。像所有的 Lisp 一样，它采用了统一的结构、少量的特殊运算符，以及从藏在麻省理工学院下面的小括号矿井中不断提供的小括号，Lisp 就是在那里诞生的。\n形式 所有的 Clojure 代码都是以统一结构编写的。Clojure 可以识别两种结构。\n 数据结构的字面表示（如数字、字符串、Map 和 Vector） 操作  我们使用术语form来指代有效的代码。我有时也会用表达式来指代 Clojure 形式。但不要太纠结于术语。Clojure 评价每一个表单，以产生一个值。这些字面表达都是有效的形式。\n1 \u0026quot;a string\u0026quot; [\u0026quot;a\u0026quot; \u0026quot;vector\u0026quot; \u0026quot;of\u0026quot; \u0026quot;strings\u0026quot;] 当然，你的代码很少包含自由浮动的字元，因为它们本身实际上并不做什么。相反，你会在操作中使用字面符号。操作是你做事情的方式。所有操作的形式都是：*开括号，*操作符，*操作数，闭括号。\n(operator operand1 operand2 ... operandn) 请注意，这里没有逗号。Clojure 使用空格来分隔操作数，它将逗号视为空格。下面是一些操作的例子。\n(+ 1 2 3) ; =\u0026gt; 6 (str \u0026quot;It was the panda \u0026quot; \u0026quot;in the library \u0026quot; \u0026quot;with a dust buster\u0026quot;) ; =\u0026gt; \u0026quot;It was the panda in the library with a dust buster\u0026quot; 在第一个操作中，运算符+将操作数1、2和3相加。在第二个操作中，运算符str将三个字符串连接起来，形成一个新的字符串。这两种形式都是有效的。这里有一个不是形式的东西，因为它没有一个结束的小括号。","title":"Chapter3 速成班"},{"content":"如何使用 Emacs，一个优秀的 Clojure 编辑器 在你掌握 Clojure 的过程中，你的编辑器将是你最亲密的盟友。我强烈建议使用 Emacs，但你当然也可以使用任何你想要的编辑器。如果你不遵循本章中关于 Emacs 的详尽说明，或者你选择使用一个不同的编辑器，那么至少值得投入一些时间来设置你的编辑器，以便与 REPL 一起工作。我推荐的两个在社区中受到好评的替代品是Cursive和Nightcode。\n我推荐 Emacs 的原因是，它提供了与 Clojure REPL 的紧密集成，这使你可以在写作时立即尝试你的代码。这种紧密的反馈回路在学习 Clojure 和以后编写真正的 Clojure 程序时都很有用。Emacs 也很适合与任何 Lisp 方言一起工作；事实上，Emacs 是用一种叫做 Emacs Lisp（elisp）的 Lisp 方言编写的。\n在本章结束时，你的 Emacs 设置将看起来像图 2-1。\n图 2-1: 使用 Clojure 的典型 Emacs 设置：一边是代码，另一边是 REPL。\n为了达到这个目的，你将从安装 Emacs 开始，设置一个适合新人的 Emacs 配置。然后你将学习基础知识：如何打开、编辑和保存文件，以及如何使用基本的键绑定与 Emacs 进行交互。最后，你将学习如何实际编辑 Clojure 代码并与 REPL 进行交互。\n安装 你应该使用 Emacs 的最新主要版本，即 Emacs 24，用于你工作的平台。\n OS X从*http://emacsformacosx.com*安装 vanilla Emacs 作为一个 Mac 应用程序。其他选项，如 Aquamacs，应该是为了使 Emacs 更 \u0026ldquo;像 Mac\u0026rdquo;，但从长远来看是有问题的，因为它们的设置与标准 Emacs 有很大的不同，以至于很难使用 Emacs 手册或跟随教程。 Ubuntu按照*https://launchpad.net/~cassou/+archive/emacs*上的说明。 Windows你可以在*Index of /gnu/emacs/windows找到一个二进制文件。在你下载并解压最新版本后，你可以在bin\\runemacs.exe*下运行 Emacs 可执行文件。  安装完 Emacs 后，打开它。你应该看到类似图 2-2 的东西。\n图 2-2：当你第一次打开 Emacs 时显示的屏幕\n欢迎来到 Emacs 的崇拜！你已经使 Richard Stallman 成为了 Emacs 的一员。你让 Richard Stallman 感到骄傲!\n配置 我创建了一个库，里面有为 Clojure 配置 Emacs 所需的所有文件，可在https://github.com/flyingmachine/emacs-for-clojure/archive/book1.zip。\n注意：这些工具一直在更新，所以如果下面的说明对你不起作用，或者你想使用最新的配置，请阅读GitHub - flyingmachine/emacs-for-clojure上的说明。\n按以下步骤删除你现有的 Emacs 配置并安装对 Clojure 友好的配置。\n  关闭 Emacs。\n  删除*~/.emacs或~/.emacs.d*，如果它们存在的话。(Windows 用户，你的 Emacs 文件可能在C:\\Users\\your_user_name\\AppData\\Roaming*。因此，举例来说，你可以删除C:\\Users\\jason\\AppData\\Roaming.emacs.d*）。这是 Emacs 寻找配置文件的地方，删除这些文件和目录将确保你从一个干净的地方开始。\n  下载上面列出的 Emacs 配置压缩文件并解压。其内容应该是一个文件夹，emacs-for-clojure-book1。运行 mv path/to/emacs-for-clojure-book1 ~/.emacs.d。    打开 Emacs。\n  当你打开 Emacs 时，你可能会看到大量的活动，因为 Emacs 正在下载一堆有用的软件包。一旦这些活动停止，继续前进，退出 Emacs，然后再打开它。(如果你没有看到任何活动，那也没关系！退出并重新启动 Emacs。退出并重新启动 Emacs 只是为了好玩）。在你这样做之后，你应该看到一个像图 2-3 那样的窗口。\n图 2-3：Emacs 在安装了你可爱的新配置后的样子\n现在我们已经设置好了一切，让我们来学习如何使用 Emacs!\nEmacs 逃逸舱口 在我们进入有趣的东西之前，你需要知道一个重要的 Emacs 键绑定：ctrl-G。这个键绑定可以退出你试图运行的任何 Emacs 命令。所以，如果事情进展不顺利，按住 ctrl，按 G，然后再试一次。它不会关闭 Emacs，也不会使你失去任何工作；它只是取消你当前的行动。\nEmacs 缓冲区 所有的编辑都发生在 Emacs 的*缓冲区中。当你第一次启动 Emacs 时，一个名为 \u0026ldquo;scratch\u0026ldquo;的缓冲区被打开。Emacs 总是在窗口的底部显示当前缓冲区的名称，如图 2-4 所示。\n图 2-4：Emacs 会一直显示当前缓冲区的名称。\n默认情况下，*scratch*缓冲区处理括号和缩进的方式对 Lisp 开发来说是最理想的，但对编写纯文本却很不方便。让我们创建一个新的缓冲区，这样我们就可以在不发生意外的情况下进行游戏。要创建一个缓冲区，请这样做。\n 按住 ctrl 键并按下 X 键。 2.松开 ctrl 键。 按 B 键。  我们可以用一个更紧凑的格式来表达同样的序列。 C-x b。\n执行这个按键序列后，你会在应用程序的底部看到一个提示，如图 2-5 所示。\n图 2-5: 迷你缓冲区是 Emacs 提示你输入的地方。\n这个区域被称为minibuffer，它是 Emacs 提示你输入的地方。现在它正在提示我们输入一个缓冲区的名称。你可以输入一个已经打开的缓冲区的名称，也可以输入一个新的缓冲区名称。输入 emacs-fun-times，然后按回车键。现在你应该看到一个完全空白的缓冲区，可以直接开始输入。你会发现，按键的工作方式与你所期望的差不多。字符在你输入时出现。上、下、左、右方向键会像你所期望的那样移动你，而回车键会创建一个新行。\n你还会注意到，你不会突然长出浓密的 Unix 胡须或穿上 Birkenstocks（除非你一开始就有）。这应该有助于缓解你对使用 Emacs 的任何恐惧感。当你玩够了之后，继续前进，通过输入C-x k enter来杀死**的缓冲区。(这可能会让人吃惊，但 Emacs 实际上是很暴力的，它充分使用了杀这个词）。\n现在你已经杀死了emacs-fun-times缓冲区，你应该回到*scratch*缓冲区。一般来说，你可以用C-x b创建任意多的新缓冲区。你也可以用同样的命令在缓冲区之间快速切换。当你以这种方式创建一个新的缓冲区时，它只存在于内存中，直到你把它保存为一个文件；缓冲区不一定有文件支持，创建一个缓冲区也不一定会创建一个文件。让我们来学习一下关于文件的工作。\n与文件一起工作 在 Emacs 中打开文件的键位是C-x C-f。注意，当你按下 X 和 F 时，你需要按住 ctrl。导航到*~/.emacs.d/customizations/ui.el*，它可以自定义 Emacs 的外观和你与它的互动方式。Emacs 在一个与文件名相同的新缓冲区中打开文件。让我们转到第 37 行，去掉前面的分号，取消注释。它将看起来像这样。\n(setq initial-frame-alist \u0026#39;((top . 0) (left . 0) (width . 120) (height . 80)) 然后改变 \u0026ldquo;width \u0026ldquo;和 \u0026ldquo;height \u0026ldquo;的值，它们为活动窗口设置字符的尺寸。通过改变这些值，你可以设置 Emacs 窗口在每次启动时以某种尺寸打开。一开始可以试试小一点的，比如 80 和 20。\n(setq initial-frame-alist \u0026#39;((top . 0) (left . 0) (width . 80) (height . 20)) 现在用下面的键绑定来保存你的文件。 C-x C-s。你应该在 Emacs 的底部得到一个信息，如写了/Users/snuffleupagus/.emacs.d/customizations/ui.el`。你也可以尝试使用你在其他应用程序中使用的键绑定来保存你的缓冲区（例如，ctrl-S 或 cmd-S）。你下载的 Emacs 配置应该允许这样做，但如果不允许，也没什么大不了的。\n保存文件后，退出 Emacs 并再次启动它。我敢打赌，它非常小! 请看我在图 2-6 中的例子。\n图 2-6：你可以配置 Emacs，使其在每次打开时都设置高度和宽度。\n同样的过程要进行几次，直到 Emacs 以你喜欢的尺寸开始。或者再把这几行注释掉就可以了（在这种情况下，Emacs 将以其默认的宽度和高度打开）。如果你完成了对ui.el的编辑，你可以用C-x k关闭其缓冲区。无论如何，你已经完成了在 Emacs 中保存第一个文件的工作 如果发生了一些疯狂的事情，你可以按照第 13 页的 \u0026ldquo;配置\u0026rdquo;中的指示来使 Emacs 重新工作。\n如果你想创建一个新的文件，只需使用C-x C-f并在迷你缓冲区中输入新文件的路径。一旦你保存了缓冲区，Emacs 就会按照你输入的路径用缓冲区的内容创建一个文件。\n让我们来回顾一下。\n 在 Emacs 中，编辑是在缓冲区*.*中进行的。 要切换到一个缓冲区，使用C-x b并在 minibuffer*.*中输入缓冲区的名称。 要创建一个新的缓冲区，使用C-x b并输入一个新的缓冲区名称。 要打开一个文件，使用C-x C-f并导航到该文件。  要将缓冲区保存到文件中，使用C-x C-s。   要创建一个新的文件，使用C-x C-f并输入新文件的路径。当你保存缓冲区时，Emacs 将在文件系统中创建文件。  键绑定和模式 你已经走了很长一段路了! 你现在可以像一个非常基本的编辑器一样使用 Emacs。如果你需要在服务器上使用 Emacs，或者被迫与 Emacs 书呆子配对，这应该能帮助你度过难关。\n然而，要想真正有成效，了解一些关于键绑定的*关键细节对你来说是很有用的（哈哈！）。然后我将介绍 Emacs 模式。之后，我将介绍一些核心术语，并介绍一些超级有用的键绑定。\nEmacs 是一个 Lisp 解释器 术语键绑定源于这样一个事实：Emacs 将键击打绑定到命令上，而这些命令只是 elisp 函数（我将交替使用命令和函数）。例如，C-x b被绑定到函数switch-to-buffer。同样地，C-x C-s与save-file绑定。\n但 Emacs 甚至比这更进一步。甚至像f和a这样简单的按键也被绑定到一个函数上，在这个例子中是 \u0026ldquo;self-insert-command\u0026rdquo;，是向你正在编辑的缓冲区添加字符的命令。\n从 Emacs 的角度来看，所有的函数都是平等的，你可以重新定义所有的函数，甚至像save-file这样的核心函数。你可能不会想要重新定义核心函数，但你可以。\n你可以重新定义函数，因为就其核心而言，Emacs 只是一个 Lisp 解释器，恰好加载了代码编辑功能。Emacs 的大部分内容都是用 elisp 编写的，所以从 Emacs 的角度来看，save-file只是一个函数，就像switch-to-buffer和你能运行的几乎所有其他命令一样。不仅如此，你创建的任何函数都被当作内置函数来对待。你甚至可以用 Emacs 来执行 elisp，在它运行时修改 Emacs。\n使用强大的编程语言修改 Emacs 的自由是 Emacs 如此灵活的原因，也是为什么像我这样的人对它如此疯狂。是的，它有很多表面上的复杂性，可能需要花时间去学习。但 Emacs 的底层是 Lisp 的优雅简洁，以及随之而来的无限的可修补性。这种可修补性并不局限于创建和重新定义函数。你还可以创建、重新定义和删除键绑定。从概念上讲，按键绑定只是一个查询表中的条目，它将按键与函数联系起来，而这个查询表是完全可修改的。\n你也可以使用M-x函数名称来运行命令，而不需要特定的键绑定（例如，M-x save-buffer）。 M代表meta，这是一个现代键盘不具备的键，但在 Windows 和 Linux 上被 Map 到 alt，在 Mac 上则是 option。 M-x运行smex命令，它提示你要运行的另一个命令的名称。\n现在你已经了解了键的绑定和功能，你将能够理解什么是模式以及它们是如何工作的。\n模式 Emacs 的模式是一个键绑定和功能的集合，它被打包在一起，帮助你在编辑不同类型的文件时提高工作效率。(模式也可以做一些事情，比如告诉 Emacs 如何做语法高亮，但这是次要的，我不会在这里介绍。)\n例如，当你在编辑一个 Clojure 文件时，你会想加载 Clojure 模式。现在我正在写一个 Markdown 文件并使用 Markdown 模式，它有很多专门用于 Markdown 工作的有用的键绑定。在编辑 Clojure 时，最好有一套 Clojure 专用的键绑定，比如C-c C-k将当前的缓冲区加载到 REPL 中并进行编译。\n模式有两种类型。 主要模式和次要模式。Markdown 模式和 Clojure 模式是主要模式。主要模式通常在你打开文件时由 Emacs 设置，但你也可以通过运行相关的 Emacs 命令明确地设置模式，例如用M-x clojure-mode 或M-x major-mode。每次只有一种主要模式是激活的。\n主要模式是针对某种文件类型或语言的 Emacs，而次要模式通常提供对各种文件类型都有用的功能。例如，abbrev 模式 \u0026ldquo;根据预先定义的缩写定义自动展开文本\u0026rdquo;（根据 Emacs 手册1.）。你可以同时激活多个次要模式。\n你可以在*模式行中看到哪些模式处于活动状态，如图 2-7 所示。\n图 2-7：模式行显示哪些模式是活动的。\n如果你打开一个文件，而 Emacs 没有为它加载一个主要模式，那么这个模式很有可能存在。你只需要下载它的软件包。说到这个 \u0026hellip; .\n安装软件包 许多模式都是以包的形式发布的，这只是存储在包仓库中的 elisp 文件的捆绑。你在本章开始时安装的 Emacs 24，使浏览和安装软件包变得非常容易。 M-x package-list-packages 会显示几乎所有可用的软件包；只要确保你先运行M-x package-refresh-contents 就能得到最新的列表。你可以用M-x package-install 来安装软件包。\n你也可以通过加载你自己的 elisp 文件或你在网上找到的文件来定制 Emacs。Emacs 初学者指南》（见*http://www.masteringemacs.org/articles/2010/10/04/beginners-guide-to-emacs/*）在文章底部的 \u0026ldquo;加载新包 \u0026ldquo;一节中对如何加载自定义文件有很好的描述。\n核心编辑术语和键绑定 如果你只想把 Emacs 当做一个文本编辑器来使用，你可以完全跳过这一节！但你将会错过很多东西。但你将会错过一些好东西。在这一节中，我们将介绍 Emacs 的关键术语；如何选择、剪切、复制和粘贴文本；如何选择、剪切、复制和粘贴文本（看到我做了什么吗？ 哈哈哈！）；以及如何有效地在缓冲区内移动。\n要想开始，请在 Emacs 中打开一个新的缓冲区，并将其命名为jack-handy。然后输入以下杰克-汉迪的语录。\nIf you were a pirate, you know what would be the one thing that would really make you mad? Treasure chests with no handles. How the hell are you supposed to carry it?! The face of a child can say it all, especially the mouth part of the face. To me, boxing is like a ballet, except there\u0026#39;s no music, no choreography, and the dancers hit each other. 用这个例子来试验本节中的导航和编辑。\n点 如果你一直在关注，你应该在你的 Emacs 缓冲区看到一个橘红色的矩形。这就是游标，它是点的图形表示。点是所有魔法发生的地方：你在点上插入文本，大多数编辑命令都是与点有关的。即使你的光标看起来是在一个字符的上面，但点实际上是位于该字符和前一个字符之间。\n例如，把你的光标放在If you were a pirate中的f上。点就位于I和f之间。现在，如果你使用C-k，从字母f开始的所有文字将消失。 C-k运行命令kill-line，它*杀了当前行中从点开始的所有文字（我将在后面讲到更多的杀戮）。用**C-/**撤销这一改变。另外，尝试用正常的操作系统的键绑定来撤消；这也应该是有效的。\n移动 你可以像其他编辑器一样用方向键来移动点，但许多键的绑定可以让你更有效地进行导航，如表 2-1 所示。\n 表 2-1: 文本导航的键位绑定     关键字 描述     C-a 移动到行首。   M-m 移动到该行的第一个非空格字符。   C-e 移动到行尾。   C-f 向前移动一个字符。   *C-b *向后移动一个字符。    M-f 向前移动一个字（我经常用这个）。   M-b 向后移动一个字（我也经常用这个）。   C-s Regex 搜索当前缓冲区内的文本，并移动到它。再按一次C-s，移到下一个匹配。   C-r 与C-s相同，但以反向方式搜索。   M-\u0026lt; 移到缓冲区的开头。   M-\u0026gt; 移动到缓冲区的末端。   M-g g 转到该行。    来吧，在你的***缓冲区里试试这些键的绑定!\n带区域的选择 在 Emacs 中，我们并不选择文本。我们创建区域，并通过用C-spc（ctrl-spacebar）设置*标记来实现。然后，当你移动点时，标记和点之间的所有东西都是区域。这与 shift 选择文本的基本目的非常相似。\n例如，在你的****缓冲区里做以下事情。\n 转到文件的开头。 使用C-spc。 使用M-f两次。你应该看到一个高亮的区域，包括If you。  按退格键。这将会删除如果你。    使用标记而不是 Shift 选择文本的一个很酷的事情是，你可以在设置标记后自由使用 Emacs 的所有移动命令。例如，你可以设置一个标记，然后用C-s来搜索缓冲区内几百行的一些文本。这样做将创建一个非常大的区域，而你就不必紧张地按住 Shift 键了。\n区域还可以让你把一个操作限制在缓冲区的有限区域内。试试这个。\n 创建一个区域，包括孩子的脸可以说明一切。  使用M-x替换字符串，用head替换face。    这将在当前区域内进行替换，而不是在点之后的整个缓冲区内进行替换，这是默认行为。\n杀戮和杀戮环 在大多数应用程序中，我们可以切割文本，这只是轻微的暴力。我们还可以复制和粘贴。剪切和复制将选择的内容添加到剪贴板上，而粘贴则将剪贴板上的内容复制到当前的应用程序中。在 Emacs 中，我们采取杀人的方法，杀区域，把它们加入到杀圈。当你知道你正在浪费数千字节的文本时，你不觉得勇敢和坚强吗？然后我们可以yank，在点上插入最近杀死的文本。我们还可以复制文本到杀戮环，而不需要真正杀死它。\n为什么要用这些病态的术语呢？嗯，首先，当你听到有人在 Emacs 中谈论杀死东西时，你不会感到害怕。但更重要的是，Emacs 允许你做一些典型的剪切/复制/粘贴剪贴板功能集所不能做的工作。\nEmacs 在杀戮环上存储了多个文本块，你可以循环使用它们。这很酷，因为你可以通过循环来找回你很久之前杀死的文本。让我们来看看这个功能的实际应用。\n 在第一行的Treasure这个词上创建一个区域。 2.使用M-w，它与 \u0026ldquo;杀死-循环-保存 \u0026ldquo;命令绑定。一般来说，M-w就像复制一样。它将该区域添加到杀戮环中，而不从你的缓冲区中删除它。 将指针移到最后一行的choreography字样上。 使用M-d，它与kill-word命令绑定。这将把choreogra**phy添加到杀戮环中，并将其从你的缓冲区中删除。 使用C-y。这将把你刚刚杀死的文字choreography*，插入到点的位置。 使用M-y。这将删除choreography，并拉出杀戮环上的下一个项目，Treasure。  你可以在表 2-2 中看到一些有用的杀戮/拉扯键的绑定。\n 表 2-2：杀戮和拉扯的键位绑定 文本     关键字 描述     C-w 杀戮区域。   M-w 复制区域到杀戮环。   C-y 绞刑。   M-y 在拉动后循环使用杀伤环。   M-d 杀字。   C-k 杀行。    编辑和帮助 表 2-3 显示了一些额外的、有用的编辑键绑定，你应该知道如何处理间距和扩展文本。\n 表 2-3：其他有用的编辑键绑定方式     关键字 描述     *Tab 缩进行。   C-j 新行和缩进，相当于回车后的 tab。   M-/ 嬉皮士扩展；循环浏览点之前的文本可能的扩展方式。   *M-* 删除点周围的所有空格和制表符。(我经常使用这个。)    Emacs 也有很好的内置帮助。表 2-4 中显示的两个键绑定将为你提供良好的服务。\n 表 2-4：内置帮助的键位绑定     关键字 描述     C-h k 键绑定 说明与该键绑定的功能。为了使其发挥作用，你在输入C-h k后实际执行按键序列。    C-h f *描述功能。     帮助文本出现在一个新的*窗口中，这个概念我将在本章后面介绍。现在，你可以通过按C-x o q关闭帮助窗口。\n使用 Emacs 与 Clojure 接下来，我将解释如何使用 Emacs 来有效地开发一个 Clojure 应用程序。你将学习如何启动一个与 Emacs 相连的 REPL 进程，以及如何与 Emacs 窗口一起工作。然后，我将介绍大量有用的键绑定，用于评估表达式、编译文件和执行其他方便的任务。最后，我将向你展示如何处理 Clojure 的错误，并介绍 Paredit 的一些功能，这是一种可选的次要模式，对编写和编辑 Lisp 风格语言的代码很有用。\n如果你想开始钻研 Clojure 代码，请务必跳过前面的内容！你可以在以后再回来。你可以稍后再回来。\n开启你的 REPL 正如你在第 1 章中所学到的，REPL 允许你交互地编写和运行 Clojure 代码。REPL 是一个正在运行的 Clojure 程序，它给你一个提示，然后读取你的输入，评估它，打印结果，并循环返回到提示。在第 1 章中，你在终端窗口用lein repl启动了 REPL。在本节中，你将直接在 Clojure 中启动一个 REPL。\n为了将 Emacs 连接到 REPL，你将使用 Emacs 软件包 CIDER，可在*[GitHub - clojure-emacs/cider: The Clojure Interactive Development Environment that Rocks for Emacs]（https://github.com/clojure-emacs/cider/）*。如果你按照本章前面的配置说明，你应该已经安装了它，但你也可以通过运行M-x包-安装，输入 cider，然后按回车键来安装它。\nCIDER 允许你在 Emacs 中启动一个 REPL，并为你提供键绑定，使你能更有效地与 REPL 进行交互。现在就去启动一个 REPL 会话吧。使用 Emacs，打开clojure-noob/**src/clojure_noob/core.clj文件，该文件是你在第一章中创建的。接下来，使用M-x cider-jack-in。这将启动 REPL 并创建一个新的缓冲区，在那里你可以与它进行交互。经过短暂的等待（应该不到一分钟），你应该看到类似图 2-8 的东西。\n图 2-8：运行 M-x cider-jack-in 后你的 Emacs 应该是这样的\n现在我们有两个窗口：我们的core.clj文件在左边打开，REPL 在右边运行。如果你从来没有见过 Emacs 像这样分成两半，不要担心！我将讲述 Emacs 是如何做到的。我一会儿会讲到 Emacs 是如何分割窗口的。同时，在 REPL 中尝试评估一些代码。键入以下加粗的行。当你按下回车键时，你应该看到打印在 REPL 中的结果，显示在每一行代码的后面。这时不要担心代码，我将在下一章中介绍所有这些功能。\n(+ 1 2 3 4) ; =\u0026gt; 10 (map inc [1 2 3 4]) ; =\u0026gt; (2 3 4 5) (reduce + [5 6 100]) ; =\u0026gt; 111 相当漂亮! 你可以像在第一章中使用lein repl那样使用这个 REPL。你还可以做更多的事情，但在这之前，我将解释如何在分屏 Emacs 中工作。\n###插曲。Emacs 的窗口和框架\n让我们绕道来谈谈 Emacs 是如何处理框架和窗口的，并讨论一些与窗口有关的有用的键绑定方法。如果你已经熟悉了 Emacs 的窗口，请随意跳过这一部分。\nEmacs 是在 1802 年左右发明的，所以它使用的术语与你习惯的略有不同。你通常所说的窗口，Emacs 称之为框架，而框架可以分割成多个窗口。分割成多个窗口允许你一次查看多个缓冲区。你在运行cider-jack-in时已经看到了这种情况（见图 2-9）。\n图 2-9：在 Emacs 中，一个框架包含有窗口。\n表 2-5 显示了用于处理框架和窗口的几个键的绑定情况。\n 表 2-5: Emacs 窗口的键位绑定     关键字 描述     C-x o 将光标切换到另一个窗口。现在试试这个，在你的 Clojure 文件和 REPL 之间切换。   C-x 1 删除所有其他窗口，框架中只留下当前窗口。这不会关闭你的缓冲区，也不会导致你失去任何工作。   C-x 2 分割框架的上方和下方。   C-x 3 并排分割框架。   C-x 0 删除当前窗口。    我鼓励你试试 Emacs 的窗口键绑定。例如，把你的光标放在左边的窗口，也就是有 Clojure 文件的那个，然后使用C-x 1。另一个窗口应该消失，而你应该只看到 Clojure 代码。然后做以下工作。\n 使用C-x 3将窗口再次并排分开。 使用C-x o来切换到右边的窗口。 使用C-x b cider-repl来切换到右边窗口的 CIDER 缓冲区。  一旦你做了一些实验，设置 Emacs，使它包含两个并排的窗口，左边是 Clojure 代码，右边是 CIDER 缓冲区，就像前面的图片一样。如果你有兴趣了解更多关于窗口和框架的知识，Emacs 手册中有大量的信息：见*http://www.gnu.org/software/emacs/manual/html_node/elisp/Windows.html#Windows*。\n现在你可以浏览 Emacs 窗口了，是时候学习一些 Clojure 开发的键绑定了\n###有用的键绑定的丰富内容\n现在你已经准备好学习一些按键绑定，它们将揭示在 Clojure 项目中使用 Emacs 的真正力量。这些命令将使你只需按下几个简单的键就能评估、调整、编译和运行代码。让我们先来看看如何快速评估一个表达式。\n在core.clj的底部，添加以下内容。\n(println \u0026#34;Cleanliness is next to godliness\u0026#34;) 现在使用C-e导航到行尾，然后使用C-x C-e.文本Cleanliness is next to godliness应该出现在 CIDER 缓冲区，如图 2-10 所示。\n图 2-10：在 REPL 中从另一个缓冲区即时评估代码\n绑定键C-x C-e运行cider-eval-last-expression命令。顾名思义，该命令将紧接在点之前的表达式发送到 REPL，然后由 REPL 评估该表达式。你也可以试试C-u C-x C-e，它打印出点之后的评估结果。\n现在让我们试着运行我们在第一章中写的-main函数，这样我们就可以让全世界都知道我们是小茶壶。\n在core.clj的缓冲区中，使用C-c M-n M-n。这个键绑定将命名空间设置为你当前文件顶部列出的命名空间，所以右边窗口的提示现在应该是clojure-noob.core\u0026gt;。我还没有详细介绍命名空间，但现在只要知道命名空间是一种组织机制，使我们能够避免命名冲突就足够了。接下来，在提示符下输入（-main）。REPL 应该打印出 \u0026ldquo;I\u0026rsquo;m a little teapot!\u0026ldquo;多么令人激动啊\n现在让我们创建一个新函数并运行它。在core.clj的底部，添加以下内容。\n(defn train [] (println \u0026#34;Choo choo!\u0026#34;) 完成后，保存你的文件并使用C-c C-k在 REPL 会话中编译你的当前文件。(现在，如果你在 REPL 中运行 (train)，它将回显 Choo choo!。\n当你还在 REPL 中时，试试C-↑（ctrl 加向上箭头键）。 C-↑和C-↓循环浏览你的 REPL 历史，其中包括你要求 REPL 评估的所有 Clojure 表达式。\nMac 用户注意：默认情况下，OS X 将C-↑、C-↓、C-←和C-→Map 为任务控制命令。你可以通过打开系统偏好设置，然后进入 Keyboard4Shortcuts4Mission Control 来改变你的 Mac 键绑定。\n最后，试试这个。\n 在 REPL 提示符下输入（-main）。注意没有结尾的括号。 按C-enter。  CIDER 应该关闭小括号并评估表达式。这只是 CIDER 为处理这么多小括号而提供的一个很好的小便利。\nCIDER 还有一些键的绑定，在你学习 Clojure 的时候非常好。按C-c C-d C-d将显示该符号下的文档，这可以大大节省时间。当你看完文档后，按q来关闭文档缓冲区。绑定的键**M-.将导航到点下符号的源代码，而M-,**将使你回到原来的缓冲区和位置。最后，C-c C-d C-a可以让你在函数名和文档中搜索任意的文本。当你不能完全记住一个函数的名字时，这是一个很好的方法来寻找它。\nCIDER README（GitHub - clojure-emacs/cider: The Clojure Interactive Development Environment that Rocks for Emacs)有一个全面的键绑定列表，你可以慢慢学习，但现在，表 2-6 和 2-7 包含了我们刚刚经历的键绑定的总结。\n 表 2-6：Clojure 缓冲区的键绑定情况     键值 描述     C-c M-n M-n 切换到当前缓冲区的命名空间。   C-x C-e 评估紧邻点的表达式。   C-c C-k 编译当前缓冲区。   C-c C-d C-d 显示点下符号的文档。   M-. 和 M-, 浏览到该点下的符号的源代码，并返回到原来的缓冲区。   C-c C-d C-a Apropros 搜索；在函数名和文档中查找任意文本。     表 2-7: CIDER 缓冲区的键绑定方式     关键字 描述     **C-↑, C-**↓ 循环浏览 REPL 历史。   C-enter 关闭圆括号并评估。    如何处理错误 在这一节中，你将写一些有错误的代码，这样你就可以看到 Emacs 是如何反应的，以及你如何从错误中恢复并继续你的快乐之路。你将在 REPL 缓冲区和 core.clj 缓冲区中进行这项工作。让我们从 REPL 开始。在提示符下，输入(map)并按回车。你应该看到类似图 2-11 的东西。\n图 2-11：这就是在 REPL 中运行坏代码时发生的情况。\n正如你所看到的，在没有参数的情况下调用map会使 Clojure 失去理智\u0026ndash;它在你的 REPL 缓冲区中显示一个`ArityException\u0026rsquo;错误信息，并在你的左边窗口中填满文本，看起来像一个疯子的呓语。这些呓语就是堆栈跟踪，它显示了实际抛出异常的函数，以及哪个函数调用了那个函数，沿着函数调用的堆栈。\nClojure 的堆栈跟踪在你刚开始的时候可能很难解读，但经过一段时间后，你会学会从其中获得有用的信息。CIDER 通过允许你过滤堆栈痕迹来帮你一把，这可以减少噪音，这样你就可以将异常的原因锁定。*cider-error*缓冲区的第 2 行有 Clojure、Java、REPL、Tooling、Duplicates 和 All 等过滤器。你可以点击每个选项来激活该过滤器。你也可以点击每个堆栈跟踪行来跳到相应的源代码。\n下面是如何关闭左边窗口中的堆栈跟踪。\n 使用C-x o来切换到窗口。 按q关闭堆栈跟踪，回到 CIDER。  如果你想再次查看错误，你可以切换到*cider-error*缓冲区。你也可以在尝试编译文件时得到错误信息。要看这个，请到core.clj缓冲区，写一些有错误的代码，然后进行编译。\n 在结尾处添加(map)。 使用C-c C-k进行编译。  你应该看到一个*cider-error*缓冲区，类似于你之前看到的那个。同样，按q关闭堆栈跟踪。\nParedit 在 Clojure 缓冲区中写代码时，你可能已经注意到了一些意外的事情发生。例如，每当你输入一个左括号，一个右括号就会立即被插入。\n这要归功于paredit-mode，这是一种次要的模式，它将 Lisp 的大量小括号从一种责任变成了一种资产。Paredit 确保所有的小括号、双引号和大括号都是封闭的，从而减轻了你那可恶的负担。\nParedit 还提供了键绑定功能，以轻松浏览和改变所有这些括号所创建的结构。在下一节中，我将介绍最有用的键绑定，但你也可以在*https://github.com/georgek/paredit-cheatsheet/blob/master/paredit-cheatsheet.pdf*（在骗局中，红色管子代表点）查看全面的骗局表。\n然而，如果你不习惯，paredit 有时会很烦人。我认为花点时间来学习它是非常值得的，但你可以随时用M-x paredit-mode 来禁用它，它可以切换该模式的开启和关闭。\n下面的部分向你展示了最有用的键绑定。\nWrapping 和 Slurping Wrapping用小括号包围点之后的表达式。 Slurping将结束的小括号移到右边包括下一个表达式。例如，假设我们用这个开始。\n(+ 1 2 3 4) 而我们想得到这个结果。\n(+ 1 (* 2 3) 4) 我们可以把2包起来，加一个星号，然后再把3溜走。首先，放置点，这里表示为一个垂直的管道，|。\n(+ 1 |2 3 4) 然后输入M-(，与paredit-wrap-round绑定，得到这个结果。\n(+ 1 (|2) 3 4) 加上星号和空格。\n(+ 1 (* |2) 3 4) 要在 \u0026ldquo;3 \u0026ldquo;上啧啧称奇，请按C-→。\n(+ 1 (* |2 3) 4) 这样就可以很容易地增加和扩展括号，而不必浪费宝贵的时间按住方向键来移动点。\nBarfing 假设在前面的例子中，你不小心吐了四条。要解开它（也被称为barfing），将你的光标（|）放在括号内的任何地方。\n(+ 1 (|* 2 3 4)) 然后使用C-←。\n(+ 1 (|* 2 3) 4) Ta-da! 现在你知道如何随意扩展和收缩括号了。\n导航 在用 Lisp 方言写作时，你经常会遇到这样的表达式。\n(map (comp record first) (d/q \u0026#39;[:find ?post :in $ ?search :where [(fulltext $ :post/content ?search) [[?post ?content]]]] (db/db) (:q params)) 对于这种表达式，快速从一个子表达式跳到下一个子表达式是很有用的。如果你把 point 放在开头的小括号之前，C-M-f会把你带到结束的小括号。同样，如果 point 紧跟在闭合小括号之后，C-M-b将带你到开头小括号。\n表 2-8 总结了你刚刚学到的 Paredit 键的绑定。\n 表 2-8：Paredit 键的绑定方式     关键字 描述     M-x paredit-mode 切换 paredit 模式。   M-( 括号内点后的表达式(paredit-wrap-round)。   **C-**→ Slurp;将结束的小括号向右移动，以包括下一个表达式。   **C-**← Barf；将括号向左移动，排除最后一个表达式。   *C-M-f,*C-M-b 移动到开头/结尾小括号。    继续学习 Emacs 是历史最悠久的编辑器之一，它的追随者对它的热情往往接近狂热。一开始使用它可能会很别扭，但坚持下去，你会在一生中得到充分的回报。\n每当我打开 Emacs 时，我都会感到受到鼓舞。就像一个工匠进入他的工作室一样，我感到一个可能性的领域在我面前打开。我感到这个环境的舒适，它随着时间的推移已经发展到完全适合我\u0026ndash;各种各样的包和键绑定，帮助我日复一日地把想法变成现实。\n在你继续你的 Emacs 之旅时，这些资源将帮助你。\n Emacs 手册提供了优秀、全面的指导。每天早上花点时间看看它吧! 下载 PDF，在旅途中阅读。http://www.gnu.org/software/emacs/manual/html_node/emacs/index.html#Top*。 *《Emacs 参考卡》*是一个方便的小抄。 http://www.ic.unicamp.br/~helio/disciplinas/MC102/Emacs_Reference_Card.pdf。 Mickey Petersen 的Mastering Emacs是最好的 Emacs 资源之一。从阅读指南开始。 阅读指南-掌握 Emacs 。 对于更注重视觉效果的人，我推荐手绘的《如何学习 Emacs》。Emacs 24 或更高版本的初学者指南\u0026rdquo;，作者 Sacha Chua。 http://sachachua.com/blog/wp-content/uploads/2013/05/How-to-Learn-Emacs8.png。 只要按C-h t就可以看到内置的教程。  摘要 呜呼! 你已经覆盖了很多地方。你现在知道了 Emacs 作为一个 Lisp 解释器的真正性质。绑定键是执行 elisp 函数的快捷方式，而模式是绑定键和函数的集合。你学会了如何以自己的方式与 Emacs 互动，并掌握了缓冲区、窗口、区域、杀戮和拉动。最后，你学会了如何使用 CIDER 和 paredit 轻松地与 Clojure 工作。\n有了这些来之不易的 Emacs 知识，现在是时候开始认真学习 Clojure 了\n1 http://www.gnu.org/software/emacs/manual/html_node/emacs/Minor-Modes.html。\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter2/","summary":"如何使用 Emacs，一个优秀的 Clojure 编辑器 在你掌握 Clojure 的过程中，你的编辑器将是你最亲密的盟友。我强烈建议使用 Emacs，但你当然也可以使用任何你想要的编辑器。如果你不遵循本章中关于 Emacs 的详尽说明，或者你选择使用一个不同的编辑器，那么至少值得投入一些时间来设置你的编辑器，以便与 REPL 一起工作。我推荐的两个在社区中受到好评的替代品是Cursive和Nightcode。\n我推荐 Emacs 的原因是，它提供了与 Clojure REPL 的紧密集成，这使你可以在写作时立即尝试你的代码。这种紧密的反馈回路在学习 Clojure 和以后编写真正的 Clojure 程序时都很有用。Emacs 也很适合与任何 Lisp 方言一起工作；事实上，Emacs 是用一种叫做 Emacs Lisp（elisp）的 Lisp 方言编写的。\n在本章结束时，你的 Emacs 设置将看起来像图 2-1。\n图 2-1: 使用 Clojure 的典型 Emacs 设置：一边是代码，另一边是 REPL。\n为了达到这个目的，你将从安装 Emacs 开始，设置一个适合新人的 Emacs 配置。然后你将学习基础知识：如何打开、编辑和保存文件，以及如何使用基本的键绑定与 Emacs 进行交互。最后，你将学习如何实际编辑 Clojure 代码并与 REPL 进行交互。\n安装 你应该使用 Emacs 的最新主要版本，即 Emacs 24，用于你工作的平台。\n OS X从*http://emacsformacosx.com*安装 vanilla Emacs 作为一个 Mac 应用程序。其他选项，如 Aquamacs，应该是为了使 Emacs 更 \u0026ldquo;像 Mac\u0026rdquo;，但从长远来看是有问题的，因为它们的设置与标准 Emacs 有很大的不同，以至于很难使用 Emacs 手册或跟随教程。 Ubuntu按照*https://launchpad.","title":"Chapter2 如何使用 Emacs"},{"content":"构建、运行和 REPL 在本章中，你将预先投入少量时间来熟悉建立和运行 Clojure 程序的快速、傻瓜式方法。让一个真正的程序运行起来感觉很好。达到了这个里程碑，你就可以自由地进行实验，分享你的工作，并向那些仍在使用上个世纪的语言的同事幸灾乐祸。这将有助于保持你的积极性!\n你还将学习如何使用*Read-Eval-Print Loop（REPL）*在一个正在运行的 Clojure 进程中即时运行代码，这使你能够快速测试你对语言的理解并更有效地学习。\n但首先，我将简要地介绍 Clojure。接下来，我将介绍 Leiningen，这是 Clojure 事实上的标准构建工具。在本章结束时，你将知道如何做以下事情。\n 用 Leiningen 创建一个新的 Clojure 项目 构建该项目以创建一个可执行的 JAR 文件 执行 JAR 文件 在 Clojure REPL 中执行代码  第一重要的事: 什么是 Clojure Clojure 是由 Rich Hickey 在一座神话般的火山中铸造的。他使用 Lisp、函数式编程和他自己的一绺史诗般的头发的合金，创造了一种令人愉快而强大的语言。它的 Lisp 遗产使你有能力写出比大多数非 Lisp 语言更有表现力的代码，而它对函数式编程的独特理解将使你作为一个程序员的思维更敏锐。此外，Clojure 为你提供了更好的工具来处理复杂的领域（如并发编程），这些领域在传统上被认为会使开发人员陷入多年的治疗中。\n不过，在谈论 Clojure 时，重要的是要牢记 Clojure 语言和 Clojure 编译器之间的区别。Clojure 语言是一种强调函数的 Lisp 方言，其语法和语义与任何实现都无关。编译器是一个可执行的 JAR 文件，clojure.jar，它接收用 Clojure 语言编写的代码并将其编译为 Java 虚拟机（JVM）字节码。你会看到Clojure被用来指代语言和编译器，如果你不知道它们是独立的东西，就会感到困惑。但现在你意识到了，你就会好起来。\n这种区分是必要的，因为与大多数编程语言如 Ruby、Python、C 和其他许多语言不同，Clojure 是一种托管语言。Clojure 程序在 JVM 中执行，并依赖 JVM 的核心功能，如线程和垃圾收集。Clojure 还针对 JavaScript 和微软的通用语言运行时（CLR），但本书只关注 JVM 的实现。\n稍后我们将更多地探讨 Clojure 和 JVM 之间的关系，但现在你需要了解的主要概念是这些。\n JVM 进程执行 Java 字节码。 通常情况下，Java 编译器从 Java 源代码中产生 Java 字节码。 JAR 文件是 Java 字节码的集合。 Java 程序通常以 JAR 文件分发。 Java 程序clojure.jar 读取 Clojure 源代码并产生 Java 字节码。 然后，该 Java 字节码由已经运行clojure.jar的 JVM 进程执行。  Clojure 持续在发展。截至目前，Clojure 的版本为 1.9.0，开发工作仍在进行中。如果你在遥远的未来读到这本书，并且 Clojure 有更高的版本号，不要担心！这本书涵盖了 Clojure 的所有内容。本书涵盖了 Clojure 的基础知识，这些知识在不同的版本中应该不会改变。没有必要让你的机器人管家把这本书退回给书店。\n现在你知道什么是 Clojure 了，让我们来实际构建一个该死的 Clojure 程序吧!\nlein new app clojure-noob 这个命令应该创建一个与此相似的目录结构（如果有一些差异也没关系）。\n| .gitignore | doc | | intro.md ➊ | project.clj | README.md ➋ | resources | src | | clojure_noob ➌ | | | core.clj ➍ | test | | clojure_noob | | | core_test.clj 这个项目骨架本身并不特别，也不像 Clojure 那样。它只是 Leiningen 使用的一种惯例。你将使用 Leiningen 来构建和运行 Clojure 应用程序，Leiningen 希望你的应用程序有这种结构。第一个需要注意的文件是位于➊的project.clj，它是 Leiningen 的一个配置文件。它可以帮助 Leiningen 回答这样的问题：\u0026ldquo;这个项目有什么依赖？\u0026ldquo;和 \u0026ldquo;当这个 Clojure 程序运行时，什么函数应该先运行？\u0026rdquo; 一般来说，你会把你的源代码保存在src/\u0026lt;project_name\u0026gt;。在这种情况下，位于➌的src/clojure_noob/core.clj文件就是你要写一段时间的 Clojure 代码的地方。位于➍的test目录显然包含了测试，而位于➋的resources是你存储图片等资产的地方。\n运行 Clojure 项目 现在让我们来实际运行这个项目。在你喜欢的编辑器中打开src/clojure_noob/core.clj。你应该看到这个。\n➊ (ns clojure-noob.core (:gen-class)) ➋ (defn -main \u0026#34;I don\u0026#39;t do a whole lot...yet.\u0026#34; [\u0026amp; args] ➌ (println \u0026#34;Hello, World!\u0026#34;)) ➊处的行声明了一个命名空间，你现在不需要担心这个问题。➋处的-main'函数是你的程序的*入口，这个话题将在附录A中介绍。现在，将➌处的\u0026ldquo;Hello, World!\u0026quot;改为\u0026ldquo;I\u0026rsquo;m a little teapot!\u0026quot;。全行应该是(println \u0026ldquo;I\u0026rsquo;m a little teapot!\u0026quot;))`。\n接下来，在你的终端导航到clojure_noob目录，然后输入。\nlein run 你应该看到输出\u0026quot;I'm a little teapot!\u0026quot;恭喜你，小茶壶，你编写并执行了一个程序！\u0026quot;。\n当你阅读本书时，你会了解到更多关于程序中实际发生的事情，但现在你需要知道的是，你创建了一个函数，-main，当你在命令行执行lein run时，这个函数就会运行。\n构建 Clojure 项目 使用lein run对于尝试你的代码是很好的，但是如果你想与没有安装 Leiningen 的人分享你的工作，该怎么办？要做到这一点，你可以创建一个独立的文件，任何安装了 Java 的人（基本上就是所有人）都可以执行。要创建这个文件，请运行以下程序。\nlein uberjar 这个命令创建了target/uberjar/clojure-noob-0.1.0**-SNAPSHOT-standalone.jar文件。你可以通过运行这个命令使 Java 执行它。\njava -jar target/uberjar/clojure-noob-0.1.0-SNAPSHOT-standalone.jar 看看这个! 文件target/uberjar/clojure-noob-0.1.0-SNAPSHOT**-standalone.jar是你的 Clojure 程序，你可以在几乎任何平台上发布和运行。\n现在你已经掌握了构建、运行和分发（非常）基本的 Clojure 程序所需的所有基本细节。在后面的章节中，你会了解到更多的细节，当你运行前面的命令时，Leiningen 在做什么，对 Clojure 与 JVM 的关系以及你如何运行生产代码有了完整的了解。\n在我们进入第二章，讨论 Emacs 的神奇和荣耀之前，让我们来看看另一个重要的工具：REPL。\n使用 REPL REPL 是一个用于试验代码的工具。它允许你与正在运行的程序进行交互，并快速尝试各种想法。它通过向你提供一个提示，让你输入代码来实现这一目的。然后，它读取你的输入，评估它，打印结果，并循环，再次向你提供提示。\n这个过程实现了一个快速的反馈循环，这在大多数其他语言中是不可能的。我强烈建议你经常使用它，因为你能够在学习过程中快速检查你对 Clojure 的理解。除此之外，REPL 开发是 Lisp 体验的一个重要部分，如果你不使用它，你就真的错过了。\n要启动一个 REPL，请运行以下程序。\nlein repl 输出应该是这样的。\nnREPL server started on port 28925 REPL-y 0.1.10 Clojure 1.9.0 Exit: Control+D or (exit) or (quit) Commands: (user/help) Docs: (doc function-name-here) (find-doc \u0026#34;part-of-name-here\u0026#34;) Source: (source function-name-here) (user/sourcery function-name-here) Javadoc: (javadoc java-object-or-class-here) Examples from clojuredocs.org: [clojuredocs or cdoc] (user/clojuredocs name-here) (user/clojuredocs \u0026#34;ns-here\u0026#34; \u0026#34;name-here\u0026#34;) clojure-noob.core=\u0026gt; 最后一行，clojure-noob.core=\u0026gt;，告诉你，你在clojure -noob.core命名空间中。你将在后面学习命名空间，但现在注意到命名空间基本上与你的src/clojure_noob/core.clj文件的名称一致。另外，注意到 REPL 显示的版本是Clojure 1.9.0，但如前所述，无论你使用哪个版本，一切都可以正常工作。\n该提示还表明你的代码在 REPL 中被加载，你可以执行被定义的函数。现在只有一个函数，-main，被定义了。现在就去执行它吧。\nclojure-noob.core=\u0026gt; (-main) I\u0026#39;m a little teapot! nil 干得好! 你刚刚使用 REPL 评估了一个函数调用。试试几个更基本的 Clojure 函数。\nclojure-noob.core=\u0026gt; (+ 1 2 3 4) 10 clojure-noob.core=\u0026gt; (* 1 2 3 4) 24 clojure-noob.core=\u0026gt; (first [1 2 3 4]) 1 真棒! 你加了一些数字，乘了一些数字，并从一个 Vector 中取出了第一个元素。你还第一次接触到了奇怪的 Lisp 语法! 所有的 Lisp，包括 Clojure，都采用前缀符号，这意味着运算符在表达式中总是排在第一位。如果你不确定这意味着什么，不要担心。你很快就会了解到 Clojure 的所有语法。\n从概念上讲，REPL 类似于安全外壳（SSH）。就像你可以使用 SSH 与远程服务器交互一样，Clojure REPL 允许你与正在运行的 Clojure 进程交互。这项功能可以非常强大，因为你甚至可以将 REPL 附加到一个实时生产的应用程序，并在它运行时修改你的程序。不过现在，你将使用 REPL 来建立你对 Clojure 语法和语义的了解。\n还有一点要注意：今后，本书将介绍没有 REPL 提示的代码，但请尝试一下这些代码! 下面是一个例子。\n(do (println \u0026#34;no prompt here!\u0026#34;) (+ 1 3)) ; =\u0026gt; no prompt here! ; =\u0026gt; 4 当你看到这样的代码片段时，以；=\u0026gt;开头的行表示正在运行的代码的输出。在这种情况下，应该打印出这里没有提示'的文字，代码的返回值是4'。\nClojure 编辑器 到此为止，你应该已经具备了开始学习 Clojure 语言所需的基本知识，而不需要对编辑器或集成开发环境（IDE）大费周章。但如果你确实想要一个关于强大编辑器的好教程，第 2 章涉及 Emacs，这是 Clojurists 中最受欢迎的编辑器。你绝对不需要在 Clojure 开发中使用 Emacs，但 Emacs 提供了与 Clojure REPL 的紧密集成，非常适合编写 Lisp 代码。然而，最重要的是，你要使用适合你的东西。\n如果 Emacs 不是你的那杯茶，这里有一些为 Clojure 开发设置其他文本编辑器和 IDE 的资源。\n 这个 YouTube 视频将告诉你如何为 Clojure 开发设置 Sublime Text 2。 - YouTube。 Vim 有很好的工具用于 Clojure 开发。这篇文章是一个很好的起点。 Writing Clojure With Vim In 2013 - mybuddymichael.com。 Counterclockwise 是一个强烈推荐的 Eclipse 插件。GoogleCodeHome - ccw-ide/ccw Wiki - GitHub。 Cursive Clojure 是推荐给那些使用 IntelliJ 的 IDE： https://cursiveclojure.com/。 Nightcode 是一个用 Clojure 编写的简单、免费的 IDE。 GitHub - oakes/Nightcode: An IDE for Clojure。  总结 我真为你感到骄傲，小茶壶。你已经运行了你的第一个 Clojure 程序! 不仅如此，你还熟悉了 REPL，这是开发 Clojure 软件的最重要工具之一。太神奇了! 这让我想起了我个人英雄之一的《万岁》中的不朽名句。\n You held your head like a hero\nOn a history book page\nIt was the end of a decade\nBut the start of an age\n—Taylor Swift\n 好样的!\n","permalink":"https://zhenfeng-zhu.github.io/posts/chapter1/","summary":"构建、运行和 REPL 在本章中，你将预先投入少量时间来熟悉建立和运行 Clojure 程序的快速、傻瓜式方法。让一个真正的程序运行起来感觉很好。达到了这个里程碑，你就可以自由地进行实验，分享你的工作，并向那些仍在使用上个世纪的语言的同事幸灾乐祸。这将有助于保持你的积极性!\n你还将学习如何使用*Read-Eval-Print Loop（REPL）*在一个正在运行的 Clojure 进程中即时运行代码，这使你能够快速测试你对语言的理解并更有效地学习。\n但首先，我将简要地介绍 Clojure。接下来，我将介绍 Leiningen，这是 Clojure 事实上的标准构建工具。在本章结束时，你将知道如何做以下事情。\n 用 Leiningen 创建一个新的 Clojure 项目 构建该项目以创建一个可执行的 JAR 文件 执行 JAR 文件 在 Clojure REPL 中执行代码  第一重要的事: 什么是 Clojure Clojure 是由 Rich Hickey 在一座神话般的火山中铸造的。他使用 Lisp、函数式编程和他自己的一绺史诗般的头发的合金，创造了一种令人愉快而强大的语言。它的 Lisp 遗产使你有能力写出比大多数非 Lisp 语言更有表现力的代码，而它对函数式编程的独特理解将使你作为一个程序员的思维更敏锐。此外，Clojure 为你提供了更好的工具来处理复杂的领域（如并发编程），这些领域在传统上被认为会使开发人员陷入多年的治疗中。\n不过，在谈论 Clojure 时，重要的是要牢记 Clojure 语言和 Clojure 编译器之间的区别。Clojure 语言是一种强调函数的 Lisp 方言，其语法和语义与任何实现都无关。编译器是一个可执行的 JAR 文件，clojure.jar，它接收用 Clojure 语言编写的代码并将其编译为 Java 虚拟机（JVM）字节码。你会看到Clojure被用来指代语言和编译器，如果你不知道它们是独立的东西，就会感到困惑。但现在你意识到了，你就会好起来。\n这种区分是必要的，因为与大多数编程语言如 Ruby、Python、C 和其他许多语言不同，Clojure 是一种托管语言。Clojure 程序在 JVM 中执行，并依赖 JVM 的核心功能，如线程和垃圾收集。Clojure 还针对 JavaScript 和微软的通用语言运行时（CLR），但本书只关注 JVM 的实现。","title":"Chapter1 构建、运行和 REPL"},{"content":"简介 在你的内心深处，你一直都知道你注定要学习 Clojure。 每当你高举着键盘，为一个难以理解的类层次结构而痛苦地哭泣时；每当你晚上躺在床上，为一个突变引起的海森堡虫而哭泣扰乱你的亲人时；每当一个竞赛条件使你拔掉更多你不断减少的头发时，你的某个秘密部分已经知道一定有一个更好的办法。\n现在，终于，你面前的教学材料将使你与你渴望已久的编程语言结合起来。\n学习一种新的编程语言：穿越四个迷宫的旅程 为了最大限度地发挥 Clojure 的作用，你需要在每个学习新语言的程序员面临的四个迷宫中找到自己的路。\n 工具之林 友好而高效的编程环境使你能够轻松地尝试你的想法。你将学习如何设置你的环境。 语言之山 随着你的攀登，你将获得 Clojure 的语法、语义和数据结构方面的知识。你将学习如何使用最强大的编程工具之一\u0026ndash;宏，并学习如何利用 Clojure 的并发结构来简化你的生活。 神器之洞 在它的深处，你将学会构建、运行和发布你自己的程序，以及如何使用代码库。你还将学习 Clojure 与 Java 虚拟机（JVM）的关系。 心态云堡 在其稀薄的空气中，你将了解 Lisp 和函数式编程的原因和方法。你将了解渗透在 Clojure 中的简单哲学，以及如何像 Clojurist 一样解决问题。  别搞错了，你要工作。但这本书会让你感觉到工作是令人振奋的，而不是疲惫的。这是因为本书遵循三个准则。\n 它采取了甜点优先的方法，给你提供了你需要的开发工具和语言细节，以便立即开始玩真正的程序。 它假定你对 JVM、函数式编程或 Lisp 没有经验。它详细地涵盖了这些主题，所以当你构建和运行 Clojure 程序时，你会对你正在做的事情感到自信。 它避开了 真实世界 的例子，而选择了更有趣的练习，如 攻击霍比特人 和 追踪闪亮的吸血鬼 。  到最后，你将能够使用 Clojure\u0026ndash;现存的最令人兴奋和最有趣的编程语言之一!\n本书是如何组织的 本书分为三个部分，以便更好地指导你完成你的勇敢探索，勇敢的初出茅庐的 Clojurist。\n第一部分：环境设置 为了保持动力和高效学习，你需要实际写代码和构建可执行文件。这些章节将带领你快速浏览你所需要的工具，以便轻松地编写程序。这样，你就可以专注于学习 Clojure，而不是摆弄你的环境。\n第 1 章：构建、运行和 REPL\n让一个真正的程序运行起来，有一种强大的激励作用。一旦你能做到这一点，你就可以自由地进行实验，而且你可以真正地分享你的工作\n在这短短的一章中，你将投入少量时间来熟悉建立和运行 Clojure 程序的快速方法。你将学习如何在一个正在运行的 Clojure 进程中使用 read-eval-print 循环（REPL）来实验代码。这将收紧你的反馈回路，帮助你更有效地学习。\n第二章：如何使用 Emacs，一个优秀的 Clojure 编辑器\n快速的反馈回路对学习至关重要。在这一章中，我从头开始介绍 Emacs，以保证你有一个高效的 Emacs/Clojure 工作流程。\n第二部分：语言基础 这些章节为你继续学习 Clojure 奠定了坚实的基础。你将从学习 Clojure 的基础知识（语法、语义和数据结构）开始，这样你就可以做事情。然后，你将退一步详细研究 Clojure 最常用的函数，并学习如何使用函数式编程*的思维方式来解决这些问题。\n第三章：做事情：Clojure 速成班\n在这里，你将开始真正深入了解 Clojure。这也是你需要关闭窗户的地方，因为你会开始大喊：\u0026quot;HOLY MOLEY THAT\u0026rsquo;S SPIFFY!\u0026quot;，而且直到你读完本书的索引才会停止。\n毫无疑问，你已经听说过 Clojure 令人敬畏的并发支持和其他了不起的功能，但 Clojure 最突出的特点是它是一种 Lisp。你将探索这个 Lisp 核心，它由两部分组成：函数和数据。\n第 4 章：深入探讨核心函数\n在这一章中，你将了解 Clojure 的几个基本概念。这将为你提供所需的基础，使你能够阅读你以前没有使用过的函数的文档，并理解当你尝试它们时发生了什么。\n你还会看到你最需要的函数的使用例子。这将为你编写自己的代码以及阅读和学习其他人的项目打下坚实的基础。还记得我是如何提到追踪闪闪发光的吸血鬼的吗？你会在这一章中做到这一点（除非你已经在业余时间做到了）。\n第五章：函数式编程\n在这一章中，你将把你在函数和数据结构方面的具体经验与一种新的思维方式结合起来：函数式编程思维方式。你将通过构建席卷全国的最热门的新游戏来炫耀你的知识。Peg Thing!\n第 6 章：组织你的项目：一个图书管理员的故事\n本章解释了什么是命名空间，以及如何使用它们来组织你的代码。我不想透露太多，但它也涉及到一个国际奶酪大盗。\n第 7 章：Clojure 炼金术：读取、评估和宏\n在这一章中，我们将退一步描述 Clojure 如何运行你的代码。这将给你一个概念性的结构，你需要真正理解 Clojure 是如何工作的，以及它与其他非 Lisp 语言有什么不同。有了这个结构，我将介绍宏，这是现有的最强大的工具之一。\n第 8 章：编写宏\n这一章彻底研究了如何编写宏，从基本的例子开始，并在复杂程度上有所提高。最后，你将戴上你的假想帽，假装你经营一家网上药水店，并使用宏来验证客户的订单。\n第三部分：高级主题 这些章节涵盖了 Clojure 的额外有趣的主题：并发、Java 互操作和抽象。尽管你可以在不了解这些工具和概念的情况下编写程序，但它们在智力上是有价值的，并能给你作为一个程序员带来巨大的力量。人们说学习 Clojure 会让你成为一个更好的程序员，原因之一就是它让这些章节中涉及的概念变得易于理解和实际使用。\n第 9 章：并发和并行编程的神圣艺术\n在这一章中，你将了解什么是并发和并行，以及它们为什么重要。你将了解在编写并行程序时面临的挑战，以及 Clojure 的设计如何帮助缓解这些挑战。你将使用期货、延迟和承诺来安全地编写并行程序。\n第 10 章：Clojure 形而上学：原子、Refs、Vars 和拥抱僵尸\n本章详细介绍了 Clojure 管理状态的方法以及如何简化并发编程。你将学习如何使用原子、参考数和变量这三种管理状态的结构，并学习如何用pmap进行无状态的并行计算。还会有抱抱的僵尸。\n第 11 章：用 core.async 掌握并发\n在这一章中，你将思考宇宙中的一切是一台热狗售卖机的想法。我的意思是，你将学习如何为独立运行的进程系统建模，这些进程通过使用 core.async 库的通道相互通信。\n第 12 章：与 JVM 一起工作\n这一章就像一本短语书和 Java 大陆的文化介绍之间的交叉。它向你概述了什么是 JVM，它如何运行程序，以及如何为它编译程序。它还向你简要介绍了常用的 Java 类和方法，并解释了如何在 Clojure 中与它们进行交互。不仅如此，它还向你展示了如何思考和理解 Java，以便你能将任何 Java 库纳入你的 Clojure 程序中。\n第 13 章：用多重方法、协议和记录创建和扩展抽象概念\n在第 4 章中，你了解到 Clojure 是以抽象的方式编写的。本章是对创建和实现你自己的抽象的世界的介绍。你将学习多重方法、协议和记录的基础知识。\n附录 A：用 Leiningen 构建和开发\n本附录阐明了使用 Leiningen 的一些细微之处，比如什么是 Maven，如何计算出 Java 库的版本号，以便你能使用它们。\n附录 B：Boot，花哨的 Clojure 构建框架\nBoot 是 Leiningen 的一个替代品，它提供了相同的功能，但有一个额外的好处，即它更容易扩展和编写可组合的任务。本附录解释了 Boot 的基本概念，并指导你编写你的第一个任务。\n代码 你可以在*http://www.nostarch.com/clojure/*下载该书的所有源代码。这些代码是按章节组织的。\n第 1 章描述了运行 Clojure 代码的不同方式，包括如何使用 REPL。我建议当你遇到大多数例子时，在 REPL 中运行它们，特别是第 3 章到第 8 章。这将有助于你习惯于编写和理解 Lisp 代码，并能帮助你保留你所学的一切。但是对于那些很长的例子，最好把你的代码写到一个文件中，然后在 REPL 中运行你写的代码。\n旅程开始了 你准备好了吗，勇敢的读者？你准备好迎接你真正的命运了吗？带上你最好的一对小括号：你即将踏上一生的旅程!\n","permalink":"https://zhenfeng-zhu.github.io/posts/introduction/","summary":"简介 在你的内心深处，你一直都知道你注定要学习 Clojure。 每当你高举着键盘，为一个难以理解的类层次结构而痛苦地哭泣时；每当你晚上躺在床上，为一个突变引起的海森堡虫而哭泣扰乱你的亲人时；每当一个竞赛条件使你拔掉更多你不断减少的头发时，你的某个秘密部分已经知道一定有一个更好的办法。\n现在，终于，你面前的教学材料将使你与你渴望已久的编程语言结合起来。\n学习一种新的编程语言：穿越四个迷宫的旅程 为了最大限度地发挥 Clojure 的作用，你需要在每个学习新语言的程序员面临的四个迷宫中找到自己的路。\n 工具之林 友好而高效的编程环境使你能够轻松地尝试你的想法。你将学习如何设置你的环境。 语言之山 随着你的攀登，你将获得 Clojure 的语法、语义和数据结构方面的知识。你将学习如何使用最强大的编程工具之一\u0026ndash;宏，并学习如何利用 Clojure 的并发结构来简化你的生活。 神器之洞 在它的深处，你将学会构建、运行和发布你自己的程序，以及如何使用代码库。你还将学习 Clojure 与 Java 虚拟机（JVM）的关系。 心态云堡 在其稀薄的空气中，你将了解 Lisp 和函数式编程的原因和方法。你将了解渗透在 Clojure 中的简单哲学，以及如何像 Clojurist 一样解决问题。  别搞错了，你要工作。但这本书会让你感觉到工作是令人振奋的，而不是疲惫的。这是因为本书遵循三个准则。\n 它采取了甜点优先的方法，给你提供了你需要的开发工具和语言细节，以便立即开始玩真正的程序。 它假定你对 JVM、函数式编程或 Lisp 没有经验。它详细地涵盖了这些主题，所以当你构建和运行 Clojure 程序时，你会对你正在做的事情感到自信。 它避开了 真实世界 的例子，而选择了更有趣的练习，如 攻击霍比特人 和 追踪闪亮的吸血鬼 。  到最后，你将能够使用 Clojure\u0026ndash;现存的最令人兴奋和最有趣的编程语言之一!\n本书是如何组织的 本书分为三个部分，以便更好地指导你完成你的勇敢探索，勇敢的初出茅庐的 Clojurist。\n第一部分：环境设置 为了保持动力和高效学习，你需要实际写代码和构建可执行文件。这些章节将带领你快速浏览你所需要的工具，以便轻松地编写程序。这样，你就可以专注于学习 Clojure，而不是摆弄你的环境。\n第 1 章：构建、运行和 REPL\n让一个真正的程序运行起来，有一种强大的激励作用。一旦你能做到这一点，你就可以自由地进行实验，而且你可以真正地分享你的工作\n在这短短的一章中，你将投入少量时间来熟悉建立和运行 Clojure 程序的快速方法。你将学习如何在一个正在运行的 Clojure 进程中使用 read-eval-print 循环（REPL）来实验代码。这将收紧你的反馈回路，帮助你更有效地学习。","title":"Introduction 简介"},{"content":"致谢 有很多人帮助我诞生了这个奇怪的婴儿，我对他们的支持感到感激。\n首先，感谢我的妻子杰西，她为这本书绘制了插图，使它具有我所希望的视觉特性。也感谢你的支持，感谢你在我处于疯狂的作家模式时容忍我。(附注：通过一本编程书的封面感谢我的妻子，感觉很奇怪。）\n感谢我在麦肯锡的朋友和同事，他们阅读了早期的修订稿并鼓励我继续写作。其中最重要的是 Pat Shaughnessy、Alex Rothenberg、Thomas Newton、Jalil Fanaian、Chris Parker、Mark Daggett、Christian Lilley，以及 Mike Morreale。你们都太伟大了；请搬到 Durham。\n感谢我的朋友布里奇特-希勒（Bridget Hillyer）一直以来的支持。我总是觉得你是我的后盾，这对我来说意义重大。也感谢我的朋友乔-杰克逊，感谢他阅读、听我喋喋不休、并为我提供反馈，并感谢他在我面前对其他人大谈这本书，让我感觉很酷。Alan Dipert，朋友，技术评论员，现在的同事，我向你表示万分感谢，感谢你出色的技术编辑，感谢你首先将我引入 Clojure。\n我不知道是否每个作家都会不断地问自己：\u0026ldquo;我到底为什么要这样做？是否有人会读它？\u0026ldquo;但我肯定会这样做。因此，我想感谢所有在这本书的最初网络版本编写过程中写信给我并建议进行编辑的友好人士。这些积极的反馈使我感到有信心，我正在做一件有意义的事情。同样地，感谢所有购买 Leanpub 版本的人\n非常感谢 Clojure 社区领导人 Eric Normand、David Nolen 和 Alex Miller 对本书的积极宣传。在下一届 Conj 大会上见!\n最后，要感谢 No Starch 出版社的各位同仁，感谢你们对本书的帮助，使之成为我无比自豪的作品。感谢你们的高标准。感谢你们不断地促使本书更加清晰，甚至提出笑话。(Seph 的 \u0026ldquo;蜡球 \u0026ldquo;编辑仍然让我开怀大笑。) Seph Kramer, Riley Hoffman, Hayley Baker, Alison Law, Tyler Ortman, Anne Marie Walker: 谢谢你们!\n","permalink":"https://zhenfeng-zhu.github.io/posts/acknowledgments/","summary":"致谢 有很多人帮助我诞生了这个奇怪的婴儿，我对他们的支持感到感激。\n首先，感谢我的妻子杰西，她为这本书绘制了插图，使它具有我所希望的视觉特性。也感谢你的支持，感谢你在我处于疯狂的作家模式时容忍我。(附注：通过一本编程书的封面感谢我的妻子，感觉很奇怪。）\n感谢我在麦肯锡的朋友和同事，他们阅读了早期的修订稿并鼓励我继续写作。其中最重要的是 Pat Shaughnessy、Alex Rothenberg、Thomas Newton、Jalil Fanaian、Chris Parker、Mark Daggett、Christian Lilley，以及 Mike Morreale。你们都太伟大了；请搬到 Durham。\n感谢我的朋友布里奇特-希勒（Bridget Hillyer）一直以来的支持。我总是觉得你是我的后盾，这对我来说意义重大。也感谢我的朋友乔-杰克逊，感谢他阅读、听我喋喋不休、并为我提供反馈，并感谢他在我面前对其他人大谈这本书，让我感觉很酷。Alan Dipert，朋友，技术评论员，现在的同事，我向你表示万分感谢，感谢你出色的技术编辑，感谢你首先将我引入 Clojure。\n我不知道是否每个作家都会不断地问自己：\u0026ldquo;我到底为什么要这样做？是否有人会读它？\u0026ldquo;但我肯定会这样做。因此，我想感谢所有在这本书的最初网络版本编写过程中写信给我并建议进行编辑的友好人士。这些积极的反馈使我感到有信心，我正在做一件有意义的事情。同样地，感谢所有购买 Leanpub 版本的人\n非常感谢 Clojure 社区领导人 Eric Normand、David Nolen 和 Alex Miller 对本书的积极宣传。在下一届 Conj 大会上见!\n最后，要感谢 No Starch 出版社的各位同仁，感谢你们对本书的帮助，使之成为我无比自豪的作品。感谢你们的高标准。感谢你们不断地促使本书更加清晰，甚至提出笑话。(Seph 的 \u0026ldquo;蜡球 \u0026ldquo;编辑仍然让我开怀大笑。) Seph Kramer, Riley Hoffman, Hayley Baker, Alison Law, Tyler Ortman, Anne Marie Walker: 谢谢你们!","title":"Acknowledgments 致谢"},{"content":"前言 当你阅读这本搞笑的书时，你会在某个时刻经历一个非常严肃的时刻。在了解了一些 Clojure 之后，编程变得更加有趣。这也是你在这本书上的投资，包括金钱和时间，得到回报的时刻\u0026ndash;有趣。\n幽默与严肃性有一定的关系。对严肃的事情开玩笑是合适的，但只有在适当的时间过去之后。例如，当我想起我最喜欢的叔叔的最后一句话时，我花了很多年才能够破涕为笑。\u0026ldquo;拿着我的啤酒\u0026rdquo;。\n这本书的工作方式正好相反。它在严肃事件发生之前，甚至在严肃事件发生期间，适时地指出了真正有趣的事情\u0026ndash;那一刻你意识到你因为 Clojure 而更喜欢编程。它在做到这一点的同时，并没有掩盖你将要学习的 Clojure 编程的深层技术层面。\n这种方法令人耳目一新，因为我读过的大多数编程书籍都比骆驼的屁还干。我们很幸运，丹尼尔是一位出色的程序员和作家，他的妻子杰斯是一位同样出色的插图画家。我们特别幸运的是，他们两个都疯了，决定在完全相同的时间写一本书。\nClojure 是本书的主题，但在某种程度上它\u0026ndash;或者说它的创造者 Rich Hickey\u0026ndash;也是作者之一，因为 Clojure 是有史以来最优雅的编程语言。就像早午餐的概念一样，Clojure 是如此的优雅，以至于如果不以某种方式提高他们的水平，就很难告诉别人关于它的任何事情。\n优雅是编程语言家族中许多 Lisp 方言经常被赋予的品质，Clojure 就是其中之一。所有的 Lisp 都是由数学家 John McCarthy 在 1958 年做出的一系列简单而美丽的发现演变而来。\n自 1958 年以来，出现了许多 Lisp 方言 和 Lisp 书籍。还有更多的 Lisp 方言 和书籍即将问世。作为过去和未来的神器，每一种都适合它们的作者在各自的时代所面临的独特的约束和欲望的组合。\n我发现 Clojure，以及这本关于它的特殊书籍，特别适合现在。我希望你也会这样。\nAlan Dipert\n","permalink":"https://zhenfeng-zhu.github.io/posts/foreword/","summary":"前言 当你阅读这本搞笑的书时，你会在某个时刻经历一个非常严肃的时刻。在了解了一些 Clojure 之后，编程变得更加有趣。这也是你在这本书上的投资，包括金钱和时间，得到回报的时刻\u0026ndash;有趣。\n幽默与严肃性有一定的关系。对严肃的事情开玩笑是合适的，但只有在适当的时间过去之后。例如，当我想起我最喜欢的叔叔的最后一句话时，我花了很多年才能够破涕为笑。\u0026ldquo;拿着我的啤酒\u0026rdquo;。\n这本书的工作方式正好相反。它在严肃事件发生之前，甚至在严肃事件发生期间，适时地指出了真正有趣的事情\u0026ndash;那一刻你意识到你因为 Clojure 而更喜欢编程。它在做到这一点的同时，并没有掩盖你将要学习的 Clojure 编程的深层技术层面。\n这种方法令人耳目一新，因为我读过的大多数编程书籍都比骆驼的屁还干。我们很幸运，丹尼尔是一位出色的程序员和作家，他的妻子杰斯是一位同样出色的插图画家。我们特别幸运的是，他们两个都疯了，决定在完全相同的时间写一本书。\nClojure 是本书的主题，但在某种程度上它\u0026ndash;或者说它的创造者 Rich Hickey\u0026ndash;也是作者之一，因为 Clojure 是有史以来最优雅的编程语言。就像早午餐的概念一样，Clojure 是如此的优雅，以至于如果不以某种方式提高他们的水平，就很难告诉别人关于它的任何事情。\n优雅是编程语言家族中许多 Lisp 方言经常被赋予的品质，Clojure 就是其中之一。所有的 Lisp 都是由数学家 John McCarthy 在 1958 年做出的一系列简单而美丽的发现演变而来。\n自 1958 年以来，出现了许多 Lisp 方言 和 Lisp 书籍。还有更多的 Lisp 方言 和书籍即将问世。作为过去和未来的神器，每一种都适合它们的作者在各自的时代所面临的独特的约束和欲望的组合。\n我发现 Clojure，以及这本关于它的特殊书籍，特别适合现在。我希望你也会这样。\nAlan Dipert","title":"Foreword 前言"},{"content":" 本文主要介绍 Thrift 的 IDL 基本语法。\n IDL Thrift 采用 IDL（Interface Definition Language）来定义通用的服务接口，然后通过 Thrift 提供的编译器，可以将服务接口编译成不同语言编写的代码，通过这个方式来实现跨语言的功能。\n基本类型 thrift基本支持所有的 Java 基本类型以及引用类型。\n bool  布尔值，对应 java 中的 boolean   byte  有符号字节，对应 java 中的 byte   i16  16 位有符号整型，对应 java 中的 short   i32  32 位有符号整型，对应 java 中的 int   i64  64 位有符号整型，对应 java 中的 long   double  64 位浮点型，对应 java 中的 double   string  字符串，对应 java 中的 String   binary  对应 java 中的 byte[]    struct 结构体 struct 有以下的一些约束：\n struct 不能继承，但是可以嵌套，不能嵌套自己。 其成员都是有明确的类型 成员都是被正整数编号过的，其中的编号不能重复，为了在传输过程中编码使用。 成员分隔符可以是逗号（,）或者分号（;），而且可以混用。 字段会有有 optional 和 required 之分。但是如果不指定则为无类型–可以不填充该值，但是在序列化传输的时候也会序列化进去，optional 是不填充则不序列化，required 是必须填充也必须序列化。 每个字段可以设置默认值。 同一个文件可以定义多个 struct，也可以定义在不同的文件，进行 include 引入。  例子：\nstruct User { 1: required string name, // 该字段值必须填写  2: optional i32 age = 0; // 默认值  3: bool gender // 默认为optional } 如果 required 标识的域没有赋值，Thrift 将给予提示；\n  如果 optional 标识的域没有赋值，该域将不会被序列化传输；\n  如果某个 optional 标识域有缺省值而用户没有重新赋值，则该域的值一直为缺省值；\n  如果某个 optional 标识域有缺省值或者用户已经重新赋值，而不设置它的__isset 为 true，也不会被序列化传输。\n  container 容器 有三种可用的容器类型：\n list\u0026lt;t\u0026gt;  元素类型为 t 的有序列表，允许重复。类似于 java 中的 ArrayList。   set\u0026lt;t\u0026gt;  元素类型为 t 的无序表，不允许重复。类似于 java 中的 HashSet。   map\u0026lt;t, t\u0026gt;  键类型为 t，值类型为 t 的键值对，键不允许重复。类似于 java 中的 HashMap。    例子：\nstruct Test { 1: map\u0026lt;string, User\u0026gt; usermap, 2: set\u0026lt;i32\u0026gt; intset, 3: list\u0026lt;double\u0026gt; doublelist } enum 枚举 enum 类型有如下约束：\n 编译器默认从 0 开始赋值。 可以赋予某个常量为某个整数。 允许常量是 16 进制整数。 末尾没有分号。 给常量赋缺省值的时候，使用常量全程。  Thrift 不支持枚举类嵌套，枚举常量必须是 32 位正整数。\n例子：\nenum HTTPStatus { OK = 200, NOT_FOUND = 404 } const 常量 在变量前加 const。\n例子：\nconst i32 age = 28; typedef 类型定义 Thrift 支持类似 C/C++的类型定义。\n例子：\ntypedef i32 myInt typedef i64 myNumber 类型定义的末尾没有逗号。\nexception 异常 异常在语法和功能上类似于结构体，差别是异常使用关键字 exception，而且异常是继承每种语言的基础异常类。\n例子：\nexception MyException { 1: i32 errCode, 2: string errMsg } service 服务 服务的定义方法在语义上等同于面向对象语言中的接口。\n例子：\nservice HelloService { i32 sayInt(1:i32 param) string sayString(1:string param) bool sayBoolean(1:bool param) void sayVoid() } namespace 命名空间 Thrift 中的命名空间类似于 C++中的 namespace 和 java 中的 package，它们提供了一种组织（隔离）代码的简便方式。\n名字空间也可以用于解决类型定义中的名字冲突。\n例子：\nnamespace java com.example.test namespace py example namespace go example include 引用 为了便于管理、重用和提高模块性/组织性，我们常常分割 Thrift 定义在不同的文件中。\nThrift 允许文件包含其它 thrift 文件，用户需要使用 thrift 文件名作为前缀访问被包含的对象。\nThrift 文件名要用双引号包含，末尾没有逗号或者分号。\n例子：\ninclude \u0026#34;test.thrift\u0026#34; include \u0026#34;../test.thrift\u0026#34; 注释 支持多行和单行风格。\n例子：\n/** * This is a multi-line comment. * Just like in C. */ // C++/Java style single-line comments work just as well. 参考资料\n Thrift Types [Thrift IDL 基本语法](http://1csh1.github.io/2017/02/21/Thrift IDL 基本语法/) Thrift IDL 快速入门  ","permalink":"https://zhenfeng-zhu.github.io/posts/thrfit-get-started/","summary":"本文主要介绍 Thrift 的 IDL 基本语法。\n IDL Thrift 采用 IDL（Interface Definition Language）来定义通用的服务接口，然后通过 Thrift 提供的编译器，可以将服务接口编译成不同语言编写的代码，通过这个方式来实现跨语言的功能。\n基本类型 thrift基本支持所有的 Java 基本类型以及引用类型。\n bool  布尔值，对应 java 中的 boolean   byte  有符号字节，对应 java 中的 byte   i16  16 位有符号整型，对应 java 中的 short   i32  32 位有符号整型，对应 java 中的 int   i64  64 位有符号整型，对应 java 中的 long   double  64 位浮点型，对应 java 中的 double   string  字符串，对应 java 中的 String   binary  对应 java 中的 byte[]    struct 结构体 struct 有以下的一些约束：","title":"Thrfit 入门"},{"content":"问题表现 某天，我的 vscode 的 git 管理出现了问题。\n类似这个样子。\n解决方式 @builtin @id:vscode.git 直接卸载了。\n出现原因 应该是某个公司的插件给我自动装上导致的\n","permalink":"https://zhenfeng-zhu.github.io/posts/fix-vscode-git-cannot-use-api-proposal-scmvalidation/","summary":"问题表现 某天，我的 vscode 的 git 管理出现了问题。\n类似这个样子。\n解决方式 @builtin @id:vscode.git 直接卸载了。\n出现原因 应该是某个公司的插件给我自动装上导致的","title":"修复 Vscode Git Cannot Use Api Proposal ScmValidation"},{"content":" Gavin Wood 在 2014 年创造了 Web3（最初是 Web 3.0）这个词。当时，他刚开始帮助开发以太坊，这是一种在知名度和市场规模上仅次于比特币的加密货币。如今，他经营着支持去中心化技术项目的 Web3 基金会，以及专注于为 Web3 构建区块链基础设施的公司 Parity Technologies。居住在瑞士的 Gavin 上周通过视频与我讨论了 Web 2.0 出错的地方、他对未来的展望，以及为什么我们都需要更少的信任。以下采访是我们谈话的记录的整理版。\n  WIRED：据我所知，Web3 最基本的想法是当前的 Web2.0 不好。因此，在我们讨论 Web3 会带来什么之前，你会怎么描述现在的问题？\nGavin Wood：我认为 Web 2.0 的模型与互联网出现之前的社会模型非常相似。如果你回到 500 年前，人们基本上只在他们的小村庄和乡镇，并与他们认识的人进行交易。从广义上讲，他们依靠社会结构来确保他们的期望是可信的，并且很可能会真正发生，比如，这些苹果没有腐烂，或者这个马蹄铁在三周后不会破裂。\n这种机制运行很好，因为在城镇之间移动既困难又耗时且成本高昂。所以你有相当高的可信度，就会有人留下来，他们并不想被流放。\n但是随着社会变得更大规模，我们有了城市、国家和国际组织，我们开始关注这种奇怪的品牌声誉问题。我们创建了这些强大但受监管的机构，监管机构原则上确保满足我们的期望。想要在特定行业开展业务，你必须满足某些法定要求。\n这不是一个很好的解决方案，原因有几个。其中之一是，去监管新兴产业非常困难。政府的行动是比较缓慢的，需要一段时间才能赶上。另一个是监管机构不完善。尤其是当他们与行业密切合作时，行业和监管机构之间通常会存在一些旋转门关系。\n另一个是监管机构的支持力度非常有限，也就是政府投入多少资金。因此，监管将是不完整的。他们能够监管最大的罪犯，但他们无法在任何地方都保持真正强大的影响力。当然，监管机构和法律因司法管辖区而异。如果你去欧盟的某个地方，那么 xx 活动就可以了；如果你去别的地方，那就不行了。随着我们成为一个非常国际化的社会，这实际上意味着你的期望仍未得到满足。\n所以我们需要超越这一点。但不幸的是，Web 2.0 仍然存在于这种非常中心化的模型中。\nWIRED：我们真的在谈论技术的失败吗？还是我们在谈论治理、监管和竞争政策的失败？因为听起来你是在说：这是监管的失败，但答案却不是更好的监管，而是需要有一个新的技术层，因为监管失败是不可避免的。我是否正确描述了您的观点？\nGavin Wood：是的，这个模型坏了。\nWIRED：那么让我们来谈谈应该用什么来代替它。我们一直在讨论为什么 Web 2.0 不起作用。你对 Web3 的定义是什么？\nGavin Wood：Less trust, more truth。更少的信任，更多的事实。\nWIRED：“less trust”是什么意思？\nGavin Wood：我对信任有一个特殊的含义，它本质上是信仰。这是一种信念（faith），即某些事情会发生的信仰，世界会以某种方式运转，而没有任何真实的证据或理性的论据来说明为什么会发生这种情况。所以我们想要的更少的信任，我们想要更多的事实真相。我真正想表达的意思是在 Web3 下更加可以相信我们的期望会得到满足。\nWIRED：这听起来像是在说“减少盲目信仰，增加信誉的可信度”。\nGavin Wood：可以说是，也可以说不是。我认为信任本身实际上围绕着坏事。信任意味着你将某种权力授予其他人或某个组织，他们将能够以某种任意方式使用该权力。一旦它成为可信的信任，它就不再是真正的信任。它会有一个机制，一个基本原理，一个论点，一个逻辑机制。无论如何，但在我看来，这不是信任。\nWIRED：已经写到 Web3 将打破像 Google 和 Facebook 这样的垄断企业平台。你能解释一下它将如何做到这一点吗？\nGavin Wood：是的，我认为这是一个合乎逻辑的改进。而且我认为在更大的计划中，这是不可避免的。要么这是不可避免的，要么社会正在走向衰落。但就具体而言，这是一个很难回答的问题。\n在技术方面，我们有什么？我们有密码学。在基本层面上，密码学允许我与我的朋友隐私的交谈，即使在公开的沟通渠道或通过第三方，我仍然有良好的期望，可信的期望。这将是私密的，就好像我们在田野里互相聊天，可以看到周围没有人。\nWIRED：仅以加密通信为例，目前看来与企业垄断非常相似。就像，WhatsApp 提供加密通信。关于这在多大程度上真正满足了你对隐私的渴望存在一些争议，但我仍然认为这是加密通信的一个例子，它由世界上最强大的公司之一控制，拥有数十亿用户。\nGavin Wood：这是一个有趣的事情，从表面上看，是这样的。但是有一些重要的区别。其中之一是，如果 WhatsApp 在他们的服务中引入了一个允许他们解密所有对话的密钥怎么办？我们怎么知道它不存在？你必须信任。我们看不到代码，我们看不到他们的服务是如何运行的，我们看不到他们的密钥结构。所以我们能做的只有盲目相信他们说的是真的。现在他们说实话也许是因为他们害怕如果不这样做，他们的声誉会受到很大的打击。但是，正如我们从斯诺登的一些启示中看到的那样，有时公司没有机会说实话。有时，安全服务可以在他们的后台安装一个盒子，然后他们被告知，“你不需要看这个盒子，你不能对这个盒子说或做任何事情，你只能安静的坐着。”\nWIRED：听起来开源软件可以实现你所说的，但你并不是在描述开源软件。当我们谈论 Web3 时，我们谈论的是区块链，这是一种完全不同的互联网架构方式。那么，从技术上讲，你如何实现这种对信任的依赖呢？\nGavin Wood：我认为一定程度的 truth 是必要的。我的意思是开放、透明。区块链技术同时使用密码学和某些博弈论经济学来提供服务。我们需要了解网络的节点基础设施，它真的是点对点的？还是实际上由制造和销售硬件的公司从一个数据中心运行？新节点上线之前需要进行咨询吗？细节决定了它是否是伪装的 Web 2.0，还是否真正合法地开放、透明、去中心化、点对点。\nWIRED：让我们深入探讨下“去中心化”的概念。互联网已经去中心化了，对吧？Internet 协议不归公司所有。虽然在实际层面上，人们倾向于通过中心化的平台来引导他们的行为，但他们不一定必须这样做。你不必在 Facebook 上发消息，它只是很方便。那么当我们谈论中心化和去中心化时，这意味着什么？\nGavin Wood：从本质上讲，这意味着我个人可以像世界上任何其他人一样轻松地成为这项整体服务的提供者或共同提供者。\nWIRED：这有多现实？在我看来，只有一小部分具有高技术素养的人可以做到。在这种语境下，这听起来会出现一种不同的中心化。\nGavin Wood：如果你不厌其烦地教育自己，那么拥有可以执行的权利或自由与由于缺乏排他性团体的包容性而无法在非常基本和基础的层面上做某事之间存在很大差异。如果我对免费提供的材料进行了充分的教育，并且这就是成为该服务的共同提供者所需的全部内容，那么这就是免费服务。\nWIRED：我上过法学院，我可以说，看，任何人都可以学习法律，任何人都可以进入法学院，然后为律师学习。但实际上，至少在美国，它是一个进入门槛非常高的公会，最显着的是成本。即使进入法律行业的门槛高于编程，这并不一定意味着你的行业的进入门槛不高。我理解你所描绘的区别，但我想知道这是否有点天真，认为每个人都可以选择成为一名专业的 Web3 程序员？\nGavin Wood：原则上，这与成为一名 Web3 程序员无关。您应该能够享受评估某些事物的大部分能力，而无需成为深入的核心开发人员。但是世界上的程序员比律师多得多。这是有充分理由的。为机器编程实际上只需要了解一种相当容易学习的语言。你可以在印度的一个小村庄里，碰巧有互联网，你可以在一周内学习 JavaScript。但你不能用美国法律做到这一点。\n我不会试图说服你相信世界上每个人都可以做到这一点。但关键是，能做到这一点的人越多，门槛就越低。\nWIRED：这感觉还是有点抽象。阅读本文的人可能会想，“我会在 Web3 世界中做什么？” 你能勾勒出它的样子吗？某一种活动或应用程序界面或交易？\nGavin Wood：我认为最初的 Web3 应用程序可能是对 Web 2.0 应用程序的小迭代。但是 Web3 带来的 Web 2.0 无法轻松服务的一件事是财务义务或经济上强大的应用程序。这是点对点方式的个人可以在他们之间获得经济服务的地方。\n这不是关于汇款本身，而是关于发送非常稀有、非常困难或在某些方面非常昂贵的东西。因此，我们可以想象，例如，约会应用程序可以发送虚拟鲜花，但无论你支付多少钱，我们每天只能发送一束虚拟鲜花。因此，如果你每天向同一个人送一束鲜花是一个非常强烈的信号，表明他们喜欢你。这就是重点，你不能付钱送更多的花。\nWIRED：我觉得 Tinder 可以添加该功能。\nGavin Wood：对，他们可以，你每天只能做一次。但他们是一家以利润为动机的公司。因此，如果你想要支付足够的 Tinder 费用，你就可以发送任意数量的星星。\nWIRED：但是，建立在 Web3 上的公司是否仍然拥有与 Web 2.0 公司相同的市场激励？我很难想象历史上的技术发展不允许政治或经济权力更加中心。那么我们为什么要期望这个基于区块链的去中心化 Web3 打破常规呢？\nGavin Wood：我从小就喜欢技术。我在八岁的时候学会了编码。我从来没有见过一种技术可以限制一个人的权力。正如你所说，我能想到的每一项技术都有助于让用户变得更强大。他们可以做更多的事情。他们可以更富有，他们可以更快、更好地或向更多人提供他们提供的服务。区块链不会那样做，这是根本的不同。它实际上是一种社会结构，这是一套规则。而这些规则唯一的作用就是在系统内没有人拥有任意权力。你可以相当确定，特别是如果你是一名程序员，那么你可以查看代码并知道它在做正确的事情。但是，你也可以合理地确定，因为有这么多人在这种期望的支持下加入了网络。如果这个期望没有得到满足，他们就会离开网络。\nWIRED：很多人都被加密行业所吸引，因为他们将其视为推翻现有政治秩序或中央银行权力的一种方式。但是你已经建议 Web3 支持自由的战后秩序。你怎么看它这样做？\nGavin Wood：我认为由于技术允许的权力集中，我们所拥有的服务和期望正受到威胁。这只是一个事实。在 Facebook 和谷歌之前，几乎没有什么东西能让这么少的人拥有这种级别的权力。并不是说我不认为 Facebook 和 Google 以及所有其他公司都应该被取代，这并不是 Web3 的症结所在。对我来说，Web3 实际上更像是一场更大的社会政治运动，它正在从任意权威转向一个更加理性的自由模型。这是我能看到的保护自由世界的唯一方式，这是我们过去 70 年来享受的生活。这是我们能够让它在未来 70 年继续运行的唯一方法。但目前，我认为我们正在朝着一个完全不同的方向。\n","permalink":"https://zhenfeng-zhu.github.io/posts/what-is-web3/","summary":"Gavin Wood 在 2014 年创造了 Web3（最初是 Web 3.0）这个词。当时，他刚开始帮助开发以太坊，这是一种在知名度和市场规模上仅次于比特币的加密货币。如今，他经营着支持去中心化技术项目的 Web3 基金会，以及专注于为 Web3 构建区块链基础设施的公司 Parity Technologies。居住在瑞士的 Gavin 上周通过视频与我讨论了 Web 2.0 出错的地方、他对未来的展望，以及为什么我们都需要更少的信任。以下采访是我们谈话的记录的整理版。\n  WIRED：据我所知，Web3 最基本的想法是当前的 Web2.0 不好。因此，在我们讨论 Web3 会带来什么之前，你会怎么描述现在的问题？\nGavin Wood：我认为 Web 2.0 的模型与互联网出现之前的社会模型非常相似。如果你回到 500 年前，人们基本上只在他们的小村庄和乡镇，并与他们认识的人进行交易。从广义上讲，他们依靠社会结构来确保他们的期望是可信的，并且很可能会真正发生，比如，这些苹果没有腐烂，或者这个马蹄铁在三周后不会破裂。\n这种机制运行很好，因为在城镇之间移动既困难又耗时且成本高昂。所以你有相当高的可信度，就会有人留下来，他们并不想被流放。\n但是随着社会变得更大规模，我们有了城市、国家和国际组织，我们开始关注这种奇怪的品牌声誉问题。我们创建了这些强大但受监管的机构，监管机构原则上确保满足我们的期望。想要在特定行业开展业务，你必须满足某些法定要求。\n这不是一个很好的解决方案，原因有几个。其中之一是，去监管新兴产业非常困难。政府的行动是比较缓慢的，需要一段时间才能赶上。另一个是监管机构不完善。尤其是当他们与行业密切合作时，行业和监管机构之间通常会存在一些旋转门关系。\n另一个是监管机构的支持力度非常有限，也就是政府投入多少资金。因此，监管将是不完整的。他们能够监管最大的罪犯，但他们无法在任何地方都保持真正强大的影响力。当然，监管机构和法律因司法管辖区而异。如果你去欧盟的某个地方，那么 xx 活动就可以了；如果你去别的地方，那就不行了。随着我们成为一个非常国际化的社会，这实际上意味着你的期望仍未得到满足。\n所以我们需要超越这一点。但不幸的是，Web 2.0 仍然存在于这种非常中心化的模型中。\nWIRED：我们真的在谈论技术的失败吗？还是我们在谈论治理、监管和竞争政策的失败？因为听起来你是在说：这是监管的失败，但答案却不是更好的监管，而是需要有一个新的技术层，因为监管失败是不可避免的。我是否正确描述了您的观点？\nGavin Wood：是的，这个模型坏了。\nWIRED：那么让我们来谈谈应该用什么来代替它。我们一直在讨论为什么 Web 2.0 不起作用。你对 Web3 的定义是什么？\nGavin Wood：Less trust, more truth。更少的信任，更多的事实。\nWIRED：“less trust”是什么意思？\nGavin Wood：我对信任有一个特殊的含义，它本质上是信仰。这是一种信念（faith），即某些事情会发生的信仰，世界会以某种方式运转，而没有任何真实的证据或理性的论据来说明为什么会发生这种情况。所以我们想要的更少的信任，我们想要更多的事实真相。我真正想表达的意思是在 Web3 下更加可以相信我们的期望会得到满足。\nWIRED：这听起来像是在说“减少盲目信仰，增加信誉的可信度”。\nGavin Wood：可以说是，也可以说不是。我认为信任本身实际上围绕着坏事。信任意味着你将某种权力授予其他人或某个组织，他们将能够以某种任意方式使用该权力。一旦它成为可信的信任，它就不再是真正的信任。它会有一个机制，一个基本原理，一个论点，一个逻辑机制。无论如何，但在我看来，这不是信任。\nWIRED：已经写到 Web3 将打破像 Google 和 Facebook 这样的垄断企业平台。你能解释一下它将如何做到这一点吗？","title":"Gavin Wood: Web3 去中心化技术是维护自由民主的唯一希望"},{"content":"Lab 11 - 高级函数 - 使用 HMAC 的信任 前言 用于微服务的传统认证策略与函数的工作原理完全相同。在这个实验室中，我们将讨论使用共享秘密和基于哈希的消息验证码（HMAC）的几种可用方法之一。有关其他认证策略和想法，请参见。openfaas-function-auth\n这绝不是一个广泛的清单，安全和认证是一个复杂的领域，最好留给专家使用经过试验的方法。\n准备好你的环境 在开始这个实验之前，创建一个新的文件夹\nmkdir -p lab11\\`bash \u0026amp;\u0026amp; cd lab11 也要确保你的faas-cli'版本是0.7.4\u0026rsquo;或以上，使用以下命令。\nfaas-cli version 什么是 HMAC 如果没有任何形式的认证或信任，我们的函数可能会暴露给任何能猜到其 URL 的人。如果我们的函数可以在互联网或本地网络上访问，那么它们就可能被坏的行为者调用。默认情况下，函数会对任何请求做出响应。然而，如果我们想控制对函数的访问，我们可以使用基于哈希的消息验证码（HMAC）来验证信息的来源。\n来自[alexellis/hmac]（https://github.com/alexellis/hmac）。\n HMAC 使用发送方/接收方提前共享的对称密钥。发送方在想要传输信息时将产生一个哈希值\u0026ndash;该数据与有效载荷一起发送。然后，收件人将用共享密钥签署有效载荷，如果哈希值匹配，则假定有效载荷来自发件人。\n 这样我们就可以避免我们的函数被无效的甚至是危险的信息所调用。\n使用 HMAC 我们将使用 faas-cli 提供的--sign标志来包含一个头，其中包含使用我们用--key标志提供的共享密钥创建的散列信息。\n 注意: --sign和--key必须同时存在。\n 让我们首先通过部署-env函数来检查该标志的作用，该函数将打印函数中可访问的所有环境变量。\nfaas-cli deploy --name env --fprocess=\u0026#34;env\u0026#34; --image=\u0026#34;function/alpine:new\u0026#34;  调用不带--sign标志的函数。  $ echo \u0026#34;The message\u0026#34; | faas-cli invoke env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/sbin:/bin HOSTNAME=d2c1a2cb20c2 fprocess=env HOME=/root Http_X_Call_Id=b84947c6-2970-4fcf-ba3b-66dde6943999 Http_X_Forwarded_For=10.255.0.2:34974 Http_X_Forwarded_Host=127.0.0.1:8080 Http_Content_Length=0 Http_Accept_Encoding=gzip Http_Content_Type=text/plain Http_User_Agent=Go-http-client/1.1 Http_X_Start_Time=1538725657952768349 ...  再次调用该函数，但这次有--sign标志。  $ echo -n \u0026#34;The message\u0026#34; | faas-cli invoke env --sign=HMAC --key=cookie PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=d2c1a2cb20c2 fprocess=env HOME=/root Http_User_Agent=Go-http-client/1.1 Http_Content_Length=0 Http_Accept_Encoding=gzip ... Http_Hmac=sha1=9239edfe20185eafd7a5513c303b03d207d22f64 ... 我们看到HMAC被作为环境变量Http_Hmac提供。生成的值是用钥匙cookie签名后的消息的哈希值，然后用散列方法sha1进行预处理。\nHMAC 在行动 为了我们的目的，我们将创建一个新的 Python 3 函数。让我们把它叫做hmac-protected。\nfaas-cli new --lang python3 hmac-protected --prefix=\u0026#34;\u0026lt;your-docker-username\u0026gt;\u0026#34; 添加payload-secret，它将作为哈希有效载荷的密钥。\n像我们在lab10中那样创建payload-secret。\necho -n \u0026#34;\u0026lt;your-secret\u0026gt;\u0026#34; ! | faas-cli secret create payload-secret  注意：记住你放在\u0026quot;\u0026ldquo;位置的字符串。\n 我们的 hmac-protected.yml应该看起来像。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: hmac-protected: lang: python3 handler: ./hmac-protected image: \u0026lt;your-docker-username\u0026gt;/hmac-protected:latest secrets: - payload-secret 用以下代码替换handler.py的内容。\nimport os, hmac, hashlib def validateHMAC(message, secret, hash): # GitHub and the sign flag prefix the hash with \u0026#34;sha1=\u0026#34; receivedHash = getHash(hash) # Hash message with secret expectedMAC = hmac.new(secret.encode(), message.encode(), hashlib.sha1) createdHash = expectedMAC.hexdigest() return receivedHash == createdHash def getHash(hash): if \u0026#34;sha1=\u0026#34; in hash: hash=hash[5:] return hash def handle(req): # We receive the hashed message in form of a header messageMAC = os.getenv(\u0026#34;Http_Hmac\u0026#34;) # Read secret from inside the container with open(\u0026#34;/var/openfaas/secrets/payload-secret\u0026#34;,\u0026#34;r\u0026#34;) as secretContent: payloadSecret = secretContent.read() # Function to validate the HMAC if validateHMAC(req, payloadSecret, messageMAC): return \u0026#34;Successfully validated: \u0026#34; + req return \u0026#34;HMAC validation failed.\u0026#34;  源代码也可在hmac-protected/hmac-protected/handler.py\n  通过使用faas-cli up在一个命令中构建、推送和部署该函数。  faas-cli up -f ./hmac-protected.yml 调用函数 我们将通过发送两个值来调用该函数。\n  正常的请求信息\n  一个包含同一消息的哈希值的头，当用--key标志的值签名时\n  在收到请求后，该函数将使用payload-secret以与发送者相同的方式签署请求信息。这将创建第二个 HMAC，并与传输的头信息 Http-Hmac进行比较。\n这里我们比较生成和接收的哈希值。\n... # Function to validate the HMAC if validateHMAC(req, payloadKey, receivedHMAC): return \u0026#34;Successfully validated: \u0026#34; + req return \u0026#34;HMAC validation failed.\u0026#34; ...  用标志来调用该函数。  echo -n \u0026#34;This is a message\u0026#34; | faas-cli invoke hmac-protected --sign hmac --key=\u0026lt;your-secret\u0026gt; 检查响应并确认它与所传达的信息相符。在我们的例子中，我们应该得到。\nSuccessfully validated: This is a message  用错误的--key调用函数，检查失败信息。  $ echo -n \u0026#34;This is a message\u0026#34; | faas-cli invoke hmac-protected --sign hmac --key=wrongkey HMAC validation failed. 作为后续任务，你可以应用 HMAC 来保护你在实验室 5的issue-bot上的端点。\n你已经完成了实验，可以返回到主页。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab11/","summary":"Lab 11 - 高级函数 - 使用 HMAC 的信任 前言 用于微服务的传统认证策略与函数的工作原理完全相同。在这个实验室中，我们将讨论使用共享秘密和基于哈希的消息验证码（HMAC）的几种可用方法之一。有关其他认证策略和想法，请参见。openfaas-function-auth\n这绝不是一个广泛的清单，安全和认证是一个复杂的领域，最好留给专家使用经过试验的方法。\n准备好你的环境 在开始这个实验之前，创建一个新的文件夹\nmkdir -p lab11\\`bash \u0026amp;\u0026amp; cd lab11 也要确保你的faas-cli'版本是0.7.4\u0026rsquo;或以上，使用以下命令。\nfaas-cli version 什么是 HMAC 如果没有任何形式的认证或信任，我们的函数可能会暴露给任何能猜到其 URL 的人。如果我们的函数可以在互联网或本地网络上访问，那么它们就可能被坏的行为者调用。默认情况下，函数会对任何请求做出响应。然而，如果我们想控制对函数的访问，我们可以使用基于哈希的消息验证码（HMAC）来验证信息的来源。\n来自[alexellis/hmac]（https://github.com/alexellis/hmac）。\n HMAC 使用发送方/接收方提前共享的对称密钥。发送方在想要传输信息时将产生一个哈希值\u0026ndash;该数据与有效载荷一起发送。然后，收件人将用共享密钥签署有效载荷，如果哈希值匹配，则假定有效载荷来自发件人。\n 这样我们就可以避免我们的函数被无效的甚至是危险的信息所调用。\n使用 HMAC 我们将使用 faas-cli 提供的--sign标志来包含一个头，其中包含使用我们用--key标志提供的共享密钥创建的散列信息。\n 注意: --sign和--key必须同时存在。\n 让我们首先通过部署-env函数来检查该标志的作用，该函数将打印函数中可访问的所有环境变量。\nfaas-cli deploy --name env --fprocess=\u0026#34;env\u0026#34; --image=\u0026#34;function/alpine:new\u0026#34;  调用不带--sign标志的函数。  $ echo \u0026#34;The message\u0026#34; | faas-cli invoke env PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/sbin:/bin HOSTNAME=d2c1a2cb20c2 fprocess=env HOME=/root Http_X_Call_Id=b84947c6-2970-4fcf-ba3b-66dde6943999 Http_X_Forwarded_For=10.255.0.2:34974 Http_X_Forwarded_Host=127.0.0.1:8080 Http_Content_Length=0 Http_Accept_Encoding=gzip Http_Content_Type=text/plain Http_User_Agent=Go-http-client/1.","title":"Openfaas Workshop Lab11"},{"content":"Lab 10 - 高级函数 - 秘密 在开始本实验室之前，为你的文件创建一个新的文件夹。由于本实验室是建立在先前的实验室基础上的，因此请复制 lab5。\n$ cp -r lab5 lab10\\ \u0026amp;\u0026amp; cd lab10 使用秘密 实验室 5研究了issue-bot如何从环境变量（auth_token）获得 GitHub 的*个人访问令牌。 另一种方法是使用机密来存储敏感信息。\n来自 Docker 文档。\n \u0026hellip; 秘密是一团数据，如密码、SSH 私钥、SSL 证书或其他数据，不应通过网络传输或未经加密存储在 Docker 文件或应用程序的源代码中。\n 这是一个比环境变量更安全的选择。环境变量更容易使用，但最适合于非保密的配置项目。 似乎很适合用于存储auth_token值。\n请参阅docs中关于秘密的更多信息和它的设计。\n创建一个秘密  秘密名称必须遵循 DNS-1123 惯例，由小写字母数字字符或'-\u0026lsquo;组成，并且必须以一个字母数字字符开始和结束\n 从一个终端运行以下命令。\necho -n \u0026lt;auth_token\u0026gt; | faas-cli secret create auth-token 测试秘密是否被创建。\nfaas-cli secret ls  注意：请记住，-g标志可以在网关之间轻松切换。 这也适用于秘密。\n kubectl get secret auth-token -n openfaas-fn -o json  注意：如果你在远程网关上部署你的函数，确保你在你用于网关的虚拟机上创建你的秘密。\n 当秘密被函数挂载时，它将以文件形式出现在/var/openfaas/secrets/auth-token下。这可以由handler.py读取，以获得 GitHub 的个人访问令牌。\n更新 issue-bot.yml 用一个指令取代对env.yml的引用，使auth-token的秘密对函数可用。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: issue-bot: lang: python3 handler: ./issue-bot image: \u0026lt;your-username\u0026gt;/issue-bot environment: write_debug: true gateway_hostname: \u0026#34;gateway.openfaas\u0026#34; positive_threshold: 0.25 secrets: - auth-token 更新issue-bot函数 函数处理程序需要改变，以使其读取auth-token秘密，而不是环境变量。 这只是一个单行的改动，在这里。\npython g = Github(os.getenv(\u0026ldquo;auth_token\u0026rdquo;))\n被替换为 ```python with open(\u0026#34;/var/openfaas/secrets/auth-token\u0026#34;, \u0026#34;r\u0026#34;) as authToken: g = Github(authToken.read())  完整的源代码可在issue-bot-secrets/bot-handler/handler.py\n  构建和部署  使用 CLI 来构建和部署该函数。\nfaas-cli up -f issue-bot.yml 现在转到Lab 11。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab10/","summary":"Lab 10 - 高级函数 - 秘密 在开始本实验室之前，为你的文件创建一个新的文件夹。由于本实验室是建立在先前的实验室基础上的，因此请复制 lab5。\n$ cp -r lab5 lab10\\ \u0026amp;\u0026amp; cd lab10 使用秘密 实验室 5研究了issue-bot如何从环境变量（auth_token）获得 GitHub 的*个人访问令牌。 另一种方法是使用机密来存储敏感信息。\n来自 Docker 文档。\n \u0026hellip; 秘密是一团数据，如密码、SSH 私钥、SSL 证书或其他数据，不应通过网络传输或未经加密存储在 Docker 文件或应用程序的源代码中。\n 这是一个比环境变量更安全的选择。环境变量更容易使用，但最适合于非保密的配置项目。 似乎很适合用于存储auth_token值。\n请参阅docs中关于秘密的更多信息和它的设计。\n创建一个秘密  秘密名称必须遵循 DNS-1123 惯例，由小写字母数字字符或'-\u0026lsquo;组成，并且必须以一个字母数字字符开始和结束\n 从一个终端运行以下命令。\necho -n \u0026lt;auth_token\u0026gt; | faas-cli secret create auth-token 测试秘密是否被创建。\nfaas-cli secret ls  注意：请记住，-g标志可以在网关之间轻松切换。 这也适用于秘密。\n kubectl get secret auth-token -n openfaas-fn -o json  注意：如果你在远程网关上部署你的函数，确保你在你用于网关的虚拟机上创建你的秘密。\n 当秘密被函数挂载时，它将以文件形式出现在/var/openfaas/secrets/auth-token下。这可以由handler.","title":"Openfaas Workshop Lab10"},{"content":"Lab 9 - 高级函数 - 自动缩放 自动缩放函数的应用 正如文档中描述的那样，OpenFaaS 带有自动扩展函数。在这个实验室中，我们将看看自动扩展是如何运作的。\n前提条件   在完成了Lab 1中对 OpenFaaS 的设置后，你将拥有触发自动扩展所需的一切。\n  多个工具可以用来创建足够的流量来触发自动扩展 - 在这个例子中，`curl\u0026rsquo;将被使用，因为它很容易在 Mac 和 Linux 上使用，并在 Windows 上与 Git Bash 打包。\n  自动扩展的背景 开箱即用的 OpenFaaS 是这样配置的，它将根据 Prometheus 测量的 每秒请求指标进行自动扩展。 这个指标是在流量通过 API 网关的时候捕获的。如果超过了定义的 每秒请求的阈值，AlertManager 就会启动。这个阈值应该被重新配置为适合生产使用的水平，因为在这个例子中，为了演示，它被设置为一个低值。\n 在文档网站中找到更多关于自动缩放的信息。\n 每次警报被 AlertManager 触发时，API 网关将把你的函数的一定数量的副本添加到集群中。OpenFaaS 有两个配置选项，允许指定复制的起始/最低数量，也允许停止复制的最大数量。\n你可以通过设置com.openfaas.scale.min来控制函数的最小复制量，目前默认值为1。\n你可以通过设置com.openfaas.scale.max来控制一个函数可以产生的最大复制量，目前默认值是20。\n 注意: 如果你把com.openfaas.scale.min和com.openfaas.scale.max设置成相同的值，你就会禁用自动缩放函数。\n 查看 Prometheus 你需要运行这个端口转发命令，以便能够在http://127.0.0.1:9090访问 Prometheus。\nkubectl port-forward deployment/prometheus 9090:9090 -n openfaas 现在添加一个所有成功调用部署的函数的图。我们可以通过执行rate( gateway_function_invocation_total{code=\u0026quot;200\u0026quot;} [20s])作为查询来实现。导致一个看起来像这样的页面。\n继续打开一个新的标签，在其中使用http://127.0.0.1:9090/alerts导航到警报部分。在这个页面上，你以后可以看到什么时候超过了 每秒请求 的阈值。\n触发缩放的 Go 函数 首先是 Alex Ellis 的 echo-fn函数。\n$ git clone https://github.com/alexellis/echo-fn \\  \u0026amp;\u0026amp; cd echo-fn \\  \u0026amp;\u0026amp; faas-cli template store pull golang-http \\  \u0026amp;\u0026amp; faas-cli deploy \\  --label com.openfaas.scale.max=10 \\  --label com.openfaas.scale.min=1 现在检查用户界面，看什么时候 go-echo函数从 不准备变成 准备。你也可以用faas-cli describe go-echo来检查。\n使用这个脚本反复调用 go-echo 函数，直到你看到复制数从 1 变成 5，以此类推。你可以在 Prometheus 中通过添加`gateway_service_count\u0026rsquo;的图表或在选择该函数的情况下查看 API 网关来监控这个值。\n$ for i in {0..10000}; do echo -n \u0026#34;Post $i\u0026#34; | faas-cli invoke go-echo \u0026amp;\u0026amp; echo; done;  注意：如果你在 Kubernetes 上运行，使用$OPENFAAS_URL而不是http://127.0.0.1:8080。\n 监控警报 现在你应该可以看到，在之前创建的图表中，go-echo函数的调用量有所增加。移动到你打开警报页面的标签。一段时间后，你应该开始看到 APIHighInvocationRate的状态（和颜色）变为 \u0026ldquo;待定\u0026rdquo;，然后再次变为 \u0026ldquo;发射\u0026rdquo;。你也可以使用$ faas-cli list或通过ui看到自动缩放的情况。\n现在你可以使用$ docker service ps go-echo来验证go-echo的新副本是否已经启动。\n现在停止 bash 脚本，你会看到复制的数量在几秒钟后回到 1 个复制。\n疑难解答 如果你认为你的自动扩展没有被触发，那么请检查以下内容。\n 普罗米修斯中的警报页面 - 这应该是红色/粉色的，并显示 FIRING - 即在http://127.0.0.1:9090/alerts。 检查核心服务的日志，即网关、Prometheus / AlertManager。  为了获得核心服务的日志，运行docker service ls，然后docker service logs \u0026lt;service-name\u0026gt;。\n负载测试(可选) 需要注意的是，在受控环境中应用科学方法和工具与在你自己的笔记本电脑上运行拒绝服务攻击是有区别的。你的笔记本电脑不适合做负载测试，因为一般来说，你是在 Windows 或 Mac 主机上的 Linux 虚拟机中运行 OpenFaaS，而这也是一个单节点。这并不代表生产部署。\n请看构建一个合适的性能测试的文档。\n如果curl没有为你的测试产生足够的流量，或者你想获得一些关于事情如何分解的统计数据，那么你可以试试hey工具。hey可以通过每秒的请求或给定的持续时间产生结构化的负载。\n这里有一个在 1GHz 的 2016 年 12 英寸 MacBook 上运行的例子，带有 Docker Desktop。这是一台非常低功率的计算机，正如所描述的，不代表生产性能。\n$ hey -z=30s -q 5 -c 2 -m POST -d=Test http://127.0.0.1:8080/function/go-echo Summary: Total: 30.0203 secs Slowest: 0.0967 secs Fastest: 0.0057 secs Average: 0.0135 secs Requests/sec: 9.9932 Total data: 1200 bytes Size/request: 4 bytes Response time histogram: 0.006 [1] | 0.015 [244] |■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 0.024 [38] |■■■■■■ 0.033 [10] |■■ 0.042 [4] |■ 0.051 [1] | 0.060 [0] | 0.069 [0] | 0.078 [0] | 0.088 [0] | 0.097 [2] | Latency distribution: 10% in 0.0089 secs 25% in 0.0101 secs 50% in 0.0118 secs 75% in 0.0139 secs 90% in 0.0173 secs 95% in 0.0265 secs 99% in 0.0428 secs Details (average, fastest, slowest): DNS+dialup: 0.0000 secs, 0.0057 secs, 0.0967 secs DNS-lookup: 0.0000 secs, 0.0000 secs, 0.0000 secs req write: 0.0001 secs, 0.0000 secs, 0.0016 secs resp wait: 0.0131 secs, 0.0056 secs, 0.0936 secs resp read: 0.0001 secs, 0.0000 secs, 0.0013 secs Status code distribution: [200] 300 responses 以上模拟了两个活跃的用户-c，每秒 5 个请求-q，持续时间-z为 30 秒。\n要使用hey，你必须在本地计算机上安装 Golang。\n也请参见。hey on GitHub\n尝试从零开始扩展 如果你把你的函数规模缩小到 0 个副本，你仍然可以调用它。该调用将触发网关将函数缩放到一个非零值。\n用下面的命令试试吧。\nkubectl scale deployment --replicas=0 nodeinfo -n openfaas-fn 打开 OpenFaaS 用户界面，检查 nodeinfo 是否有 0 个副本，或者通过`kubectl get deployment nodeinfo -n openfaas-fn'。\n现在调用该函数并检查它是否扩展到 1 个副本。\n现在转到Lab 10。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab9/","summary":"Lab 9 - 高级函数 - 自动缩放 自动缩放函数的应用 正如文档中描述的那样，OpenFaaS 带有自动扩展函数。在这个实验室中，我们将看看自动扩展是如何运作的。\n前提条件   在完成了Lab 1中对 OpenFaaS 的设置后，你将拥有触发自动扩展所需的一切。\n  多个工具可以用来创建足够的流量来触发自动扩展 - 在这个例子中，`curl\u0026rsquo;将被使用，因为它很容易在 Mac 和 Linux 上使用，并在 Windows 上与 Git Bash 打包。\n  自动扩展的背景 开箱即用的 OpenFaaS 是这样配置的，它将根据 Prometheus 测量的 每秒请求指标进行自动扩展。 这个指标是在流量通过 API 网关的时候捕获的。如果超过了定义的 每秒请求的阈值，AlertManager 就会启动。这个阈值应该被重新配置为适合生产使用的水平，因为在这个例子中，为了演示，它被设置为一个低值。\n 在文档网站中找到更多关于自动缩放的信息。\n 每次警报被 AlertManager 触发时，API 网关将把你的函数的一定数量的副本添加到集群中。OpenFaaS 有两个配置选项，允许指定复制的起始/最低数量，也允许停止复制的最大数量。\n你可以通过设置com.openfaas.scale.min来控制函数的最小复制量，目前默认值为1。\n你可以通过设置com.openfaas.scale.max来控制一个函数可以产生的最大复制量，目前默认值是20。\n 注意: 如果你把com.openfaas.scale.min和com.openfaas.scale.max设置成相同的值，你就会禁用自动缩放函数。\n 查看 Prometheus 你需要运行这个端口转发命令，以便能够在http://127.0.0.1:9090访问 Prometheus。\nkubectl port-forward deployment/prometheus 9090:9090 -n openfaas 现在添加一个所有成功调用部署的函数的图。我们可以通过执行rate( gateway_function_invocation_total{code=\u0026quot;200\u0026quot;} [20s])作为查询来实现。导致一个看起来像这样的页面。","title":"Openfaas Workshop Lab9"},{"content":"Lab 8 - 高级函数 - 超时 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab8 \\ \u0026amp;\u0026amp; cd lab8 用read_timeout扩展超时时间 timeout对应于一个函数可以运行多长时间，直到被执行。它对防止分布式系统中的误操作很重要。\n有几个地方可以为你的函数配置超时，在每个地方都可以通过使用环境变量来完成。\n  函数超时\n  read_timeout - 允许函数通过 HTTP 读取一个请求的时间\n  write_timeout - 允许函数在 HTTP 上写一个响应的时间\n  exec_timeout - 一个函数在被终止前可以运行的最大时间。\n  API 网关的默认时间是 20 秒，所以我们来测试一下在一个函数上设置一个更短的超时时间。\nfaas-cli new --lang python3 sleep-for --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑handler.py。\nimport time import os def handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; sleep_duration = int(os.getenv(\u0026#34;sleep_duration\u0026#34;, \u0026#34;10\u0026#34;)) preSleep = \u0026#34;Starting to sleep for %d\u0026#34; % sleep_duration time.sleep(sleep_duration) # Sleep for a number of seconds postSleep = \u0026#34;Finished the sleep\u0026#34; return preSleep + \u0026#34;\\n\u0026#34; + postSleep 现在编辑sleep-for.yml文件，添加这些环境变量。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: sleep-for: lang: python3 handler: ./sleep-for image: \u0026lt;your-docker-username-here\u0026gt;/sleep-for:0.1 environment: sleep_duration: 10 read_timeout: \u0026#34;5s\u0026#34; write_timeout: \u0026#34;5s\u0026#34; exec_timeout: \u0026#34;5s\u0026#34; 使用 CLI 来构建、推送、部署和调用该函数。\n$ echo | faas-cli invoke sleep-for Server returned unexpected status code: 502 - 你应该看到它没有打印消息就终止了，因为sleep_duration比超时值高。\n现在把sleep_duration设置为一个较低的数字，如2，然后再次运行faas-cli deploy。在编辑函数的 YAML 文件时，你不需要重建这个函数。\n$ echo | faas-cli invoke sleep-for Starting to sleep for 2 Finished the sleep  API 网关  要为你的函数设置超出默认限制的扩展超时，请遵循以下教程。扩展的超时\n现在转到实验室 9\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab8/","summary":"Lab 8 - 高级函数 - 超时 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab8 \\ \u0026amp;\u0026amp; cd lab8 用read_timeout扩展超时时间 timeout对应于一个函数可以运行多长时间，直到被执行。它对防止分布式系统中的误操作很重要。\n有几个地方可以为你的函数配置超时，在每个地方都可以通过使用环境变量来完成。\n  函数超时\n  read_timeout - 允许函数通过 HTTP 读取一个请求的时间\n  write_timeout - 允许函数在 HTTP 上写一个响应的时间\n  exec_timeout - 一个函数在被终止前可以运行的最大时间。\n  API 网关的默认时间是 20 秒，所以我们来测试一下在一个函数上设置一个更短的超时时间。\nfaas-cli new --lang python3 sleep-for --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑handler.py。\nimport time import os def handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; sleep_duration = int(os.","title":"Openfaas Workshop Lab8"},{"content":"实验 7\u0026ndash;异步函数 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab7 \\ \u0026amp;\u0026amp; cd lab7 同步与异步地调用一个函数 当你同步调用一个函数时，一个连接会通过网关连接到你的函数，并且在整个执行过程中保持开放。同步调用是*阻塞的，所以你应该看到你的客户端暂停，变得不活跃，直到该函数完成其任务。\n 网关使用的路由是。/function/\u0026lt;function_name\u0026gt;。 你必须等待，直到它完成 你在调用后得到结果 你知道它是通过还是失败  异步任务以类似的方式运行，但有一些区别。\n 网关使用不同的路由：/async-function/\u0026lt;function_name\u0026gt;。 客户端从网关得到一个立即的202 接受的响应。 该函数稍后使用一个队列工作器来调用 默认情况下，结果被丢弃  让我们试一试快速演示。\nfaas-cli new --lang dockerfile long-task --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑long-task/Dockerfile并将 fprocess 改为sleep 1。\n现在构建、部署并同步调用你的函数 10 次，像这样。\necho -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task 现在异步调用该函数 10 次。\necho -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task --async 你观察到了什么？第一个例子应该花了 10 秒，而第二个例子会在一秒或更短的时间内返回到你的提示。这项工作仍然需要 10x1 秒来完成，但现在要放在队列中延迟执行。\n异步函数调用非常适用于那些可以推迟到以后执行的任务，或者你不需要客户端上的结果。\n 一个很好的例子是在接收 GitHub 的 webhooks 时\u0026ndash;可能有一个最大的处理时间，GitHub 会允许你的连接保持开放，一个异步调用接受工作并立即返回。\n 查看队列工作者的日志 OpenFaaS 的默认栈使用 NATS 流来排队和延迟执行。你可以用以下命令查看日志。\nkubectl logs deployment/queue-worker -n openfaas 使用一个`X-Callback-Url\u0026rsquo;与 requirebin 如果你需要一个异步调用的函数的结果，你有两个选择。\n 改变它的代码，用它的结果通知一个端点或消息系统  这个选项可能不是在所有情况下都适用，并且需要编写额外的代码。\n 利用回调的内置行为  内置的回调允许对一个函数的调用提供一个 URL，队列工作器将自动报告函数的成功或失败，以及结果。 一些额外的请求头被发送到回调，完整的列表见回调请求头\n前往 requestbin 并创建一个新的 bin \u0026ndash;这将是公共互联网上的一个 URL，可以接收你的函数的结果。\n 为了这个实验室的目的，一定要取消勾选 私有 复选框，这将使你不需要登录。\n https://requestbin.com/\n现在复制 \u0026ldquo;Bin URL \u0026ldquo;并将其粘贴在下面。\n例如(http://requestbin.com/r/1i7i1we1)\necho -n \u0026#34;LaterIsBetter\u0026#34; | faas-cli invoke figlet --async --header \u0026#34;X-Callback-Url http://requestbin.com/r/1i7i1we1\u0026#34; 现在刷新 requestbin 站点上的页面，你将看到来自 figlet 的结果。\n_ _ ___ ____ _ _ | | __ _| |_ ___ _ _|_ _|___| __ ) ___| |_| |_ ___ _ __ | | / _` | __/ _ \\ \u0026#39;__| |/ __| _ \\ / _ \\ __| __/ _ \\ \u0026#39;__| | |__| (_| | || __/ | | |\\__ \\ |_) | __/ |_| || __/ | |_____\\__,_|\\__\\___|_| |___|___/____/ \\___|\\__|\\__\\___|_|  建议：也可以使用另一个函数作为 X-Callback-Url \u0026ndash;这对于在异步工作负载被处理时通过 Slack 或 Email 通知自己是非常好的。要用结果调用另一个函数，将X-Callback-Url设置为http://gateway:8080/function/\u0026lt;function_name\u0026gt;。\n 现在进入实验室 8\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab7/","summary":"实验 7\u0026ndash;异步函数 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab7 \\ \u0026amp;\u0026amp; cd lab7 同步与异步地调用一个函数 当你同步调用一个函数时，一个连接会通过网关连接到你的函数，并且在整个执行过程中保持开放。同步调用是*阻塞的，所以你应该看到你的客户端暂停，变得不活跃，直到该函数完成其任务。\n 网关使用的路由是。/function/\u0026lt;function_name\u0026gt;。 你必须等待，直到它完成 你在调用后得到结果 你知道它是通过还是失败  异步任务以类似的方式运行，但有一些区别。\n 网关使用不同的路由：/async-function/\u0026lt;function_name\u0026gt;。 客户端从网关得到一个立即的202 接受的响应。 该函数稍后使用一个队列工作器来调用 默认情况下，结果被丢弃  让我们试一试快速演示。\nfaas-cli new --lang dockerfile long-task --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑long-task/Dockerfile并将 fprocess 改为sleep 1。\n现在构建、部署并同步调用你的函数 10 次，像这样。\necho -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task echo -n \u0026#34;\u0026#34; | faas-cli invoke long-task 现在异步调用该函数 10 次。","title":"Openfaas Workshop Lab7"},{"content":"实验 6\u0026ndash;你的函数的 HTML 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab6\\ \u0026amp;\u0026amp; cd lab6 从一个函数中生成并返回基本的 HTML 函数可以返回 HTML，并将Content-Type设置为text/html。因此，函数返回的 HTML 可以通过浏览器进行渲染。让我们创建一个简单的函数，生成并返回一个基本的 HTML。\nfaas-cli new --lang python3 show-html --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑handler.py。\ndef handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; html = \u0026#39;\u0026lt;html\u0026gt;\u0026lt;h2\u0026gt;Hi, from your function!\u0026lt;/h2\u0026gt;\u0026lt;/html\u0026gt;\u0026#39; return html 这将返回 HTML 给调用者。 还有一件事我们应该做的是设置响应的Content-Type'。我们100%确定这个函数将返回一个HTML，所以Content-Type应该总是text/html。我们可以利用show-html.yml文件中的environment`部分来设置。\n编辑show-html.yml。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: show-html: lang: python3 handler: ./show-html image: \u0026lt;your-docker-username-here\u0026gt;/show-html environment: content_type: text/html environment中的content_type键将设置响应的Content-Type。\n现在构建、推送和部署该函数。\nfaas-cli up -f show-html.yml 运行以下程序以获得函数的 URL。\nfaas-cli describe -f show-html.yml show-html URL: http://127.0.0.1:8080/function/show-html HTML 应该被正确渲染。\n从磁盘上读取并返回一个静态的 HTML 文件 一般来说，当你提供 HTML 服务时，你有一个静态的 HTML 文件在前面。让我们看看我们如何在函数中打包 HTML 文件，并从 HTML 文件中提供内容。\n首先，让我们创建一个 HTML 文件。\n创建一个名为html的目录，并放置一个名为new.html的文件，使其结构看起来像下面这样。\n├── show-html │ ├── __init__.py │ ├── handler.py │ ├── html │ │ └── new.html │ └── requirements.txt └── show-html.yml Edit new.html :\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#39;en\u0026#39;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#39;UTF-8\u0026#39;\u0026gt; \u0026lt;title\u0026gt;OpenFaaS\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;Here\u0026#39;s a new page!\u0026lt;/h2\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 现在把你的handler.py改为以下内容。\nimport os def handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; dirname = os.path.dirname(__file__) path = os.path.join(dirname, \u0026#39;html\u0026#39;, \u0026#39;new.html\u0026#39;) with(open(path, \u0026#39;r\u0026#39;)) as file: html = file.read() return html 现在构建、推送和部署该函数。\nfaas-cli up -f show-html.yml 打开你的浏览器，访问http://127.0.0.1:8080/function/show-html。你应该看到一个 这里有一个新的页面！ 在浏览器中呈现的 HTML 页面。\n现在我们要为这个函数的 URL 添加一个路径。\n在html文件夹中添加新的list.html文件，内容如下。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#39;en\u0026#39;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#39;UTF-8\u0026#39;\u0026gt; \u0026lt;title\u0026gt;OpenFaaS\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;This is a list!\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;One\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Two\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Three\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 将你的handler.py编辑成以下内容。\nimport os def handle(req): path = os.environ[\u0026#39;Http_Path\u0026#39;] pathArr = path.split(\u0026#34;/\u0026#34;) pageName = pathArr[1] dirname = os.path.dirname(__file__) page = os.path.join(dirname, \u0026#39;html\u0026#39;, pageName + \u0026#39;.html\u0026#39;) with(open(page, \u0026#39;r\u0026#39;)) as file: html = file.read() return html 构建、推送和部署该函数。\nfaas-cli up -f show-html.yml 现在在http://127.0.0.1:8080/function/show-html/new 或 http://127.0.0.1:8080/function/show-html/list 上打开你的网页。 这将输出。\n\u0026lt;h2\u0026gt;Here\u0026#39;s a new page!\u0026lt;/h2\u0026gt; and\n\u0026lt;h2\u0026gt;This is a list!\u0026lt;/h2\u0026gt; \u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;One\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Two\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;Three\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 读取查询字符串并返回不同的 HTML 现在我们已经了解了如何通过函数来提供 HTML，让我们动态地改变通过查询字符串提供的 HTML。正如我们在实验室 4中学到的，查询字符串可以通过一个叫做Http_Query的环境变量来检索。假设我们做了一个看起来像这样的查询。\nhttp://127.0.0.1:8080/function/show-html?action=new\n查询字符串是action=new，因此Http_Query的值将是action=new。我们也可以使用urllib.parse包中的parse_qs函数，轻松解析这个查询字符串。\n我们的函数的目录结构看起来是这样的。\n├── show-html │ ├── __init__.py │ ├── handler.py │ ├── html │ │ ├── list.html │ │ └── new.html │ └── requirements.txt └── show-html.yml 改变你的handler.py。\nimport os from urllib.parse import parse_qs def handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; query = os.environ[\u0026#39;Http_Query\u0026#39;] params = parse_qs(query) action = params[\u0026#39;action\u0026#39;][0] dirname = os.path.dirname(__file__) path = os.path.join(dirname, \u0026#39;html\u0026#39;, action + \u0026#39;.html\u0026#39;) with(open(path, \u0026#39;r\u0026#39;)) as file: html = file.read() return html 现在构建、推送和部署该函数。\nfaas-cli up -f show-html.yml 打开你的浏览器，首先访问。\nhttp://127.0.0.1:8080/function/show-html?action=new\n你应该看到 这里有一个新的页面！就像你在上一节看到的那样。现在访问。\nhttp://127.0.0.1:8080/function/show-html?action=list\n你应该看到一个显示列表的 HTML。\n与其他函数协作 最后，让我们看看如何利用 JavaScript 和 Ajax 的优势，从 HTML 函数中与另一个函数（例如figlet函数）协作。\n首先，让我们再创建一个名为figlet.html的 HTML 文件。所以现在的结构应该是这样的。\n├── show-html │ ├── __init__.py │ ├── handler.py │ ├── html │ │ ├── figlet.html │ │ ├── list.html │ │ └── new.html │ └── requirements.txt └── show-html.yml 编辑figlet.html。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#39;en\u0026#39;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#39;UTF-8\u0026#39;\u0026gt; \u0026lt;title\u0026gt;OpenFaaS\u0026lt;/title\u0026gt; \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.3.1.min.js\u0026#34; integrity=\u0026#34;sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; .result { font-family: \u0026#39;Roboto Mono\u0026#39;, monospace; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;Figlet\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt; Text: \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;text\u0026#34; id=\u0026#34;text\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;generate\u0026#34;\u0026gt;Generate\u0026lt;/button\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;textarea class=\u0026#34;result\u0026#34; cols=\u0026#34;80\u0026#34; rows=\u0026#34;10\u0026#34;\u0026gt;\u0026lt;/textarea\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; $(function(){ // Generate button click  $(\u0026#39;#generate\u0026#39;).on(\u0026#39;click\u0026#39;, function() { // Execute ajax request  $.ajax({ url:\u0026#39;./figlet\u0026#39;, type:\u0026#39;POST\u0026#39;, data:$(\u0026#39;#text\u0026#39;).val() }) .done(function(data) { // ajax success  $(\u0026#39;.result\u0026#39;).val(data); console.log(data); }) .fail(function(data) { // ajax failure  $(\u0026#39;.result\u0026#39;).val(data); console.log(data); }); }); }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 如果你不太了解 JavaScript，请不要担心。这个页面所做的就是。\n 在 input中输入文字 *按下 生成按钮 创建一个 Ajax 请求到figlet函数端点（/function/figlet）。 将结果应用到 textarea 中。  没有必要改变handler.py，因为它可以动态地提供上一节中的 HTML。尽管没有改变handler.py，我们还是需要构建和推送函数镜像，因为我们需要在函数容器中打包新的figlet.html。\n现在构建、推送和部署这个函数。\nfaas-cli up -f show-html.yml 本节假设你已经部署了实验室 2中的figlet函数。\n打开你的浏览器，首先访问。\nhttp://127.0.0.1:8080/function/show-html?action=figlet\n你应该看到 Figlet 页面，并且应该看到一个输入。输入任何你想输入的文本，然后点击 生成 按钮。如果请求成功，textarea 应该包含你在 input 中输入的 figlet。这是一个微不足道的例子，但通过使用这种技术，你甚至可以用函数创建强大的 SPA（单页应用程序）。\n在这个实验室中，你学到了如何从你的函数中提供 HTML，并设置响应的Content-Type。此外，你还学会了如何用 HTML+JavaScript 调用其他函数，以及用函数创建动态页面。\n现在进入实验室 7\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab6/","summary":"实验 6\u0026ndash;你的函数的 HTML 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab6\\ \u0026amp;\u0026amp; cd lab6 从一个函数中生成并返回基本的 HTML 函数可以返回 HTML，并将Content-Type设置为text/html。因此，函数返回的 HTML 可以通过浏览器进行渲染。让我们创建一个简单的函数，生成并返回一个基本的 HTML。\nfaas-cli new --lang python3 show-html --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 编辑handler.py。\ndef handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; html = \u0026#39;\u0026lt;html\u0026gt;\u0026lt;h2\u0026gt;Hi, from your function!\u0026lt;/h2\u0026gt;\u0026lt;/html\u0026gt;\u0026#39; return html 这将返回 HTML 给调用者。 还有一件事我们应该做的是设置响应的Content-Type'。我们100%确定这个函数将返回一个HTML，所以Content-Type应该总是text/html。我们可以利用show-html.yml文件中的environment`部分来设置。\n编辑show-html.yml。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: show-html: lang: python3 handler: ./show-html image: \u0026lt;your-docker-username-here\u0026gt;/show-html environment: content_type: text/html environment中的content_type键将设置响应的Content-Type。\n现在构建、推送和部署该函数。","title":"Openfaas Workshop Lab6"},{"content":"Lab 5 - 创建一个 GitHub 机器人 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab5\\  \u0026amp;\u0026amp; cd lab5 我们将使用 OpenFaaS 的函数来创建一个名为 issue-bot的 GitHub 机器人。\n问题机器人的工作是通过分析 描述 字段的情绪来分流新的问题，然后它将应用一个积极或审查的标签。这将有助于维护者在繁忙的工作中，可以优先考虑哪些问题需要首先处理。\n问题机器人的图示](./diagram/issue-bot.png)\n获取一个 GitHub 账户   注册一个GitHub 账户，如果你还没有一个账户。\n  创建一个新的仓库，并将其称为bot-test。\n  注意：我们将只使用这个仓库作为创建问题的测试场所。你不需要在那里提交任何代码。\n建立一个带有入口的隧道 你需要接收来自 GitHub 的 webhooks。幸运的是，inlets 让这一切变得非常快速和简单。它可以按月或按年订阅，所以如果你不确定是否全年都需要它，你可以只付一个月的钱。\ninlets 有一个叫做 inlets-operator 的 Kubernetes 集成。你可以用它来设置 LoadBalancers 或带有 TLS 的 Ingress。它的工作原理是为你创建一个云虚拟机，并在那里运行一个隧道服务器，然后为你运行一个隧道客户端作为一个 Pod，你就可以获得传入流量。\n在你喜欢的云提供商（如 DigitalOcean）的 API 页面下创建一个写入访问令牌，然后将内容保存到digital-ocean-api-token.txt。\n设置完订阅后，将你的密钥保存到$HOME/.inlets/LICENSE，然后运行以下程序。\narkade install inlets-operator \\  --provider digitalocean \\  --region lon1 \\  --token-file $HOME/digital-ocean-api-token.txt 这将部署 inlets-operator，并指示它在 DigitalOcean 上为你的隧道服务器配置新的主机到伦敦地区。其他供应商和地区也可以使用，更多信息请见文档。\n用网关的公共 IP 登录你的网关 用信息检索你的网关密码，从。\narkade info openfaas LoadBalancer 的公共 IP 大约需要 10-30 秒才能出现。\nkubectl get svc -n openfaas gateway-external NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE gateway-external LoadBalancer 10.96.29.46 \u0026lt;pending\u0026gt; 8080:32278/TCP 5h56m gateway-external LoadBalancer 10.96.29.46 165.227.233.227 8080:32278/TCP 5h56m 然后把它保存到环境变量中。\nexport OPENFAAS_URL=http://165.227.233.227:8080 用给你的密码登录到公共 IP。\necho $PASSWORD | faas-cli login --password-stdin 最后测试远程 URL，如http://165.227.233.227:8080\n你可以通过设置OPENFAAS_URL环境变量或使用--gateway标志来对远程网关运行命令。\n如果你想用 TLS 证书和自定义域名来暴露 OpenFaaS，你可以按照这些说明来代替。\narkade install ingress-nginx arkade install cert-manager arkade install openfaas arkade install openfaas-ingress \\  --email web@example.com \\  --domain openfaas.example.com 然后创建一个 DNS A 记录，指向 ingress-nginx 的 IP 地址。\nkubectl get svc ingress-nginx-controller NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ingress-nginx-controller LoadBalancer 10.96.179.20 \u0026lt;pending\u0026gt; 80:30319/TCP,443:31591/TCP 20s ingress-nginx-controller LoadBalancer 10.96.179.20 209.97.135.63 80:30319/TCP,443:31591/TCP 52s 现在你可以为https://openfaas.example.com提供一个自定义的 TLS 记录。\n创建一个 webhook 接收器issue-bot export OPENFAAS_PREFIX=\u0026#34;docker.io/your-username\u0026#34; $ faas-cli new --lang python3 \\  issue-bot 现在编辑该函数的 YAML 文件issue-bot.yml并添加一个环境变量write_debug: true。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: issue-bot: lang: python3 handler: ./issue-bot image: docker.io/your-username/issue-bot environment: write_debug: true  构建、推送和部署该函数，使用  faas-cli up -f ./issue-bot.yml 从 GitHub 接收 webhooks 重新登录 GitHub 并导航到你的仓库bot-tester。\n点击 设置 -\u0026gt; Webhooks -\u0026gt; 添加 Webhook\n现在输入你从 inlets 或你的自定义域中得到的 URL，在最后加上/function/issue-bot，例如。\nhttps://openfaas.example.com 对于Content-type选择。application/json\n暂时将Secret留空。\n并选择 让我选择个别事件\n对于事件选择事件和事件评论。\n！设置事件\n检查它是否有效 现在去 GitHub，创建一个新问题。在标题和描述中输入 test。\n检查该函数被调用了多少次\u0026ndash;这个数字至少应该是1。\n$ faas-cli list Function Invocations issue-bot 2 每次你创建一个问题，由于 GitHub 的 API 调用了该函数，计数会增加。\n你可以通过输入docker service logs -f issue-bot（或kubectl logs deployment/issue-bot -n openfaas-fn）看到通过 GitHub 发送的有效载荷。\nGitHub 的 Webhooks 页面也会在 Recent Deliveries下显示每条发送的消息，你可以在这里重放一条消息，看看你的函数返回的响应。\n部署 SentimentAnalysis 函数 为了使用这个 issue-bot 函数，你将需要首先部署 SentimentAnalysis 函数。 这是一个 python 函数，为通过 TextBlob 项目输入的每个句子提供正/负（极性-1.0-1.0）和主观性的评级。\n如果你在Lab 4中没有这样做，你可以从函数商店部署 SentimentAnalysis。\n$ echo -n \u0026#34;I am really excited to participate in the OpenFaaS workshop.\u0026#34; | faas-cli invoke sentimentanalysis Polarity: 0.375 Subjectivity: 0.75 $ echo -n \u0026#34;The hotel was clean, but the area was terrible\u0026#34; | faas-cli invoke sentimentanalysis Polarity: -0.316666666667 Subjectivity: 0.85 更新issue-bot函数 打开issue-bot/handler.py，用这段代码替换模板。\nimport requests, json, os, sys def handle(req): event_header = os.getenv(\u0026#34;Http_X_Github_Event\u0026#34;) if not event_header == \u0026#34;issues\u0026#34;: sys.exit(\u0026#34;Unable to handle X-GitHub-Event: \u0026#34; + event_header) return gateway_hostname = os.getenv(\u0026#34;gateway_hostname\u0026#34;, \u0026#34;gateway.openfaas\u0026#34;) payload = json.loads(req) if not payload[\u0026#34;action\u0026#34;] == \u0026#34;opened\u0026#34;: return #sentimentanalysis res = requests.post(\u0026#39;http://\u0026#39; + gateway_hostname + \u0026#39;:8080/function/sentimentanalysis\u0026#39;, data=payload[\u0026#34;issue\u0026#34;][\u0026#34;title\u0026#34;]+\u0026#34; \u0026#34;+payload[\u0026#34;issue\u0026#34;][\u0026#34;body\u0026#34;]) if res.status_code != 200: sys.exit(\u0026#34;Error with sentimentanalysis, expected: %d, got: %d\\n\u0026#34; % (200, res.status_code)) return res.json() 用 HTTP/HTTPs 的请求模块更新你的requirements.txt文件。\nrequests 在issue-bot.yml文件中添加gateway_hostname环境变量，并将其值设置为gateway.openfaas。\n... environment: gateway_hostname: \u0026#34;gateway.openfaas\u0026#34; ... 上面代码中的下面一行将 GitHub 问题的标题和正文作为文本发布给sentimentanalysis函数。响应将是 JSON 格式。\nres = requests.post(\u0026#39;http://\u0026#39; + gateway_hostname + \u0026#39;:8080/function/sentimentanalysis\u0026#39;, data=payload[\u0026#34;issue\u0026#34;][\u0026#34;title\u0026#34;]+\u0026#34; \u0026#34;+payload[\u0026#34;issue\u0026#34;][\u0026#34;body\u0026#34;])  构建和部署  使用 CLI 来构建和部署该函数。\nfaas-cli up -f issue-bot.yml 现在在bot-test仓库中创建一个新问题。GitHub 将通过我们之前配置的 Inlets 隧道向你的函数发送一个 JSON 有效载荷。\n你可以在 GitHub 上直接查看请求/响应\u0026ndash;导航到Settings -\u0026gt; Webhook，如下所示。\n回复到 GitHub 下一步是让我们贴上 正面 或 评论 的标签，但由于这个动作涉及到向仓库写入内容，我们需要从 GitHub 获得一个个人访问令牌。\n为 GitHub 创建一个个人访问令牌 进入你的GitHub 配置文件 -\u0026gt; 设置/开发者设置 -\u0026gt; 个人访问令牌，然后点击生成新令牌。\n勾选 repo的方框，允许访问你的存储库\n点击页面底部的 Generate Token按钮\n在你的issue-bot.yml文件所在的目录中创建一个名为env.yml的文件，内容如下。\nenvironment: auth_token: \u0026lt;auth_token_value\u0026gt; 用 GitHub 上的令牌更新auth_token变量。\n现在更新你的 issue-bot.yml 文件，告诉它使用env.yml文件。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: issue-bot: lang: python3 handler: ./issue-bot image: \u0026lt;your-username\u0026gt;/issue-bot environment: write_debug: true gateway_hostname: \u0026#34;gateway.openfaas\u0026#34; positive_threshold: 0.25 environment_file: - env.yml  positive_threshold环境变量用于微调一个问题是否获得positive或review标签。\n 任何敏感信息都会被放在一个外部文件中（即env.yml），这样它就可以被包含在.gitignore文件中，这将有助于防止这些信息被存储在公共的 Git 仓库中。\nOpenFaaS 也支持使用原生的 Docker 和 Kubernetes 的秘密，详情请见Lab 10\n通过 GitHub 的 API 应用标签 你可以使用 API 来执行许多不同的任务，文档在这里可以找到。\n下面是一个 Python 代码的例子，我们可以用它来应用标签，但你先不要把它添加到你的函数中。\nissue_number = 1 repo_name = \u0026#34;alexellis/issue_bot\u0026#34; auth_token = \u0026#34;xyz\u0026#34; g = Github(auth_token) repo = g.get_repo(repo_name) issue = repo.get_issue(issue_number) 这个用于 GitHub 的库是由社区提供的，不是官方的，但似乎很受欢迎。它可以通过我们的requirements.txt文件从pip调入。\n完成函数  更新你的issue-bot/requirements.txt文件，为PyGithub添加一行内容  requests PyGithub  打开issue-bot/handler.py，将代码替换为以下内容。  import requests, json, os, sys from github import Github def handle(req): event_header = os.getenv(\u0026#34;Http_X_Github_Event\u0026#34;) if not event_header == \u0026#34;issues\u0026#34;: sys.exit(\u0026#34;Unable to handle X-GitHub-Event: \u0026#34; + event_header) return gateway_hostname = os.getenv(\u0026#34;gateway_hostname\u0026#34;, \u0026#34;gateway.openfaas\u0026#34;) payload = json.loads(req) if not payload[\u0026#34;action\u0026#34;] == \u0026#34;opened\u0026#34;: sys.exit(\u0026#34;Action not supported: \u0026#34; + payload[\u0026#34;action\u0026#34;]) return # Call sentimentanalysis res = requests.post(\u0026#39;http://\u0026#39; + gateway_hostname + \u0026#39;:8080/function/sentimentanalysis\u0026#39;, data= payload[\u0026#34;issue\u0026#34;][\u0026#34;title\u0026#34;]+\u0026#34; \u0026#34;+payload[\u0026#34;issue\u0026#34;][\u0026#34;body\u0026#34;]) if res.status_code != 200: sys.exit(\u0026#34;Error with sentimentanalysis, expected: %d, got: %d\\n\u0026#34; % (200, res.status_code)) # Read the positive_threshold from configuration positive_threshold = float(os.getenv(\u0026#34;positive_threshold\u0026#34;, \u0026#34;0.2\u0026#34;)) polarity = res.json()[\u0026#39;polarity\u0026#39;] # Call back to GitHub to apply a label apply_label(polarity, payload[\u0026#34;issue\u0026#34;][\u0026#34;number\u0026#34;], payload[\u0026#34;repository\u0026#34;][\u0026#34;full_name\u0026#34;], positive_threshold) return \u0026#34;Repo: %s, issue: %s, polarity: %f\u0026#34; % (payload[\u0026#34;repository\u0026#34;][\u0026#34;full_name\u0026#34;], payload[\u0026#34;issue\u0026#34;][\u0026#34;number\u0026#34;], polarity) def apply_label(polarity, issue_number, repo, positive_threshold): g = Github(os.getenv(\u0026#34;auth_token\u0026#34;)) repo = g.get_repo(repo) issue = repo.get_issue(issue_number) has_label_positive = False has_label_review = False for label in issue.labels: if label == \u0026#34;positive\u0026#34;: has_label_positive = True if label == \u0026#34;review\u0026#34;: has_label_review = True if polarity \u0026gt; positive_threshold and not has_label_positive: issue.set_labels(\u0026#34;positive\u0026#34;) elif not has_label_review: issue.set_labels(\u0026#34;review\u0026#34;)  源代码也可在issue-bot/bot-handler/handler.py\n  构建和部署  使用 CLI 来构建和部署该函数。\nfaas-cli up -f issue-bot.yml 现在通过在bot-test仓库中创建一些新的问题来试试。检查 正面和 评论标签是否被正确应用，如果你不确定信息是否被传递或怀疑有错误被抛出，请查阅 GitHub Webhooks 页面。\n 注意：如果标签没有立即出现，请先尝试刷新页面。\n 用 HMAC 验证有效载荷 在Lab 11中，我们将学习如何通过使用 HMAC 保护无服务器函数不被篡改。\n现在转到Lab 6。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab5/","summary":"Lab 5 - 创建一个 GitHub 机器人 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab5\\  \u0026amp;\u0026amp; cd lab5 我们将使用 OpenFaaS 的函数来创建一个名为 issue-bot的 GitHub 机器人。\n问题机器人的工作是通过分析 描述 字段的情绪来分流新的问题，然后它将应用一个积极或审查的标签。这将有助于维护者在繁忙的工作中，可以优先考虑哪些问题需要首先处理。\n问题机器人的图示](./diagram/issue-bot.png)\n获取一个 GitHub 账户   注册一个GitHub 账户，如果你还没有一个账户。\n  创建一个新的仓库，并将其称为bot-test。\n  注意：我们将只使用这个仓库作为创建问题的测试场所。你不需要在那里提交任何代码。\n建立一个带有入口的隧道 你需要接收来自 GitHub 的 webhooks。幸运的是，inlets 让这一切变得非常快速和简单。它可以按月或按年订阅，所以如果你不确定是否全年都需要它，你可以只付一个月的钱。\ninlets 有一个叫做 inlets-operator 的 Kubernetes 集成。你可以用它来设置 LoadBalancers 或带有 TLS 的 Ingress。它的工作原理是为你创建一个云虚拟机，并在那里运行一个隧道服务器，然后为你运行一个隧道客户端作为一个 Pod，你就可以获得传入流量。\n在你喜欢的云提供商（如 DigitalOcean）的 API 页面下创建一个写入访问令牌，然后将内容保存到digital-ocean-api-token.txt。\n设置完订阅后，将你的密钥保存到$HOME/.inlets/LICENSE，然后运行以下程序。\narkade install inlets-operator \\  --provider digitalocean \\  --region lon1 \\  --token-file $HOME/digital-ocean-api-token.","title":"Openfaas Workshop Lab5"},{"content":"区块 想要了解区块到底是什么，最简单快捷的方法就是分析它的数据结构，以 bitcoin 种的区块为例：\n{ \u0026#34;hash\u0026#34;:\u0026#34;00000000000000000018b0a6ae560fa33c469b6528bc9e0fb0c669319a186c33\u0026#34;, \u0026#34;confirmations\u0026#34;:1009, \u0026#34;strippedsize\u0026#34;:956228, \u0026#34;size\u0026#34;:1112639, \u0026#34;weight\u0026#34;:3981323, \u0026#34;height\u0026#34;:514095, \u0026#34;version\u0026#34;:536870912, \u0026#34;versionHex\u0026#34;:\u0026#34;20000000\u0026#34;, \u0026#34;merkleroot\u0026#34;:\u0026#34;5f8f8e053fd4c0c3175c10ac5189c15e6ba218909319850936fe54934dcbfeac\u0026#34;, \u0026#34;tx\u0026#34;:[ // ... 　], \u0026#34;time\u0026#34;:1521380124, \u0026#34;mediantime\u0026#34;:1521377506, \u0026#34;nonce\u0026#34;:3001236454, \u0026#34;bits\u0026#34;:\u0026#34;17514a49\u0026#34;, \u0026#34;difficulty\u0026#34;:3462542391191.563, \u0026#34;chainwork\u0026#34;:\u0026#34;0000000000000000000000000000000000000000014d2b41a340e60b72292430\u0026#34;, \u0026#34;previousblockhash\u0026#34;:\u0026#34;000000000000000000481ab128418847dc25db4dafec464baa5a33e66490990b\u0026#34;, \u0026#34;nextblockhash\u0026#34;:\u0026#34;0000000000000000000c74966205813839ad1c6d55d75f95c9c5f821db9c3510\u0026#34; } 在这个 Block 的结构体中，previousblockhash 和 merkleroot 是两个最重要的字段；前者是一个哈希指针，它其实是前一个 Block 的哈希，通过 previousblockhash 我们能递归地找到全部的 Block，也就是整条主链，后者是一个 Merkle 树的根，Merkle 树中包含整个 Block 中的全部交易，通过保存 merkleroot，我们可以保证当前 Block 中任意交易都不会被修改。 Ethereum 的区块链模型虽然与 Bitcoin 有非常大的不同，但是它的 Block 结构中也有着类似的信息：\n{ \u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;:{ \u0026#34;author\u0026#34;:\u0026#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d\u0026#34;, \u0026#34;difficulty\u0026#34;:\u0026#34;0x785042b0\u0026#34;, \u0026#34;extraData\u0026#34;:\u0026#34;0x414952412f7630\u0026#34;, \u0026#34;gasLimit\u0026#34;:\u0026#34;0x47b784\u0026#34;, \u0026#34;gasUsed\u0026#34;:\u0026#34;0x44218a\u0026#34;, \u0026#34;hash\u0026#34;:\u0026#34;0x4de91e4af8d135e061d50ddd6d0d6f4119cd0f7062ebe8ff2d79c5af0e8344b9\u0026#34;, \u0026#34;logsBloom\u0026#34;:\u0026#34;0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;miner\u0026#34;:\u0026#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d\u0026#34;, \u0026#34;mixHash\u0026#34;:\u0026#34;0xb8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443\u0026#34;, \u0026#34;nonce\u0026#34;:\u0026#34;0xad14fb6803147c7c\u0026#34;, \u0026#34;number\u0026#34;:\u0026#34;0x2000f1\u0026#34;, \u0026#34;parentHash\u0026#34;:\u0026#34;0x31919e2bf29306778f50bbc376bd490a7d056ddfd5b1f615752e79f32c7f1a38\u0026#34;, \u0026#34;receiptsRoot\u0026#34;:\u0026#34;0xa2a7af5e3b9e1bbb6252ba82a09302321b8f0eea7ec8e3bb977401e4f473e672\u0026#34;, \u0026#34;sealFields\u0026#34;:[ \u0026#34;0xa0b8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443\u0026#34;, \u0026#34;0x88ad14fb6803147c7c\u0026#34; ], \u0026#34;sha3Uncles\u0026#34;:\u0026#34;0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347\u0026#34;, \u0026#34;size\u0026#34;:\u0026#34;0x276\u0026#34;, \u0026#34;stateRoot\u0026#34;:\u0026#34;0x87e7e54cf229003014f453d64f0344e2ba4fc7ee3b95c7dd2642cca389fa1efe\u0026#34;, \u0026#34;timestamp\u0026#34;:\u0026#34;0x5a10968a\u0026#34;, \u0026#34;totalDifficulty\u0026#34;:\u0026#34;0x1804de0c47ffe1\u0026#34;, \u0026#34;transactions\u0026#34;:[...], \u0026#34;transactionsRoot\u0026#34;:\u0026#34;0xc2091b032961ca23cf8323ea827e8956fe6dda9e68d75bcfaa8b910035397e35\u0026#34;, \u0026#34;uncles\u0026#34;:[] }, \u0026#34;id\u0026#34;:1 } parentHash 和 transactionsRoot 分别对应着 Bitcoin 中 previousblockhash 和 merkleroot，这两者在整个区块链网络中是非常重要的。\n哈希指针 Block 结构体中的哈希指针在区块链中有两个作用，它不仅能够连接不同的区块，还能够对 Block 进行验证，保证 Block 中的数据不会被其他恶意节点篡改。\n除了第一个 Block，每一个 Block 中的 prev_hash 都是前一个 Block 的哈希，如果某一个节点想要修改主链上 Block 的交易，就会改变当前 Block 的哈希，后面的 Block 就没有办法通过 prev_hash 找到前面的链，所以当前节点篡改交易的行为就会被其他节点发现。\nMerkle Tree 另一个字段 merkleroot 其实就是一个 Merkle 树 的根节点，它其实是一种使用哈希指针连接的数据结构；虽然 Merkle 树有叶节点和非叶节点，但是它只有叶节点会存储数据，所有的非叶结点都是用于验证数据完整性的哈希。\n每一个 Block 中的全部交易都是存储在这个 Merkle 树中并将 merkleroot 保存在 Block 的结构体中，保证当前 Block 中任意交易的篡改都能被立刻发现。\n总结 prev_hash 和 merkleroot 分别通过『指针』的方式保证所有的 Block 和交易都是连接起来的，最终保证 Block 和交易不会被恶意节点或攻击者篡改，几乎全部的区块链项目都会使用类似方式连接不同的 Block 和交易，这可以说是区块链项目的基础设施和标配了。\n","permalink":"https://zhenfeng-zhu.github.io/posts/blockchain-schema/","summary":"区块 想要了解区块到底是什么，最简单快捷的方法就是分析它的数据结构，以 bitcoin 种的区块为例：\n{ \u0026#34;hash\u0026#34;:\u0026#34;00000000000000000018b0a6ae560fa33c469b6528bc9e0fb0c669319a186c33\u0026#34;, \u0026#34;confirmations\u0026#34;:1009, \u0026#34;strippedsize\u0026#34;:956228, \u0026#34;size\u0026#34;:1112639, \u0026#34;weight\u0026#34;:3981323, \u0026#34;height\u0026#34;:514095, \u0026#34;version\u0026#34;:536870912, \u0026#34;versionHex\u0026#34;:\u0026#34;20000000\u0026#34;, \u0026#34;merkleroot\u0026#34;:\u0026#34;5f8f8e053fd4c0c3175c10ac5189c15e6ba218909319850936fe54934dcbfeac\u0026#34;, \u0026#34;tx\u0026#34;:[ // ... 　], \u0026#34;time\u0026#34;:1521380124, \u0026#34;mediantime\u0026#34;:1521377506, \u0026#34;nonce\u0026#34;:3001236454, \u0026#34;bits\u0026#34;:\u0026#34;17514a49\u0026#34;, \u0026#34;difficulty\u0026#34;:3462542391191.563, \u0026#34;chainwork\u0026#34;:\u0026#34;0000000000000000000000000000000000000000014d2b41a340e60b72292430\u0026#34;, \u0026#34;previousblockhash\u0026#34;:\u0026#34;000000000000000000481ab128418847dc25db4dafec464baa5a33e66490990b\u0026#34;, \u0026#34;nextblockhash\u0026#34;:\u0026#34;0000000000000000000c74966205813839ad1c6d55d75f95c9c5f821db9c3510\u0026#34; } 在这个 Block 的结构体中，previousblockhash 和 merkleroot 是两个最重要的字段；前者是一个哈希指针，它其实是前一个 Block 的哈希，通过 previousblockhash 我们能递归地找到全部的 Block，也就是整条主链，后者是一个 Merkle 树的根，Merkle 树中包含整个 Block 中的全部交易，通过保存 merkleroot，我们可以保证当前 Block 中任意交易都不会被修改。 Ethereum 的区块链模型虽然与 Bitcoin 有非常大的不同，但是它的 Block 结构中也有着类似的信息：\n{ \u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;, \u0026#34;result\u0026#34;:{ \u0026#34;author\u0026#34;:\u0026#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d\u0026#34;, \u0026#34;difficulty\u0026#34;:\u0026#34;0x785042b0\u0026#34;, \u0026#34;extraData\u0026#34;:\u0026#34;0x414952412f7630\u0026#34;, \u0026#34;gasLimit\u0026#34;:\u0026#34;0x47b784\u0026#34;, \u0026#34;gasUsed\u0026#34;:\u0026#34;0x44218a\u0026#34;, \u0026#34;hash\u0026#34;:\u0026#34;0x4de91e4af8d135e061d50ddd6d0d6f4119cd0f7062ebe8ff2d79c5af0e8344b9\u0026#34;, \u0026#34;logsBloom\u0026#34;:\u0026#34;0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;miner\u0026#34;:\u0026#34;0x00d8ae40d9a06d0e7a2877b62e32eb959afbe16d\u0026#34;, \u0026#34;mixHash\u0026#34;:\u0026#34;0xb8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443\u0026#34;, \u0026#34;nonce\u0026#34;:\u0026#34;0xad14fb6803147c7c\u0026#34;, \u0026#34;number\u0026#34;:\u0026#34;0x2000f1\u0026#34;, \u0026#34;parentHash\u0026#34;:\u0026#34;0x31919e2bf29306778f50bbc376bd490a7d056ddfd5b1f615752e79f32c7f1a38\u0026#34;, \u0026#34;receiptsRoot\u0026#34;:\u0026#34;0xa2a7af5e3b9e1bbb6252ba82a09302321b8f0eea7ec8e3bb977401e4f473e672\u0026#34;, \u0026#34;sealFields\u0026#34;:[ \u0026#34;0xa0b8155224974967443d8b83e484402fb6e1e18ff69a8fc5acdda32f2bcc6dd443\u0026#34;, \u0026#34;0x88ad14fb6803147c7c\u0026#34; ], \u0026#34;sha3Uncles\u0026#34;:\u0026#34;0x1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347\u0026#34;, \u0026#34;size\u0026#34;:\u0026#34;0x276\u0026#34;, \u0026#34;stateRoot\u0026#34;:\u0026#34;0x87e7e54cf229003014f453d64f0344e2ba4fc7ee3b95c7dd2642cca389fa1efe\u0026#34;, \u0026#34;timestamp\u0026#34;:\u0026#34;0x5a10968a\u0026#34;, \u0026#34;totalDifficulty\u0026#34;:\u0026#34;0x1804de0c47ffe1\u0026#34;, \u0026#34;transactions\u0026#34;:[.","title":"Blockchain 数据结构分析"},{"content":"周末的时候，写了一个简单的小项目，用来抓取 web3 的文章，然后存到本地。最后选取了公司对外的轻服务：https://qingfuwu.cn/docs/nodejs/\n整项目用到了两个库\n axios：用来做 http 请求 cheerio：用来解析 html  观察目标网页的格式 我们以巴比特为例：https://www.8btc.com/web3.0，打开控制台，定位到正文的 div，可以发现是 article-list。\n右键复制一下 selector，然后在代码中这样实现就可以了。\n抓取网页信息 const cheerio = require(\u0026#39;cheerio\u0026#39;).default const axios = require(\u0026#39;axios\u0026#39;).default async function getData() { const data = await (await axios.get(\u0026#39;https://www.8btc.com/web3.0\u0026#39;, { headers: { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\u0026#39; } })).data const $ = cheerio.load(data) let list = [] $(\u0026#39;#news \u0026gt; div.articles-list\u0026#39;).find(\u0026#39;.article-info\u0026#39;).each( (item, elem) =\u0026gt; { const href = $(elem).find(\u0026#39;\u0026gt; a\u0026#39;).attr(\u0026#39;href\u0026#39;) const title = $(elem).find(\u0026#39;\u0026gt; a \u0026gt; h3\u0026#39;).text() const desc = $(elem).find(\u0026#39;\u0026gt; div \u0026gt; p\u0026#39;).text() list.push({ title, href: `https://www.8btc.com${href}`, desc }) } ) console.log(list) return list } 保存数据到轻服务的数据管理中 在轻服务中创建一个表，然后新增几列。\n然后调用内置的 inspirecloud.db 进行操作数据库，比如我的就是：\nasync function save(list) { const table = inspirecloud.db.table(\u0026#39;web3\u0026#39;) for (let item of list) { const one = await table.where({ title: item.title }).findOne() console.log(one) if (one != null) { console.log(`${item}已经存在`) continue } await table.save(item) } } 设置定时任务 最后我们把代码补充完整：\n/** * @param params 调用参数，HTTP 请求下为请求体 * @param context 调用上下文 * * @return 函数的返回数据，HTTP 场景下会作为 Response Body * * 完整信息可参考： * https://qingfuwu.cn/docs/cloud-function/basic.html */ const cheerio = require(\u0026#39;cheerio\u0026#39;).default const axios = require(\u0026#39;axios\u0026#39;).default async function getData() { const data = await (await axios.get(\u0026#39;https://www.8btc.com/web3.0\u0026#39;, { headers: { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\u0026#39; } })).data const $ = cheerio.load(data) let list = [] $(\u0026#39;#news \u0026gt; div.articles-list\u0026#39;).find(\u0026#39;.article-info\u0026#39;).each( (item, elem) =\u0026gt; { const href = $(elem).find(\u0026#39;\u0026gt; a\u0026#39;).attr(\u0026#39;href\u0026#39;) const title = $(elem).find(\u0026#39;\u0026gt; a \u0026gt; h3\u0026#39;).text() const desc = $(elem).find(\u0026#39;\u0026gt; div \u0026gt; p\u0026#39;).text() list.push({ title, href: `https://www.8btc.com${href}`, desc }) } ) console.log(list) return list } async function save(list) { const table = inspirecloud.db.table(\u0026#39;web3\u0026#39;) for (let item of list) { const one = await table.where({ title: item.title }).findOne() console.log(one) if (one != null) { console.log(`${item}已经存在`) continue } await table.save(item) } } module.exports = async function (params, context) { console.log(params); const data = await getData() await save(data) return { test: \u0026#34;Hello World!\u0026#34;, }; } 在左侧的定时任务中去创建一个定时任务，每天执行一次即可。\n","permalink":"https://zhenfeng-zhu.github.io/posts/how-to-crawl-a-web-in-nodejs/","summary":"周末的时候，写了一个简单的小项目，用来抓取 web3 的文章，然后存到本地。最后选取了公司对外的轻服务：https://qingfuwu.cn/docs/nodejs/\n整项目用到了两个库\n axios：用来做 http 请求 cheerio：用来解析 html  观察目标网页的格式 我们以巴比特为例：https://www.8btc.com/web3.0，打开控制台，定位到正文的 div，可以发现是 article-list。\n右键复制一下 selector，然后在代码中这样实现就可以了。\n抓取网页信息 const cheerio = require(\u0026#39;cheerio\u0026#39;).default const axios = require(\u0026#39;axios\u0026#39;).default async function getData() { const data = await (await axios.get(\u0026#39;https://www.8btc.com/web3.0\u0026#39;, { headers: { \u0026#39;User-Agent\u0026#39;: \u0026#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\u0026#39; } })).data const $ = cheerio.load(data) let list = [] $(\u0026#39;#news \u0026gt; div.articles-list\u0026#39;).find(\u0026#39;.article-info\u0026#39;).each( (item, elem) =\u0026gt; { const href = $(elem).","title":"轻服务 nodejs 助力爬虫 web3"},{"content":"This roadmap defines the things that we want to have in the language and plan to do.\nLanguage Stuff that has to do with the language syntax, semantic and runtime.\nConcurrency Finalize multithreading support, so fibers can run on multiple threads.\nWindows support Finalize support for Windows platform. The compiler already works, but some stdlib features like concurrency support are still missing. Ongoing efforts on #5430.\nType system review Make a review and possible formalisation of Crystal\u0026rsquo;s type system, with a strong emphasis on generics, type restrictions and the meta-model in general.\nMacros review Review the macros intermediate language, to allow for more expressiveness and to provide the compilers with hints with regards to reusing previous runs for incremental compilation.\nExceptions review Review the exception layout and hierarchy to allow developers to catch more specific errors, and get more information on what exactly went wrong via variables inside the exception.\nIncremental compilation Allow the compiler to re-use information from previous compilations, by defining dependencies between files/modules and only reprocessing changed ones. This feature also opens the door for better IDE integration and tooling.\nStandard library Implement the missing or review the existing following modules from the standard library:\n TLS library File, FileUtils HTTP/2 #2125 XML Test mocks  Tools Improvements or developments on either built-in or external tools for the language.\nDocumentation Improve not only the documentation itself, but the docs generator as well. Add support for links between documents from different packages, alternate READMEs for the docs, better searching options, and easier docs hosting options.\nShards Improve Crystal\u0026rsquo;s dependency manager for better dependencies version resolution, provide further metadata on the project, support registering executable tasks, better handling of transitive dependencies, and more. Implement centralised discovery of Crystal shards, sorted by category, and including support for the latest versions of the language, as reported by a CI.\nPlayground Improve Crystal\u0026rsquo;s playground by adding shards' workbooks to explore the usage of the project\u0026rsquo;s registered dependencies, and other features to discuss.\nIDE support Make use of Crystal\u0026rsquo;s compile-time type information to develop better IDE tools, such as in-place documentation, autocomplete or refactoring tools.\n","permalink":"https://zhenfeng-zhu.github.io/posts/crystal_roadmap/","summary":"This roadmap defines the things that we want to have in the language and plan to do.\nLanguage Stuff that has to do with the language syntax, semantic and runtime.\nConcurrency Finalize multithreading support, so fibers can run on multiple threads.\nWindows support Finalize support for Windows platform. The compiler already works, but some stdlib features like concurrency support are still missing. Ongoing efforts on #5430.\nType system review Make a review and possible formalisation of Crystal\u0026rsquo;s type system, with a strong emphasis on generics, type restrictions and the meta-model in general.","title":"Crystal Roadmap"},{"content":"Crystal 1.2.0 发布 我们正在发布一个包含多个错误修复和改进的新版本。下面我们列出了最重要或最有趣的变化，但没有提到几个错误修正。有关详细信息，请访问发行说明。重大更改标有 ⚠️。\n统计数据 在此版本中，我们包含了自 1.1.1 版本以来 32 位贡献者的 181 个 PR。我们感谢为改进语言及其标准库所做的所有努力！❤️\n平台支持 正如在 1.2 的上一篇博客文章中提到的，我们决定降低对 32 位 x86 架构的支持。但是我们确实有一些好消息要分享！\n我们在原生 Windows 支持方面取得了进展，在此版本中包括套接字实现（#11205、#11137、#10605、#10605）。\n与 Windows 相关，也与 ARM64 架构相关，我们修复了一个重要的代码生成错误。我们现在处于将 aarch64 平台提升到 Tier 1 的条件，预计很快就会支持。这也与带有 M1 芯片组的 macOS 相关：从这个版本开始，我们包含一个适用于 x86 和 M1 mac 的通用 macOS 包。\n我们发现 Windows 和 M1 的 mac 上出现的两个错误来自 LLVM 11 和 12。我们预计该修复将随最近发布的 LLVM 13 一起提供。Crystal 1.2.0 与 LLVM 12 兼容，尽管我们建议不要使用 LLVM 11 和 12.\n语言变化 现在可以将泛型类的子类分配给父类的实例：\nclass Foo(T); end class Bar(T) \u0026lt; Foo(T); end x = Foo x = Bar 也与泛型类有关，有些情况下编译器没有正确替换泛型参数（#11166、#11067。\n为支持 ThinLTO 汇编被丢弃，因为它并没有在 crystal 0.25 下可用。\n宏 可以在 for 循环中添加下划线来忽略值。例如，在以下代码中，map 的 key 被忽略：\n{% for _, v, i in {1 =\u0026gt; 2, 3 =\u0026gt; 4, 5 =\u0026gt; 6} %} p {{v + i}} {% end %} 此外，还有一个新的 file_exists?宏方法来检查文件的存在（#10540），#is_a?现在可以识别 AST 节点层次结构（#11062）。\n标准库 ⚠️ 我们正在延续 1.1.0 版本开始的趋势，帮助获得更好的错误信息和文档：对一些方法使用预期类型进行了注释。添加注释可能会在特定情况下破坏现有代码，因此，如果您遇到这种情况，请立即告诉我们。\n数值类型 数值类型的主要改进是支持 128 位整数（#11206 和#11245）所采取的步骤。\n作为微小的改进，现在可以调整 Int#to_s 输出的精度；通过新方法#next_float 和#prev_float 迭代可表示的浮点数集；对 BigDecimal 使用负指数；并计算一个数的整数平方根。\n集合 可变集合现在包含一个 Indexable::Mutable(T)模块，它极大地扩展了对某些集合（例如 BitArray 和 ）的操作集 Deque。以下现在有效：\nba = BitArray.new(10) # ba is BitArray[0000000000] ba[0] = true # ba is BitArray[1000000000] ba.rotate!(-1) # ba is BitArray[0100000000] 此外，Indexable::Mutable(T)扩展为包括稳定和不稳定的排序方法（#11254、#11029、#10163）。默认 sort 操作现在调用稳定算法。\n⚠️ 作为一项重大更改，Array#product 已弃用，取而代之的是新的泛型和更好命名的 Indexable#cartesian_product.\n另外两个值得一提的贡献：可枚举对象配备了将它们与给定谓词（Enumerable#tally_by）相匹配的方法；和方法 Array#transpose, Enumerable#reject, 和 Enumerable#to_h 现在使用元组。\n文件 ⚠️ 该方法 IO#write_utf8 已被弃用，取而代之的是更具描述性的 name IO#write_string，因为您可以使用它来编写各种编码的字符串，具体取决于 IO 的配置。我们还修复了一些与使用 IO#write 而不是 IO#write_string 将文本附加到 IO 相关的错误。\n网络 ⚠️ 为了提高 STDLIB 的安全性，URI.encode 被弃用 URI.encode_path 和 URI.encode_path_segment 。\n现在支持从 websockets ( #10854 ) 中的 URI 获取基本身份验证，并正确处理 cookie ( #10564 )的 max-age 和 expires 。\n文本 ⚠️String#unsafe_byte_at 已被弃用，因为 String 已经有一个#to_unsafe 方法。\nCrystal 现在支持 Unicode 14.0.0。\n序列化 有一种新方法 XML::Node#namespace_definition 可以获取节点的明确定义的 XML 命名空间，URI 现在可以将 URI 序列化为 JSON 和 YAML。\n工具：新的文档生成器 API 文档现在使用 markd 来呈现 Markdown ( #11040 )。这就解决了内部渲染器实现带来的缺点。\n基础设施 现在可以 make install 了。\n","permalink":"https://zhenfeng-zhu.github.io/posts/crystal1.2/","summary":"Crystal 1.2.0 发布 我们正在发布一个包含多个错误修复和改进的新版本。下面我们列出了最重要或最有趣的变化，但没有提到几个错误修正。有关详细信息，请访问发行说明。重大更改标有 ⚠️。\n统计数据 在此版本中，我们包含了自 1.1.1 版本以来 32 位贡献者的 181 个 PR。我们感谢为改进语言及其标准库所做的所有努力！❤️\n平台支持 正如在 1.2 的上一篇博客文章中提到的，我们决定降低对 32 位 x86 架构的支持。但是我们确实有一些好消息要分享！\n我们在原生 Windows 支持方面取得了进展，在此版本中包括套接字实现（#11205、#11137、#10605、#10605）。\n与 Windows 相关，也与 ARM64 架构相关，我们修复了一个重要的代码生成错误。我们现在处于将 aarch64 平台提升到 Tier 1 的条件，预计很快就会支持。这也与带有 M1 芯片组的 macOS 相关：从这个版本开始，我们包含一个适用于 x86 和 M1 mac 的通用 macOS 包。\n我们发现 Windows 和 M1 的 mac 上出现的两个错误来自 LLVM 11 和 12。我们预计该修复将随最近发布的 LLVM 13 一起提供。Crystal 1.2.0 与 LLVM 12 兼容，尽管我们建议不要使用 LLVM 11 和 12.\n语言变化 现在可以将泛型类的子类分配给父类的实例：","title":"Crystal 1.2 版本更新说明"},{"content":"可观测性 可观测性 ≠ 监控   核心不同\n 监控以运维为核心，通过各项指标来定义整体的运行状态、失败情况。 观测则以开发为核心，除了监控，它还会对系统进行分析。    维度不同\n 监控是从外围的角度，通过各种指标（机器 CPU、负载、网络等维度）来判断整个系统的执行情况。 可观测性则在上述外部指标基础上，以应用内的各个维度来展开推测，通过二者的数据结合来真实的反应应用的运行情况。    展现的信息不同\n 有些系统在正常运行时十分稳定，但是一到高并发就会出现问题，此时监控只能汇报问题出现的状况，而可观测性可以很好的通过图形化的方式告知我们问题的原因，不用我们通过经验来猜测。    可观测性打破了开发和运维的原有问题解决方式，不再是运维发现问题开发解决，而是以开发为中心。\n监控数据来源   端上访问\n 用户体验监控  web 页面的白屏时间 dom 元素/资源加载耗时 文档网络耗时 app 卡顿率 崩溃率 热启动加载时长   日志 端到端  用户端到后端的请求状况，访问量、成功率、响应时间等。 还需要端上所处的地区、网络环境、响应状态码   可用率  访问是否可用、响应耗时长短的一些指标和 cdn、dns 等公共资源有关系。      应用程序\n 执行情况 资源消耗 vm 指标监控 容量 服务关系 应用日志 健康情况    业务监控\n 业务指标能很好的体现出系统是否稳定，任何系统如果出现了问题，最先受影响的肯定是业务指标。    基础设施\n 资源利用  这个很好理解，像 IO 使用率、cpu 利用率、内存使用率、磁盘使用率、网络使用率等。   通信情况  主机之间的网络情况。      可观测性的核心概念 - 日志（Logging） 日志的一般描述是：在特定时间发生的事件，被以结构化的形式记录并产生的文本数据。\n 日志的功能   便于调试 快速定位问题 高度定制化 信息埋点 追踪数据变化 数据分析  日志级别   debug info warning error  日志常见来源   终端 网关  访问日志：当服务到达网关之后，就会形成一条日志。 错误日志：网关执行时出了问题   应用层  容器启动日志 请求访问日志 普通日志   组件层  mysql 和 redis 等 应用运行时的日志 慢查询 审计   基础层  偏向运维的日志 系统日志和 linux 操作日志等    如何写好日志  寻找编写位置 =\u0026gt; 编写日志 =\u0026gt; 上线 =\u0026gt; 日志 review =\u0026gt; 定期修改\n  选择一个常用的日志框架\n  编写方式从如下几个方面考虑\n 日志开发时  日志编写位置 写入性能 占位符 可读性 关键信息隐蔽   开发完成后  减少代码位置信息的输出 文件分类 日志 review      编写位置\n  几个比较重要的编写日志的位置：\n 系统/应用启动和参数变更：当系统启动时，将相关的参数信息进行打印 关键操作节点 大型任务进度上报：防止因为长时间没有处理而无法得知程序的执行状态 异常   写入性能  日志的写入性能受如下几个因素影响：\n 日志编写位置，如果是在 for 循环中打印，需要考虑一下是否有必要 日志数量：大量的写日志质量会降低，而且过多日志也会影响程序的执行效率 日志编写等级：不正确的等级，会让我们查问题时间增加 日志的输出级别：线上不建议 debug 模式。 无用输出参数：大字段、无用字段可以不用输出  好的日志一定是便于你去排查问题的，在编写日志的时候一定要思考这个日志可以帮你做什么。\n 占位符  日志的编写尽可能的选择基于占位符的编写方式：\n 节约性能，在生成高级别的日志时，低级别的日志会不停的叠加字符串而占用过多的内存和 CPU。 便于编写。先确定日志所要表达的内容，再确认所需要编写的参数，这样写日志的时候目的会更加明确。 便于查看。更方便的查看日志想表达的意思，而不被参数打乱。   可读性  一些容易遗漏的信息，之后要加上：\n 会话标识：当前操作的用户和当前请求相关的信息 请求标识：每个请求都有一个唯一标识，一般会配合链路追踪系统使用，这样可以跨服务追踪 参数信息 发生数据的结果   关键信息隐蔽  把一些关键的信息模糊掉\n 减少代码位置信息的输出  提升效率\n 文件分类  把不同业务逻辑按不同的文件来分类，不会被干扰\n 日志 review  每一次功能上线时，出了对功能进行回扫，也要确认日志的内容输出情况是不是符合预期\n  日志管理\n  日志格式\n   系统之间的格式应该保持一致 不编写多行日志内容 不适用日志中的常见内容来分割，比如空格等。   日志归档  一般情况下都是按小时或者日期来归档，每天生成一个日志文件，方便管理和查看\n- 度量（Metrics） 统计指标也是我们经常使用的。它是一种可累加的聚合的数值结果，具有原子性。因此，我们可以通过各种数学计算方式来获取一段时间内的数值。\n- 追踪（Tracing） 链路追踪是将链路的完整行为信息进行记录，然后通过可视化的形式展现出来\n我们一般将数据的来源分为 2 个级别：\n 请求级别：数据来源于真实的请求，比如一次 http 调用、rpc 调用等 聚合级别：真实的请求指标，或是系统的一些参数数据聚合，比如 qps、cpu 使用率  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/","summary":"可观测性 可观测性 ≠ 监控   核心不同\n 监控以运维为核心，通过各项指标来定义整体的运行状态、失败情况。 观测则以开发为核心，除了监控，它还会对系统进行分析。    维度不同\n 监控是从外围的角度，通过各种指标（机器 CPU、负载、网络等维度）来判断整个系统的执行情况。 可观测性则在上述外部指标基础上，以应用内的各个维度来展开推测，通过二者的数据结合来真实的反应应用的运行情况。    展现的信息不同\n 有些系统在正常运行时十分稳定，但是一到高并发就会出现问题，此时监控只能汇报问题出现的状况，而可观测性可以很好的通过图形化的方式告知我们问题的原因，不用我们通过经验来猜测。    可观测性打破了开发和运维的原有问题解决方式，不再是运维发现问题开发解决，而是以开发为中心。\n监控数据来源   端上访问\n 用户体验监控  web 页面的白屏时间 dom 元素/资源加载耗时 文档网络耗时 app 卡顿率 崩溃率 热启动加载时长   日志 端到端  用户端到后端的请求状况，访问量、成功率、响应时间等。 还需要端上所处的地区、网络环境、响应状态码   可用率  访问是否可用、响应耗时长短的一些指标和 cdn、dns 等公共资源有关系。      应用程序\n 执行情况 资源消耗 vm 指标监控 容量 服务关系 应用日志 健康情况    业务监控","title":"如何理解可观测性"},{"content":"我们常见的静态网站生成器有 Hugo、Hexo 等，程序员们经常会使用类似的工具去将自己的播客托管到 github pages。前段时间研究了一下实现的方式，用 Elixir 简单实现了一个版本。\n一个静态网站生成器的工作流程通常有如下几个步骤：\n 读取源文件，一般是 markdown 格式的。 模板引擎的渲染 生成目标文件  接下来会从每个步骤来进行简单介绍。\n最终版本的请参考：https://github.com/zhenfeng-zhu/ego， 欢迎 pr 和 issue。\n极简 MVP 版本介绍 初始化 mix new ego 在 mix.exs 中添加依赖\n earmark 是将 markdown 转换为 html。 plug_cowboy 是提供本地预览 html 文件的 server。 json 是一个 json 解析库 指定以 escript 的方式启动  解析 markdown 文件 将一个 markdown 文件转为 html 也是比较简单的，首先读取，然后调用 Earmark.as_html!函数，就能将 markdown 转换为 html 了。\neg.\ndef gen_blogs(m) do m |\u0026gt; File.read!() |\u0026gt; Earmark.as_html!() end 更进一步的我们认为 markdown 的博客源文件都在当前项目目录下面，即{current_dir()}/contents/。如果要获取到所有的文件，可以使用 wildcard 函数。\ndef blog_files do Path.wildcard(\u0026#34;#{current_dir()}/contents/*.md\u0026#34;) end 因此就可以批量对目录下的所有 markdown 文件进行转换。\neg.\nblog_files() |\u0026gt; Enum.each(fn m -\u0026gt; gen_blogs(m) end) 模板引擎渲染 既然用了 elixir，那就得使用 eex 来进行渲染了。\n我们写一个最简单的 eex 模板文件，eg\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;article class=\u0026#34;markdown-body\u0026#34;\u0026gt;\u0026lt;%= @content %\u0026gt;\u0026lt;/article\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 上述的模板文件中，content 是 markdown 生成的 html。\n渲染 eex 也是很简单，eg\ndef blog_layout do \u0026#34;#{current_dir()}/layouts/blog.eex\u0026#34; end def eval_blog(m) do title = get_title(m) EEx.eval_file(blog_layout(), assigns: [content: m] ) end 生成目标文件 需要将上述的文件生成到文件系统中，我们先生成到 public 目录下面。\nElixir 的写入函数也是特别好用，只需要把 string 写入到目标文件即可，eg\ndef write_to(d, m) do title = get_title(m) File.write!(\u0026#34;#{static_dir()}/#{title}.html\u0026#34;, d) end 一些优化 生成目录文件 生成 index 目录文件和生成 blog 的流程类似，我们需要解析每个 markdown 的文件名，然后填充到 index 的 layout 中即可。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div\u0026gt; \u0026lt;article class=\u0026#34;markdown-body\u0026#34;\u0026gt; \u0026lt;%= for item \u0026lt;- @list do %\u0026gt; \u0026lt;p\u0026gt; \u0026lt;a href=\u0026#34;\u0026lt;%= item[:href] %\u0026gt;\u0026#34;\u0026gt; \u0026lt;%= item[:title] %\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt; \u0026lt;% end %\u0026gt; \u0026lt;/article\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; s 注意在生成目录的时候，一定要指定目标博客的地址，因此要对目录加一个\u0026lt;a href\u0026gt; \u0026lt;/a\u0026gt;的标签。\ndef gen_index(blogs) do blogs |\u0026gt; Enum.map(fn m -\u0026gt; m |\u0026gt; get_title() |\u0026gt; build_title_with_href() end) |\u0026gt; eval_index() |\u0026gt; write_to(\u0026#34;index\u0026#34;) end def build_title_with_href(title) do %{:title =\u0026gt; title, :href =\u0026gt; get_href(title)} end def get_href(title) do \u0026#34;#{EgoConfig.domain()}/#{title}.html\u0026#34; end def eval_index(titles) do EEx.eval_file(index_layout(), assigns: [t: \u0026#34;zzf-blog\u0026#34;, list: titles] ) end 加速构建 上面的构建流程有一点小小的问题，就是每个文件的生成都是串行的，我们可以加速一下。\nTask.start_link(fn -\u0026gt; blog_files() |\u0026gt; gen_index() end) blog_files() |\u0026gt; Enum.map(fn m -\u0026gt; Task.async(fn -\u0026gt; gen_blogs(m) end) end) |\u0026gt; Task.await_many() |\u0026gt; IO.inspect() 让生成 index 的时候在后台执行，同时生成 blog 的时候，开启 async 模式，并 await 一下。\n本地预览 简单使用 plug 来做本地预览\ndefmodule MyPlug do use Plug.Router import Plug.Conn plug(:match) plug(:dispatch) get \u0026#34;/\u0026#34; do conn |\u0026gt; put_resp_content_type(\u0026#34;text/html\u0026#34;) |\u0026gt; send_file(200, \u0026#34;public/index.html\u0026#34;) end get \u0026#34;/:file\u0026#34; do conn |\u0026gt; put_resp_content_type(\u0026#34;text/html\u0026#34;) |\u0026gt; send_file(200, \u0026#34;public/#{file}\u0026#34;) end get \u0026#34;favicon.ico\u0026#34; do send_resp(conn, 404, \u0026#34;not found\u0026#34;) end match _ do send_resp(conn, 404, \u0026#34;not found\u0026#34;) end end 通过访问域名，可以进到 index 文件，当点击目录的时候，就访问目标博客文件。\n美化  添加代码高亮，  在 head 中引入 highlight.js 即可。\neg.\n\u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/styles/default.min.css\u0026#34; /\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/highlight.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; hljs.highlightAll(); \u0026lt;/script\u0026gt; 居中展示  在 layout 文件中加上如下 css 样式即可。\n\u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34; /\u0026gt; \u0026lt;style\u0026gt; .markdown-body { box-sizing: border-box; min-width: 200px; max-width: 980px; margin: 0 auto; padding: 45px; } @media (max-width: 767px) { .markdown-body { padding: 15px; } } \u0026lt;/style\u0026gt; 构建可执行文件 通过 escript 来生成可执行文件\n参考 https://elixirschool.com/zh-hans/lessons/advanced/escripts/\n丰富命令行 defp parse_args(args) do case hd(args) do \u0026#34;server\u0026#34; -\u0026gt; start_server() \u0026#34;build\u0026#34; -\u0026gt; Mark.convert() \u0026#34;new\u0026#34; -\u0026gt; gen_template(args) end end ego server 启动本地预览模式\nego build 就将本地的博客生成 html 文件\nego new site xxx 生成静态站点\n更多 elixir 写起来很丝滑，一个最终版本的请参考：https://github.com/zhenfeng-zhu/ego，欢迎 pr 和 issue。\n另外也给 elixir-ls 提了一个 pr，大家快去 conversation 呀，尽快让 merge 了：https://github.com/elixir-lsp/elixir-ls/pull/574\n","permalink":"https://zhenfeng-zhu.github.io/posts/how-to-write-a-static-site-generator/","summary":"我们常见的静态网站生成器有 Hugo、Hexo 等，程序员们经常会使用类似的工具去将自己的播客托管到 github pages。前段时间研究了一下实现的方式，用 Elixir 简单实现了一个版本。\n一个静态网站生成器的工作流程通常有如下几个步骤：\n 读取源文件，一般是 markdown 格式的。 模板引擎的渲染 生成目标文件  接下来会从每个步骤来进行简单介绍。\n最终版本的请参考：https://github.com/zhenfeng-zhu/ego， 欢迎 pr 和 issue。\n极简 MVP 版本介绍 初始化 mix new ego 在 mix.exs 中添加依赖\n earmark 是将 markdown 转换为 html。 plug_cowboy 是提供本地预览 html 文件的 server。 json 是一个 json 解析库 指定以 escript 的方式启动  解析 markdown 文件 将一个 markdown 文件转为 html 也是比较简单的，首先读取，然后调用 Earmark.as_html!函数，就能将 markdown 转换为 html 了。\neg.\ndef gen_blogs(m) do m |\u0026gt; File.read!() |\u0026gt; Earmark.","title":"如何从零开始写一个静态网站生成器"},{"content":"实验室 2\u0026ndash;测试东西 在开始这个实验之前，创建一个新的文件夹。\n$ mkdir -p lab2 \\  \u0026amp;\u0026amp; cd lab2 使用 UI 门户 现在你可以测试一下 OpenFaaS 的用户界面了。\n如果你已经设置了一个$OPENFAAS_URL，那么就可以得到这个 URL，然后点击它。\necho $OPENFAAS_URL http://127.0.0.1:31112 如果你没有设置\u0026quot;$OPENFAAS_URL\u0026quot;，那么默认情况下是这样的。http://127.0.0.1:8080.\n我们可以部署一些样本函数，然后用它们来测试一下。\nfaas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 你可以在用户界面中试用它们，比如将 Markdown 代码转换为 HTML 的 Markdown 函数。\n在Request字段中键入以下内容。\n## The **OpenFaaS** _workshop_ 现在点击Invoke，看到响应出现在屏幕的下半部分。\n即。\n\u0026lt;h2\u0026gt;The \u0026lt;strong\u0026gt;OpenFaaS\u0026lt;/strong\u0026gt; \u0026lt;em\u0026gt;workshop\u0026lt;/em\u0026gt;\u0026lt;/h2\u0026gt; 你将看到以下字段显示。\n 状态 - 该函数是否准备好运行。在状态显示准备好之前，你将不能从用户界面调用该函数。 Replicas - 在集群中运行的函数的副本数量 镜像 - 发布在 Docker Hub 或 Docker 资源库中的 Docker 图像名称和版本 调用次数 - 这显示了该函数被调用的次数，每 5 秒更新一次  点击Invoke若干次，看到Invocation count的增加。\n通过函数库进行部署 你可以从 OpenFaaS 商店中部署一个函数。该商店是一个由社区维护的免费函数集合。\n点击 部署新的函数 点击 from store\n 点击 Figlet 或在搜索栏中输入 figlet ，然后点击 Deploy 。  Figlet 函数现在将出现在你左边的函数列表中。给它一点时间从 Docker Hub 下载，然后输入一些文本，像我们对 Markdown 函数所做的那样，点击 Invoke。\n你会看到一个 ASCII 码的标志，像这样生成。\n_ ___ ___ _ __ / |/ _ \\ / _ (_)/ / | | | | | | | |/ / | | |_| | |_| / /_ |_|\\___/ \\___/_/(_) 了解 CLI 的情况 你现在可以测试一下 CLI 了，但首先要注意一下备用网关的 URL。\n如果你的网关没有部署在http://127.0.0.1:8080，那么你将需要指定替代位置。有几种方法来实现这一点。\n 设置环境变量OPENFAAS_URL，faas-cli将指向当前 shell 会话中的那个端点。例如：export OPENFAAS_URL http://openfaas.endpoint.com:8080。如果你是按照 Kubernetes 的指示，这已经在Lab 1中设置好了。 用 g或--gateway标志在线指定正确的端点： faas deploy --gateway http://openfaas.endpoint.com:8080。 在你的部署 YAML 文件中，改变gateway:对象在provider:下指定的值。  列出已部署的函数 这将显示这些函数，你有多少个副本和调用次数。\nfaas-cli list 你应该看到markdown函数是 markdown，figlet函数也被列出来了，还有你调用了多少次。\n现在试试使用 verbose 标志\nfaas-cli list --verbose 或\nfaas-cli list -v 现在你可以看到 Docker 镜像以及函数的名称。\n调用一个函数 从你在faas-cli list上看到的函数中挑选一个，比如markdown。\nfaas-cli invoke markdown 现在你会被要求输入一些文本。完成后点击 Control + D。\n或者你可以使用一个命令，如echo或curl作为invoke命令的输入，该命令通过使用管道工作。\n$ echo \u0026#34;# Hi\u0026#34; | faas-cli invoke markdown $ curl -sLS https://raw.githubusercontent.com/openfaas/faas/master/README.md\\。 | faas-cli invoke markdown 监测仪表板 OpenFaaS 使用 Prometheus 自动跟踪你的函数的指标。这些指标可以通过免费的开源工具变成一个有用的仪表盘，比如Grafana。\n在 OpenFaaS Kubernetes 命名空间运行 Grafana。\nkubectl -n openfaas run \\ --image=stefanprodan/faas-grafana:4.6.3 \\ --port=3000 \\ grafana 用 NodePort 暴露 Grafana。\nkubectl -n openfaas expose pod grafana \\ --type=NodePort \\ --name=grafana 找到 Grafana 节点的端口地址。\nGRAFANA_PORT=$(kubectl -n openfaas get svc grafana -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34;) GRAFANA_URL=http://IP_ADDRESS:$GRAFANA_PORT/dashboard/db/openfaas 其中IP_ADDRESS是你在 Kubernetes 的对应 IP。\n或者你可以运行这个端口转发命令，以便能够在http://127.0.0.1:3000上访问 Grafana。\nkubectl port-forward pod/grafana 3000:3000 -n openfaas 如果你使用的是 Kubernetes 1.17 或更早的版本，请使用deploy/grafana而不是上面命令中的pod/。\n服务创建后，在浏览器中打开 Grafana，用用户名admin密码admin登录，并导航到预先制作的 OpenFaaS 仪表板$GRAFANA_URL。\n图：使用 Grafana 的 OpenFaaS 仪表板的例子。\n现在转到实验室 3\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab2/","summary":"实验室 2\u0026ndash;测试东西 在开始这个实验之前，创建一个新的文件夹。\n$ mkdir -p lab2 \\  \u0026amp;\u0026amp; cd lab2 使用 UI 门户 现在你可以测试一下 OpenFaaS 的用户界面了。\n如果你已经设置了一个$OPENFAAS_URL，那么就可以得到这个 URL，然后点击它。\necho $OPENFAAS_URL http://127.0.0.1:31112 如果你没有设置\u0026quot;$OPENFAAS_URL\u0026quot;，那么默认情况下是这样的。http://127.0.0.1:8080.\n我们可以部署一些样本函数，然后用它们来测试一下。\nfaas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 你可以在用户界面中试用它们，比如将 Markdown 代码转换为 HTML 的 Markdown 函数。\n在Request字段中键入以下内容。\n## The **OpenFaaS** _workshop_ 现在点击Invoke，看到响应出现在屏幕的下半部分。\n即。\n\u0026lt;h2\u0026gt;The \u0026lt;strong\u0026gt;OpenFaaS\u0026lt;/strong\u0026gt; \u0026lt;em\u0026gt;workshop\u0026lt;/em\u0026gt;\u0026lt;/h2\u0026gt; 你将看到以下字段显示。\n 状态 - 该函数是否准备好运行。在状态显示准备好之前，你将不能从用户界面调用该函数。 Replicas - 在集群中运行的函数的副本数量 镜像 - 发布在 Docker Hub 或 Docker 资源库中的 Docker 图像名称和版本 调用次数 - 这显示了该函数被调用的次数，每 5 秒更新一次  点击Invoke若干次，看到Invocation count的增加。","title":"Openfaas Workshop Lab2"},{"content":"Lab 1 - 用 Kubernetes 设置 OpenFaaS 安装最新的 kubectl 使用下面的说明或官方文档为你的操作系统安装kubectl。\n Linux  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  MacOS  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/darwin/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  Windows  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/windows/amd64/kubectl.exe chmod +x kubectl.exe mkdir -p $HOME/bin/ mv kubectl $HOME/bin/ 设置一个 Kubernetes 集群 你可以在使用 Kubernetes 的同时按照实验进行操作，但你可能需要沿途做一些小改动。网关的服务地址从http://gateway:8080改为http://gateway.openfaas:8080。这些差异已经尽可能地被记录下来，每个实验室都提供了替代方案。\n在你的笔记本电脑上创建一个本地集群 k3s 使用 k3d 如果你的电脑上有 Docker，那么你可以使用 Rancher 实验室托管的k3d工具。它安装了一个轻量级的 Kubernetes 版本，叫做k3s，并在 Docker 容器中运行，这意味着它可以在任何有 Docker 的电脑上运行。\n  安装 k3d\n  启动一个集群\n   k3d cluster create CLUSTER_NAME创建一个新的单节点集群（=1 个运行 k3s 的容器+1 个负载均衡器容器） 2.kubectl 的上下文会自动更新，你可以用kubectl config get-contexts来检查。 执行一些命令，如kubectl get pods --all-namespaces。 如果你想删除默认集群k3d cluster delete CLUSTER_NAME。  Docker for Mac  安装 Docker for Mac   请注意，Kubernetes 仅在 Docker for Mac 17.12 CE 及以上版本中可用。\n 使用 Minikube   要安装 Minikube，请根据你的平台从最新版本下载适当的安装程序。\n  现在运行 Minikube\n  minikube start minikube 虚拟机通过一个仅限主机的 IP 地址暴露给主机系统。用minikube ip检查这个 IP。 这是你以后将用于网关 URL 的 IP。\n 注意：Minikube 还需要一个 Hypervisor，如 VirtualBox 或 Hyperkit（在 MacOS 上）。按照 minikube 的说明和文件\n 在云上创建一个远程集群 你可以在云端创建一个远程集群，享受与本地开发一样的体验，同时节省 RAM/CPU 和电池。运行一个集群 1-2 天的费用是最低的。\n在 DigitalOcean 的 Kubernetes 服务上运行 你可以使用免费点数通过 DigitalOcean 的用户界面创建一个集群。\n然后 DigitalOcean 的仪表板将指导你如何配置你的kubectl和KUBECONFIG文件，以便在实验室中使用。\n 申请你的免费点数\u0026ndash;30 天内有 50 美元的点数。  即使你已经申请了免费学分，一个 2-3 个节点的集群 24-48 小时的运行费用也是可以忽略不计的。\n点击仪表板左侧面板上的 Kubernetes，然后点击 启用有限访问\n一旦登录，点击 Kubernetes菜单项并创建一个集群。\n建议使用最新的 Kubernetes 版本，并选择离你最近的数据中心区域，以尽量减少延时。\n 在 添加节点池下  使用 2 个 4GB / 2vCPU\n 注意：如果需要，你可以在以后添加更多的容量\n   下载doctlCLI 并把它放在你的路径中。\n  在您的 DigitalOcean 仪表板上创建一个API 密钥\n  追踪您的 API 密钥（将其复制到剪贴板）。\n 认证 CLI  doctl auth init 粘贴你的 API 密钥\n 现在获得集群的名称。  $ doctl k8s cluster list GUID workshop-lon1 nyc1 1.13.5-do.1 provisioning workshop-lon1-1  保存一个配置文件，使kubectl指向新集群。  doctl k8s cluster kubeconfig save workshop-lon1 现在你需要切换你的 Kubernetes 上下文以指向新的集群。\n用kubectl config get-contexts找到集群名称，如果它没有突出显示，则输入kubectl config set-context \u0026lt;context-name\u0026gt;。\n在 GKE（谷歌 Kubernetes 引擎）上运行 登录到谷歌云，创建一个项目，并为其启用计费。如果你没有账户，你可以在这里注册，获得免费点数。\n安装Google Cloud SDK - 这将使gcloud和kubectl命令可用。 对于 Windows，请按照文档中的说明。\n安装 gcloud 命令行工具后，用gcloud init配置你的项目，并设置默认项目、计算区域和区域（用你自己的项目替换PROJECT_ID）。\ngcloud config set project PROJECT_ID gcloud config set compute/region us-central1 gcloud config set compute/zone us-central1-a 启用 Kubernetes 服务。\ngcloud services enable container.googleapis.com 安装 kubectl。\ngcloud components install kubectl 创建一个 Kubernetes 集群。\n$ gcloud container clusters create openfaas \\ --zone=us-central1-a \\ --num-nodes=1 \\ --machine-type=n1-standard-2 \\ --disk-size=30 \\ --no-enable-cloud-logging 为 kubectl设置凭证。\ngcloud container clusters get-credentials openfaas 创建一个集群管理员角色绑定:\n$ kubectl create clusterrolebinding \u0026#34;cluster-admin-$(whoami)\u0026#34; \\ --clusterrole=cluster-admin \\ --user=\u0026#34;$(gcloud config get-value core/account)\u0026#34; 现在验证kubectl已经配置到 GKE 集群。\n$ kubectl get nodes NAME STATUS ROLES AGE VERSION gke-name-default-pool-eceef152-qjmt Ready \u0026lt;none\u0026gt; 1h v1.10.7-gke.2 部署 OpenFaaS 部署 OpenFaaS 的说明会时常改变，因为我们努力使其更加简单。\n安装 OpenFaaS 有三种方式来安装 OpenFaaS，你可以选择对你和你的团队有意义的方式。在这个研讨会上，我们将使用官方的安装程序arkade。\n  arkade应用安装 - arkade 使用其官方舵手图安装 OpenFaaS。它还可以通过用户友好的 CLI 提供其他软件，如cert-manager和nginx-ingress。这是最简单和最快速的方式来启动和运行。\n  舵手图 - 理智的默认值，易于通过 YAML 或 CLI 标志进行配置。安全选项，如 Helm 模板或 Helm 3，也适用于那些在限制性环境中工作的人。\n  普通 YAML 文件 - 硬编码的设置/值。像 Kustomize 这样的工具可以提供自定义设置\n  用arkade安装  获取 arkade  对于 MacOS / Linux:\n# MacOS users may need to run \u0026#34;bash\u0026#34; first if this command fails curl -SLsf https://dl.get-arkade.dev/ | sudo sh 对于 Windows。\ncurl -SLsf https://dl.get-arkade.dev/ | sh  安装 OpenFaaS 应用程序  如果你使用的是提供 LoadBalancers 的管理云 Kubernetes 服务，那么运行以下内容。\narkade install openfaas --load-balancer  注意：--load-balancer标志的默认值是false，所以通过该标志，安装将向你的云提供商请求一个。\n 如果你使用的是本地 Kubernetes 集群或虚拟机，那么请运行。\narkade install openfaas 在后面的实验室中，我们将向你展示如何使用 Kubernetes Ingress 设置一个带有 TLS 的自定义域。\n或者用 helm 安装（高级） 如果你愿意，你可以使用helm chart的说明来安装 OpenFaaS。\n登录你的 OpenFaaS 网关  检查网关是否准备好了  kubectl rollout status -n openfaas deploy/gateway 如果你使用你的笔记本电脑，虚拟机，或任何其他类型的 Kubernetes 分布，请运行以下内容。\nkubectl port-forward svc/gateway -n openfaas 8080:8080 这个命令将打开一个从 Kubernetes 集群到本地计算机的隧道，这样你就可以访问 OpenFaaS 网关。还有其他方法可以访问 OpenFaaS，但这已经超出了本次研讨会的范围。\n你的网关 URL 是。http://127.0.0.1:8080\n如果你使用的是管理云 Kubernetes 服务，那么从下面的命令中的EXTERNAL-IP字段中获取 LoadBalancer 的 IP 地址或 DNS 条目。\nkubectl get svc -o wide gateway-external -n openfaas 你的 URL 将是上面的 IP 或 DNS 条目，端口为8080。\n 登录。  export OPENFAAS_URL=\u0026#34;\u0026#34; # Populate as above # This command retrieves your password PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath=\u0026#34;{.data.basic-auth-password}\u0026#34; | base64 --decode; echo) # This command logs in and saves a file to ~/.openfaas/config.yml echo -n $PASSWORD | faas-cli login --username admin --password-stdin  检查faas-cli list是否工作。  faas-cli list 永久保存你的 OpenFaaS URL 编辑~/.bashrc或~/.bash_profile\u0026ndash;如果该文件不存在，则创建它。\n现在添加以下内容\u0026ndash;按照你上面看到的 URL 进行修改。\nexport OPENFAAS_URL=\u0026#34;\u0026#34; # populate as above 现在转到实验室 2\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1b/","summary":"Lab 1 - 用 Kubernetes 设置 OpenFaaS 安装最新的 kubectl 使用下面的说明或官方文档为你的操作系统安装kubectl。\n Linux  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/linux/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  MacOS  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/darwin/amd64/kubectl chmod +x kubectl mv kubectl /usr/local/bin/  Windows  export VER=$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt) curl -LO https://storage.googleapis.com/kubernetes-release/release/$VER/bin/windows/amd64/kubectl.exe chmod +x kubectl.exe mkdir -p $HOME/bin/ mv kubectl $HOME/bin/ 设置一个 Kubernetes 集群 你可以在使用 Kubernetes 的同时按照实验进行操作，但你可能需要沿途做一些小改动。网关的服务地址从http://gateway:8080改为http://gateway.openfaas:8080。这些差异已经尽可能地被记录下来，每个实验室都提供了替代方案。\n在你的笔记本电脑上创建一个本地集群 k3s 使用 k3d 如果你的电脑上有 Docker，那么你可以使用 Rancher 实验室托管的k3d工具。它安装了一个轻量级的 Kubernetes 版本，叫做k3s，并在 Docker 容器中运行，这意味着它可以在任何有 Docker 的电脑上运行。","title":"Openfaas Workshop Lab1b"},{"content":"Lab 1 - 为 OpenFaaS 做准备 OpenFaaS 需要一个Kubernetes集群来运行。你可以使用一个单节点集群或多节点集群，不管是在你的笔记本电脑上还是在云端。\n任何 OpenFaaS 函数的基本原件都是一个 Docker 镜像，它是使用faas-cli工具链构建的。\n前提条件 让我们来安装 Docker、OpenFaaS CLI 以及设置 Kubernetes。\nDocker 适用于 Mac\n Docker CE for Mac Edge Edition  适用于 Windows\n 仅使用 Windows 10 Pro 或企业版 安装Docker CE for Windows   请确保通过使用 Windows 任务栏通知区的 Docker 菜单来使用Linux容器的 Docker 守护程序。\n  安装Git Bash  当你安装 git bash 时，选择以下选项。install UNIX commands和use true-type font。\n 注意：请在所有步骤中使用Git Bash：不要试图使用PowerShell、WSL或Bash for Windows。\n Linux - Ubuntu 或 Debian\n Docker CE for Linux   你可以从[Docker Store]（https://store.docker.com）安装 Docker CE。\n 注意：作为最后的手段，如果你有一台不兼容的 PC，你可以在https://labs.play-with-docker.com/上面体验。\nOpenFaaS CLI 你可以使用官方的 bash 脚本来安装 OpenFaaS CLI，brew也可以使用，但可能会落后一到两个版本。\n在 MacOS 或 Linux 下，在终端运行以下程序。\n# MacOS users may need to run \u0026#34;bash\u0026#34; first if this command fails $ curl -sLSf https://cli.openfaas.com | sudo sh 对于 Windows，在Git Bash中运行这个。\ncurl -sLSf https://cli.openfaas.com | sh  如果你遇到任何问题，你可以从releases page手动下载最新的faas-cli.exe。你可以把它放在本地目录或C:\\Windows\\路径中，这样它就可以从命令提示符中获得。\n 我们将使用faas-cli来搭建新的函数，构建、部署和调用函数。你可以通过faas-cli --help找到 cli 的可用命令。\n测试 faas-cli。打开一个终端或 Git Bash 窗口，键入\nfaas-cli help faas-cli version 配置 Docker Hub 注册一个 Docker Hub 账户。Docker Hub允许你在互联网上发布你的 Docker 镜像，以便在多节点集群上使用或与更广泛的社区分享。我们将在研讨会期间使用 Docker Hub 来发布我们的函数。\n你可以在这里注册。Docker Hub\n打开一个终端或 Git Bash 窗口，用你上面注册的用户名登录 Docker Hub。\ndocker login  注意：来自社区的提示\u0026ndash;如果你在 Windows 机器上试图运行这个命令时遇到错误，那么点击任务栏中的 Docker for Windows 图标，在那里登录 Docker，而不是 登录/创建 Docker ID。\n  为新镜像设置你的 OpenFaaS 前缀  OpenFaaS 镜像存储在 Docker 注册表或 Docker Hub 中，我们可以设置一个环境变量，使你的用户名自动添加到你创建的新函数中。这将在研讨会过程中为你节省一些时间。\n编辑~/.bashrc或~/.bash_profile\u0026ndash;如果该文件不存在，则创建它。\n现在添加以下内容\u0026ndash;按照你上面看到的 URL 进行修改。\nexport OPENFAAS_PREFIX=\u0026#34;\u0026#34; # Populate with your Docker Hub username 设置一个单节点集群 实验室使用 Kubernetes，Swarm 已经不再被 OpenFaaS 社区支持。有些实验室可以用于 faasd，但你可能需要改变命令，而且当使用 faasd 的时候，我们不提供对该实验室的支持。\n Kubernetes。Lab 1b  ","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab1/","summary":"Lab 1 - 为 OpenFaaS 做准备 OpenFaaS 需要一个Kubernetes集群来运行。你可以使用一个单节点集群或多节点集群，不管是在你的笔记本电脑上还是在云端。\n任何 OpenFaaS 函数的基本原件都是一个 Docker 镜像，它是使用faas-cli工具链构建的。\n前提条件 让我们来安装 Docker、OpenFaaS CLI 以及设置 Kubernetes。\nDocker 适用于 Mac\n Docker CE for Mac Edge Edition  适用于 Windows\n 仅使用 Windows 10 Pro 或企业版 安装Docker CE for Windows   请确保通过使用 Windows 任务栏通知区的 Docker 菜单来使用Linux容器的 Docker 守护程序。\n  安装Git Bash  当你安装 git bash 时，选择以下选项。install UNIX commands和use true-type font。\n 注意：请在所有步骤中使用Git Bash：不要试图使用PowerShell、WSL或Bash for Windows。\n Linux - Ubuntu 或 Debian","title":"Openfaas Workshop Lab1"},{"content":"openfaas-workshop 这是一个自定进度的研讨会，学习如何使用 OpenFaaS 构建、部署和运行无服务器函数。\n在这个工作坊中，你将首先把 OpenFaaS 部署到你的笔记本电脑或使用 Docker for Mac 或 Windows 的远程集群。然后你将对 OpenFaaS 的用户界面、CLI 和函数商店进行测试。在用 Python 构建、部署和调用你自己的无服务器函数之后，你将继续学习以下内容：用 pip 管理依赖关系，通过安全秘密处理 API 令牌，用 Prometheus 监控函数，异步调用函数以及将函数连接起来创建应用程序。实验的高潮是让你创建自己的 GitHub 机器人，可以自动响应问题。同样的方法可以通过 IFTTT.com 连接到在线事件流\u0026ndash;这将使你能够建立机器人、自动回复器以及与社交媒体和物联网设备的集成。\n最后，实验室涵盖了更多的高级主题，并给出了进一步学习的建议。\n译文\n 日本語 简体中文  免费学习，作为 GitHub 赞助商表示感谢 OpenFaaS 连同这些材料都是免费提供的，需要时间和精力来维护。\n 成为OpenFaaS on GitHub的赞助商。  要求 我们在Lab 1中讲解了如何安装这些需求。请在参加讲师指导的研讨会之前做Lab 1。\n 函数将用 Python 语言编写，所以有编程或脚本经验者优先。 安装推荐的代码编辑器/IDE VSCode 对于 Windows，安装Git Bash 首选的操作系统。MacOS, Windows 10 Pro/Enterprise, Ubuntu Linux  Docker。\n Docker CE for Mac/Windows 边缘版。 Docker CE for Linux   注意：作为最后的手段，如果你有一台不兼容的 PC，你可以在https://labs.play-with-docker.com/ 上运行该研讨会。\n 教员指导的研讨会 如果你正在参加一个由教师指导的研讨会，那么我们将分享一个链接，以加入 OpenFaaS Slack 社区。使用研讨会的指定频道来讨论评论、问题和建议。\n挑选你的轨道 在实验室 1 中，你将选择你的轨道，然后在整个实验室中注意你的轨道的容器协调器所需的任何特殊命令。\nKubernetes 你也可以使用 OpenFaaS 学习 Kubernetes 上的 Serverless。\nOpenFaaS 社区的建议是，你在生产中运行 Kubernetes，但你能的所有知识都是可以转移的，函数也不必重新构建。\nLab 1 - Prepare for OpenFaaS  安装前提条件 用 Kubernetes 建立一个单节点集群 Docker Hub 账户 OpenFaaS CLI 部署 OpenFaaS  Lab 2 - Test things out  使用 UI 门户 通过函数商店进行部署 了解 CLI 的情况 用 Prometheus 查找指标  Lab 3 - Introduction to Functions  架构或生成一个新的函数 建立 astronaut-finder 函数 用pip添加依赖 故障排除：找到容器的日志 故障排除：用write_debug进行粗略输出 使用自定义和第三方语言模板 使用模板商店发现社区模板  Lab 4 - Go deeper with functions  通过环境变量注入配置 *在部署时使用 yaml  动态地使用 HTTP 上下文\u0026ndash;查询字符串/头信息等   安全性：只读的文件系统 利用日志 创建工作流  在客户端串联函数 *从另一个函数中调用一个函数    Lab 5 - Create a GitHub bot  建立 issue-bot\u0026ndash;GitHub 问题的自动回复者\n  获得一个 GitHub 账户 用 ngrok 建立一个隧道 创建一个 webhook 接收器issue-bot。 接收来自 GitHub 的 webhooks 部署 SentimentAnalysis 函数 通过 GitHub 的 API 应用标签 完成函数  Lab 6 - HTML for your functions  从一个函数生成并返回基本的 HTML 从磁盘读取并返回一个静态 HTML 文件 与其他函数协作  Lab 7 - Asynchronous Functions   同步地与异步地调用一个函数\n  查看队列工作者的日志\n  在 requestbin 和 ngrok 中使用X-Callback-Url。\n  Lab 8 - Advanced Feature - Timeouts  用read_timeout调整超时时间 适应更长的运行函数  Lab 9 - Advanced Feature - Auto-scaling  查看自动缩放的操作  关于最小和最大复制的一些见解 发现并访问本地 Prometheus 执行和普罗米修斯查询 使用 curl 调用一个函数 观察自动缩放的启动    Lab 10 - Advanced Feature - Secrets  调整 issue-bot 以使用一个秘密  用 faas-cli 创建一个 Kubernetes 秘密 在函数中访问秘密    Lab 11 - Advanced feature - Trust with HMAC  使用 HMAC 对函数应用信任  你可以从第一个实验室Lab 1开始。\n拆解/清理 你可以找到如何停止和删除 OpenFaaS这里\n接下来的步骤 如果你在一个教师指导的研讨会上，并且已经完成了实验，你可能想回到实验室，编辑/修改代码和值，或者进行一些你自己的实验。\n以下是一些后续任务/主题的想法。\nOpenFaaS 云 试试 OpenFaaS 的多用户管理体验\u0026ndash;在社区集群上，或者通过托管你自己的 OpenFaaS 云。\n Docs: OpenFaaS Cloud  TLS  用 Kubernetes Ingress 在你的网关上启用 HTTPS  CI/CD 设置 Jenkins、Google Cloud Build 或 GitLab，使用 OpenFaaS CLI 构建和部署你自己的函数。\n CI/CD 介绍  存储/数据库   用 Minio 尝试开源对象存储\n  尝试用 Mongo 存储数据的 OpenFaaS\n  仪器仪表/监控  探索 Prometheus 中可用的指标  其他博文和教程   OpenFaaS 博客上的教程\n  社区博客文章\n  附录 附录包含一些额外的内容。\nAcknowledgements 感谢@iyovcheva, @BurtonR, @johnmccabe, @laurentgrangeau, @stefanprodan, @kenfdev, @templum \u0026amp; @rgee0 对实验室的贡献、测试和翻译。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop/","summary":"openfaas-workshop 这是一个自定进度的研讨会，学习如何使用 OpenFaaS 构建、部署和运行无服务器函数。\n在这个工作坊中，你将首先把 OpenFaaS 部署到你的笔记本电脑或使用 Docker for Mac 或 Windows 的远程集群。然后你将对 OpenFaaS 的用户界面、CLI 和函数商店进行测试。在用 Python 构建、部署和调用你自己的无服务器函数之后，你将继续学习以下内容：用 pip 管理依赖关系，通过安全秘密处理 API 令牌，用 Prometheus 监控函数，异步调用函数以及将函数连接起来创建应用程序。实验的高潮是让你创建自己的 GitHub 机器人，可以自动响应问题。同样的方法可以通过 IFTTT.com 连接到在线事件流\u0026ndash;这将使你能够建立机器人、自动回复器以及与社交媒体和物联网设备的集成。\n最后，实验室涵盖了更多的高级主题，并给出了进一步学习的建议。\n译文\n 日本語 简体中文  免费学习，作为 GitHub 赞助商表示感谢 OpenFaaS 连同这些材料都是免费提供的，需要时间和精力来维护。\n 成为OpenFaaS on GitHub的赞助商。  要求 我们在Lab 1中讲解了如何安装这些需求。请在参加讲师指导的研讨会之前做Lab 1。\n 函数将用 Python 语言编写，所以有编程或脚本经验者优先。 安装推荐的代码编辑器/IDE VSCode 对于 Windows，安装Git Bash 首选的操作系统。MacOS, Windows 10 Pro/Enterprise, Ubuntu Linux  Docker。\n Docker CE for Mac/Windows 边缘版。 Docker CE for Linux   注意：作为最后的手段，如果你有一台不兼容的 PC，你可以在https://labs.","title":"Openfaas Workshop"},{"content":" 有效的复杂系统总是从简单\n ","permalink":"https://zhenfeng-zhu.github.io/posts/streaming-101/","summary":" 有效的复杂系统总是从简单\n ","title":"Streaming 101"},{"content":"openfaas https://github.com/openfaas/workshop/blob/master/lab1b.md\n安装 docker brew install homebrew/cask/docker 安装单节点 K8S brew install k3d 配置单节点 K8S 集群\nk3d cluster create CLUSTER_NAME k3d kubeconfig merge CLUSTER_NAME --kubeconfig-switch-context kubectl get pods --all-namespaces 安装 arkade curl -SLsf https://dl.get-arkade.dev/ | sudo sh 安装 openfaas 客户端 faas-cli brew install faas-cli 安装 openfaas server 端 arkade install openfaas 配置 openfaas 的 ui 界面\nkubectl rollout status -n openfaas deploy/gateway kubectl port-forward svc/gateway -n openfaas 8080:8080 这样就可以在浏览器里输入 127.0.0.1:8080 进入到 openfaas 的 ui 界面了。\n但是当你打开页面的时候，要输入密码，那就需要下面的操作：\n# This command retrieves your password PASSWORD=$(kubectl get secret -n openfaas basic-auth -o jsonpath=\u0026#34;{.data.basic-auth-password}\u0026#34; | base64 --decode; echo) # This command logs in and saves a file to ~/.openfaas/config.yml echo -n $PASSWORD | faas-cli login --username admin --password-stdin 或者直接在命令行输入，拿到密码：\necho $(kubectl get secret -n openfaas basic-auth -o jsonpath=\u0026#34;{.data.basic-auth-password}\u0026#34; | base64 --decode; echo) 用户名是 admin，密码输入到浏览器里即可。\n","permalink":"https://zhenfeng-zhu.github.io/posts/k3d-with-openfaas/","summary":"openfaas https://github.com/openfaas/workshop/blob/master/lab1b.md\n安装 docker brew install homebrew/cask/docker 安装单节点 K8S brew install k3d 配置单节点 K8S 集群\nk3d cluster create CLUSTER_NAME k3d kubeconfig merge CLUSTER_NAME --kubeconfig-switch-context kubectl get pods --all-namespaces 安装 arkade curl -SLsf https://dl.get-arkade.dev/ | sudo sh 安装 openfaas 客户端 faas-cli brew install faas-cli 安装 openfaas server 端 arkade install openfaas 配置 openfaas 的 ui 界面\nkubectl rollout status -n openfaas deploy/gateway kubectl port-forward svc/gateway -n openfaas 8080:8080 这样就可以在浏览器里输入 127.0.0.1:8080 进入到 openfaas 的 ui 界面了。","title":"K3d With Openfaas"},{"content":" 面向对象不是设计代码的唯一方法 函数式编程不一定是复杂和纯数学的 编程的基础不是赋值、if 语句和循环 并发不一定需要锁、信号量、监视器等类似的东西 进程不必消耗大量的资源 元编程不只是语言的附属品 即使编程是你的工作，也应该是充满乐趣的  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E6%8D%A2%E4%B8%80%E7%A7%8D%E6%96%B9%E5%BC%8F%E6%80%9D%E8%80%83/","summary":" 面向对象不是设计代码的唯一方法 函数式编程不一定是复杂和纯数学的 编程的基础不是赋值、if 语句和循环 并发不一定需要锁、信号量、监视器等类似的东西 进程不必消耗大量的资源 元编程不只是语言的附属品 即使编程是你的工作，也应该是充满乐趣的  ","title":"换一种方式思考"},{"content":"首先把所有的 vim 相关的都删除 cd rm -rf .vim* 创建自己的.vimrc vim .vimrc 一些基本的设置 在.vimrc 中添加下面的代码\n\u0026#34; basic set set number set noswapfile set encoding=utf-8 set fileencodings=utf-8,gb18030 set backspace=eol,start,indent set laststatus=2 set colorcolumn=80 set cursorline set linebreak set autoindent set ignorecase set smartcase set ruler set diffopt+=internal,indent-heuristic,algorithm:patience set showcmd set clipboard^=unnamed,unnamedplus set showmode set mouse=a set tabstop=2 set shiftwidth=4 set expandtab set softtabstop=2 set showmatch set incsearch set nobackup set autoread set wildmenu set wildmode=longest:list,full set nofoldenable filetype plugin indent on syntax on 有了上面的设置，会让你的 vim 更好用一些。\n每个参数的含义，可以看下阮一峰写的vim 配置入门\n安装 vim-plug curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 我是用 vim-plug 来管理 vim 的插件配置的，用起来比较简单。\n它的思路是这样的，把 github 的 vim 配置 clone 下来，然后加载。\n安装一些插件 在.vimrc 中继续添加下面的代码\n\u0026#34; Plugs call plug#begin() Plug \u0026#39;luochen1990/rainbow\u0026#39; Plug \u0026#39;jiangmiao/auto-pairs\u0026#39; Plug \u0026#39;mechatroner/rainbow_csv\u0026#39; Plug \u0026#39;liuchengxu/space-vim-theme\u0026#39; Plug \u0026#39;lvht/mru\u0026#39; Plug \u0026#39;preservim/tagbar\u0026#39; Plug \u0026#39;preservim/nerdtree\u0026#39; Plug \u0026#39;Xuyuanp/nerdtree-git-plugin\u0026#39; Plug \u0026#39;ryanoasis/vim-devicons\u0026#39; Plug \u0026#39;liuchengxu/nerdtree-dash\u0026#39; Plug \u0026#39;fatih/vim-go\u0026#39;, { \u0026#39;do\u0026#39;: \u0026#39;:GoUpdateBinaries\u0026#39; } Plug \u0026#39;godlygeek/tabular\u0026#39; Plug \u0026#39;plasticboy/vim-markdown\u0026#39; Plug \u0026#39;liuchengxu/eleline.vim\u0026#39; Plug \u0026#39;tpope/vim-fugitive\u0026#39; call plug#end() 这些是我比较常用的插件\n rainbow 是一个每个括号都用不同颜色区分，增加代码的可读性 auto-pairs 是自动补全括号 rainbow_csv 是打开 csv 文件更好看一些的插件 space-vim-theme 是 vim 的一个主题 mru 是最近最常使用的文件 tagbar 显示代码结构的 nerdtree + nerdtree-git-plugin + vim-devicons + nerdtree-dash 这几个搭配起来，展示一个更好看的文件目录 vim-go 写 go 必备 tabular + vim-markdown 写 markdown 必备的 eleline 状态栏更好看一些 vim-fugitive vim 的 git 插件  插件的自定义设置 安装了这么多插件，一般可能会自定义一下，有些插件都提供了一些变量，我们可以通过 let g:xxx 的方式去自定义\n这些设置也是在 vimrc 中，要在插件安装的下面\n\u0026#34; plug settings let g:rainbow_active=1 keymap 的设置 我们可以设置一些快捷键加快操作。\nvim 有一个 leader 键，这个键的作用是按下之后，再按别的键，触发一些命令。 之所以有这个 leader 键，就是为了防止用户自己的快捷键，覆盖了默认的。 vim 默认的 leader 键是|,也就是 enter 上面那个中竖线。\n\u0026#34; key map nnoremap \u0026lt;silent\u0026gt; \u0026lt;c-m\u0026gt; :Mru\u0026lt;cr\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;c-p\u0026gt; :call fzf#Open()\u0026lt;cr\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;leader\u0026gt;t :TagbarToggle\u0026lt;cr\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;leader\u0026gt;e :NERDTreeToggle\u0026lt;cr\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;leader\u0026gt;f :NERDTreeFind\u0026lt;cr\u0026gt; nnoremap \u0026lt;silent\u0026gt; \u0026lt;leader\u0026gt;c :call lv#Term()\u0026lt;cr\u0026gt; 如果你想和我的一样 参考这个 github 项目：https://github.com/zhenfeng-zhu/vim\ngit clone --recursive https://github.com/zhenfeng-zhu/vim.git ~/.vim ln -s ~/.vim/init.vim ~/.vimrc 然后就可以愉快的自己定制了。\n","permalink":"https://zhenfeng-zhu.github.io/posts/vim/","summary":"首先把所有的 vim 相关的都删除 cd rm -rf .vim* 创建自己的.vimrc vim .vimrc 一些基本的设置 在.vimrc 中添加下面的代码\n\u0026#34; basic set set number set noswapfile set encoding=utf-8 set fileencodings=utf-8,gb18030 set backspace=eol,start,indent set laststatus=2 set colorcolumn=80 set cursorline set linebreak set autoindent set ignorecase set smartcase set ruler set diffopt+=internal,indent-heuristic,algorithm:patience set showcmd set clipboard^=unnamed,unnamedplus set showmode set mouse=a set tabstop=2 set shiftwidth=4 set expandtab set softtabstop=2 set showmatch set incsearch set nobackup set autoread set wildmenu set wildmode=longest:list,full set nofoldenable filetype plugin indent on syntax on 有了上面的设置，会让你的 vim 更好用一些。","title":"小白都能快速上手的 Vim 配置"},{"content":"之前我采用的方式是两个 github repo 的方式：\n一个叫 hugo-blog，用于存放 blog 的源文件\n一个叫 zhenfeng-zhu.github.io，用于存放生成之后的文件\n然后通过写一个 shell 脚本，将生成之后的文件推向 zhenfeng-zhu.github.io 仓库中，同时将 blog 的源文件也做了一个 backup。后来使用了一个 github action 的方式， 就不用在两个仓库中进行折腾，一切都由 github action 来做了。\n方案 设置 workflow 首先创建一个.github/workflows/gh-pages.yml\nname: github pages on: push: branches: - main  # Set a branch to deploy jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;latest\u0026#39; # extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 我们看下这个 workflow 的步骤：\n  name 就是 github pages\n  on 的意思代表，是什么行为会触发这个 action 的构建。 这里我们设置的是当 push 到 main 分支的时候进行构建。\n  jobs 就是具体的工作，这里指定了几个步骤：\n   首先是在 Ubuntu 18.04 下进行构建 这些步骤都是用的 actions/checkout@v2 模板进行，拉取 submodules。 setup hugo：采用的是 peaceiris/actions-hugo@v2 模板 build：简单的 hugo 命令 deploy：采用 peaceiris/actions-gh-pages@v3 方式，把自己的 github token 也配置上。具体可以点进去看下这个步骤做了什么操作。  然后把博客的源文件，放在 main 分支里，当我们 push 之后，就会发现出现了一个 gh-pages 分支。\n设置 github pages 打开该 repo 的 settings，选到 GitHub Pages。\n我们选择分支是 gh-pages 即可。\n","permalink":"https://zhenfeng-zhu.github.io/posts/hugo-github-action/","summary":"之前我采用的方式是两个 github repo 的方式：\n一个叫 hugo-blog，用于存放 blog 的源文件\n一个叫 zhenfeng-zhu.github.io，用于存放生成之后的文件\n然后通过写一个 shell 脚本，将生成之后的文件推向 zhenfeng-zhu.github.io 仓库中，同时将 blog 的源文件也做了一个 backup。后来使用了一个 github action 的方式， 就不用在两个仓库中进行折腾，一切都由 github action 来做了。\n方案 设置 workflow 首先创建一个.github/workflows/gh-pages.yml\nname: github pages on: push: branches: - main  # Set a branch to deploy jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .","title":"Github Action 自动部署 blog"},{"content":"Elixir  everything is a process. process are strongly isolated. process creation and destruction is a lightweight operation. message passing is the only way for processes to interact. processes have unique names. if you know the name of a process you can send it a message. processes share no resources. error handling is non-local. processes do what they are supposed to do or fail.  Go  simple, poetic, pithy don\u0026rsquo;t communicate by sharing memory, share memory by communicating concurrency is not parallelism channels orchestrate; mutexes serialize the bigger the interface, the weaker the abstraction make the zero value useful interface{} says nothing gofmt\u0026rsquo;s style is no one\u0026rsquo;s favorite, yet gofmt is everyone\u0026rsquo;s favorite A little copying is better than a little dependency  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%96%E7%95%8C%E8%A7%82/","summary":"Elixir  everything is a process. process are strongly isolated. process creation and destruction is a lightweight operation. message passing is the only way for processes to interact. processes have unique names. if you know the name of a process you can send it a message. processes share no resources. error handling is non-local. processes do what they are supposed to do or fail.  Go  simple, poetic, pithy don\u0026rsquo;t communicate by sharing memory, share memory by communicating concurrency is not parallelism channels orchestrate; mutexes serialize the bigger the interface, the weaker the abstraction make the zero value useful interface{} says nothing gofmt\u0026rsquo;s style is no one\u0026rsquo;s favorite, yet gofmt is everyone\u0026rsquo;s favorite A little copying is better than a little dependency  ","title":"编程语言的世界观"},{"content":"什么是指标体系 指标体系是在业务的不同阶段，分析师牵头与业务方协助，制定一套能从各个维度反映业务状况的待实施框架。\n关键点  在业务的前期、中期和后期，指标体系是不一样的 一定是由分析师牵头与业务方协助，而不是闭门造车 从各个维度去反应业务的核心状况，指标有很多维度 最后就是一个大的实施框架，一定要实施，否则就是浪费大家的时间  指标选取的几个原则  根本性：对于核心数据一定要理解到位和准确，如果这里错了，后面基本就不用看。 可理解性：所有指标要配上业务解释 结构性：能够充分从各维度对业务进行解读，方便归因。  建立步骤   理清业务阶段和方向 我们需要知道当前产品或者业务处于什么阶段，具体的业务方向是什么。一般都是分为三个阶段： 第一阶段：业务前期。在业务的前期更多的是想要快速推出来，有更多人去使用我们的产品。所以此时我们的指标体系应该更多的围绕用户量提升做各种维度的拆解 第二阶段：业务中期（快速发展期）。在业务中期，除了关注盘子的大小，还要看产品的健康度。 第三阶段：业务后期（成熟期）。主要看变现能力以及市场份额。\n  确定核心指标 找核心指标不是一件容易的事儿。 只能多花时间去考虑这个事儿。\n  指标核心维度拆解 核心指标的波动必然是由某种维度的波动引起，所以监控核心指标指标，本质是监控核心维度。 通用的拆解方法是先对核心指标进行公式计算，再按照业务路径或者业务模块去拆解。 核心指标的拆解，需要多和业务方进行沟通，把能够考虑的模块都考虑进去，基本上就能比较全面。\n  指标宣贯、存档和落地 宣贯：实际上搭建号指标体系之后，要当面触达所有相关的业务接口人。 存档：同时对指标的口径和业务逻辑进行详细的描述存档，也就是指标口径归档 落地：落地就是建立核心指标的相关报表，实际工作中，报表会在埋点前建好，这样一旦版本上线就能立刻看到数据，这样各方的配合度就会很高。\n  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E6%8C%87%E6%A0%87%E4%BD%93%E7%B3%BB/","summary":"什么是指标体系 指标体系是在业务的不同阶段，分析师牵头与业务方协助，制定一套能从各个维度反映业务状况的待实施框架。\n关键点  在业务的前期、中期和后期，指标体系是不一样的 一定是由分析师牵头与业务方协助，而不是闭门造车 从各个维度去反应业务的核心状况，指标有很多维度 最后就是一个大的实施框架，一定要实施，否则就是浪费大家的时间  指标选取的几个原则  根本性：对于核心数据一定要理解到位和准确，如果这里错了，后面基本就不用看。 可理解性：所有指标要配上业务解释 结构性：能够充分从各维度对业务进行解读，方便归因。  建立步骤   理清业务阶段和方向 我们需要知道当前产品或者业务处于什么阶段，具体的业务方向是什么。一般都是分为三个阶段： 第一阶段：业务前期。在业务的前期更多的是想要快速推出来，有更多人去使用我们的产品。所以此时我们的指标体系应该更多的围绕用户量提升做各种维度的拆解 第二阶段：业务中期（快速发展期）。在业务中期，除了关注盘子的大小，还要看产品的健康度。 第三阶段：业务后期（成熟期）。主要看变现能力以及市场份额。\n  确定核心指标 找核心指标不是一件容易的事儿。 只能多花时间去考虑这个事儿。\n  指标核心维度拆解 核心指标的波动必然是由某种维度的波动引起，所以监控核心指标指标，本质是监控核心维度。 通用的拆解方法是先对核心指标进行公式计算，再按照业务路径或者业务模块去拆解。 核心指标的拆解，需要多和业务方进行沟通，把能够考虑的模块都考虑进去，基本上就能比较全面。\n  指标宣贯、存档和落地 宣贯：实际上搭建号指标体系之后，要当面触达所有相关的业务接口人。 存档：同时对指标的口径和业务逻辑进行详细的描述存档，也就是指标口径归档 落地：落地就是建立核心指标的相关报表，实际工作中，报表会在埋点前建好，这样一旦版本上线就能立刻看到数据，这样各方的配合度就会很高。\n  ","title":"如何建立指标体系"},{"content":"对于大部分公司而言，能够写底层代码或者中间件代码的人总是有限的，写业务代码会面临更高的复杂度。这里分三个层次来看其中的机会：\n 第一个层次，让代码写的不一样。可从代码规范、可读性、可扩展性等角度着手，这也是程序员的基本功。 第二个层次，考虑业务问题和技术问题的匹配。可从写业务代码中理解需求，并做好分析设计。被动接收需求和实现接口，确实成长空间不大。 第三个层次，总结相关方法体系，成为业务及技术双料专家。  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E4%B8%9A%E5%8A%A1%E4%BB%A3%E7%A0%81%E7%9A%84%E6%88%90%E9%95%BF%E6%9C%BA%E4%BC%9A/","summary":"对于大部分公司而言，能够写底层代码或者中间件代码的人总是有限的，写业务代码会面临更高的复杂度。这里分三个层次来看其中的机会：\n 第一个层次，让代码写的不一样。可从代码规范、可读性、可扩展性等角度着手，这也是程序员的基本功。 第二个层次，考虑业务问题和技术问题的匹配。可从写业务代码中理解需求，并做好分析设计。被动接收需求和实现接口，确实成长空间不大。 第三个层次，总结相关方法体系，成为业务及技术双料专家。  ","title":"业务代码的成长机会"},{"content":" 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件，甚至是操作系统，要尽早尝试，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。  ","permalink":"https://zhenfeng-zhu.github.io/posts/unix-philosophy/","summary":" 让每个程序都做好一件事。要做一件新的工作，写一个新程序，而不是通过添加“功能”让老程序复杂化。 期待每个程序的输出成为另一个程序的输入。不要将无关信息混入输出。避免使用严格的列数据或二进制输入格式。不要坚持交互式输入。 设计和构建软件，甚至是操作系统，要尽早尝试，最好在几周内完成。不要犹豫，扔掉笨拙的部分，重建它们。 优先使用工具来减轻编程任务，即使必须曲线救国编写工具，且在用完后很可能要扔掉大部分。  ","title":"unix 哲学"},{"content":"一般来说 web 前端是指网站业务逻辑之前的部分，比如：浏览器加载、网站视图模型、图片服务、CDN 服务等等。web 前端优化主要从如下三个方面入手：\n浏览器访问优化   减少 http 请求\nhttp 协议是一个无状态的，每次请求都需要建立通信链路进行传输，在服务器端，一般每个请求都会分配一个线程去处理。\n减少 http 请求的主要手段是合并 CSS、合并 js、合并图片。\n  使用浏览器缓存\ncss、js、Logo、图标等静态资源文件更新频率较低，可以将这些文件缓存在浏览器中。\n在更新 js 等文件的时候，一般不是将文件内容更新，而是生成一个新的文件，然后更新 html 的引用。\n更新静态资源的时候，也是要逐量更新，以避免用户浏览器的大量缓存失效，造成服务器负载增加、网络堵塞。\n  启用压缩\n在服务器对文件压缩，然后在浏览器端解压缩，可以减少通信传输的数据量。\n  CSS 放在页面最上面，js 放在页面最下面\n浏览器会在下载完全部 CSS 之后才对整个页面进行渲染，而浏览器是在加载 js 之后就立即执行，有可能会阻塞整个页面。因此最好的做法就是把 CSS 放在最上面，js 放在最下面。但是如果是页面解析的时候就用到 js，也是要相应的 js 放在上面。\n  减少 cookie 传输\ncookie 会包含在每次请求和响应中，太大的 cookie 会影响数据传输，需要慎重考虑哪些数据写入 cookie 中。\n对于某些静态资源的访问，如 css 和 js 等，发送 cookie 没意义，可以考虑静态资源使用独立域名访问，避免请求静态资源时发送 cookie。\n  CDN 加速 CDN（content distribute network，内容分发网络）的本质仍然是一个缓存。将缓存放在离用户最近的地方，使得用户可以以最快的速度获取数据。\nCDN 缓存的一般是静态资源，如图片、文件、CSS、js、静态网页等。\n反向代理 反向代理服务器位于网站中心机房的一侧，代理网站 web 服务器接收 http 请求。\n反向代理可以在一定程度上保护网站安全，来自互联网的访问请求必须经过代理服务器，相当于在 web 服务器和攻击之间加了一个屏障。\n反向代理也可以通过配置缓存，静态资源被缓存在反向代理服务器，当用户访问时，可以从反向代理服务器上返回。有些网站也会将部分动态内容缓存在代理服务器上，通过内部通知机制，更新缓存。\n反向代理也可以实现负载均衡的功能。\n写在最后 可以发现，在 web 前端性能优化的时候，提到最多的就是缓存。\n 网站性能优化第一定律：优先考虑使用缓存！\n ","permalink":"https://zhenfeng-zhu.github.io/posts/web%E5%89%8D%E7%AB%AF%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","summary":"一般来说 web 前端是指网站业务逻辑之前的部分，比如：浏览器加载、网站视图模型、图片服务、CDN 服务等等。web 前端优化主要从如下三个方面入手：\n浏览器访问优化   减少 http 请求\nhttp 协议是一个无状态的，每次请求都需要建立通信链路进行传输，在服务器端，一般每个请求都会分配一个线程去处理。\n减少 http 请求的主要手段是合并 CSS、合并 js、合并图片。\n  使用浏览器缓存\ncss、js、Logo、图标等静态资源文件更新频率较低，可以将这些文件缓存在浏览器中。\n在更新 js 等文件的时候，一般不是将文件内容更新，而是生成一个新的文件，然后更新 html 的引用。\n更新静态资源的时候，也是要逐量更新，以避免用户浏览器的大量缓存失效，造成服务器负载增加、网络堵塞。\n  启用压缩\n在服务器对文件压缩，然后在浏览器端解压缩，可以减少通信传输的数据量。\n  CSS 放在页面最上面，js 放在页面最下面\n浏览器会在下载完全部 CSS 之后才对整个页面进行渲染，而浏览器是在加载 js 之后就立即执行，有可能会阻塞整个页面。因此最好的做法就是把 CSS 放在最上面，js 放在最下面。但是如果是页面解析的时候就用到 js，也是要相应的 js 放在上面。\n  减少 cookie 传输\ncookie 会包含在每次请求和响应中，太大的 cookie 会影响数据传输，需要慎重考虑哪些数据写入 cookie 中。\n对于某些静态资源的访问，如 css 和 js 等，发送 cookie 没意义，可以考虑静态资源使用独立域名访问，避免请求静态资源时发送 cookie。\n  CDN 加速 CDN（content distribute network，内容分发网络）的本质仍然是一个缓存。将缓存放在离用户最近的地方，使得用户可以以最快的速度获取数据。","title":"Web 前端性能优化"},{"content":"前几天跟一个朋友聊了一些关于网站缓存分布式的一些东西，发现自己的知识还是太过贫瘠。理论+协议，这是现在我亟待加强的。这个周末买了两本关于分布式网站的书，本着好记性不如烂笔头，便有了这样一系列的文章。希望一同分享，也请多指教。\n code less, play more!\n 前言 这个世界上没有哪个网站从诞生起就是大型网站；也没有哪个网站第一次发布的时候就拥有庞大的用户，高并发的访问，海量的数据；大型网站都是从小型网站发展而来。网站的价值在于它能给用户提供什么家宅，在于网站能做什么，而不在于它是怎么做的，所以网站在小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供更好的服务来创造价值，得到用户认可，活下去，野蛮生长。\n大型网站软件系统的特点  高并发，大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，发布平频繁 渐进式发展  大型网站的发展历程   初始阶段的网站架构\n最开始没有多少人访问，所以应用程序，数据库，文件都在同一台机器上。\n  应用服务器和数据服务分离\n应用和数据分离之后，一般需要三台服务器。应用服务器，文件服务器和数据库服务器，这三种服务器对于硬件要求各不相同。\n 应用服务器：更强大的 CPU 数据库服务器：更快速的磁盘和更大的内存 文件服务器：容量更大的硬盘    使用缓存改善性能\n网站的访问也遵循二八定律：80%的业务集中在 20%的数据上。因此可以把这一小部分数据缓存在内存中，减少数据库的访问压力。\n网站的缓存可以分为两种：\n 本地缓存：缓存在应用服务器上。本地缓存访问速度快，但是受制于内存限制，缓存数量有限，而且也会出现和应用程序争抢内存的情况。 远程分布式缓存：以集群的方式，缓存在大内存的专用缓存服务器。可以在理论上做到不受内存容量限制。    使用应用服务器集群提高并发能力\n当一台服务器的处理能力和存储空间不足的时候，不要企图更换更强大的服务器。对于大型网站来说，不管多么强大的服务器，都满足不了网站持续增长的业务需求。此时就可以考虑集群的方式，通过负载均衡调度服务器，可以将来自用户的请求分发到应用服务器集群中的任何一台服务器上。\n  数据库读写分离\n使用缓存后，大部分的数据读操作访问都可以不通过数据库完成，但是仍有部分读操作（如缓存过期，缓存不命中）和全部的写操作需要访问数据库。\n目前大部分数据库都提供主从热备的功能，在写数据的时候，访问主库，主库通过主从复制机制将数据更新同步至从数据库，在读的时候就可以通过从数据库获取数据。\n  使用反向代理和 CDN 加速网站响应\n在《web 性能权威指南》中有讲到，网站性能的瓶颈，大部分时间都浪费在 TCP 的握手和传输上。因此可以通过 CDN 和反向代理的方式来加快响应。\nCDN 和反向代理的本质都是通过缓存，不同的主要是：\n CDN 部署在服务器器上的机房，用户在请求时，从距离自己最近的机房获取数据。 反向代理是部署在中心机房，用户请求到达中心机房之后，首先访问的服务器是反向代理的拂去其，如果反向代理服务器中缓存着用户请求的额资源，就将其返回给用户。    使用分布式文件系统和分布式数据库系统\n随着业务的发展，依旧不能满足的时候，就采用分布式的文件和分布式的数据库系统。\n分布式数据库是数据库拆分的最后手段，只用在单表数据规模特别庞大的时候才使用。更常用的拆分手段是业务分库，将不同的业务数据存储在不同的数据库中。\n  使用 NoSQL 和搜索引擎\n对数据检索和存储越来越复杂的时候，就可以采用一些非关系型数据库如 HBase 和非数据库查询技术如 ElasticSearch 等等\n  业务拆分\n业务场景复杂的时候，一般讲整个网站业务分为不同的产品线，如首页，订单，买家，卖家等等。\n技术上也会根据产品线划分，将一个网站分为许多不同的应用，每个应用独立部署维护，应用之间可以通过一个超链接建立联系，也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统。\n  分布式服务\n随着业务越拆越小，存储越来越大，维护越来越困难。此时就可以将相同业务操作的提取出来，独立部署。应用系统只需要管理用户界面，通过分布式服务调用共同的业务服务完成具体的业务操作。也就是最近概念越来越火的——微服务。\n  云计算\n大型网站架构解决了海量数据库管理和高并发事务处理，可以将这些解决方案应用到网站自身以外的业务上。现在像阿里云，亚马逊等云计算平台，将计算作为一种基础资源出售，中小网站不需要关系技术架构等问题，只需要按需付费，就可以使网站随着业务的增长获得更大的存储和计算资源。\n  未来\n未来还能变成什么样子，我也不清楚，也许以后都不是开发人员来维护了，所有的这些都是 AI 来完成，程序员要做的就是如何完善 AI。也许 AI 发展到最后，人类都不需要存在了吧。\n  结语 网站的技术是为业务而存在的，除此以外毫无意义。在技术选型和架构设计中，脱离业务发展实际，一味的追求新技术，可能会把技术发展引入一个歪路。\n技术是用来解决业务的问题，而技术不可能将所有问题都解决掉，涉及业务自身的问题，还是要通过业务手段去解决。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E5%A4%A7%E5%9E%8B%E7%BD%91%E7%AB%99%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B/","summary":"前几天跟一个朋友聊了一些关于网站缓存分布式的一些东西，发现自己的知识还是太过贫瘠。理论+协议，这是现在我亟待加强的。这个周末买了两本关于分布式网站的书，本着好记性不如烂笔头，便有了这样一系列的文章。希望一同分享，也请多指教。\n code less, play more!\n 前言 这个世界上没有哪个网站从诞生起就是大型网站；也没有哪个网站第一次发布的时候就拥有庞大的用户，高并发的访问，海量的数据；大型网站都是从小型网站发展而来。网站的价值在于它能给用户提供什么家宅，在于网站能做什么，而不在于它是怎么做的，所以网站在小的时候就去追求网站的架构是舍本逐末，得不偿失的。小型网站最需要做的就是为用户提供更好的服务来创造价值，得到用户认可，活下去，野蛮生长。\n大型网站软件系统的特点  高并发，大流量 高可用 海量数据 用户分布广泛，网络情况复杂 安全环境恶劣 需求快速变更，发布平频繁 渐进式发展  大型网站的发展历程   初始阶段的网站架构\n最开始没有多少人访问，所以应用程序，数据库，文件都在同一台机器上。\n  应用服务器和数据服务分离\n应用和数据分离之后，一般需要三台服务器。应用服务器，文件服务器和数据库服务器，这三种服务器对于硬件要求各不相同。\n 应用服务器：更强大的 CPU 数据库服务器：更快速的磁盘和更大的内存 文件服务器：容量更大的硬盘    使用缓存改善性能\n网站的访问也遵循二八定律：80%的业务集中在 20%的数据上。因此可以把这一小部分数据缓存在内存中，减少数据库的访问压力。\n网站的缓存可以分为两种：\n 本地缓存：缓存在应用服务器上。本地缓存访问速度快，但是受制于内存限制，缓存数量有限，而且也会出现和应用程序争抢内存的情况。 远程分布式缓存：以集群的方式，缓存在大内存的专用缓存服务器。可以在理论上做到不受内存容量限制。    使用应用服务器集群提高并发能力\n当一台服务器的处理能力和存储空间不足的时候，不要企图更换更强大的服务器。对于大型网站来说，不管多么强大的服务器，都满足不了网站持续增长的业务需求。此时就可以考虑集群的方式，通过负载均衡调度服务器，可以将来自用户的请求分发到应用服务器集群中的任何一台服务器上。\n  数据库读写分离\n使用缓存后，大部分的数据读操作访问都可以不通过数据库完成，但是仍有部分读操作（如缓存过期，缓存不命中）和全部的写操作需要访问数据库。\n目前大部分数据库都提供主从热备的功能，在写数据的时候，访问主库，主库通过主从复制机制将数据更新同步至从数据库，在读的时候就可以通过从数据库获取数据。\n  使用反向代理和 CDN 加速网站响应\n在《web 性能权威指南》中有讲到，网站性能的瓶颈，大部分时间都浪费在 TCP 的握手和传输上。因此可以通过 CDN 和反向代理的方式来加快响应。\nCDN 和反向代理的本质都是通过缓存，不同的主要是：\n CDN 部署在服务器器上的机房，用户在请求时，从距离自己最近的机房获取数据。 反向代理是部署在中心机房，用户请求到达中心机房之后，首先访问的服务器是反向代理的拂去其，如果反向代理服务器中缓存着用户请求的额资源，就将其返回给用户。    使用分布式文件系统和分布式数据库系统","title":"大型网站发展历程"},{"content":"在上一篇文章《Geth 入门》中，主要讲了开发环境下以太坊 geth 客户端的使用。今天简单说下私链的配置。\ngenesis.json { \u0026#34;config\u0026#34;: { \u0026#34;chainId\u0026#34;: 10, \u0026#34;homesteadBlock\u0026#34;: 0, \u0026#34;eip155Block\u0026#34;: 0, \u0026#34;eip158Block\u0026#34;: 0 }, \u0026#34;coinbase\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000\u0026#34;, \u0026#34;difficulty\u0026#34; : \u0026#34;0x40000\u0026#34;, \u0026#34;extraData\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;gasLimit\u0026#34; : \u0026#34;0xffffffff\u0026#34;, \u0026#34;nonce\u0026#34; : \u0026#34;0x0000000000000042\u0026#34;, \u0026#34;mixhash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;parentHash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;timestamp\u0026#34; : \u0026#34;0x00\u0026#34;, \u0026#34;alloc\u0026#34;: { } }    参数 描述     nonce nonce 就是一个 64 位随机数，用于挖矿   mixhash 与 nonce 配合用于挖矿，由上一个区块的一部分生成的 hash   difficulty 设置当前区块的难度，如果难度过大，cpu 挖矿就很难，这里设置较小难度   alloc 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以   coinbase 矿工的账号，随便填   timestamp 设置创世块的时间戳   parentHash 上一个区块的 hash 值，因为是创世块，所以这个值是 0   extraData 附加信息，随便填，可以填你的个性信息   gasLimit 该值设置对 GAS 的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大。   config Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的 json 文件中，缺少 config 部分。看到这个信息，我们不需要把 geth 退回到 v1.5 版本，而是需要加上 config 部分。    创建创世区块 打开终端，输入以下命令，在当前目录下创建创世区块。\ngeth --datadir \u0026#34;./\u0026#34; init genesis.json 可以发现在当前目录新增了两个文件夹：\n geth 中保存的是区块链的相关数据 keystore 中保存的是该链条中的用户信息  启动私链 geth --datadir \u0026#34;./\u0026#34; --nodiscover console 2\u0026gt;\u0026gt;geth.log  --datadir：代表以太坊私链的创世区块的地址 --nodiscover：私链不要让公链上的节点发现  也可将此命令写入一个 shell 文件中，每次启动的时候执行脚本就可以了。\n输入此命令后，就可以进入到 geth 的控制台中了，在这里可以进行挖矿，智能合约的编写。\n","permalink":"https://zhenfeng-zhu.github.io/posts/geth-%E7%A7%81%E9%93%BE/","summary":"在上一篇文章《Geth 入门》中，主要讲了开发环境下以太坊 geth 客户端的使用。今天简单说下私链的配置。\ngenesis.json { \u0026#34;config\u0026#34;: { \u0026#34;chainId\u0026#34;: 10, \u0026#34;homesteadBlock\u0026#34;: 0, \u0026#34;eip155Block\u0026#34;: 0, \u0026#34;eip158Block\u0026#34;: 0 }, \u0026#34;coinbase\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000\u0026#34;, \u0026#34;difficulty\u0026#34; : \u0026#34;0x40000\u0026#34;, \u0026#34;extraData\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;gasLimit\u0026#34; : \u0026#34;0xffffffff\u0026#34;, \u0026#34;nonce\u0026#34; : \u0026#34;0x0000000000000042\u0026#34;, \u0026#34;mixhash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;parentHash\u0026#34; : \u0026#34;0x0000000000000000000000000000000000000000000000000000000000000000\u0026#34;, \u0026#34;timestamp\u0026#34; : \u0026#34;0x00\u0026#34;, \u0026#34;alloc\u0026#34;: { } }    参数 描述     nonce nonce 就是一个 64 位随机数，用于挖矿   mixhash 与 nonce 配合用于挖矿，由上一个区块的一部分生成的 hash   difficulty 设置当前区块的难度，如果难度过大，cpu 挖矿就很难，这里设置较小难度   alloc 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以   coinbase 矿工的账号，随便填   timestamp 设置创世块的时间戳   parentHash 上一个区块的 hash 值，因为是创世块，所以这个值是 0   extraData 附加信息，随便填，可以填你的个性信息   gasLimit 该值设置对 GAS 的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大。   config Fatal: failed to write genesis block: genesis has no chain configuration ：这个错误信息，就是说，你的 json 文件中，缺少 config 部分。看到这个信息，我们不需要把 geth 退回到 v1.","title":"Geth 私链"},{"content":"Geth 简介 go-ethereum\ngo-ethereum 客户端通常被称为 geth，它是个命令行界面，执行在 Go 上实现的完整以太坊节点。通过安装和运行 geth，可以参与到以太坊前台实时网络并进行以下操作：\n 挖掘真的以太币 在不同地址间转移资金 创建合约，发送交易 探索区块历史 及很多其他   网站: http://ethereum.github.io/go-ethereum/ Github: https://github.com/ethereum/go-ethereum 维基百科: https://github.com/ethereum/go-ethereum/wiki/geth Gitter: https://gitter.im/ethereum/go-ethereum\n mac 下安装 geth  首先安装 homebrew， 使用 brew 安装即可。在安装 geth 的时候，会将 go 也安装上。  brew tap ethereum/ethereum brew install ethereum  在命令行输入 geth —help，如果出现\nzhuzhenengdeMBP:blog zhuzhenfeng$ geth --help NAME: geth - the go-ethereum command line interface Copyright 2013-2017 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments...] VERSION: 1.7.3-unstable-eea996e4 证明安装成功。\n  使用 Geth   打开终端，输入以下命令，以开发的方式启动 geth\ngeth --datadir “~/Documents/github/ethfans/ethdev” --dev \u0026ndash;datadir 是指定 geth 的开发目录，引号的路径可以随便设置\n  新开一个终端，执行以下命令，进入 geth 的控制台\ngeth --dev console 2\u0026gt;\u0026gt;file_to_log_output 该命令会将在 console 中执行的命令，生成一个文本保存在 file_to_log_output 文件中。\n  再新开一个终端，查看打印出来的日志\ntail -f file_to_log_output   切换到 geth 控制台终端，geth 有如下常用的命令\n  eth.accounts\n查看有什么账户\n  personal.newAccount('密码')\n创建一个账户\n  user1=eth.accounts[0]\n可以把账户赋值给某一个变量\n  eth.getBalance(user1)\n获取某一账户的余额\n  miner.start()\n启动挖矿程序\n  miner.stop()\n停止挖矿程序\n  eth.sendTransaction({from: user1,to: user2,value: web3.toWei(3,\u0026quot;ether\u0026quot;)})\n从 user1 向 user2 转以太币\n  personal.unlockAccount(user1, '密码')\n解锁账户\n  以太坊启动挖矿程序的时候，头结点会产生以太币，在进行转账操作之后，必须进行挖矿才会使交易成功。\n","permalink":"https://zhenfeng-zhu.github.io/posts/geth/","summary":"Geth 简介 go-ethereum\ngo-ethereum 客户端通常被称为 geth，它是个命令行界面，执行在 Go 上实现的完整以太坊节点。通过安装和运行 geth，可以参与到以太坊前台实时网络并进行以下操作：\n 挖掘真的以太币 在不同地址间转移资金 创建合约，发送交易 探索区块历史 及很多其他   网站: http://ethereum.github.io/go-ethereum/ Github: https://github.com/ethereum/go-ethereum 维基百科: https://github.com/ethereum/go-ethereum/wiki/geth Gitter: https://gitter.im/ethereum/go-ethereum\n mac 下安装 geth  首先安装 homebrew， 使用 brew 安装即可。在安装 geth 的时候，会将 go 也安装上。  brew tap ethereum/ethereum brew install ethereum  在命令行输入 geth —help，如果出现\nzhuzhenengdeMBP:blog zhuzhenfeng$ geth --help NAME: geth - the go-ethereum command line interface Copyright 2013-2017 The go-ethereum Authors USAGE: geth [options] command [command options] [arguments.","title":"Geth"},{"content":"json 字符串处理  get_json_object lateral_view explode substr json_tuple  get_json_object get_json_object(string json_string, string path)\n解析 json 字符串 json_string，返回 path 指定的内容。如果输入的 json 字符串是无效的，那么返回 null。\npath 就是 \u0026lsquo;$.字段名\u0026rsquo;。\n如果该字段的 value 也是 json，就可以一直点下去。\n如果该字段的 value 是数组，就可以用 \u0026lsquo;$.字段名[0]'，类似这样下标的形式去访问。\nexplode explode(array)\n经常和 lateral view 一起使用，将数组中的元素拆分成多行显示。\nsubstr substr(string A, int start, int len)\n返回字符串 A 从 start 位置开始，长度为 len 的字符串\njson_tuple json_tuple(string json_string, col1, col2, \u0026hellip;)\n经常和 lateral view 一起使用，同时解析多个 json 字符串中的多个字段。\nparse_url, regexp_replace, regexp_extract parse_url parse_url(string urlString, string partToExtract, string keyToExtract)\n返回 url 中的指定部分，如 host，path，query 等等。\npartToExtract 是个枚举值：HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO。\nregex_replace regex_extract(string a, string b, string c)\n将字符串 a 中符合正在表达式 b 的部分替换为 c\njson_to_struct json_to_struct(json, \u0026lsquo;array 或者 map 等\u0026rsquo;)\nunion_map union_map(map(k, v))\nlateral view from_unix_time from_unix_time(unix 时间戳, \u0026lsquo;yyyyMMddHH\u0026rsquo;)\nrow_number row_number() over (partition by 字段 a order by 计算项 b desc ) rank\nhive 中的分组和组内排序\n rank 是排序的别名 partition by： 类似于 hive 的建表，分区的意思 order by： 排序，默认是升序，加 desc 降序  这个意思就是按字段 a 分区，对计算项 b 进行降序排列\n这个是经常用到计算分区中的排序问题。\ncoalesce 非空查找函数\ncoalesce(v1, v2, v3, \u0026hellip;)\n返回参数中的第一个非空值，如果所有值都是 NULL，返回 NULL\n","permalink":"https://zhenfeng-zhu.github.io/posts/hive%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/","summary":"json 字符串处理  get_json_object lateral_view explode substr json_tuple  get_json_object get_json_object(string json_string, string path)\n解析 json 字符串 json_string，返回 path 指定的内容。如果输入的 json 字符串是无效的，那么返回 null。\npath 就是 \u0026lsquo;$.字段名\u0026rsquo;。\n如果该字段的 value 也是 json，就可以一直点下去。\n如果该字段的 value 是数组，就可以用 \u0026lsquo;$.字段名[0]'，类似这样下标的形式去访问。\nexplode explode(array)\n经常和 lateral view 一起使用，将数组中的元素拆分成多行显示。\nsubstr substr(string A, int start, int len)\n返回字符串 A 从 start 位置开始，长度为 len 的字符串\njson_tuple json_tuple(string json_string, col1, col2, \u0026hellip;)\n经常和 lateral view 一起使用，同时解析多个 json 字符串中的多个字段。\nparse_url, regexp_replace, regexp_extract parse_url parse_url(string urlString, string partToExtract, string keyToExtract)","title":"hive 常用函数"},{"content":"SQL 条件语句 IF if(exp1, exp2, exp3)\nexp1 是条件，条件为 true 的话，是 exp2，否则是 exp3\ncase when case 列名 when 条件 then 结果 else 其他结果 end 别名 IFNULL IFNULL(exp1, exp2)\n在 exp1 的值不为 null 的情况下，返回 exp1，如果 exp1 位 null，返回 exp2 的值。\n","permalink":"https://zhenfeng-zhu.github.io/posts/mysql%E7%9A%84%E5%AD%A6%E4%B9%A0/","summary":"SQL 条件语句 IF if(exp1, exp2, exp3)\nexp1 是条件，条件为 true 的话，是 exp2，否则是 exp3\ncase when case 列名 when 条件 then 结果 else 其他结果 end 别名 IFNULL IFNULL(exp1, exp2)\n在 exp1 的值不为 null 的情况下，返回 exp1，如果 exp1 位 null，返回 exp2 的值。","title":"mysql 的学习"},{"content":"ClickHouse ClickHouse 是一个用于联机分析（Online Analytical Processing：OLAP）的列式数据库管理系统(DBMS)。通过使用 OLAP 工具，用户能够从多个角度交互地分析多维数据。\nOLAP 由三个基本的分析操作组成：上卷（roll-up）、钻取（drill-down）、切片（slicing）和切块（dicing）。\n  上卷（roll-up）：涉及可以在一个或多个维度中累积和计算的数据的聚合。例如，所有的销售办事处汇总到销售部门，以预测销售趋势。\n  钻取（drill-down）：是一种允许用户浏览详细信息的技术。例如，用户可以查看组成一个地区销售额的单个产品的销售额。\n  切片（slicing）和切块（dicing）：用户可以从 OLAP 多维数据集中取出（切片）一组特定的数据，并从不同的角度查看（切块）切片。这些角度有时被称为维度（例如按销售人员、按日期、按客户、按产品或按地区查看相同的销售情况等）。\n  传统行式数据库中，处于同一行中的数据总是被物理的存在一起。列式数据库总是将同一列的数据存储在一起，不同列的数据分开存储。\n行式数据库：mysql，pg\n列式数据库：vertica，druid\nOLAP 的关键特征  大多是读请求 数据总是以相当大的批（\u0026gt;1000w）进行写入 不修改已经添加的数据 每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列 宽表，即每个表包含大量的列 较少的查询（通常每台服务器每秒数百个查询或更少） 对于简单的查询，允许延迟大约 50ms 列中的数据相对较小：数字和短字符串 处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行） 事务不是必须的 对数据一致性要求低 每一个查询除了一个大表外都很小 查询结果明显小于数据源，换句话说，数据被过滤或者聚合之后能够被放在单台服务器的内存中  列式数据库更适合 OLAP 场景 Input/Output  分析类的查询，通常只需要读取表的一小部分列。 数据总是打包成批量读取，列压缩更容易 IO 降低了  CPU 由于执行一个查询需要处理大量的行，因此在整个 Vector 上执行所有操作将比在每一行上执行所有操作更加高效。同时这将有助于实现一个几乎没有调用成本的查询引擎。\n Vector 引擎 代码生成  为了提高 CPU 效率，查询语言必须是声明型的(SQL 或 MDX)， 或者至少一个 Vector(J，K)。 查询应该只包含隐式循环，允许进行优化。\nclickhouse 的独特功能 真正的列式数据库管理系统 ","permalink":"https://zhenfeng-zhu.github.io/posts/clickhouse/","summary":"ClickHouse ClickHouse 是一个用于联机分析（Online Analytical Processing：OLAP）的列式数据库管理系统(DBMS)。通过使用 OLAP 工具，用户能够从多个角度交互地分析多维数据。\nOLAP 由三个基本的分析操作组成：上卷（roll-up）、钻取（drill-down）、切片（slicing）和切块（dicing）。\n  上卷（roll-up）：涉及可以在一个或多个维度中累积和计算的数据的聚合。例如，所有的销售办事处汇总到销售部门，以预测销售趋势。\n  钻取（drill-down）：是一种允许用户浏览详细信息的技术。例如，用户可以查看组成一个地区销售额的单个产品的销售额。\n  切片（slicing）和切块（dicing）：用户可以从 OLAP 多维数据集中取出（切片）一组特定的数据，并从不同的角度查看（切块）切片。这些角度有时被称为维度（例如按销售人员、按日期、按客户、按产品或按地区查看相同的销售情况等）。\n  传统行式数据库中，处于同一行中的数据总是被物理的存在一起。列式数据库总是将同一列的数据存储在一起，不同列的数据分开存储。\n行式数据库：mysql，pg\n列式数据库：vertica，druid\nOLAP 的关键特征  大多是读请求 数据总是以相当大的批（\u0026gt;1000w）进行写入 不修改已经添加的数据 每次查询都从数据库中读取大量的行，但是同时又仅需要少量的列 宽表，即每个表包含大量的列 较少的查询（通常每台服务器每秒数百个查询或更少） 对于简单的查询，允许延迟大约 50ms 列中的数据相对较小：数字和短字符串 处理单个查询时需要高吞吐量（每个服务器每秒高达数十亿行） 事务不是必须的 对数据一致性要求低 每一个查询除了一个大表外都很小 查询结果明显小于数据源，换句话说，数据被过滤或者聚合之后能够被放在单台服务器的内存中  列式数据库更适合 OLAP 场景 Input/Output  分析类的查询，通常只需要读取表的一小部分列。 数据总是打包成批量读取，列压缩更容易 IO 降低了  CPU 由于执行一个查询需要处理大量的行，因此在整个 Vector 上执行所有操作将比在每一行上执行所有操作更加高效。同时这将有助于实现一个几乎没有调用成本的查询引擎。\n Vector 引擎 代码生成  为了提高 CPU 效率，查询语言必须是声明型的(SQL 或 MDX)， 或者至少一个 Vector(J，K)。 查询应该只包含隐式循环，允许进行优化。","title":"clickhouse"},{"content":"https://mubu.com/doc/oHlgG0FSu0\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-29/","summary":"https://mubu.com/doc/oHlgG0FSu0","title":"每日学习 2"},{"content":"开言英语 极客时间 编译原理之美 语义分析（下）：如何做上下文相关情况的处理  语义分析的本质，就是针对上下文相关的情况做处理。  引用消解：不同作用域里可能有相同名称的变量，必须找到正确的那个，这个过程就是引用消解。  函数引用消解 命名空间引用消解   左值和右值  左值取的是变量的地址或者说是变量的引用，获得地址之后，我们就可以把新值写进去。 右值就是我们常说的值。 不是所有的表达式都能生成一个合格的左值。   属性计算  上下文分析或者说语义分析的一种算法。 属性文法的主要思路是计算机科学的重要开拓者，是在上下文无关文法的基础上做了一些增强，使之可以计算属性值。   过程  类型和作用域解析 类型的消解 引用的消解和 S 属性的类型推导 做类型检查 做一些语义合法性检查      趣谈 Linux 操作系统 Namespace 技术：内部创业公司应该独立运营 为了隔离不同类型的资源，Linux 内核里面有如下几种不同类型的 namespace：\n UTS，表示不同的 namespace 可以配置不同的 hostname User，可以配置不同的用户和组 Mount，文件系统挂载点是隔离的 PID，有完全独立的 pid Network，有独立的网络协议栈  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E6%AF%8F%E6%97%A5%E5%AD%A6%E4%B9%A0-2019-09-24/","summary":"开言英语 极客时间 编译原理之美 语义分析（下）：如何做上下文相关情况的处理  语义分析的本质，就是针对上下文相关的情况做处理。  引用消解：不同作用域里可能有相同名称的变量，必须找到正确的那个，这个过程就是引用消解。  函数引用消解 命名空间引用消解   左值和右值  左值取的是变量的地址或者说是变量的引用，获得地址之后，我们就可以把新值写进去。 右值就是我们常说的值。 不是所有的表达式都能生成一个合格的左值。   属性计算  上下文分析或者说语义分析的一种算法。 属性文法的主要思路是计算机科学的重要开拓者，是在上下文无关文法的基础上做了一些增强，使之可以计算属性值。   过程  类型和作用域解析 类型的消解 引用的消解和 S 属性的类型推导 做类型检查 做一些语义合法性检查      趣谈 Linux 操作系统 Namespace 技术：内部创业公司应该独立运营 为了隔离不同类型的资源，Linux 内核里面有如下几种不同类型的 namespace：\n UTS，表示不同的 namespace 可以配置不同的 hostname User，可以配置不同的用户和组 Mount，文件系统挂载点是隔离的 PID，有完全独立的 pid Network，有独立的网络协议栈  ","title":"每日学习-2019-09-24"},{"content":"折腾一下 tmux\n安装 brew install tmux 概念  session：理解为一个会话，持久保存工作状态。 window：可以理解为我们常说的 tab 页。 pane：一个 window 被分成若干个 pane，理解为 iterm 的分屏。  session 新建\ntmux new -s your-session-name 断开\ntmux detach 恢复\ntmux attach-session -t your-session-name 或者 tmux a -t your-session-name 关闭\n kill-server kill-session kill-window kill-pane  tmux kill-session -t your-session-name tmux kill-server 查看\ntmux list-session tmux ls tmux 的基础配置 prefix 是 tmux 的前缀键，默认是 ctrl+b 。只有按下前缀键，才会激活 tmux，然后再按其他的键进行 tmux 操作。这样可以避免与其他应用的快捷键进行冲突。\n配置前缀 需要去 tmux.conf 中去配置\n分屏 水平分屏：prefix+\u0026quot;，前缀键加引号 垂直分屏：prefix+%，前缀键加百分号\n","permalink":"https://zhenfeng-zhu.github.io/posts/tmux/","summary":"折腾一下 tmux\n安装 brew install tmux 概念  session：理解为一个会话，持久保存工作状态。 window：可以理解为我们常说的 tab 页。 pane：一个 window 被分成若干个 pane，理解为 iterm 的分屏。  session 新建\ntmux new -s your-session-name 断开\ntmux detach 恢复\ntmux attach-session -t your-session-name 或者 tmux a -t your-session-name 关闭\n kill-server kill-session kill-window kill-pane  tmux kill-session -t your-session-name tmux kill-server 查看\ntmux list-session tmux ls tmux 的基础配置 prefix 是 tmux 的前缀键，默认是 ctrl+b 。只有按下前缀键，才会激活 tmux，然后再按其他的键进行 tmux 操作。这样可以避免与其他应用的快捷键进行冲突。\n配置前缀 需要去 tmux.conf 中去配置","title":"tmux"},{"content":"突然搞明白了 crystal 的 vscode 插件的正确使用姿势，记录一下。\n安装 crystal brew install crystal 安装 vscode 插件 https://marketplace.visualstudio.com/items?itemName=faustinoaq.crystal-lang\n安装 scry scry 是 crystal 的 language server 的 client 工具，在本地安装 scry 就可以做到代码跳转了。\n$ git clone https://github.com/crystal-lang-tools/scry.git $ cd scry $ shards build -v Dependencies are satisfied Building: scry crystal build -o /Users/lucas/Documents/demos/crystal/scry/bin/scry src/scry.cr /Users/lucas/Documents/demos/crystal/scry/bin/scry 就是编译出来的二进制的路径\n配置插件 \u0026#34;crystal-lang.compiler\u0026#34;: \u0026#34;crystal\u0026#34;, \u0026#34;crystal-lang.server\u0026#34;: \u0026#34;/Users/lucas/Documents/demos/crystal/scry/bin/scry\u0026#34;, \u0026#34;crystal-lang.maxNumberOfProblems\u0026#34;: 20, \u0026#34;crystal-lang.mainFile\u0026#34;: \u0026#34;${workspaceRoot}/src/main.cr\u0026#34;, \u0026#34;crystal-lang.processesLimit\u0026#34;: 5, \u0026#34;crystal-lang.hover\u0026#34;: true, \u0026#34;crystal-lang.problems\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;crystal-lang.implementations\u0026#34;: true, \u0026#34;crystal-lang.completion\u0026#34;: true, \u0026#34;crystal-lang.logLevel\u0026#34;: \u0026#34;info\u0026#34;, 把上面的配置加到 vscode 的 settings 文件中，就可以愉快的开发啦。\n","permalink":"https://zhenfeng-zhu.github.io/posts/crystal%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","summary":"突然搞明白了 crystal 的 vscode 插件的正确使用姿势，记录一下。\n安装 crystal brew install crystal 安装 vscode 插件 https://marketplace.visualstudio.com/items?itemName=faustinoaq.crystal-lang\n安装 scry scry 是 crystal 的 language server 的 client 工具，在本地安装 scry 就可以做到代码跳转了。\n$ git clone https://github.com/crystal-lang-tools/scry.git $ cd scry $ shards build -v Dependencies are satisfied Building: scry crystal build -o /Users/lucas/Documents/demos/crystal/scry/bin/scry src/scry.cr /Users/lucas/Documents/demos/crystal/scry/bin/scry 就是编译出来的二进制的路径\n配置插件 \u0026#34;crystal-lang.compiler\u0026#34;: \u0026#34;crystal\u0026#34;, \u0026#34;crystal-lang.server\u0026#34;: \u0026#34;/Users/lucas/Documents/demos/crystal/scry/bin/scry\u0026#34;, \u0026#34;crystal-lang.maxNumberOfProblems\u0026#34;: 20, \u0026#34;crystal-lang.mainFile\u0026#34;: \u0026#34;${workspaceRoot}/src/main.cr\u0026#34;, \u0026#34;crystal-lang.processesLimit\u0026#34;: 5, \u0026#34;crystal-lang.hover\u0026#34;: true, \u0026#34;crystal-lang.problems\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;crystal-lang.implementations\u0026#34;: true, \u0026#34;crystal-lang.completion\u0026#34;: true, \u0026#34;crystal-lang.logLevel\u0026#34;: \u0026#34;info\u0026#34;, 把上面的配置加到 vscode 的 settings 文件中，就可以愉快的开发啦。","title":"crystal 开发环境"},{"content":"关注 crystal 也有一段时间了，看到多线程的 pr 已经提了，今天简单写一下。\n Fast as C, Slick as Ruby\n 语法 crystal 的语法和 Ruby 比较类似。\n# A very basic HTTP server require \u0026#34;http/server\u0026#34; server = HTTP::Server.new do |context| context.response.content_type = \u0026#34;text/plain\u0026#34; context.response.print \u0026#34;Hello world, got #{context.request.path}!\u0026#34; end puts \u0026#34;Listening on http://127.0.0.1:8080\u0026#34; server.listen(8080) 类型系统 crystal 的一大卖点就是静态类型系统，但是写起来又和脚本语言类似。\ndef shout(x) # Notice that both Int32 and String respond_to `to_s` x.to_s.upcase end foo = ENV[\u0026#34;FOO\u0026#34;]? || 10 typeof(foo) # =\u0026gt; (Int32 | String) typeof(shout(foo)) # =\u0026gt; String 空引用检查 crystal 可以在编译的时候检查空引用，避免出现空指针异常。\nif rand(2) \u0026gt; 0 my_string = \u0026#34;hello world\u0026#34; end puts my_string.upcase 如果运行上述的代码，执行结果如下：\n$ crystal hello_world.cr Error in hello_world.cr:5: undefined method \u0026#39;upcase\u0026#39; for Nil (compile-time type is (String | Nil)) puts my_string.upcase 宏 另一个重要的特性是宏。通过宏，可以实现向 ruby 那么强大的元编程。\nclass Object def has_instance_var?(name) : Bool {{ @type.instance_vars.map \u0026amp;.name.stringify }}.includes? name end end person = Person.new \u0026#34;John\u0026#34;, 30 person.has_instance_var?(\u0026#34;name\u0026#34;) #=\u0026gt; true person.has_instance_var?(\u0026#34;birthday\u0026#34;) #=\u0026gt; false 并发 crystal 的并发是通过绿色线程实现的，即 fibers。和 Go 的并发模式很像，也是基于 channel 的 CSP 模型。\nchannel = Channel(Int32).new total_lines = 0 files = Dir.glob(\u0026#34;*.txt\u0026#34;) files.each do |f| spawn do lines = File.read(f).lines.size channel.send lines end end files.size.times do total_lines += channel.receive end puts total_lines C 绑定 C 语言一般用来实现比较底层的系统，而且 C 的生态丰富，一般现代语言都会提供 C 绑定，来复用 C 的生态。\n# Fragment of the BigInt implementation that uses GMP @[Link(\u0026#34;gmp\u0026#34;)] lib LibGMP alias Int = LibC::Int alias ULong = LibC::ULong struct MPZ _mp_alloc : Int32 _mp_size : Int32 _mp_d : ULong* end fun init_set_str = __gmpz_init_set_str(rop : MPZ*, str : UInt8*, base : Int) : Int fun cmp = __gmpz_cmp(op1 : MPZ*, op2 : MPZ*) : Int end struct BigInt \u0026lt; Int def initialize(str : String, base = 10) err = LibGMP.init_set_str(out @mpz, str, base) raise ArgumentError.new(\u0026#34;invalid BigInt: #{str}\u0026#34;) if err == -1 end def \u0026lt;=\u0026gt;(other : BigInt) LibGMP.cmp(mpz, other) end end 依赖管理 任何一个偏工程性的语言，都会提供一个包管理系统。crystal 的包管理是 shards，其实和 go module 类似。这种项目级别的包管理其实更为实用一些。\n但是 go 的任何一个项目，其实都可以是一个包，crystal 还是会有一些限制的。\nname: my-project version: 0.1 license: MIT crystal: 0.21.0 dependencies: mysql: github: crystal-lang/crystal-mysql version: ~\u0026gt; 0.3.1 ","permalink":"https://zhenfeng-zhu.github.io/posts/crystal%E7%AE%80%E4%BB%8B/","summary":"关注 crystal 也有一段时间了，看到多线程的 pr 已经提了，今天简单写一下。\n Fast as C, Slick as Ruby\n 语法 crystal 的语法和 Ruby 比较类似。\n# A very basic HTTP server require \u0026#34;http/server\u0026#34; server = HTTP::Server.new do |context| context.response.content_type = \u0026#34;text/plain\u0026#34; context.response.print \u0026#34;Hello world, got #{context.request.path}!\u0026#34; end puts \u0026#34;Listening on http://127.0.0.1:8080\u0026#34; server.listen(8080) 类型系统 crystal 的一大卖点就是静态类型系统，但是写起来又和脚本语言类似。\ndef shout(x) # Notice that both Int32 and String respond_to `to_s` x.to_s.upcase end foo = ENV[\u0026#34;FOO\u0026#34;]? || 10 typeof(foo) # =\u0026gt; (Int32 | String) typeof(shout(foo)) # =\u0026gt; String 空引用检查 crystal 可以在编译的时候检查空引用，避免出现空指针异常。","title":"crystal 简介"},{"content":"Socket 网络模型 osi 七层模型  应用层 表示层 会话层 传输层 网络层 数据链路层 物理层  对应的 tcpip 就是  应用层  dns http   传输层  icmp tcp udp   ip 层  ipv4 ipv6   mac 层  arp vlan   物理层  Ethernet    为什么要分层 因为网络环境过于复杂，不是一个能够集中控制的体系。全球的服务器和设备各有各的体系，但是可以通过同一套网络协议栈切分成多个层次和组合，来满足不同设备之间的通信需求。\n二层到四层，即 mac、ip 和传输等层都是 Linux 内核中处理。应用层的如浏览器、Nginx 和 Tomcat 等都是用户态的。\n传输层的 tcp 和 udp 里都有端口的概念，不同应用监听不同的段即可。\n应用层和内核的互通机制，就是通过 socket 系统调用。其实 socket 哪一层都不属于，它是属于操作系统的概念，而不是网络分层的概念。因为操作系统把二层到四层的处理代码在内核里，应用层的处理代码让应用自己做，两者需要跨内核态和用户态进行通信，这个就是 socket。\nTCP 和 UDP 的区别  tcp 是面向连接的，udp 是面向无连接的 tcp 提供可靠交付，无差错、不丢失、不重复、并且按序到达。udp 不提供可靠交付，可能丢失，不按顺序。 tcp 是面向字节流的，发送的是一个流，无头无尾。udp 是数据报文的，一个一个发送。 tcp 可以提供流量控制和拥塞控制，可以防止对端被压垮，也防止网络被压垮。  所谓的连接，指两端的数据结构状态的协同，两边状态对的上，符合 tcp 协议的规则，就认为连接是存在的，否则就是断掉的。\n所谓的建立连接，其实是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态。并用这样的数据结构来保证面向连接的特性。tcp 无法左右中间的任何通路，也没有什么虚拟的连接。\n所谓的可靠，也是两端的数据结构做的事情。不丢失其实是数据结构在“点名”，顺序到达是数据结构在“排序”，面向数据流其实是数据结构将零散的包，按照顺序捏成一个流发给应用层。\n所谓的流量控制和拥塞控制，其实就是根据收到的对端的网络包，调整两端的数据结构状态。\nsocket 函数 int socket(int domain, int type, int protocol) socket 函数用于创建一个 socket 文件描述符。\n domain  使用什么 ip 层的协议。AF_INET 标识 ipv4，AF_INET6 标识 ipv6。   type  socket 的类型。 SOCK_STREAM，tcp 流的 SOCK_DGRAM，udp 报文的 SOCK_RAW，可以直接操作 ip 层，或非 tcp 和 udp 类型的   protocol  协议 IPPROTO_TCP, IPPROTO_UDP    ","permalink":"https://zhenfeng-zhu.github.io/posts/socket/","summary":"Socket 网络模型 osi 七层模型  应用层 表示层 会话层 传输层 网络层 数据链路层 物理层  对应的 tcpip 就是  应用层  dns http   传输层  icmp tcp udp   ip 层  ipv4 ipv6   mac 层  arp vlan   物理层  Ethernet    为什么要分层 因为网络环境过于复杂，不是一个能够集中控制的体系。全球的服务器和设备各有各的体系，但是可以通过同一套网络协议栈切分成多个层次和组合，来满足不同设备之间的通信需求。\n二层到四层，即 mac、ip 和传输等层都是 Linux 内核中处理。应用层的如浏览器、Nginx 和 Tomcat 等都是用户态的。\n传输层的 tcp 和 udp 里都有端口的概念，不同应用监听不同的段即可。\n应用层和内核的互通机制，就是通过 socket 系统调用。其实 socket 哪一层都不属于，它是属于操作系统的概念，而不是网络分层的概念。因为操作系统把二层到四层的处理代码在内核里，应用层的处理代码让应用自己做，两者需要跨内核态和用户态进行通信，这个就是 socket。","title":"socket"},{"content":"Diagnostics go 提供了一系列诊断逻辑和性能问题的工具。\n profiling 分析 tracing 跟踪 debuging 调试 运行时统计信息和事件  Profiling profiling 信息可以在 go test 或者 net/http/pprof 包的时候使用。\nruntime/pprof 包有：\n cpu  主动消费 cpu 周期所花费的时间，不包括睡眠或者 io 等待   heap  报告内存分配采样； 当前或历史内存使用状况 检测内存泄露   threadcreate  报告创建新的系统线程   goroutine  当前所有协程的堆栈跟踪   block  显示 goroutine 阻塞等待同步原语的位置。 默认不开启，使用 runtime.SetBlockProfileRate 启用   mutex  报告锁竞争。 如果认为自己的程序因为互斥锁导致 cpu 不能充分利用的时候，使用这个。 默认也是不开启，使用 runtime.SetMutexProfileFraction 启用。    其他可用的的性能分析工具\nLinux 使用https://perf.wiki.kernel.org/index.php/Tutorial，perf 可以分析 cgo/SWIG 代码和系统内核。\nmac 上使用 https://developer.apple.com/library/content/documentation/DeveloperTools/Conceptual/InstrumentsUserGuide/ 就足够了。\n分析线上处于生产状态服务\n在生产上分析程序也是没问题的，但是开启某些指标会增加成本。\n可视化分析数据\ngo 提供了很多可视化的工具，参考https://blog.golang.org/profiling-go-programs\n也可以创建自定义的 profil 文件：参考https://golang.org/pkg/runtime/pprof/#Profile\n也可以自定义修改 pprof 程序监听的端口和路径，参考：\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/http/pprof\u0026#34; ) func main() { mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/custom_debug_path/profile\u0026#34;, pprof.Profile) log.Fatal(http.ListenAndServe(\u0026#34;:7777\u0026#34;, mux)) } ","permalink":"https://zhenfeng-zhu.github.io/posts/go%E8%BF%9B%E9%98%B6/","summary":"Diagnostics go 提供了一系列诊断逻辑和性能问题的工具。\n profiling 分析 tracing 跟踪 debuging 调试 运行时统计信息和事件  Profiling profiling 信息可以在 go test 或者 net/http/pprof 包的时候使用。\nruntime/pprof 包有：\n cpu  主动消费 cpu 周期所花费的时间，不包括睡眠或者 io 等待   heap  报告内存分配采样； 当前或历史内存使用状况 检测内存泄露   threadcreate  报告创建新的系统线程   goroutine  当前所有协程的堆栈跟踪   block  显示 goroutine 阻塞等待同步原语的位置。 默认不开启，使用 runtime.SetBlockProfileRate 启用   mutex  报告锁竞争。 如果认为自己的程序因为互斥锁导致 cpu 不能充分利用的时候，使用这个。 默认也是不开启，使用 runtime.SetMutexProfileFraction 启用。    其他可用的的性能分析工具","title":"go 进阶"},{"content":"MySQL 基本架构 客户端\nserver 层\n  连接器：管理连接，权限验证\n  查询缓存：命中规则，直接返回结果 8.0 之后全部删除了这个模块\n  分析器：词法分析，语法分析\n  优化器：执行计划生成，索引选择\n  执行器：操作引擎，返回结果\n  存储引擎：存储数据，提供读写接口\n数据库中的长连接指连接成功之后，如果客户端持续有请求，则一直使用同一个连接。短连接是指每次执行完很少的几次查询之后就断开连接，下次再重新建立。\n如果全部使用长连接，会导致 mysql 内存涨的很快，可能出现 OOM，因此要定期断开长连接，或者在执行一个比较大的操作之后，执行 mysql_reset_connection 重置一下。\n日志系统 redo log 重做日志 redo log 是 innodb 引擎特有的。物理日志，记录的是某个数据页上做了什么修改。循环写入。\nWAL 技术：Write-Ahead Logging：关键点就是先写日志，再写磁盘。当一条记录更新时，先把记录写到 redolog 中，更新到内存，这时这个更新操作就成功了。然后 innodb 引擎就会在适当的时候，将这个操作记录更新到磁盘中。因此在数据库异常重启的时候，之前的提交的记录不会丢失。\nbinlog 归档日志 binlog 是 server 层实现的，所有的引擎都可以使用。binlog 是逻辑日志，记录的是这个语句的原始逻辑。binlog 是写到一定大小后，切换下一个，不会覆盖以前的日志。\n因此一个 update 操作就是：\n找到该行\n判断数据页是否在内存中，如果是返回行数据，否则从磁盘读入到内存中。\n将值进行更新，写入新行\n新行更新到内存\n写入 redolog，处于 prepare 阶段\n写入 binlog\n提交事务，处于 commit 阶段。\n这个就是两阶段提交。\n事务隔离 Isolation：隔离性\n脏读，幻读，不可重复读\n隔离的越严实，效率越低。\nSQL 的标准隔离级别：\n读未提交：一个事务没提交的时候，它做的变更就能被别的事务看到\n读提交：一个事务提交之后，做的变更才能被其他事务看到\n可重复读：一个事务执行时看到的数据，总是跟这个事务启动时看到的数据时一致的。\n串行化：顾名思义，对于同一行记录，写会加写锁，读也会加读锁。当读写锁冲突时，后访问的事务，必须等前一个事务完成。\n在实现的时候，数据库会创建一个视图，访问的时候以视图的逻辑结果为准。\n 可重复读，这个视图是在事务启动时创建，整个事务存在期间都用这个视图。 读提交，这个视图在每个 sql 语句开始执行的时候创建 读未提交直接返回记录的最新值，没有视图的概念。 串行化是用加锁的方式。  mysql 在每条记录更新的时候，都会记录一条回滚操作，记录上的最新值都可以通过回滚操作，得到前一个状态的值。当没有事务需要用到回滚日志时，就会被删除。所以不建议使用长事务，这样会占用存储空间和锁。\nmysql 启动事务的方式\n 显式启动：begin 或者 start transaction。配套的提交语句是 commit，回滚语句是 rollback。 set autocommit=0 这个命令会将这个线程的自动提交关闭。意味着如果只执行一个 select 语句，事务就启动了，而且不会自动关闭，除非主动执行 commit 或者 rollback，或者断开连接。  因此一般 set autocommit=1，打开显示启动的模式。\n","permalink":"https://zhenfeng-zhu.github.io/posts/mysql/","summary":"MySQL 基本架构 客户端\nserver 层\n  连接器：管理连接，权限验证\n  查询缓存：命中规则，直接返回结果 8.0 之后全部删除了这个模块\n  分析器：词法分析，语法分析\n  优化器：执行计划生成，索引选择\n  执行器：操作引擎，返回结果\n  存储引擎：存储数据，提供读写接口\n数据库中的长连接指连接成功之后，如果客户端持续有请求，则一直使用同一个连接。短连接是指每次执行完很少的几次查询之后就断开连接，下次再重新建立。\n如果全部使用长连接，会导致 mysql 内存涨的很快，可能出现 OOM，因此要定期断开长连接，或者在执行一个比较大的操作之后，执行 mysql_reset_connection 重置一下。\n日志系统 redo log 重做日志 redo log 是 innodb 引擎特有的。物理日志，记录的是某个数据页上做了什么修改。循环写入。\nWAL 技术：Write-Ahead Logging：关键点就是先写日志，再写磁盘。当一条记录更新时，先把记录写到 redolog 中，更新到内存，这时这个更新操作就成功了。然后 innodb 引擎就会在适当的时候，将这个操作记录更新到磁盘中。因此在数据库异常重启的时候，之前的提交的记录不会丢失。\nbinlog 归档日志 binlog 是 server 层实现的，所有的引擎都可以使用。binlog 是逻辑日志，记录的是这个语句的原始逻辑。binlog 是写到一定大小后，切换下一个，不会覆盖以前的日志。\n因此一个 update 操作就是：\n找到该行\n判断数据页是否在内存中，如果是返回行数据，否则从磁盘读入到内存中。\n将值进行更新，写入新行\n新行更新到内存\n写入 redolog，处于 prepare 阶段\n写入 binlog\n提交事务，处于 commit 阶段。","title":"mysql"},{"content":"graphql 经常被认为是聚焦于前端的技术。\n核心概念 SDL：schema definition language（模式定义语言） 如：\ntype Person{ name: String! age: Int! } 这个类型有两个字段，name 和 age，他们的类型是 String 和 Int。！的意思代表他们是必需的。\ntype Post{ title: String! author: Person! } 接下来的 Post 也有两个字段，其中 Person 也是可以作为一个类型。\n也可以这样，在 Person 中添加一个 post：\ntype Person{ name: String! age: Int! posts: [Post!]! } 通过 Query 获取数据 基本查询 客户端发送下面的数据给服务器\n{ allPersons { name } } allPersons 是根字段（root field），它下面的成为查询的 payload，这里仅包含了一个 name。\n服务器返回的结果会是这样的：\n{ \u0026#34;allPersons\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Johnny\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Sarah\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34; } ] } 可以看到只返回了 name 字段，age 字段是不会返回的。\n如果使用如下的 payload 就会返回：\n{ allPersons { name age } } 还可以查询 posts 中的 title：\n{ allPersons { name age posts { title } } } 带参数查询 在 graphql 中每个字段都有 0 或者更多个参数。比如 allPerson 有一个 last 参数，只返回最后两个人的信息，这里就是查询的语句：\n{ allPersons(last: 2) { name } } 通过 Mutation 写数据  创建 更新 删除  mutation 和 query 类似，只是需要加上 mutation 关键字。如：\nmutation { createPerson(name: \u0026#34;Bob\u0026#34;, age: 36) { name age } } mutation 也有一个根字段，叫 createPerson。我们知道这个字段有两个参数 name 和 age。返回值会像这样：\n{ \u0026#34;data\u0026#34;: { \u0026#34;createPerson\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;, \u0026#34;age\u0026#34;: 36 } } } graphql 会给每个记录新增一个唯一的 ID 字段，我们也可以这样设置 Person 类型：\ntype Person { id: ID! name: String! age: Int! } 然后当一个新的 Person 对象创建时，就可以访问到 id。\n通过订阅实时更新 graphql 提供了实时订阅更新。\n当客户端订阅一个事件的时候，将会保持一个和服务器的稳定连接，当有变化时会告诉客户端。\nsubscription { newPerson { name age } } 因此当有个用户创建或者修改时都会告诉客户端：\n{ \u0026#34;newPerson\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Jane\u0026#34;, \u0026#34;age\u0026#34;: 23 } } 定义一个模式 有几个特殊的根类型：\ntype Query { ... } type Mutation { ... } type Subscription { ... } API 的根字段都是在上面这三个之下，如：\ntype Query { allPersons: [Person!]! } allPersons 也可以有参数：\ntype Query { allPersons(last: Int): [Person!]! } 类似的 mutation 也是：\ntype Mutation { createPerson(name: String!, age: Int!): Person! } 订阅也是：\ntype Subscription { newPerson: Person! } 把他们放在一起就是：\ntype Query { allPersons(last: Int): [Person!]! } type Mutation { createPerson(name: String!, age: Int!): Person! } type Subscription { newPerson: Person! } type Person { name: String! age: Int! posts: [Post!]! } type Post { title: String! author: Person! } 架构图 graphql 直连数据库\ngraphql 连接层连接多个服务\ngraphql 混连数据库和服务\n解析函数 每个字段其实都有一个解析器，叫 resolver。\n当服务器收到一个请求时，会调用字段的 resolver 函数，一旦 resolver 函数有返回，服务器就会把数据包装成要返回的字段。\n有这样一个类型：\ntype Query { author(id: ID!): Author } type Author { posts: [Post] } type Post { title: String content: String } 当执行一个 query 的时候：\nquery { author(id: \u0026#34;abc\u0026#34;) { posts { title content } } } 会以如下的方式执行：\nQuery.author(root, { id: \u0026#39;abc\u0026#39; }, context) -\u0026gt; author Author.posts(author, null, context) -\u0026gt; posts for each post in posts Post.title(post, null, context) -\u0026gt; title Post.content(post, null, context) -\u0026gt; content 实战 ","permalink":"https://zhenfeng-zhu.github.io/posts/graphql/","summary":"graphql 经常被认为是聚焦于前端的技术。\n核心概念 SDL：schema definition language（模式定义语言） 如：\ntype Person{ name: String! age: Int! } 这个类型有两个字段，name 和 age，他们的类型是 String 和 Int。！的意思代表他们是必需的。\ntype Post{ title: String! author: Person! } 接下来的 Post 也有两个字段，其中 Person 也是可以作为一个类型。\n也可以这样，在 Person 中添加一个 post：\ntype Person{ name: String! age: Int! posts: [Post!]! } 通过 Query 获取数据 基本查询 客户端发送下面的数据给服务器\n{ allPersons { name } } allPersons 是根字段（root field），它下面的成为查询的 payload，这里仅包含了一个 name。\n服务器返回的结果会是这样的：\n{ \u0026#34;allPersons\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Johnny\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Sarah\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34; } ] } 可以看到只返回了 name 字段，age 字段是不会返回的。","title":"graphql"},{"content":" 短变量名称在声明和上次使用之间的距离很短时效果很好。 长变量名称需要证明自己的合理性; 名称越长，需要提供的价值越高。冗长的名称与页面上的重量相比，信号量较小。 请勿在变量名称中包含类型名称。 常量应该描述它们持有的值，而不是该如何使用。 对于循环和分支使用单字母变量，参数和返回值使用单个字，函数和包级别声明使用多个单词 方法、接口和包使用单个词。 请记住，包的名称是调用者用来引用名称的一部分，因此要好好利用这一点。  变量的名称应描述其内容，而不是内容的类型。\n典型错误：\nvar usersMap map[string]*User 如果users的描述性都不够用，那么usersMap也不会。\n声明变量但没有初始化时，请使用 var。\n在声明和初始化时，使用:=。\n关于变量和常量的注释应描述其内容而非其目的  任何既不明显也不简短的公共功能必须予以注释。 无论长度或复杂程度如何，对库中的任何函数都必须进行注释  在编写函数之前，请编写描述函数的注释。 如果你发现很难写出注释，那么这就表明你将要编写的代码很难理解。\n以包所提供的内容来命名，而不是它包含的内容。\n避免使用类似base，common或util的包名称 尽早return而不是深度嵌套 使用internal包来减少公共 API 不鼓励使用nil作为参数 首选可变参数函数而非[]T参数 通过消除错误来消除错误处理 使用github.com/pkg/errors包装errors 永远不要启动一个停止不了的 goroutine ","permalink":"https://zhenfeng-zhu.github.io/posts/go-best-practice/","summary":" 短变量名称在声明和上次使用之间的距离很短时效果很好。 长变量名称需要证明自己的合理性; 名称越长，需要提供的价值越高。冗长的名称与页面上的重量相比，信号量较小。 请勿在变量名称中包含类型名称。 常量应该描述它们持有的值，而不是该如何使用。 对于循环和分支使用单字母变量，参数和返回值使用单个字，函数和包级别声明使用多个单词 方法、接口和包使用单个词。 请记住，包的名称是调用者用来引用名称的一部分，因此要好好利用这一点。  变量的名称应描述其内容，而不是内容的类型。\n典型错误：\nvar usersMap map[string]*User 如果users的描述性都不够用，那么usersMap也不会。\n声明变量但没有初始化时，请使用 var。\n在声明和初始化时，使用:=。\n关于变量和常量的注释应描述其内容而非其目的  任何既不明显也不简短的公共功能必须予以注释。 无论长度或复杂程度如何，对库中的任何函数都必须进行注释  在编写函数之前，请编写描述函数的注释。 如果你发现很难写出注释，那么这就表明你将要编写的代码很难理解。\n以包所提供的内容来命名，而不是它包含的内容。\n避免使用类似base，common或util的包名称 尽早return而不是深度嵌套 使用internal包来减少公共 API 不鼓励使用nil作为参数 首选可变参数函数而非[]T参数 通过消除错误来消除错误处理 使用github.com/pkg/errors包装errors 永远不要启动一个停止不了的 goroutine ","title":"go-best-practice"},{"content":"docker 利用 Linux 的 cgroups 和 namespace，构建一个沙箱运行环境。\ndocker 镜像 其实就是一个压缩包，这个压缩包是由一个完整的操作系统的所有文件目录构成，包含了这个应用运行所需要的所有依赖，所以本地开发环境和测试环境是一样的。\n解决了应用打包的根本性问题。\n容器编排 对 Docker 容器的一系列定义、配置和创建动作的管理\n 容器本身没有价值，有价值的是“容器编排”。\n 原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造一个“边界”。\n在创建一个容器进程的时候，指定了这个进程所需要启动的一组 Namespace 参数，这样容器就只能看到当前 Namespace 所限定的资源、文件、设备、状态或配置。\nCgroups 主要作用是为一个进程组设置资源上限，如 CPU、内存、磁盘和带宽等。也可以设置进程优先级，审计，挂起，重启等。\n因此，一个正在运行的 Docker 容器，其实就是一个启用了多个 Namespace 的应用进程，而这个进程能够使用的资源是由 Cgroups 来限制。\n挂载在容器根目录上，用来为容器进程提供隔离后执行环境的文件系统，就是容器镜像，rootfs。\n 启动 Namespace 配置 设置 Cgroups 参数 切换进程根目录 rootf  docker 镜像设计时，引入了层（layer），用户制作镜像的每一步操作都会生成一个层，也就是一个增量的 rootfs。AuFS，所以就有了共享层，镜像不用那么大。\n一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到进入这个进程所在的容器的目的，这正是 docker exec 的实现原理。\nvolume 机制，允许你将宿主机上指定的目录或文件，挂载到容器里面进行读取和修改操作。\n主要依赖 Linux 依赖三大技术  Namespace Cgroups rootfs  和虚拟机比较 虚拟机是通过硬件虚拟化功能，模拟一套操作系统所需要的各种硬件，如 CPU、内存、IO 设备等，然后安装一个新的操作系统。\ndocker 是利用 Linux 的 Namespace 原理，帮助用户启动的还是系统的应用进程，只是加了一些参数，限制其能看到的资源。因此相对于虚拟机资源消耗更小，而且轻量级，敏捷高性能。\n不过缺点就是隔离不彻底，多个容器进程公用宿主机操作系统内核。有些资源和对象不可以被 Namespace 化的，如时间。\nkubernetes 要解决的问题\n编排？调度？容器云？集群管理？\n master  kube-apiserver：API 服务 kube-scheduler：调度 kube-controller-manager：编排   node  kubelet：同容器运行时打交道。依赖于 CRI（container runtime interface 容器运行接口）远程调用接口，这个接口定义了容器运行时的各项核心操作。   etcd  运行在大规模集群中的各种任务之间，实际存在各种各样的关系。这些关系的处理，才是作业编排和管理系统最困难的地方。\nsudo\n 首先，通过一个编排对象，如 pod，job 或 cronjob 等，来描述你试图管理的应用； 然后，再为它定义一些服务对象，如 service，secret，autoscaler 等。这些对象，会负责具体的平台级功能。  这种使用方法，就是所谓的“声明式 API”。这种 API 对应的编排对象和服务对象，都是 k8s 项目中的 API 对象。\n简单使用 kubectl create -f 我的配置文件 pod 就是 k8s 世界中的应用，而一个应用可以由多个容器组成。\n使用一个 API 对象管理另一个 API 对象的方法，叫控制器模式。\n每个 API 对象都有一个 metadata 字段，这个字段是 API 对象的标识，即元数据。主要用到的是 labels，spec.selector.matchLabels 就是 k8s 过滤的规则。与 labels 同层级的是 annotations，这是由 k8s 所感兴趣的，而不是用户。\n一个 k8s 的 API 对象都有 metadata 和 spec 两个部分。前者放的是对象的元数据，对所有 API 对象来讲，这部分的字段和格式基本一样；而后者存放的是属于这个对象独有的定义，用来描述它所要表达的功能。\n$ kubectl create -f nginx-deployment.yaml $ kubectl get pods -l app=nginx NAME READY STATUS RESTARTS AGE nginx-deployment-67594d6bf6-9gdvr 1/1 Running 0 10m nginx-deployment-67594d6bf6-v6j7w 1/1 Running 0 10m $ kubectl describe pod nginx-deployment-67594d6bf6-9gdvr Name: nginx-deployment-67594d6bf6-9gdvr Namespace: default Priority: 0 PriorityClassName: \u0026lt;none\u0026gt; Node: node-1/10.168.0.3 Start Time: Thu, 16 Aug 2018 08:48:42 +0000 Labels: app=nginx pod-template-hash=2315082692 Annotations: \u0026lt;none\u0026gt; Status: Running IP: 10.32.0.23 Controlled By: ReplicaSet/nginx-deployment-67594d6bf6 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 1m default-scheduler Successfully assigned default/nginx-deployment-67594d6bf6-9gdvr to node-1 Normal Pulling 25s kubelet, node-1 pulling image \u0026#34;nginx:1.7.9\u0026#34; Normal Pulled 17s kubelet, node-1 Successfully pulled image \u0026#34;nginx:1.7.9\u0026#34; Normal Created 17s kubelet, node-1 Created container Normal Started 17s kubelet, node-1 Started container $ kubectl apply -f nginx-deployment.yaml # 修改 nginx-deployment.yaml 的内容 $ kubectl apply -f nginx-deployment.yaml 在命令行中，所有 key-value 格式的参数，都使用“=“而不是”：“表示。\n在 k8s 执行过程中，对 API 对象的所有重要操作，都会被记录在这个对象的 events 中。\n在线业务\nDeployment\nStatefunSet\nDaemonSet\n离线业务\nJob\nrestartPolicy 在 job 对象里只被允许设置为 never 和 onFailure；而在 Deployment 对象中，只被允许设置为 always。\n声明式 API 和 Kubernetes 编程范式 创建一个两个 Nginx 容器的步骤：\n首先写一个 Deployment 的 yaml 文件：\napiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 然后使用 kubectl create 命令在 Kubernetes 中创建一个 Deployment 对象：\nkubectl create -f nginx.yaml 这样两个 Nginx pod 就运行起来了。\n如果要更新的话，只需要修改 yaml 文件，然后使用 kubectl apply 命令更新，触发了滚动更新。\n这个 apply 命令就是声明式 API。\nistio 项目中，最根本的组件是运行在每个 pod 里的 envoy 容器。这个代理服务以 sidecar 容器的方式，把整个 pod 的进出流量接管下来。istio 的控制层的 pilot 组件，通过调用每个 envoy 的 API，实现微服务的治理。\n利用 Kubernetes 的 Admission Control，也叫：Initializer，先创建一个 Pod，然后 istio 就是在 pod 的 yaml 给 Kubernetes 之后，自动加上 envoy 的配置。\n 所谓的声明式，指的就是我只需要提交一个定义好的 API 对象来声明我所期望的状态是什么样子。 其次，声明式 API 允许有多个 API 写端，以 PATCH 的方式对 API 对象进行修改，而无需关心原始的 YAML 文件的内容。 最后，Kubernetes 基于对 API 对象的增删改查，在无需外界干预的情况下，完成对实际状态和期望状态的调谐。  一个 API 对象在 etcd 中完整路径是由：group（API 组），version（API 版本）和 Resource（API 资源类型）三个部分组成的。\napiVersion: batch/v2 kind: CronJob batch 是组，v2 是版本，CronJob 是类型。\n对于核心 API 对象：Pod，Node 等，不需要 group 的。非核心对象是需要组。\n匹配规则就是：\n/apis/batch/v2/CronJob\n  首先 yaml 文件被提交给了 APIServer\n过滤，授权，超时处理或审计等\n  进入路由流程\n根据 yaml，按照匹配规则去找\n  根据定义，按照 yaml 中的字段，创建一个对象\n  进行 Amission 和 Validation。\n  把验证过的对象，序列化存到 etcd 中\n  RBAC 基于角色的控制\nrole：角色，一组规则，定义 Kubernetes API 对象的操作权限\nsubject：被作用者，可以是人，也可以是机器，也可以是 Kubernetes 定义的用户\nrolebinding：定义被作用者和角色的绑定关系\nServiceAccount，会被自动创建分配一个 secret 对象。\n所谓角色就是一组权限规则列表，而我们分配这些权限的方式，就是通过创建 rolebinding 对象，将被作用者和权限列表进行绑定。\n另外，与之对应的 ClusterRole 和 ClusterRoleBinding，则是 Kubernetes 集群级别的 Role 和 RoleBinding，它们的作用范围不受 Namespace 限制。\n尽管被作用者有很多种（如 User、Group），但在我们平常使用的时候，最普遍的还是 ServiceAccount。\n网络模型 Veth Pair 常常被用作连接不同 Network Namespace 的网线。veth pair 虚拟设备。总是以两张虚拟网卡形式成对出现。并且，从一个网卡中发出的数据包，可以直接出现在另一张网卡上，哪怕这两个网卡在不同的 network Namespace 里。\n一旦一张虚拟网卡被插在网桥上，他就会变成该网桥的从设备。从设备会降级成为网桥的一个端口，不能处理数据包，只能接收流入的数据包交给对应的网桥。\n两个容器的虚拟网卡都插在宿主机的一个网桥上，这个网桥就扮演一个交换机的角色。当两个容器进行网络交互时，从一个容器的发出请求到宿主机，由于 Veth Pair 的机制，另一个容器就看到有数据流入。\n因此默认情况下，被限制在 network Namespace 的容器进程，实际就是通过 veth pair 设备+宿主机网桥的方式，实现了跟其他容器的数据交换。\n跨主通信，需要有一个集群公用的网桥，所有容器都连接到该网桥上，就可以相互通信，这就是 overlay network（覆盖网络）\n","permalink":"https://zhenfeng-zhu.github.io/posts/kubernetes/","summary":"docker 利用 Linux 的 cgroups 和 namespace，构建一个沙箱运行环境。\ndocker 镜像 其实就是一个压缩包，这个压缩包是由一个完整的操作系统的所有文件目录构成，包含了这个应用运行所需要的所有依赖，所以本地开发环境和测试环境是一样的。\n解决了应用打包的根本性问题。\n容器编排 对 Docker 容器的一系列定义、配置和创建动作的管理\n 容器本身没有价值，有价值的是“容器编排”。\n 原理 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造一个“边界”。\n在创建一个容器进程的时候，指定了这个进程所需要启动的一组 Namespace 参数，这样容器就只能看到当前 Namespace 所限定的资源、文件、设备、状态或配置。\nCgroups 主要作用是为一个进程组设置资源上限，如 CPU、内存、磁盘和带宽等。也可以设置进程优先级，审计，挂起，重启等。\n因此，一个正在运行的 Docker 容器，其实就是一个启用了多个 Namespace 的应用进程，而这个进程能够使用的资源是由 Cgroups 来限制。\n挂载在容器根目录上，用来为容器进程提供隔离后执行环境的文件系统，就是容器镜像，rootfs。\n 启动 Namespace 配置 设置 Cgroups 参数 切换进程根目录 rootf  docker 镜像设计时，引入了层（layer），用户制作镜像的每一步操作都会生成一个层，也就是一个增量的 rootfs。AuFS，所以就有了共享层，镜像不用那么大。\n一个进程，可以选择加入到某个进程已有的 Namespace 当中，从而达到进入这个进程所在的容器的目的，这正是 docker exec 的实现原理。\nvolume 机制，允许你将宿主机上指定的目录或文件，挂载到容器里面进行读取和修改操作。\n主要依赖 Linux 依赖三大技术  Namespace Cgroups rootfs  和虚拟机比较 虚拟机是通过硬件虚拟化功能，模拟一套操作系统所需要的各种硬件，如 CPU、内存、IO 设备等，然后安装一个新的操作系统。\ndocker 是利用 Linux 的 Namespace 原理，帮助用户启动的还是系统的应用进程，只是加了一些参数，限制其能看到的资源。因此相对于虚拟机资源消耗更小，而且轻量级，敏捷高性能。","title":"kubernetes"},{"content":"监视器\n监视器提供了一个外部世界和函数之间的非托管的通用接口。它的工作是收集从 API 网关来的 HTTP 请求，然后调用程序。监视器是一个小型的 Golang 服务——下图展示了它是如何工作的：\n 上图：一个小型的 web 服务，可以为每个传入的 HTTP 请求分配所需要的进程。\n 每个函数都需要嵌入这个二进制文件并将其作为ENTRYPOINT 或 CMD，实际上是把它作为容器的初始化进程。一旦你的进程被创建分支，监视器就会通过stdin 传递 HTTP 请求并从stdout中读取 HTTP 响应。这意味着你的程序无需知道 web 和 HTTP 的任何信息。\n轻松创建新函数 从 CLI 创建一个函数\n创建函数最简单的方法是使用 FaaS CLI 和模板。CLI 抽象了所有 Docker 的知识，使得你只需要编写所支持语言的 handler 文件即可。\n 你的第一个使用 OpenFaaS 的无服务器 Python 函数 阅读有关 FaaS CLI 的教程  深入研究 Package your function 打包你的函数\n如果你不想使用 CLI 或者现有的二进制文件或镜像，可以使用下面的方法去打包函数：\n 使用一个现有的或者一个新的 Docker 镜像作为基础镜像 FROM 通过curl 或 ADD https://从 Releases 页面 添加 fwatchdog 二进制文件 为每个你要运行的函数设置 fprocess(函数进程) 环境变量 Expose port 8080 暴露端口 8080 Set the CMD to fwatchdog 设置 CMD为fwatchdog  一个echo函数的示例 Dockerfile：\nFROM alpine:3.7 ADD https://github.com/openfaas/faas/releases/download/0.8.0/fwatchdog /usr/bin RUN chmod +x /usr/bin/fwatchdog # Define your binary here ENV fprocess=\u0026#34;/bin/cat\u0026#34; CMD [\u0026#34;fwatchdog\u0026#34;] Implementing a Docker healthcheck 实现一个 Docker 健康检查\nDocke 的健康检查不是必需的，但是它是最佳实践。这会确保监视器已经在 API 网关转发请求之前准备好接收请求。如果函数或者监视器遇到一个不可恢复的问题，Swarm 也会重启容器。\nHere is an example of the echo function implementing a healthcheck with a 5-second checking interval.\n下面是实现了一个具有 5 秒间隔的健康检查的echo函数示例：\nFROM functions/alpine ENV fprocess=\u0026#34;cat /etc/hostname\u0026#34; HEALTHCHECK --interval=5s CMD [ -e /tmp/.lock ] || exit 1 监视器进程早启动内部 Golang HTTP 服务的时候会在 /tmp/下面创建一个.lock 文件。[ -e file_name ]shell 命令可以检查文件是否存在。在 Windows 容器中，这是一个不合法的路径，所以你可能需要设置suppress_lock 环境变量。\n有关健康检查，请阅读我的 Docker Swarm 教程：\n 10 分钟内试用 Docker 的健康检查  环境变量重载:\n监视器可以通过环境变量来配置，你必须始终指定一个fprocess 变量\n高级/调整 (新)——子监视器和 HTTP 模式  部分的监视器  为每个请求创建一个新的进程分支具有进程隔离，可移植和简单的优点。任何进程都可以在没有任何附加代码的情况下变成一个函数。of-watchdog 可和 HTTP 模式是一种优化，这样就可以在所有请求之间维护一个单一的进程。\n新版本的监视器正在openfaas-incubator/of-watchdog上测试。\n这种重写主要是生成一个可以持续维护的结构。它将会替代现有的监视器，也会有二进制的释放版。\n使用 HTTP 头 HTTP 的头和其他请求信息以下面的格式注入到环境变量中：\nX-Forwarded-By`头变成了`Http_X_Forwarded_By  Http_Method - GET/POST etc Http_Method - GET/POST 等等 Http_Query - QueryString value Http_Query - 查询字符串的值 Http_ContentLength - gives the total content-length of the incoming HTTP request received by the watchdog. Http_ContentLength - 监视器收到的 HTTP 请求的内容长度。   默认情况下，通过cgi_headers 环境变量启用该行为。\n 以下是带有附加头和查询字符串的 POST 请求的示例：\n$ cgi_headers=true fprocess=env ./watchdog \u0026amp; 2017/06/23 17:02:58 Writing lock-file to: /tmp/.lock $ curl \u0026#34;localhost:8080?q=serverless\u0026amp;page=1\u0026#34; -X POST -H X-Forwarded-By:http://my.vpn.com 如果你再 Linux 系统下设置了fprocess 到 env中，会看到如下结果：\nHttp_User_Agent=curl/7.43.0 Http_Accept=*/* Http_X_Forwarded_By=http://my.vpn.com Http_Method=POST Http_Query=q=serverless\u0026amp;page=1 也可以使用GET请求：\ncurl \u0026#34;localhost:8080?action=quote\u0026amp;qty=1\u0026amp;productId=105\u0026#34; 监视器的输出如下：\nHttp_User_Agent=curl/7.43.0 Http_Accept=*/* Http_Method=GET Http_Query=action=quote\u0026amp;qty=1\u0026amp;productId=105 现在就可以在程序中使用 HTTP 状态来做决策了。\nHTTP 方法 监视器支持的 HTTP 方法有：\n带有请求体的：\n POST, PUT, DELETE, UPDATE  不带请求体的：\n GET   API 网关现在支持函数的 POST 路由。\n 请求响应的内容类型 默认情况下，监视器会匹配客户端的\u0026quot;Content-Type\u0026quot;。\n 如果客户端发送 Content-Type 为 application/json 的 json 形式的 post 请求，将会在响应的时候自动匹配。 如果客户端发送 Content-Type 为 text/plain 的 json 形式的 post 请求，响应也会自动匹配。  若要重载所有响应的 Content-Type ，需要设置content_type 环境变量。\nI don\u0026rsquo;t want to use the watchdog 我不想使用监视器 这种案例是 OpenFaaS 所不支持的，但是如果你的容器符合以下要求，那么 OpenFaaS 的网关和其他工具也会管理和伸缩服务。\n你需要提供一个锁文件 /tmp/.lock，以便业务流程系统可以在容器中运行健康检查。如果你正在使用 swarm，那么请确保在 Dockerfile 中提供HEALTHCHECK指令——在 faas存储库中有示例。\n 在 HTTP 之上暴露 TCP 端口 8080 创建/tmp/.lock 文件，或者在响应操作 tempdir 系统调用的任何位置。  调整自动伸缩 自动伸缩式从 1 个副本开始，以 5 个位一个单位进行升级：\n 1-\u0026gt;5 5-\u0026gt;10 10-\u0026gt;15 15-\u0026gt;20  你可以通过标签来覆盖一个函数 minimum 和 maximum 。\n如果要在 2 到 15 之间的话，请在部署的时候配置以下标签：\ncom.openfaas.scale.min: \u0026#34;2\u0026#34; com.openfaas.scale.max: \u0026#34;15\u0026#34; 这些标签是可选的\n禁用自动伸缩\n如果要禁用某个函数的自动伸缩，将最小和最大的副本数设置为相同的值，即“1”。\n同样也可以删除 AlertManager。\n","permalink":"https://zhenfeng-zhu.github.io/posts/watchdog/","summary":"监视器\n监视器提供了一个外部世界和函数之间的非托管的通用接口。它的工作是收集从 API 网关来的 HTTP 请求，然后调用程序。监视器是一个小型的 Golang 服务——下图展示了它是如何工作的：\n 上图：一个小型的 web 服务，可以为每个传入的 HTTP 请求分配所需要的进程。\n 每个函数都需要嵌入这个二进制文件并将其作为ENTRYPOINT 或 CMD，实际上是把它作为容器的初始化进程。一旦你的进程被创建分支，监视器就会通过stdin 传递 HTTP 请求并从stdout中读取 HTTP 响应。这意味着你的程序无需知道 web 和 HTTP 的任何信息。\n轻松创建新函数 从 CLI 创建一个函数\n创建函数最简单的方法是使用 FaaS CLI 和模板。CLI 抽象了所有 Docker 的知识，使得你只需要编写所支持语言的 handler 文件即可。\n 你的第一个使用 OpenFaaS 的无服务器 Python 函数 阅读有关 FaaS CLI 的教程  深入研究 Package your function 打包你的函数\n如果你不想使用 CLI 或者现有的二进制文件或镜像，可以使用下面的方法去打包函数：\n 使用一个现有的或者一个新的 Docker 镜像作为基础镜像 FROM 通过curl 或 ADD https://从 Releases 页面 添加 fwatchdog 二进制文件 为每个你要运行的函数设置 fprocess(函数进程) 环境变量 Expose port 8080 暴露端口 8080 Set the CMD to fwatchdog 设置 CMD为fwatchdog  一个echo函数的示例 Dockerfile：","title":"watchdog"},{"content":"queue-worker 源码分析 异步函数和同步函数 在 OpenFaaS 中同步调用函数时，将会连接到网关，直到函数成功返回才会关闭连接。同步调用是阻塞的。\n 网关的路由是：/function/\u0026lt;function_name\u0026gt; 必须等待 在结束的时候得到结果 明确知道是成功还是失败  异步函数会有一些差异：\n 网关的路由是：/async-function/\u0026lt;function_name\u0026gt; 客户端获得 202 的即时响应码 从 queue-worker 中调用函数 默认情况下，结果是被丢弃的。  查看 queue-worker 的日志 docker service logs -f func_queue-worker 利用 requestbin 和 X-Callback-Url 获取异步函数的结果 如果需要获得异步函数的结果，有两个方法：\n 更改代码，将结果返回给端点或者消息系统 利用内置的回调 内置的回调将会允许函数提供一个 url，queue-worker 会报告函数的成功或失败。 requestbin 会创建一个新的 bin，这是互联网的一个 url 地址，可以从这里获取函数的结果。  源码分析 依赖项 github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/faas go-nats 和 go-nats-streaming 是 nats 和 nats-streaming 的 go 版本的客户端。\nfaas 这个依赖其实是只用到了 queue 包下面的 types.go 文件。这个文件是定义了异步请求的 Request 结构体和一个 CanQueueRequests 接口。如下所示：\npackage queue import \u0026#34;net/url\u0026#34; import \u0026#34;net/http\u0026#34; // Request for asynchronous processing type Request struct { Header http.Header Body []byte Method string QueryString string Function string CallbackURL *url.URL `json:\u0026#34;CallbackUrl\u0026#34;` } // CanQueueRequests can take on asynchronous requests type CanQueueRequests interface { Queue(req *Request) error } 从这里我们就可以明白作者的设计思路，只要是实现了这个 CanQueueRequests 接口，就可以作为一个 queue-worker。\n接口实现类 NatsQueue 接口的实现类 NatsQueue 是在 handler 包里。它的属性都是 nats 中常用到的，包括 clientId，clusterId，url，连接，主题等，如下所示：\n// NatsQueue queue for work type NatsQueue struct { nc stan.Conn // nats的连接 ClientID string // nats的clientId ClusterID string // nats的clusterId NATSURL string // nats的URL Topic string // 主题 } 它的 queue 方法也很简单，主要做了两件事儿：\n 解析传入的 Request 对象，并转为 json 对象 out 将 out 发布到队列里  // Queue request for processing func (q *NatsQueue) Queue(req *queue.Request) error { var err error fmt.Printf(\u0026#34;NatsQueue - submitting request: %s.\\n\u0026#34;, req.Function) out, err := json.Marshal(req) if err != nil { log.Println(err) } err = q.nc.Publish(q.Topic, out) return err } go 语言没有构造方法，所以 NatsQueue 还用于创建 NatsQueue 的实例的方法，这里就成为工厂方法。这个工厂方法主要就是从配置文件中读取环境变量的值，然后创建一个 nats 的连接，相当于给 NatsQueue 的对象的每个属性进行赋值。\nfunc CreateNatsQueue(address string, port int, clientConfig NatsConfig) (*NatsQueue, error) { queue1 := NatsQueue{} var err error natsURL := fmt.Sprintf(\u0026#34;nats://%s:%d\u0026#34;, address, port) log.Printf(\u0026#34;Opening connection to %s\\n\u0026#34;, natsURL) clientID := clientConfig.GetClientID() clusterID := \u0026#34;faas-cluster\u0026#34; nc, err := stan.Connect(clusterID, clientID, stan.NatsURL(natsURL)) queue1.nc = nc return \u0026amp;queue1, err } 这个 CreateNatsQueue 方法是 Gateway 项目中进行调用，我们可以在 Gateway 项目的 main.go 中找到，如果 Gateway 的配置开启了异步函数支持，就会调用该方法，创建一个 NatsQueue 对象，然后把函数放到队列中，这里就不深入讲解：\nif config.UseNATS() { log.Println(\u0026#34;Async enabled: Using NATS Streaming.\u0026#34;) natsQueue, queueErr := natsHandler.CreateNatsQueue(*config.NATSAddress, *config.NATSPort, natsHandler.DefaultNatsConfig{}) if queueErr != nil { log.Fatalln(queueErr) } faasHandlers.QueuedProxy = handlers.MakeQueuedProxy(metricsOptions, true, natsQueue) faasHandlers.AsyncReport = handlers.MakeAsyncReport(metricsOptions) } 到这里，我相信读者也了解到，Gateway 其实就是一个发布者，将异步请求扔到队列里。接下来肯定要有一个订阅者将请求消费处理。\n订阅者处理 我们都知道，nats streaming 的订阅者订阅到消息之后，会把消息扔给一个回调函数去处理。queue-worker 的订阅者实现也是这样，它的实现并不复杂，所有逻辑都在 main.go 的中。\n我们先看回调函数 mcb 都做了什么：\n 首先当然是将消息体反序列化成上面说到的用于异步处理的 Request 对象。 构造 http 请求的 url 和 querystring，url 的格式如下： functionURL := fmt.Sprintf(\u0026ldquo;http://%s%s:8080/%s\u0026rdquo;, req.Function, config.FunctionSuffix, queryString) 设置 http 的 header，并以 post 的形式向 functionURL 发起请求。 如果请求失败，设置返回状态码为http.StatusServiceUnavailable，并分别处理 CallbackURL 是否存在的情况。 如果请求成功，同样也是要分别处理 CallbackURL 是否存在的情况。  当然在这个 callback 中会根据一些环境变量的存在，选择是否打印日志出来。\nmcb := func(msg *stan.Msg) { i++ printMsg(msg, i) started := time.Now() req := queue.Request{} unmarshalErr := json.Unmarshal(msg.Data, \u0026amp;req) if unmarshalErr != nil { log.Printf(\u0026#34;Unmarshal error: %s with data %s\u0026#34;, unmarshalErr, msg.Data) return } fmt.Printf(\u0026#34;Request for %s.\\n\u0026#34;, req.Function) if config.DebugPrintBody { fmt.Println(string(req.Body)) } queryString := \u0026#34;\u0026#34; if len(req.QueryString) \u0026gt; 0 { queryString = fmt.Sprintf(\u0026#34;?%s\u0026#34;, strings.TrimLeft(req.QueryString, \u0026#34;?\u0026#34;)) } functionURL := fmt.Sprintf(\u0026#34;http://%s%s:8080/%s\u0026#34;, req.Function, config.FunctionSuffix, queryString) request, err := http.NewRequest(http.MethodPost, functionURL, bytes.NewReader(req.Body)) defer request.Body.Close() copyHeaders(request.Header, \u0026amp;req.Header) res, err := client.Do(request) var status int var functionResult []byte if err != nil { status = http.StatusServiceUnavailable log.Println(err) timeTaken := time.Since(started).Seconds() if req.CallbackURL != nil { log.Printf(\u0026#34;Callback to: %s\\n\u0026#34;, req.CallbackURL.String()) resultStatusCode, resultErr := postResult(\u0026amp;client, res, functionResult, req.CallbackURL.String()) if resultErr != nil { log.Println(resultErr) } else { log.Printf(\u0026#34;Posted result: %d\u0026#34;, resultStatusCode) } } statusCode, reportErr := postReport(\u0026amp;client, req.Function, status, timeTaken, config.GatewayAddress) if reportErr != nil { log.Println(reportErr) } else { log.Printf(\u0026#34;Posting report - %d\\n\u0026#34;, statusCode) } return } if res.Body != nil { defer res.Body.Close() resData, err := ioutil.ReadAll(res.Body) functionResult = resData if err != nil { log.Println(err) } if config.WriteDebug { fmt.Println(string(functionResult)) } else { fmt.Printf(\u0026#34;Wrote %d Bytes\\n\u0026#34;, len(string(functionResult))) } } timeTaken := time.Since(started).Seconds() fmt.Println(res.Status) if req.CallbackURL != nil { log.Printf(\u0026#34;Callback to: %s\\n\u0026#34;, req.CallbackURL.String()) resultStatusCode, resultErr := postResult(\u0026amp;client, res, functionResult, req.CallbackURL.String()) if resultErr != nil { log.Println(resultErr) } else { log.Printf(\u0026#34;Posted result: %d\u0026#34;, resultStatusCode) } } statusCode, reportErr := postReport(\u0026amp;client, req.Function, res.StatusCode, timeTaken, config.GatewayAddress) if reportErr != nil { log.Println(reportErr) } else { log.Printf(\u0026#34;Posting report - %d\\n\u0026#34;, statusCode) } } postResult函数是用来处理 callbackURL 存在的情况，在这个函数中将结果，以 post 请求调用 callbackURL 发送出去。\npostReport函数用来处理 callbackURL 不存在的情况，这里是将结果发到 Gateway 网关的\u0026quot;http://\u0026quot; + gatewayAddress + \u0026quot;:8088/system/async-report\u0026quot;中，我们之后就可以从这个 url 里查询异步函数的执行结果了。\n总结 本文主要分析了 NATS Streaming 版本的 queue worker 的实现，通过分析源码我们可以看到 OpenFaaS 在架构的设计很有考究，充分的考虑到了可扩展性，通过定义接口规范，使得开发者很容易实现自定义。\n","permalink":"https://zhenfeng-zhu.github.io/posts/queue-worker/","summary":"queue-worker 源码分析 异步函数和同步函数 在 OpenFaaS 中同步调用函数时，将会连接到网关，直到函数成功返回才会关闭连接。同步调用是阻塞的。\n 网关的路由是：/function/\u0026lt;function_name\u0026gt; 必须等待 在结束的时候得到结果 明确知道是成功还是失败  异步函数会有一些差异：\n 网关的路由是：/async-function/\u0026lt;function_name\u0026gt; 客户端获得 202 的即时响应码 从 queue-worker 中调用函数 默认情况下，结果是被丢弃的。  查看 queue-worker 的日志 docker service logs -f func_queue-worker 利用 requestbin 和 X-Callback-Url 获取异步函数的结果 如果需要获得异步函数的结果，有两个方法：\n 更改代码，将结果返回给端点或者消息系统 利用内置的回调 内置的回调将会允许函数提供一个 url，queue-worker 会报告函数的成功或失败。 requestbin 会创建一个新的 bin，这是互联网的一个 url 地址，可以从这里获取函数的结果。  源码分析 依赖项 github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/faas go-nats 和 go-nats-streaming 是 nats 和 nats-streaming 的 go 版本的客户端。\nfaas 这个依赖其实是只用到了 queue 包下面的 types.go 文件。这个文件是定义了异步请求的 Request 结构体和一个 CanQueueRequests 接口。如下所示：","title":"queue-worker"},{"content":" 本文是阅读http://www.netkiller.cn/blockchain/ch01s10.html 上的一些笔记。\n 理解区块链的分布式记账 http://www.netkiller.cn/blockchain/ch01s10.html\n区块链中提到的账本，记账等词汇是和会计无关的词汇。\n我们传统理解的账本是一个二维的表格，记录了某年某月某日的费用：\n   时间 用途 金额     2018-08-23 借 100   2018-08-22 还 200   2018-08-21 借 50   2018-08-20 还 1000    如果账目比较多，可以拆账，将不同分类的账目放在特定的账本中，而且二维表格还可以设置索引等，快速找到一笔交易。\n但是区块链的记账形式是：\n可以发现，区块链的这种记账方式是做了行列矩阵转换，节点之间收尾相互连接，成为链式结构，所有的账目都在一条链上。\n所谓分布式记账，其实就是上述链状的数据结构保存在所有的节点上，形成分布式集群。\n之所以采用区块链来做分布式记账，主要是区块链有如下好处：\n  去中心化\n传统的数据库存储是中心化的，通过暴露 ip 地址和端口号提供服务，后来分布式进群化之后，出现了主主从架构等。\n与数据库相比，区块链是多主架构，而且实现更为复杂，节点之间的数据之间不是简单的二进制日志同步，而是要通过加密技术，节点达成共识之后才存储。\n  可追溯\n  安全\n安全分为很多层，区块链只能做到存储层的安全。\n区块链无法解决用户层，应用层，逻辑层等安全问题，他只能保证存储在硬盘上的区块不被修改。\n  不可篡改\n很多人认为区块链数据一旦创建之后就不能修改，所以采用区块链技术很安全。其实不然，数据是可以修改的，但是不能篡改。\n撰改是指非法修改区块链数据，而修改则是合法变更数据。\n通常撰改区块链数据多指数据存储层面的修改。而修改则是通过合约提供的修改函数变更区块链里面的数据。\n多数区块链平台没有用户认证权限管理模块。所以无法控制区块中的哪些数据能被修改，哪些不能修改，哪些用户可以修改等等。即使有些区块链平台具备权限控制，颗粒度也无法达到目前的数据库控制的那么细。\n  采用区块链作为账本的时候，会面临如下几个问题：\n  不能建立索引，无法快速搜索出区块中的数据，必须依赖区块链以外的技术，如搜索引擎，数据库等。例如；etherscan.io 就是把以太坊上的区块重新入库，借助数据库实现数据检索。\n  区块链只能顺序检索，运算成本高。例如在中心化账本中汇总求和操作，区块链必须从头向后遍历。\n  所有账目均在一条链上，不同的分类混在一起，彼此相连。\n  无法归档。\n传统的数据库，我们可以归档一段时间内的数据，而这些归档的数据基本都是冷数据，不会再被查询，归档数据的备份到存储介质上的解决方案也有很多。\n但是区块链的数据都是热数据，任何新增的节点都必须从 0 开始同步，并且保证同步到最新区块，否则可能无法完成交易，数据会一直膨胀下去。\n虽然有算法能够减少同步的量，但是现阶段的体验仍然不好。\n  没有事务处理。\n因为区块链是首尾相连的链式结构，所以只能在尾部加区块，无法修改中间的区块。假设有个区块回滚，该区块的 hash 产生变化，后面的区块都要作废。\n所以当并发执行的时候，可能会出现混乱。因此我们要在应用层做一些处理。\n  性能问题\n  由于是异步执行，无法预测何时完成。\n  交易容易阻塞\n  gas 费用。\n  区块链落地的一些问题和解决方案 如果要在企业中落地区块链，尝尝有如下解决方案：\n  解决性能问题\n目前区块链只适合做低频高价值业务。\n读取性能通常是没有问题的，但是写入实际上无论你用多少个服务器节点都不能提升，因为写入区块需要做共识算法，这步操作，会在所有节点上进行，同时还需要加密运算，这些操作都是 CPU 密集型操作。\n方案：\n  通过消息队列技术异步写入，将需要写入的区块放入队列，异步完成上链操作。\n  并行写入，我们可以建设多个区块链平台。多个平台同时服务于业务。\n为了达到去中心化并行写入，我们将在客户端通过算法，匹配服务器。因为如果在平台前面增加负载均衡，加因为这样又回到了中心化系统。\n    溯源颗粒度\n对于所要被溯源的物品或者交易来讲，有四种情况，低频低价值，低频高价值，高频高价值，高频低价值 。\n对于低频高价值和高频高价值的业务，尽量做到最小颗粒度。\n对于低频低价值和高频低价值的业务，可以颗粒度更粗。\n  和传统数据库互补\n区块链技术本身是一种追求分布一致性的数据库。\n我们都知道 CAP 理论。CAP 理论是指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。大多数区块链，放弃了一些可用性，偏向了一致性和分区容错。\n区块链并非能解决所有问题，虽然他也算是一种数据库，它能解决问题十分有限，它的数据管理和查询能力还打不到 NoSQL 的水平，更别提 SQL 的复杂应用。所以在实际的应用中，区块链不能替代传统数据库，只能互补。\n  链上链下数据一致性问题\n既然区块链替代不了传统数据库，那么必然要在项目中同时使用两种技术。这样问题来了，会有两份数据，一份存储在链下，即传统数据库，另外一部分数据上链，这样就有两份重复的数据，那么怎样保证他们的一致性呢？\n区块链和比特币网络不同，比特币是在链上产生的，它与区块链密布可分，是一体的，所以它的数据安全性是自闭环的。而我们的链下数据并不是在区块链中产生的，因此我们在上链的时候，尽量采用如下的方案：\n 两端都做一次哈希，可快速对比数据是否一致 以链上数据为准，因为数据库的数据更容易被篡改 前端业务走链，后端业务走数据库，因为前台业务是为用户提供服务，所以要走链上数据，而后台是可以管理的，走数据库即可。 共享数据上链，私有数据不上链。    区块链的相关技术 区块链的技术模型自下而上分为；数据层，网路层，共识层，激励层，合约层以及应用层。\n  数据层，封装了底层数据区块的链式结构，以及相关的非对称公私钥数据加密技术和时间戳等技术，这是整个区块链技术中最底层的数据结构。\n这些技术是构建全球金融系统的基础，数十年的使用证明了它非常安全的可靠性。而区块链，正式巧妙地把这些技术结合在了一起。\n  网络层，包括 P2P 组网机制、数据传播机制和数据验证机制等。\nP2P 组网技术早期应用在 BT 这类 P2P 下载软件中，这就意味着区块链具有自动组网功能。\n  共识层，封装了网络节点的各类共识机制算法。共识机制算法是区块链的核心技术，因为这决定了到底是谁来进行记账，而记账决定方式将会影响整个系统的安全性和可靠性。\n数据层、网络层、共识层是构建区块链技术的必要元素，缺少任何一层都将不能称之为真正意义上的区块链技术。\n目前已经出现了十余种共识机制算法，其中比较最为知名的有工作量证明机制（PoW，Proof of Work）、权益证明机制（PoS，Proof ofStake）、股份授权证明机制（DPoS，Delegated ProofofStake）等。\n  激励层，将经济因素集成到区块链技术体系中来，包括经济激励的发行机制和分配机制等，主要出现在公有链当中。\n在公有链中必须激励遵守规则参与记账的节点，并且惩罚不遵守规则的节点，才能让整个系统朝着良性循环的方向发展。而在私有链当中，则不一定需要进行激励，因为参与记账的节点往往是在链外完成了博弈，通过强制力或自愿来要求参与记账。\n  合约层，封装各类脚本、算法和智能合约，是区块链可编程特性的基础。\n比特币本身就具有简单脚本的编写功能，而以太坊极大的强化了编程语言协议，理论上可以编写实现任何功能的应用。如果把比特币看成是全球账本的话，以太坊可以看作是一台“全球计算机”，任何人都可以上传和执行任意的应用程序，并且程序的有效执行能得到保证。\n  应用层，封装了区块链的各种应用场景和案例，比如搭建在以太坊上的各类区块链应用即部署在应用层，而未来的可编程金融和可编程社会也将会是搭建在应用层。\n  共识算法\n pow pos dpos poa pbft raft  HD Wallet\nBIP32 定义 Hierarchical Deterministic wallet (简称 \u0026ldquo;HD Wallet\u0026rdquo;)，是一个系统可以从单个 seed 产生树状结构储存多组 keypairs（私钥和公钥）。\nBIP39 定义钱包助记词和 seed 生成规则，一般由 12 -24 个单字组成，称为 mnemonic。\nBIP44 基于 BIP32 的系统，赋予树状结构中的各层特殊的意义。让同一个 seed 可以支援多币种、多帐户等 。\n使用助记词生成确定性钱包。\nHD Wallet 采用 2048 个单词，或者汉字作为助记词，这些词库对外公开，很多钱包仅仅使用 path 第一个地址并且没有加密。如果你知道某个用户的助记词中的 11 各词的排列顺序，那么我们就可以通过穷举方法，算出所有地址的私钥，如果碰巧找到了已经在使用的地址。就可以将里面的 ETH 全部转走。\n以太坊常用操作 计算 gas 费用\nvar estimateGas = eth.estimateGas({from:eth.accounts[1], to: eth.accounts[2], value: web3.toWei(1)}) var cost = estimateGas * gasPrice 解锁账户\npersonal.unlockAccount(eth.accounts[3], \u0026#34;12345678\u0026#34;) 转账\nvar txnHash = eth.sendTransaction({from: eth.accounts[3], to: eth.accounts[5], value: eth.getBalance(eth.accounts[3]) - cost, gas: estimateGas}) 查看交易细节\nweb3.eth.getTransaction(txnHash) 获取余额\neth.getBalance(eth.accounts[3]) keystore 文件\n以太坊的每个外部账户都是由一对密钥（一个公钥和一个私钥）定义的。账户以地址为索引，地址由公钥衍生而来，取公钥的最后 20 个字节。\n每对私钥 /地址都编码在一个钥匙文件里，也就是我们说的 keystore 文件。该文件是 JSON 文本文件，可以用任何文本编辑器打开和浏览。钥匙文件的关键部分——账户私钥，通常用你创建帐户时设置的密码进行加密。如果你丢失了这个文件，你就丢失了私钥，意味着你失去了签署交易的能力，意味着你的资金被永久的锁定在了你的账户里。\n批量转账\n有时我们需要将 Token 发送到多个地址上去。通常的做法就是使用 web.js 写一个循环程序，但是实际使用过程中发现这种做法存在很多问题，常会发生转账失败情况。\n经过分析造成发送失败原因是，频率太高，因为 web.js 是异步操作，当前程序还未完成交易，交易尚未确认的情况下第二笔交易发送出去，这时就会出错。\nweb3.eth.getTransactionCount(from).then(function(nonce){ // 问题就出在 nonce ， nonce 如同数据库中的序列主键，如果上一个交易没有完成，下一个交易取得 nonce + 1 后与上一个 pending 的交易相同，产生冲突 } 最好的解方案是在合约中实现批量转账功能，这样需要一个交易 txhash 完成多比交易。\n如果你的 Token 已经在使用了，且没有批量转账的功能怎么解决呢？我们可以在写一个 Token 继承原来的 Token，在新的 Token 中实现批量转账功能。\n代币兑换\n兑换代币通常是指使用 ETH 或者其他币兑换 Token。通常是这样实现的，使用智能合约，将 ETH 达到指定合约地址，合约会打回代币给用户。\n这种方式不用人工参与，也不用开发程序。缺点不能做到实时汇率，需要人工设置汇率。\nERC20 Token\nERC20 “描述了实现代币合约的标准功能”，ERC20 是各个代币的标准接口。ERC20 代币仅仅是以太坊代币的子集。为了充分兼容 ERC20，开发者需要将一组特定的函数集成到他们的智能合约中，以便在高层面能够执行以下操作：\n 获得代币总供应量 获得账户余额 转让代币 批准花费代币  最简单的合约如下：\npragma solidity ^0.4.24; contract EncryptToken { uint256 INITIAL_SUPPLY = 666666; mapping(address =\u0026gt; uint256) balances; constructor() public { balances[msg.sender] = INITIAL_SUPPLY; } function transfer(address to, uint256 amount) public{ assert(balances[msg.sender] \u0026gt; amount); balances[msg.sender] -= amount; balances[to] += amount; } function balanceOf(address owner) constant public returns (uint256){ return balances[owner]; } } 使用了 openzeppeline-solidity 的安全标准代币合约是：\npragma solidity ^0.4.24; import \u0026#34;openzeppelin-solidity/contracts/token/ERC20/StandardToken.sol\u0026#34;; contract BloggerCoin is StandardToken{ string public name = \u0026#34;BloggerCoin\u0026#34;; // 名字 string public symbol = \u0026#34;BLC\u0026#34;; // 简称 uint8 public decimals = 4; // 10的4次方 uint256 public INITIAL_SUPPLY = 666666; constructor() public{ totalSupply_ = INITIAL_SUPPLY; balances[msg.sender] = INITIAL_SUPPLY; } } ","permalink":"https://zhenfeng-zhu.github.io/posts/blockchain/","summary":"本文是阅读http://www.netkiller.cn/blockchain/ch01s10.html 上的一些笔记。\n 理解区块链的分布式记账 http://www.netkiller.cn/blockchain/ch01s10.html\n区块链中提到的账本，记账等词汇是和会计无关的词汇。\n我们传统理解的账本是一个二维的表格，记录了某年某月某日的费用：\n   时间 用途 金额     2018-08-23 借 100   2018-08-22 还 200   2018-08-21 借 50   2018-08-20 还 1000    如果账目比较多，可以拆账，将不同分类的账目放在特定的账本中，而且二维表格还可以设置索引等，快速找到一笔交易。\n但是区块链的记账形式是：\n可以发现，区块链的这种记账方式是做了行列矩阵转换，节点之间收尾相互连接，成为链式结构，所有的账目都在一条链上。\n所谓分布式记账，其实就是上述链状的数据结构保存在所有的节点上，形成分布式集群。\n之所以采用区块链来做分布式记账，主要是区块链有如下好处：\n  去中心化\n传统的数据库存储是中心化的，通过暴露 ip 地址和端口号提供服务，后来分布式进群化之后，出现了主主从架构等。\n与数据库相比，区块链是多主架构，而且实现更为复杂，节点之间的数据之间不是简单的二进制日志同步，而是要通过加密技术，节点达成共识之后才存储。\n  可追溯\n  安全\n安全分为很多层，区块链只能做到存储层的安全。\n区块链无法解决用户层，应用层，逻辑层等安全问题，他只能保证存储在硬盘上的区块不被修改。\n  不可篡改\n很多人认为区块链数据一旦创建之后就不能修改，所以采用区块链技术很安全。其实不然，数据是可以修改的，但是不能篡改。\n撰改是指非法修改区块链数据，而修改则是合法变更数据。\n通常撰改区块链数据多指数据存储层面的修改。而修改则是通过合约提供的修改函数变更区块链里面的数据。\n多数区块链平台没有用户认证权限管理模块。所以无法控制区块中的哪些数据能被修改，哪些不能修改，哪些用户可以修改等等。即使有些区块链平台具备权限控制，颗粒度也无法达到目前的数据库控制的那么细。\n  采用区块链作为账本的时候，会面临如下几个问题：\n  不能建立索引，无法快速搜索出区块中的数据，必须依赖区块链以外的技术，如搜索引擎，数据库等。例如；etherscan.","title":"区块链学习笔记"},{"content":"在这篇文章不考虑人工智能，谈谈我对聊天机器人框架实现机制的理解。\n聊天机器人  聊天机器人（Chatterbot）是经由对话或文字进行交谈的计算机程序[1]。能够模拟人类对话，通过图灵测试。\n 我们可以看到现有的 IM 工具上已经有了很多机器人，其实聊天机器人不只是单纯的和用户进行聊天，他其实还可以做很多事情，例如根据用户输入的一些话，可以帮用户订餐。另外在运维领域，也出现了 chatops，通过和机器人聊天，进行运维操作。\n机器人开发框架 作为聊天机器人开发者，面对如此多的 IM 工具和 SDK，常会感到无所适从。Bot 开发框架就是对聊天机器人开发过程中的人工内容做抽象化处理。简单地解释，机器人开发框架就是用来制造机器人并定义其行为。\n然而尽管很多机器人框架宣称「代码一旦写好可部署到任何地方」，但是还会是出现为每一个 IM 工具开发一个单独的聊天机器人。而一个良好的机器人框架主要包含开发 SDK，连接器和模拟器等。\n使用机器人框架其实并不适合初学者学习聊天机器人开发。它们尝试自动化太多工作，对初学者掩盖了基础机制。\n实现方式  webhook 事件回调 FSM 状态机 workflow 工作流  最简单的机器人是没有上下文的语义理解的一问一答，仅仅是对用户的对话进行响应，这种就可以采用 webhook 的方式进行开发。不需要采用什么开发框架。\n那么对于多轮对话的时候，就需要进行一定的对话管理。由此引入了 FSM 状态机。\n可能有人不是很懂有限状态机，这里做一下简单说明。\n 有限状态机在现实生活中其实随处可见，伸缩式圆珠笔其实就是一个有限状态机（两种状态互相转换）。\n有限状态机，缩写为 FSM，又称为有限状态自动机，简称状态机。是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。\n可以总结为：f(state, action) =\u0026gt; state’\n也就是说，这个函数采用当前的状态和一次行动（即更改状态的方法），之后将该行动应用于这种状态并返回新的状态。\n可以认为状态机是图灵完备的。\n 我们可以将对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。\n我们可以将对话的过程，分为一个个的状态，然后使用 DSL 来实现一个 FSM，对于开发者来讲，我们只需要关注一个个状态函数即可。\n特点是：\n 人为定义对话流程 完全有系统主导，系统问用户答 答非所问的情况直接忽略 建模简单，能清晰明了的把交互匹配到模型 难以扩展，很容易变的复杂 适用于简单的任务，难以处理复杂问题 缺少灵活性，表达能力有限，输入有限，对话结构和流转路径有限  示例：\nconst {startWith, when, goto, stay, stop} = botkit.DSL(fsm); startWith(MyStates.IDLE, {counter: 0}); when(MyStates.IDLE)(async (sender, content, data) =\u0026gt; { }); when(MyStates.UI)((sender, content, data) =\u0026gt; { }); when(MyStates.STEP1)((sender, content, data) =\u0026gt; { }); when(MyStates.STEP2)((sender, content, data) =\u0026gt; { }); when(MyStates.DONE)((sender, content, data) =\u0026gt; { }); when(MyStates.EMPTY)((sender, content, data) =\u0026gt; { }); when(MyStates.LOOP)((sender, content, data) =\u0026gt; { }); 从示例中可以发现，基于 fsm 的机器人框架需要使用类似 DSL 领域特定语言一样的描述语言，定义各种各样的状态，每一个状态都有触发点。当满足某个状态条件时，进入该状态，执行该状态的逻辑。这种基于状态机的机器人框架，对于简单的场景比较容易写，但是如果是遇到了复杂的场景，比如多轮对话中还附带上下文信息，就会写起来非常复杂。\n于是引入了基于工作流的 chatbot 框架。其实工作流是对 fsm 的一种简化封装，本质上来讲，工作流能做到的，fsm 状态机也能做到，而且 fsm 状态机或许能拆的更细，但是工作流的一个个 function，或者是 function 的集合 dialog，可以互相组合，开发起来更符合大部分人的直觉。\n  routing dialog\n// hotels.js module.exports = [ // Destination function (session) { session.send(\u0026#39;Welcome to the Hotels finder!\u0026#39;); builder.Prompts.text(session, \u0026#39;Please enter your destination\u0026#39;); }, function (session, results, next) { session.dialogData.destination = results.response; session.send(\u0026#39;Looking for hotels in %s\u0026#39;, results.response); next(); }, ... ]; // app.js var bot = new builder.UniversalBot(connector, [ function (session) { // ... }, // ... ]); bot.dialog(\u0026#39;hotels\u0026#39;, require(\u0026#39;./hotels\u0026#39;)); bot.dialog(\u0026#39;flights\u0026#39;, require(\u0026#39;./flights\u0026#39;)); 通过 routing dialog，我们可以实现 dialog 的复用。\n  waterfall dialog\n一个瀑布流的 dialog，可以让我们在一个 dialog 中像流一样完成一系列的动作。就像 fsm 的多种状态的集合。\n[ // Destination function (session) { session.send(\u0026#39;Welcome to the Hotels finder!\u0026#39;); builder.Prompts.text(session, \u0026#39;Please enter your destination\u0026#39;); }, function (session, results, next) { session.dialogData.destination = results.response; session.send(\u0026#39;Looking for hotels in %s\u0026#39;, results.response); next(); }, ... function (session) { var destination = session.dialogData.destination; var checkIn = new Date(session.dialogData.checkIn); var checkOut = checkIn.addDays(session.dialogData.nights); session.send( \u0026#39;Ok. Searching for Hotels in %s from %d/%d to %d/%d...\u0026#39;, destination, checkIn.getMonth() + 1, checkIn.getDate(), checkOut.getMonth() + 1, checkOut.getDate()); // Async search Store .searchHotels(destination, checkIn, checkOut) .then(function (hotels) { // Results session.send(\u0026#39;I found in total %d hotels for your dates:\u0026#39;, hotels.length); var message = new builder.Message() .attachmentLayout(builder.AttachmentLayout.carousel) .attachments(hotels.map(hotelAsAttachment)); session.send(message); // End session.endDialog(); }); } ]   state\n在一个 dialog 上下文中共享的数据，或者在多个 dialog 中共享的数据。对于微软的 botbuilder 来讲，他们提供了如下几个 API：\n   Field Use Cases     userData Stores information globally for the user across all conversations.   conversationData Stores information globally for a single conversation. This data is visible to everyone within the conversation so care should be used to what’s stored there. It’s disabled by default and needs to be enabled using the bots persistConversationData setting.   privateConversationData Stores information globally for a single conversation but its private data for the current user. This data spans all dialogs so it’s useful for storing temporary state that you want cleaned up when the conversation ends.   dialogData Persists information for a single dialog instance. This is essential for storing temporary information in between the steps of a waterfall.      Conversation UI 对话式 UI（Conversation UI，下文简称 CUI）。\nCUI 到底是什么？很好理解，我们日常跟人聊天的微信、短信界面就是。由一条条消息组成，按时间先后展示出来，就可以看作 CUI。\nchatbot 在与用户交流时，不单单是只有文字，还会需要用户进行互动，这时候就是 CUI 的用武之地了。我们可以和移动端进行约定，对一些特定的消息格式进行渲染，这样就可以做出按钮，列表等。\nBot Service 作为一个机器人框架，开发完成之后，还需要和 telegram，Facebook messenger，slack 等 IM 平台进行对接，如果要开发者一个个对接的话，将会特别麻烦。作为 chatbot 开发框架的一部分，bot service 的工作就是对接 IM 平台。\nBot Builder 源码阅读 微软的 botbuilder-js 出到了 V4 版本，在新版本的机器人框架有着很大的变动，相比于 V3 目录结构变化了，而且机器人编写流程也有了一定的差异。\n项目结构\n├── botbuilder ├── botbuilder-ai ├── botbuilder-azure ├── botbuilder-core ├── botbuilder-dialogs ├── botframework-config ├── botframework-connector ├── botframework-schema 目录结构更加的组件化。\n如果我们不使用微软的服务，那么 botbuilder-ai 和 botbuilder-azure 其实不重要。\nbotbuilder botbuilder 是框架的入口，在这个 package 中做的事情比较简单：\nexport * from \u0026#39;./botFrameworkAdapter\u0026#39;; export * from \u0026#39;./fileTranscriptStore\u0026#39;; export * from \u0026#39;../../botbuilder-core/lib\u0026#39;; 导出 botbuilder-core 和继承了 botAdapter 的子类 botFrameworkAdapter。\nfileTranscriptStore 是存储每个 activity 的 transcript 到文件中，Transcript 是人和 bot 的对话动作的日志。\n如果我们要定制自己的 bot 动作，其实就可以继承 botAdapter，然后对接自己的 IM 等等。botAdapter 也是 botbuilder-core 中的，所以 botbuilder-core 是核心，只要读懂了 botbuilder-core，就可以说是理解了微软的机器人框架。\nbotbuilder-core 看 botbuilder-core，也从 index.ts 开始。\nexport * from \u0026#39;../../botframework-schema/lib\u0026#39;; export * from \u0026#39;./autoSaveStateMiddleware\u0026#39;; export * from \u0026#39;./botAdapter\u0026#39;; export * from \u0026#39;./botState\u0026#39;; export * from \u0026#39;./botStatePropertyAccessor\u0026#39;; export * from \u0026#39;./botStateSet\u0026#39;; export * from \u0026#39;./browserStorage\u0026#39;; export * from \u0026#39;./cardFactory\u0026#39;; export * from \u0026#39;./conversationState\u0026#39;; export * from \u0026#39;./memoryStorage\u0026#39;; export * from \u0026#39;./memoryTranscriptStore\u0026#39;; export * from \u0026#39;./messageFactory\u0026#39;; export * from \u0026#39;./middlewareSet\u0026#39;; export * from \u0026#39;./privateConversationState\u0026#39;; export * from \u0026#39;./propertyManager\u0026#39;; export * from \u0026#39;./recognizerResult\u0026#39;; export * from \u0026#39;./showTypingMiddleware\u0026#39;; export * from \u0026#39;./storage\u0026#39;; export * from \u0026#39;./testAdapter\u0026#39;; export * from \u0026#39;./transcriptLogger\u0026#39;; export * from \u0026#39;./turnContext\u0026#39;; export * from \u0026#39;./userState\u0026#39;; 这里引入了一个 botframework-schema，通过名字可以看出来，这就是一个类型定义的包，主要是机器人 Activity 的 Schema。Activity 是人和 bot 所做的会话的程序级别的表示，该 schema 中包含了文本协议、多媒体和非内容动作（如社交互动和打字指示符）的规定。\n","permalink":"https://zhenfeng-zhu.github.io/posts/botbuilder/","summary":"在这篇文章不考虑人工智能，谈谈我对聊天机器人框架实现机制的理解。\n聊天机器人  聊天机器人（Chatterbot）是经由对话或文字进行交谈的计算机程序[1]。能够模拟人类对话，通过图灵测试。\n 我们可以看到现有的 IM 工具上已经有了很多机器人，其实聊天机器人不只是单纯的和用户进行聊天，他其实还可以做很多事情，例如根据用户输入的一些话，可以帮用户订餐。另外在运维领域，也出现了 chatops，通过和机器人聊天，进行运维操作。\n机器人开发框架 作为聊天机器人开发者，面对如此多的 IM 工具和 SDK，常会感到无所适从。Bot 开发框架就是对聊天机器人开发过程中的人工内容做抽象化处理。简单地解释，机器人开发框架就是用来制造机器人并定义其行为。\n然而尽管很多机器人框架宣称「代码一旦写好可部署到任何地方」，但是还会是出现为每一个 IM 工具开发一个单独的聊天机器人。而一个良好的机器人框架主要包含开发 SDK，连接器和模拟器等。\n使用机器人框架其实并不适合初学者学习聊天机器人开发。它们尝试自动化太多工作，对初学者掩盖了基础机制。\n实现方式  webhook 事件回调 FSM 状态机 workflow 工作流  最简单的机器人是没有上下文的语义理解的一问一答，仅仅是对用户的对话进行响应，这种就可以采用 webhook 的方式进行开发。不需要采用什么开发框架。\n那么对于多轮对话的时候，就需要进行一定的对话管理。由此引入了 FSM 状态机。\n可能有人不是很懂有限状态机，这里做一下简单说明。\n 有限状态机在现实生活中其实随处可见，伸缩式圆珠笔其实就是一个有限状态机（两种状态互相转换）。\n有限状态机，缩写为 FSM，又称为有限状态自动机，简称状态机。是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。\n可以总结为：f(state, action) =\u0026gt; state’\n也就是说，这个函数采用当前的状态和一次行动（即更改状态的方法），之后将该行动应用于这种状态并返回新的状态。\n可以认为状态机是图灵完备的。\n 我们可以将对话看做是在有限状态内跳转的过程，每个状态都有对应的动作和回复，如果能从开始节点顺利的流转到终止节点，任务就完成了。\n我们可以将对话的过程，分为一个个的状态，然后使用 DSL 来实现一个 FSM，对于开发者来讲，我们只需要关注一个个状态函数即可。\n特点是：\n 人为定义对话流程 完全有系统主导，系统问用户答 答非所问的情况直接忽略 建模简单，能清晰明了的把交互匹配到模型 难以扩展，很容易变的复杂 适用于简单的任务，难以处理复杂问题 缺少灵活性，表达能力有限，输入有限，对话结构和流转路径有限  示例：\nconst {startWith, when, goto, stay, stop} = botkit.","title":"谈谈聊天机器人框架的实现原理"},{"content":"公司项目中使用公网上的以太坊私链，交易速度比较慢，于是这几天都在鼓捣基于以太坊的联盟链，parity 是可以构建出一个基于 PoA 共识的私链，而且兼容以太坊的合约。这篇文章主要是记录自己的踩坑经历，主要实现了节点的搭建，合约的部署以及本地以太坊浏览器的启动。\n部署联盟链 parity 的文档：https://wiki.parity.io/Demo-PoA-tutorial\n安装 首先是下载 parity，在 mac 下是直接 brew 安装即可。\nbrew tap paritytech/paritytech brew install parity 创世区块 创世区块的配置文件：\n// demo-spec.json { \u0026quot;name\u0026quot;: \u0026quot;DemoPoA\u0026quot;, \u0026quot;engine\u0026quot;: { \u0026quot;authorityRound\u0026quot;: { \u0026quot;params\u0026quot;: { \u0026quot;stepDuration\u0026quot;: \u0026quot;5\u0026quot;, \u0026quot;validators\u0026quot;: { \u0026quot;list\u0026quot;: [ \u0026quot;0x00bd138abd70e2f00903268f3db08f2d25677c9e\u0026quot;, \u0026quot;0x00aa39d30f0d20ff03a22ccfc30b7efbfca597c2\u0026quot; ] } } } }, \u0026quot;params\u0026quot;: { \u0026quot;gasLimitBoundDivisor\u0026quot;: \u0026quot;0x400\u0026quot;, \u0026quot;maximumExtraDataSize\u0026quot;: \u0026quot;0x20\u0026quot;, \u0026quot;minGasLimit\u0026quot;: \u0026quot;0x1388\u0026quot;, \u0026quot;networkID\u0026quot;: \u0026quot;0x2323\u0026quot;, \u0026quot;eip155Transition\u0026quot;: 0, \u0026quot;validateChainIdTransition\u0026quot;: 0, \u0026quot;eip140Transition\u0026quot;: 0, \u0026quot;eip211Transition\u0026quot;: 0, \u0026quot;eip214Transition\u0026quot;: 0, \u0026quot;eip658Transition\u0026quot;: 0 }, \u0026quot;genesis\u0026quot;: { \u0026quot;seal\u0026quot;: { \u0026quot;authorityRound\u0026quot;: { \u0026quot;step\u0026quot;: \u0026quot;0x0\u0026quot;, \u0026quot;signature\u0026quot;: \u0026quot;0x0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u0026quot; } }, \u0026quot;difficulty\u0026quot;: \u0026quot;0x20000\u0026quot;, \u0026quot;gasLimit\u0026quot;: \u0026quot;0x5B8D80\u0026quot; }, \u0026quot;accounts\u0026quot;: { \u0026quot;0x0000000000000000000000000000000000000001\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ecrecover\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 3000, \u0026quot;word\u0026quot;: 0 } } } }, \u0026quot;0x0000000000000000000000000000000000000002\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;sha256\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 60, \u0026quot;word\u0026quot;: 12 } } } }, \u0026quot;0x0000000000000000000000000000000000000003\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ripemd160\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 600, \u0026quot;word\u0026quot;: 120 } } } }, \u0026quot;0x0000000000000000000000000000000000000004\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;identity\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 15, \u0026quot;word\u0026quot;: 3 } } } }, \u0026quot;0x004ec07d2329997267ec62b4166639513386f32e\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;10000000000000000000000\u0026quot; } } } node0 node0 节点：\n## node0.toml [parity] chain = \u0026#34;demo-spec.json\u0026#34; base_path = \u0026#34;parity0\u0026#34; [network] port = 30300 [rpc] port = 8546 apis = [\u0026#34;web3\u0026#34;, \u0026#34;eth\u0026#34;, \u0026#34;net\u0026#34;, \u0026#34;personal\u0026#34;, \u0026#34;parity\u0026#34;, \u0026#34;parity_set\u0026#34;, \u0026#34;traces\u0026#34;, \u0026#34;rpc\u0026#34;, \u0026#34;parity_accounts\u0026#34;] interface = \u0026#34;0.0.0.0\u0026#34; cors = [\u0026#34;*\u0026#34;] hosts = [\u0026#34;all\u0026#34;] [websockets] port = 8456 [account] password = [\u0026#34;node.pwds\u0026#34;] [mining] engine_signer = \u0026#34;0x00bd138abd70e2f00903268f3db08f2d25677c9e\u0026#34; reseal_on_txs = \u0026#34;none\u0026#34; node1 node1 节点：\n## node1.toml [parity] chain = \u0026#34;demo-spec.json\u0026#34; base_path = \u0026#34;parity1\u0026#34; [network] port = 30301 [rpc] port = 8541 apis = [\u0026#34;web3\u0026#34;, \u0026#34;eth\u0026#34;, \u0026#34;net\u0026#34;, \u0026#34;personal\u0026#34;, \u0026#34;parity\u0026#34;, \u0026#34;parity_set\u0026#34;, \u0026#34;traces\u0026#34;, \u0026#34;rpc\u0026#34;, \u0026#34;parity_accounts\u0026#34;] [websockets] port = 8451 [ipc] disable = true [account] password = [\u0026#34;node.pwds\u0026#34;] [mining] engine_signer = \u0026#34;0x00aa39d30f0d20ff03a22ccfc30b7efbfca597c2\u0026#34; reseal_on_txs = \u0026#34;none\u0026#34; [ui] disable = true 启动并创建账户 启动\nparity --config node0.toml --fat-db=on parity --config node1.toml --fat-db=on 创建账户：\ncurl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;parity_newAccountFromPhrase\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;node0\u0026#34;, \u0026#34;node0\u0026#34;],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8546 curl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;parity_newAccountFromPhrase\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;user\u0026#34;, \u0026#34;user\u0026#34;],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8546 curl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;parity_newAccountFromPhrase\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;node1\u0026#34;, \u0026#34;node1\u0026#34;],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8541 这样就创建了 3 个账户，其中 node0 和 node1 是见证者 user 是初始发钱的。\n因为 parity ui 是要连接 8546 端口，所以这里就让 node0 的 rpc 的端口是 8546。\n节点互通和转账 让 node0 和 node1 节点相通，其实就是让两个节点成为一个网络：\n// 获取node0的encode curl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;parity_enode\u0026#34;,\u0026#34;params\u0026#34;:[],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8546 // 调用node1的rpc，将node0加入， RESULT就是上一步获取的 curl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;parity_addReservedPeer\u0026#34;,\u0026#34;params\u0026#34;:[\u0026#34;enode://RESULT\u0026#34;],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8541 我们先给两个账户转账：\ncurl --data \u0026#39;{\u0026#34;jsonrpc\u0026#34;:\u0026#34;2.0\u0026#34;,\u0026#34;method\u0026#34;:\u0026#34;personal_sendTransaction\u0026#34;,\u0026#34;params\u0026#34;:[{\u0026#34;from\u0026#34;:\u0026#34;0x004ec07d2329997267Ec62b4166639513386F32e\u0026#34;,\u0026#34;to\u0026#34;:\u0026#34;0x00Bd138aBD70e2F00903268F3Db08f2D25677C9e\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;0xde0b6b3a7640000\u0026#34;}, \u0026#34;user\u0026#34;],\u0026#34;id\u0026#34;:0}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST localhost:8540 从 user 中转了 1 个以太坊到了 node0 账户中，同样再转给 node1。\n部署合约 再使用 truffle 开发完合约之后，把账户部署到我们刚刚起来的联盟链。部署合约需要消耗一定的 gas，truffle 使用的是 HD wallet 的 Provider，所以我们要先给一个钱包转一些以太币。\n因为这里用的是 metamask，在最初创建钱包的时候有设置 12 个助记词，所以先让钱包连接到 node0 节点：\n创建一个账户，向那个账户转几个以太币。\n然后在 truffle 中，配置如下：\n// truffle.js module.exports = { // See \u0026lt;http://truffleframework.com/docs/advanced/configuration\u0026gt; // to customize your Truffle configuration! networks: { development: { host: \u0026#34;127.0.0.1\u0026#34;, port: 8545, network_id: \u0026#34;*\u0026#34; }, parity: { provider: function () { return new HDWalletProvider(\u0026#39;这里写助记词\u0026#39;, \u0026#34;http://127.0.0.1:8546\u0026#34;) }, network_id: 3, gas: 4700000 } } }; 然后在执行部署合约的时候，指定 parity 即可：\ntruffle migrate --network parity 部署以太坊浏览器 以太坊的浏览器找了好几个，最后选中了etherchain-light。部署起来简单。\n首先 clone 代码到本地，然后 npm 安装依赖。\ngit clone https://github.com/gobitfly/etherchain-light --recursive cd etherchain-light \u0026amp;\u0026amp; yarn 一定要用—-recursive，将所有 git 的子模块都下载下来。\n修改 config.js.example 文件为 config.js，然后把 Provider 改为 HttpProvider，连接到 node0 的节点即可。\n// config.js var web3 = require(\u0026#39;web3\u0026#39;); var net = require(\u0026#39;net\u0026#39;); var config = function () { this.logFormat = \u0026#34;combined\u0026#34;; // this.ipcPath = process.env[\u0026#34;HOME\u0026#34;] + \u0026#34;/.local/share/io.parity.ethereum/jsonrpc.ipc\u0026#34;; // this.provider = new web3.providers.IpcProvider(this.ipcPath, net); this.provider = new web3.providers.HttpProvider(\u0026#34;http://127.0.0.1:8546\u0026#34;) // ... 省略其余代码 } module.exports = config; 执行npm start之后即可将以太坊浏览器运行起来。然后在浏览器中访问http://localhost:3000。\n思考 PoA 共识基于权威的共识机制，和基于 raft 协议的共识机制具体哪个更快？\nParity 文档中没有找到和权限控制相关的模块，用它来做联盟链还有待确定。\nQuorum 是 JP 摩根开源的基于以太坊的联盟链，使用的 raft 算法，可以研究研究。\n还不是很清楚，fabric 已经是联盟链主流的情况下，选择以太坊做联盟链的好处有多大。\n","permalink":"https://zhenfeng-zhu.github.io/posts/parity/","summary":"公司项目中使用公网上的以太坊私链，交易速度比较慢，于是这几天都在鼓捣基于以太坊的联盟链，parity 是可以构建出一个基于 PoA 共识的私链，而且兼容以太坊的合约。这篇文章主要是记录自己的踩坑经历，主要实现了节点的搭建，合约的部署以及本地以太坊浏览器的启动。\n部署联盟链 parity 的文档：https://wiki.parity.io/Demo-PoA-tutorial\n安装 首先是下载 parity，在 mac 下是直接 brew 安装即可。\nbrew tap paritytech/paritytech brew install parity 创世区块 创世区块的配置文件：\n// demo-spec.json { \u0026quot;name\u0026quot;: \u0026quot;DemoPoA\u0026quot;, \u0026quot;engine\u0026quot;: { \u0026quot;authorityRound\u0026quot;: { \u0026quot;params\u0026quot;: { \u0026quot;stepDuration\u0026quot;: \u0026quot;5\u0026quot;, \u0026quot;validators\u0026quot;: { \u0026quot;list\u0026quot;: [ \u0026quot;0x00bd138abd70e2f00903268f3db08f2d25677c9e\u0026quot;, \u0026quot;0x00aa39d30f0d20ff03a22ccfc30b7efbfca597c2\u0026quot; ] } } } }, \u0026quot;params\u0026quot;: { \u0026quot;gasLimitBoundDivisor\u0026quot;: \u0026quot;0x400\u0026quot;, \u0026quot;maximumExtraDataSize\u0026quot;: \u0026quot;0x20\u0026quot;, \u0026quot;minGasLimit\u0026quot;: \u0026quot;0x1388\u0026quot;, \u0026quot;networkID\u0026quot;: \u0026quot;0x2323\u0026quot;, \u0026quot;eip155Transition\u0026quot;: 0, \u0026quot;validateChainIdTransition\u0026quot;: 0, \u0026quot;eip140Transition\u0026quot;: 0, \u0026quot;eip211Transition\u0026quot;: 0, \u0026quot;eip214Transition\u0026quot;: 0, \u0026quot;eip658Transition\u0026quot;: 0 }, \u0026quot;genesis\u0026quot;: { \u0026quot;seal\u0026quot;: { \u0026quot;authorityRound\u0026quot;: { \u0026quot;step\u0026quot;: \u0026quot;0x0\u0026quot;, \u0026quot;signature\u0026quot;: \u0026quot;0x0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\u0026quot; } }, \u0026quot;difficulty\u0026quot;: \u0026quot;0x20000\u0026quot;, \u0026quot;gasLimit\u0026quot;: \u0026quot;0x5B8D80\u0026quot; }, \u0026quot;accounts\u0026quot;: { \u0026quot;0x0000000000000000000000000000000000000001\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ecrecover\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 3000, \u0026quot;word\u0026quot;: 0 } } } }, \u0026quot;0x0000000000000000000000000000000000000002\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;sha256\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 60, \u0026quot;word\u0026quot;: 12 } } } }, \u0026quot;0x0000000000000000000000000000000000000003\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;ripemd160\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 600, \u0026quot;word\u0026quot;: 120 } } } }, \u0026quot;0x0000000000000000000000000000000000000004\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;builtin\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;identity\u0026quot;, \u0026quot;pricing\u0026quot;: { \u0026quot;linear\u0026quot;: { \u0026quot;base\u0026quot;: 15, \u0026quot;word\u0026quot;: 3 } } } }, \u0026quot;0x004ec07d2329997267ec62b4166639513386f32e\u0026quot;: { \u0026quot;balance\u0026quot;: \u0026quot;10000000000000000000000\u0026quot; } } } node0 node0 节点：","title":"基于以太坊的 Parity 联盟链部署"},{"content":"redis 持久化，\n机制有两种：\n 快照：全量备份，二进制序列化，存储紧凑 AOF 日志：连续的增量备份，内存数据修改的文本  ","permalink":"https://zhenfeng-zhu.github.io/posts/dive-into-redis/","summary":"redis 持久化，\n机制有两种：\n 快照：全量备份，二进制序列化，存储紧凑 AOF 日志：连续的增量备份，内存数据修改的文本  ","title":"dive-into-redis"},{"content":"一  x509 error when using HTTPS inside a Docker container\n 因为 docker 中没有 CA 证书。\n普通的镜像解决办法\nFROM ubuntu:14.04.1 RUN apt-get update RUN apt-get install -y ca-certificates CMD curl https://www.google.com 如果是 alpine 的参考这个：\nFROM docker.finogeeks.club/base/alpine MAINTAINER \u0026#34;zhuzhenfeng@finogeeks.club\u0026#34; RUN set -ex \\ \u0026amp;\u0026amp; apk add --no-cache ca-certificates COPY src/wallet/wallet /opt/wallet ENTRYPOINT /opt/wallet 二  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x38 pc=0x26df]\n \u0026ldquo;An error is returned if caused by client policy (such as CheckRedirect), or if there was an HTTP protocol error. A non-2xx response doesn\u0026rsquo;t cause an error.\nWhen err is nil, resp always contains a non-nil resp.Body.\u0026quot;\n是 http 请求的时候，defer res.Body.Close()引起的，应该在 err 检查之后。\nThe defer only defers the function call. The field and method are accessed immediately.\n","permalink":"https://zhenfeng-zhu.github.io/posts/golang%E8%B8%A9%E5%9D%91/","summary":"一  x509 error when using HTTPS inside a Docker container\n 因为 docker 中没有 CA 证书。\n普通的镜像解决办法\nFROM ubuntu:14.04.1 RUN apt-get update RUN apt-get install -y ca-certificates CMD curl https://www.google.com 如果是 alpine 的参考这个：\nFROM docker.finogeeks.club/base/alpine MAINTAINER \u0026#34;zhuzhenfeng@finogeeks.club\u0026#34; RUN set -ex \\ \u0026amp;\u0026amp; apk add --no-cache ca-certificates COPY src/wallet/wallet /opt/wallet ENTRYPOINT /opt/wallet 二  panic: runtime error: invalid memory address or nil pointer dereference [signal 0xb code=0x1 addr=0x38 pc=0x26df]\n \u0026ldquo;An error is returned if caused by client policy (such as CheckRedirect), or if there was an HTTP protocol error.","title":"golang 踩坑"},{"content":"最近因公司项目需要，做为一个打杂工程师，操起键盘和笔记本开始了以太坊的踩坑之旅。以太坊的开发比较新，变化也比较多，还好有@cctanfujun的手把手带领下，半只脚踏入了以太坊的开发的大门。\n在这篇文章中，我将会简单介绍一下以太坊的基本概念，以及我现在用到的一些工具，还有具体的一个开发流程。因为我还没有接触到如何上主链，所以这些都是基于测试链讲解。希望能给大家带来一些帮助。\n什么是区块链\n相信大家对区块链都有自己的理解，不仅仅是互联网公司，传统企业也在“币改转型”。\n**简言之，区块链就是数据库。**它是特定数据的数据库，里面的数据不断增长，具有非凡特性：\n 一旦数据存储于数据库，永远都无法被修改或删除。区块链上的每个记录会被永久保存下来。 没有单独的个人或组织能维护该数据库。必须要上千个人才行，每个人都有数据库的副本。  什么是以太坊？\n 以太坊（英语：Ethereum）是一个开源的有智能合约功能的公共区块链平台[1][2]。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。\n 为什么选择以太坊？\n  智能合约\n  代币\n  资料相对完善，相对容易开发\n  大佬对以太坊比较熟悉\n  大佬对以太坊比较熟悉\n  大佬对以太坊比较熟悉\n  重要的事情说三遍，有一个经验丰富的人带领，做东西肯定事半功倍。\n自己动手写区块链\n这里提供两个教程，一个是书，一个是视频。其中视频和书是对应的，不清楚是不是同一个作者。\nBlockchain Tutorial\n私有区块链，我们一起 GO\n以太坊开发\n由于我是专注于后端的开发，现在的技术栈是\n node go  正式进入以太坊的开发。这是我这段时间接触到的一些资源：\n  go-ethereum：也就是 geth，官方的 go 版本的客户端\n  solidity：智能合约编程语言\n  truffle：智能合约的编程框架，基于 nodejs\n  Ganache：启动了多个节点本地私链\n  Rinkeby：以太坊测试链\n  Etherscan：以太坊区块链浏览器，可以查询交易\n  MetaMask：chrome 的钱包插件\n  web3：官方封装的开发 Dapp 的库，可以调用合约\n  truffle-hdwallet-provider：web3 的确定性钱包 provider\n  概念\n账户和钱包\n在以太坊中，一个账号就是一个地址（address），里面有余额。\n钱包是保管私钥的地址， 私钥-\u0026gt;公钥-\u0026gt;地址 这是一个一一对应的关系，钱包里面可以有多个账户。\n私钥不同的生成方法，对应着不同的钱包结构，因此分为了确定性钱包和非确定性钱包。\n 比特币最早的客户端（Satoshi client）就是非确定性钱包，钱包是一堆随机生成的私钥的集合。 客户端会预先生成 100 个随机私钥，并且每个私钥只使用一次。 确定性钱包则不需要每次转账都要备份，确定性钱包的私钥是对种子进行单向哈希运算生成的，种子是一串由随机数生成器生成的随机数。在确定性钱包中，只要有这个种子，就可以找回所有私钥  HD 钱包是目前常用的确定性钱包 ，说到 HD 钱包，大家可能第一反应会想到硬件钱包 （Hardware Wallet），其实这里的 HD 是 Hierarchical Deterministic（分层确定性）的缩写。\n 所谓分层，就是一个大公司可以为每个子部门分别生成不同的私钥，子部门还可以再管理子子部门的私钥，每个部门可以看到所有子部门里的币，也可以花这里面的币。也可以只给会计人员某个层级的公钥，让他可以看见这个部门及子部门的收支记录，但不能花里面的钱，使得财务管理更方便了。\n 生成规则是：\n 生成一个助记词（参见 BIP39） 该助记词使用 PBKDF2 转化为种子（参见 BIP39） 种子用于使用 HMAC-SHA512 生成根私钥（参见 BIP32） 从该根私钥，导出子私钥（参见 BIP32），其中节点布局由 BIP44 设置  DAPP\n以太坊与其他加密货币的主要不同在于，以太坊不是单纯的货币，而是一个环境/平台。在这个平台上，任何人都可以利用区块链的技术，通过智能合约来构建自己的项目和 DAPPS（去中心化应用）。DAPPS 发布的方式通常是采用被称为“ICO”的众筹方式。简单来说，你需要用你的以太来购买相应 DAPP 的一些 tokens。\n代币\n为什么不能在这些 DAPPS 中直接使用以太完成交易？为什么我们需要给 DAPPS 创造一种原生的货币？\n因为即使在现实生活中，我们也在使用某种形式的 Token 来代替现金。比如：在游乐场里，你先用现金兑换代币，然后用代币来支付各种服务。在这个例子中，现金就是以太，代币就是 token。\nERC20：以太坊 token 标准\n简单来说，ERC20 是开发者在自己的 tokens 中必须采用的一套具体的公式/方法，从而确保该 token 与 ERC20 兼容。在合约执行过程中，下面的四个行为是 ERC20 tokens 所需要完成的：\n 获得 Token 供给总量. 获得账户余额. 从一方向另一方转移 Token. 认可 Token 作为货币性资产的使用.  大佬说：代币其实就是智能合约，而这个合约是发生了 0 个以太的转账。\nGas 和挖矿\n不少小哥哥或小姐姐会认为挖矿就是挖以太币，其实代币不用挖的，当你挖到了区块，代币是给你的奖励。因为任何一笔交易都需要记录，一个区块的大小也就几 M，存储不了那么多交易信息，所以要持续挖区块来记录交易，同时只要是你发起了交易，就得付手续费，这些手续费也成为 Gas，会按照一定的算法奖励给挖出区块的人。\n接下来会讲一下，平时开发中如何创建钱包，如何转账，如何自己发代币，如何部署合约并调用。\n环境准备\n 安装 Ganache 并启动 安装 truffle 框架  创建钱包\ngolang\n依赖\ngithub.com/ethereum/go-ethereum 首先要连接到测试链，测试链可以是本地的也可以是公网的。\nfunc connectRPC() (*ethclient.Client, error) { // 连接测试链的节点 //rpcClient, err := rpc.Dial(\u0026#34;https://rinkeby.infura.io/v3/6c81fb1b66804f0698d49f2ec242afc9\u0026#34;) rpcClient, err := rpc.Dial(\u0026#34;http://127.0.0.1:7545\u0026#34;) if err != nil { log.Fatalln(err) return nil, err } conn := ethclient.NewClient(rpcClient) return conn, nil } 一般都选择以 keystore 的形式创建账户\nfunc CreateWallet() (key, addr string) { ks := keystore.NewKeyStore(\u0026#34;~/Documents/github/gowork/src/geth-demo/\u0026#34;, keystore.StandardScryptN, keystore.StandardScryptP) account, _ := ks.NewAccount(\u0026#34;password\u0026#34;) key_json, err := ks.Export(account, \u0026#34;password\u0026#34;, \u0026#34;password\u0026#34;) if err != nil { log.Fatalln(\u0026#34;导出账户错误: \u0026#34;, err) panic(err) } key = string(key_json) addr = account.Address.Hex() return } 当然另一种创建账户的方式是用私钥：\nfunc CreateWallet() (string, error) { key, err := crypto.GenerateKey() if err != nil { log.Fatalln(err) return \u0026#34;\u0026#34;, nil } address := crypto.PubkeyToAddress(key.PublicKey).Hex() log.Println(\u0026#34;address: \u0026#34;, address) privateKey := hex.EncodeToString(key.D.Bytes()) log.Println(\u0026#34;privateKey: \u0026#34;, privateKey) return address, nil } Node\nnode 一般使用 web3。创建 web3 对象的时候要使用一个 provider，这个 provider 用来连接到测试链，可以是钱包的，也可以是一个 HttpProvider。\n创建 web3\nconst web3 = new Web3(new Web3.providers.HttpProvider(\u0026#34;http://localhost:7545\u0026#34;)); 或者使用truffle-hdwallet-provider来创建，使用这个的前提是，自己已经创建了一个钱包，并且这个钱包是 HD 的。\nconst Web3 = require(\u0026#39;web3\u0026#39;); const HDWalletProvider = require(\u0026#39;truffle-hdwallet-provider\u0026#39;); const provider = new HDWalletProvider(助记词, 测试链url); const web3 = new Web3(provider); 创建账户\n","permalink":"https://zhenfeng-zhu.github.io/posts/eth-tools/","summary":"最近因公司项目需要，做为一个打杂工程师，操起键盘和笔记本开始了以太坊的踩坑之旅。以太坊的开发比较新，变化也比较多，还好有@cctanfujun的手把手带领下，半只脚踏入了以太坊的开发的大门。\n在这篇文章中，我将会简单介绍一下以太坊的基本概念，以及我现在用到的一些工具，还有具体的一个开发流程。因为我还没有接触到如何上主链，所以这些都是基于测试链讲解。希望能给大家带来一些帮助。\n什么是区块链\n相信大家对区块链都有自己的理解，不仅仅是互联网公司，传统企业也在“币改转型”。\n**简言之，区块链就是数据库。**它是特定数据的数据库，里面的数据不断增长，具有非凡特性：\n 一旦数据存储于数据库，永远都无法被修改或删除。区块链上的每个记录会被永久保存下来。 没有单独的个人或组织能维护该数据库。必须要上千个人才行，每个人都有数据库的副本。  什么是以太坊？\n 以太坊（英语：Ethereum）是一个开源的有智能合约功能的公共区块链平台[1][2]。通过其专用加密货币以太币（Ether，又称“以太币”）提供去中心化的虚拟机（称为“以太虚拟机”Ethereum Virtual Machine）来处理点对点合约。\n 为什么选择以太坊？\n  智能合约\n  代币\n  资料相对完善，相对容易开发\n  大佬对以太坊比较熟悉\n  大佬对以太坊比较熟悉\n  大佬对以太坊比较熟悉\n  重要的事情说三遍，有一个经验丰富的人带领，做东西肯定事半功倍。\n自己动手写区块链\n这里提供两个教程，一个是书，一个是视频。其中视频和书是对应的，不清楚是不是同一个作者。\nBlockchain Tutorial\n私有区块链，我们一起 GO\n以太坊开发\n由于我是专注于后端的开发，现在的技术栈是\n node go  正式进入以太坊的开发。这是我这段时间接触到的一些资源：\n  go-ethereum：也就是 geth，官方的 go 版本的客户端\n  solidity：智能合约编程语言\n  truffle：智能合约的编程框架，基于 nodejs\n  Ganache：启动了多个节点本地私链\n  Rinkeby：以太坊测试链\n  Etherscan：以太坊区块链浏览器，可以查询交易","title":"以太坊开发总结"},{"content":"参与了公司的一个项目，上了以太坊，这里简单记录一下踩坑。\n首先先把 go 的依赖下载下来：\ngo get -u -v github.com/ethereum/go-ethereum 有时候下载的很慢，可以从 github 上拉下来代码。\n账户 以太坊的地址在离线状态下也可以创建到。\n创建账户有两种方式：\n以公钥和私钥的形式创建 func CreateAccount() (string, error) { key, err := crypto.GenerateKey() if err != nil { log.Fatalln(err) return \u0026#34;\u0026#34;, nil } address := crypto.PubkeyToAddress(key.PublicKey).Hex() log.Println(\u0026#34;address: \u0026#34;, address) privateKey := hex.EncodeToString(key.D.Bytes()) log.Println(\u0026#34;privateKey: \u0026#34;, privateKey) return address, nil } 这种方式一般用的比较少。\n以 keystore 的形式创建 keystore 会创建一个文件，这个文件如下所示：\n{ \u0026quot;address\u0026quot;: \u0026quot;d93688757810e644f0b9c162102d9c598813f0dd\u0026quot;, \u0026quot;crypto\u0026quot;: { \u0026quot;cipher\u0026quot;: \u0026quot;aes-128-ctr\u0026quot;, \u0026quot;ciphertext\u0026quot;: \u0026quot;71ae7c8144729b2f9e0c51d95c6dfb73e63f14b5332b3594e8a1f325237c27ed\u0026quot;, \u0026quot;cipherparams\u0026quot;: { \u0026quot;iv\u0026quot;: \u0026quot;620c73001081c014a862ce80003a4648\u0026quot; }, \u0026quot;kdf\u0026quot;: \u0026quot;scrypt\u0026quot;, \u0026quot;kdfparams\u0026quot;: { \u0026quot;dklen\u0026quot;: 32, \u0026quot;n\u0026quot;: 262144, \u0026quot;p\u0026quot;: 1, \u0026quot;r\u0026quot;: 8, \u0026quot;salt\u0026quot;: \u0026quot;bd272aa37271ef9913eb095a4d143be238e348c48fce6459896e1bb1b0236741\u0026quot; }, \u0026quot;mac\u0026quot;: \u0026quot;2b3ade771645090a2b34c214906c592a1300d529e459faefb1421ba496b6fe1d\u0026quot; }, \u0026quot;id\u0026quot;: \u0026quot;e4dd5384-56a8-4ec7-b6e0-492dcd3742e9\u0026quot;, \u0026quot;version\u0026quot;: 3 } 在生成这个文件的时候，会让你输一个密码，这个文件加密码其实就是一个私钥。\n// 理论上来讲，这个函数应该只被创建一次即可 // 创建一个账户 func CreateWallet() (key, addr string) { ks := keystore.NewKeyStore(\u0026#34;/Users/zhuzhenfeng/Documents/github/gowork/src/geth-demo/\u0026#34;, keystore.StandardScryptN, keystore.StandardScryptP) account, _ := ks.NewAccount(\u0026#34;password\u0026#34;) key_json, err := ks.Export(account, \u0026#34;password\u0026#34;, \u0026#34;password\u0026#34;) if err != nil { log.Fatalln(\u0026#34;导出账户错误: \u0026#34;, err) panic(err) } key = string(key_json) addr = account.Address.Hex() return } 这个 key 和 address，\u0026ldquo;password\u0026quot;是这个文件的密码。\n私链 一种方式是连接互联网上的测试链，一种是连接本地的私链。\n本地私链的启动 启动本地私链最简单的一种方式是用 Truffle 提供的 Ganache，只要将它下载下来，启动起来即可。\n可以看到已经启动了，连接的地址是:\nhttp://127.0.0.1:7545 互联网上的测试链地址 https://rinkeby.infura.io/v3/6c81fb1b66804f0698d49f2ec242afc9 连接 我们用 geth 的 rpc 连接上面的私链地址即可：\nfunc connectRPC() (*ethclient.Client, error) { // 连接测试链的节点 //rpcClient, err := rpc.Dial(\u0026#34;https://rinkeby.infura.io/v3/6c81fb1b66804f0698d49f2ec242afc9\u0026#34;) rpcClient, err := rpc.Dial(\u0026#34;http://127.0.0.1:7545\u0026#34;) if err != nil { log.Fatalln(err) return nil, err } conn := ethclient.NewClient(rpcClient) return conn, nil } 其他操作 在上一步中连接 rpc 中，拿到了 client。用这个 client 就可以做很多事儿：\n获取余额 func GetBalance(address string) (float64, error) { client, err := connectRPC() if err != nil { log.Fatalln(\u0026#34;err: \u0026#34;, err) panic(err) } balance, err := client.BalanceAt(context.TODO(), common.HexToAddress(address), nil) if err != nil { log.Fatalln(balance) return 0, err } balanceV := float64(balance.Int64()) * math.Pow(10, -18) return balanceV, nil } 代币转账 要生成代币，需要写一个 token 的合约。可以用这一个最简单的 token.abi。复杂一般可以用 truffle 框架来编写。\n// token.abi [ { \u0026quot;anonymous\u0026quot;: false, \u0026quot;inputs\u0026quot;: [ { \u0026quot;indexed\u0026quot;: true, \u0026quot;name\u0026quot;: \u0026quot;from\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;address\u0026quot; }, { \u0026quot;indexed\u0026quot;: true, \u0026quot;name\u0026quot;: \u0026quot;to\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;address\u0026quot; }, { \u0026quot;indexed\u0026quot;: false, \u0026quot;name\u0026quot;: \u0026quot;value\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;uint256\u0026quot; } ], \u0026quot;name\u0026quot;: \u0026quot;Transfer\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;event\u0026quot; }, { \u0026quot;constant\u0026quot;: true, \u0026quot;inputs\u0026quot;: [], \u0026quot;name\u0026quot;: \u0026quot;totalSupply\u0026quot;, \u0026quot;outputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;uint256\u0026quot; } ], \u0026quot;payable\u0026quot;: false, \u0026quot;stateMutability\u0026quot;: \u0026quot;view\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot; }, { \u0026quot;constant\u0026quot;: false, \u0026quot;inputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;_to\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;address\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;_value\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;uint256\u0026quot; } ], \u0026quot;name\u0026quot;: \u0026quot;transfer\u0026quot;, \u0026quot;outputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;bool\u0026quot; } ], \u0026quot;payable\u0026quot;: false, \u0026quot;stateMutability\u0026quot;: \u0026quot;nonpayable\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot; }, { \u0026quot;constant\u0026quot;: true, \u0026quot;inputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;_owner\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;address\u0026quot; } ], \u0026quot;name\u0026quot;: \u0026quot;balanceOf\u0026quot;, \u0026quot;outputs\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;uint256\u0026quot; } ], \u0026quot;payable\u0026quot;: false, \u0026quot;stateMutability\u0026quot;: \u0026quot;view\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;function\u0026quot; } ] 然后将其转换为 go 文件：\nabigen --abi token.abi --pkg main --type Token --out token.go 生成的 token.go 文件，才是可以被操作的文件。\nfunc TransferToken() { key, to_address := CreateWallet() client, err := connectRPC() if err != nil { log.Fatalln(err) panic(err) } auth, err := bind.NewTransactor(strings.NewReader(key), \u0026#34;password\u0026#34;) if err != nil { log.Fatalln(\u0026#34;读取keystore失败\u0026#34;, err) panic(err) } token, err := cont.NewToken(common.HexToAddress(\u0026#34;0x75a26aaaecda412bd914e8fbfaed586a467fa8b5\u0026#34;), client) if err != nil { log.Fatalln(\u0026#34;获取token失败\u0026#34;, err) panic(err) } balance, err := token.BalanceOf(nil, common.HexToAddress(to_address)) if err != nil { log.Fatalln(\u0026#34;token balance of\u0026#34;, err) } log.Println(\u0026#34;to address balance: \u0026#34;, balance) amount := big.NewFloat(10.00) //这是处理位数的代码段 tenDecimal := big.NewFloat(math.Pow(10, 18)) convertAmount, _ := new(big.Float).Mul(tenDecimal, amount).Int(\u0026amp;big.Int{}) tx, err := token.Transfer(auth, common.HexToAddress(to_address), convertAmount) if nil != err { fmt.Printf(\u0026#34;err: %v \\n\u0026#34;, err) return } fmt.Printf(\u0026#34;result: %v\\n\u0026#34;, tx) }  不知为何会出现 failed to estimate gas needed 的情况\n 代币转账的代码就如上所示，有了这个，其实我们就可以发币了。\n至于上面的一句代码中的：\ntoken, err := cont.NewToken(common.HexToAddress(\u0026#34;0x75a26aaaecda412bd914e8fbfaed586a467fa8b5\u0026#34;), client) 这个0x75a26aaaecda412bd914e8fbfaed586a467fa8b5地址，就是合约的地址。关于合约的部署，其实如果是在本地调试的话，可以用 truffle。truffle 在部署的时候，会将合约地址返回。\n如下图所示：\n关于如何在以太坊上写代币的合约，下次再写一下笔记。\n总结 可以用 web3 去做这些事儿，会更简单一些。因为服务端选型用的 go，所以就用 go 踩了一些坑。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E4%BB%A5%E5%A4%AA%E5%9D%8A/","summary":"参与了公司的一个项目，上了以太坊，这里简单记录一下踩坑。\n首先先把 go 的依赖下载下来：\ngo get -u -v github.com/ethereum/go-ethereum 有时候下载的很慢，可以从 github 上拉下来代码。\n账户 以太坊的地址在离线状态下也可以创建到。\n创建账户有两种方式：\n以公钥和私钥的形式创建 func CreateAccount() (string, error) { key, err := crypto.GenerateKey() if err != nil { log.Fatalln(err) return \u0026#34;\u0026#34;, nil } address := crypto.PubkeyToAddress(key.PublicKey).Hex() log.Println(\u0026#34;address: \u0026#34;, address) privateKey := hex.EncodeToString(key.D.Bytes()) log.Println(\u0026#34;privateKey: \u0026#34;, privateKey) return address, nil } 这种方式一般用的比较少。\n以 keystore 的形式创建 keystore 会创建一个文件，这个文件如下所示：\n{ \u0026quot;address\u0026quot;: \u0026quot;d93688757810e644f0b9c162102d9c598813f0dd\u0026quot;, \u0026quot;crypto\u0026quot;: { \u0026quot;cipher\u0026quot;: \u0026quot;aes-128-ctr\u0026quot;, \u0026quot;ciphertext\u0026quot;: \u0026quot;71ae7c8144729b2f9e0c51d95c6dfb73e63f14b5332b3594e8a1f325237c27ed\u0026quot;, \u0026quot;cipherparams\u0026quot;: { \u0026quot;iv\u0026quot;: \u0026quot;620c73001081c014a862ce80003a4648\u0026quot; }, \u0026quot;kdf\u0026quot;: \u0026quot;scrypt\u0026quot;, \u0026quot;kdfparams\u0026quot;: { \u0026quot;dklen\u0026quot;: 32, \u0026quot;n\u0026quot;: 262144, \u0026quot;p\u0026quot;: 1, \u0026quot;r\u0026quot;: 8, \u0026quot;salt\u0026quot;: \u0026quot;bd272aa37271ef9913eb095a4d143be238e348c48fce6459896e1bb1b0236741\u0026quot; }, \u0026quot;mac\u0026quot;: \u0026quot;2b3ade771645090a2b34c214906c592a1300d529e459faefb1421ba496b6fe1d\u0026quot; }, \u0026quot;id\u0026quot;: \u0026quot;e4dd5384-56a8-4ec7-b6e0-492dcd3742e9\u0026quot;, \u0026quot;version\u0026quot;: 3 } 在生成这个文件的时候，会让你输一个密码，这个文件加密码其实就是一个私钥。","title":"以太坊"},{"content":"类型 Solidity 是静态类型的语言。\n值类型  bool int/uint fixed/unfixed address  balance 和 transfer send call, callcode 和 delegatecall   byte bytes 和 string 十六进制 hex\u0026quot;0012\u0026quot; enum function  引用类型   数组\nuint[]\n  结构体\nstruct\n  Map\nmapping(key =\u0026gt; value)\n  单元和全局变量   以太币的单位\n在数字后面加上 wei、 finney、 szabo 或 ether。默认是 wei\n  时间单位\n数字后面带有 seconds、 minutes、 hours、 days、 weeks 和 years。默认是秒。\n  区块和交易\n block.blockhash(uint blockNumber) returns (bytes32)：指定区块的区块哈希。 block.coinbase (address): 挖出当前区块的矿工地址 block.difficulty (uint): 当前区块难度 block.gaslimit (uint): 当前区块 gas 限额 block.number (uint): 当前区块号 block.timestamp (uint): 自 unix epoch 起始当前区块以秒计的时间戳 gasleft() returns (uint256)：剩余的 gas msg.data (bytes): 完整的 calldata msg.gas (uint): 剩余 gas - 自 0.4.21 版本开始已经不推荐使用，由 gesleft() 代替 msg.sender (address): 消息发送者（当前调用） msg.sig (bytes4): calldata 的前 4 字节（也就是函数标识符） msg.value (uint): 随消息发送的 wei 的数量 now (uint): 目前区块时间戳（block.timestamp） tx.gasprice (uint): 交易的 gas 价格 tx.origin (address): 交易发起者（完全的调用链）    地址相关\n  \u0026lt;address\u0026gt;.balance (uint256):\n以 Wei 为单位的 地址类型 的余额。\n  \u0026lt;address\u0026gt;.transfer(uint256 amount):\n向 地址类型 发送数量为 amount 的 Wei，失败时抛出异常，发送 2300 gas 的矿工费，不可调节。\n  \u0026lt;address\u0026gt;.send(uint256 amount) returns (bool):\n向 地址类型 发送数量为 amount 的 Wei，失败时返回 false，发送 2300 gas 的矿工费用，不可调节。\n  \u0026lt;address\u0026gt;.call(...) returns (bool):\n发出低级函数 CALL，失败时返回 false，发送所有可用 gas，可调节。\n  \u0026lt;address\u0026gt;.callcode(...) returns (bool)：\n发出低级函数 CALLCODE，失败时返回 false，发送所有可用 gas，可调节。\n  \u0026lt;address\u0026gt;.delegatecall(...) returns (bool):\n发出低级函数 DELEGATECALL，失败时返回 false，发送所有可用 gas，可调节。\n    合约相关\nthis (current contract\u0026rsquo;s type):\n当前合约，可以明确转换为 地址类型。\nselfdestruct(address recipient):\n销毁合约，并把余额发送到指定 地址类型。\nsuicide(address recipient):\n与 selfdestruct 等价，但已不推荐使用。\n  控制结构 输入参数和我们常见的函数的参数相同\n输出参数必须要在 returns 后面，和 go 的类似\nfunction arithmetics(uint _a, uint _b) returns (uint o_sum, uint o_product) { o_sum = _a + _b; o_product = _a * _b; } function arithmetics(uint _a, uint _b) returns (uint , uint ) { o_sum = _a + _b; o_product = _a * _b; return o_sum, o_product; } 不能用 switch 和 goto\n内部函数调用，就和普通的方法调用一样。\n从外部调用合约的函数，先创建一个合约实例（和类的对象一样），然后调用实例方法。\n调函数要发送 wei 和 gas，就像下图所示：\npragma solidity ^0.4.0; contract InfoFeed { function info() public payable returns (uint ret) { return 42; } } contract Consumer { InfoFeed feed; function setFeed(address addr) public { feed = InfoFeed(addr); } function callFeed() public { feed.info.value(10).gas(800)(); } } payable 修饰符要用于修饰 info，否则，.value() 选项将不可用。\n可以通过 new 创建一个合约，和 new 出一个对象一样。\n合约结构   状态变量\n状态变量是永久存储在合约中的值，其实可以理解为类的成员变量。\n  函数\n函数是合约的可执行单元，可以理解为类的成员函数。\n  函数修饰器\n以声明的形式改良函数语义。\n  事件\n以太坊的日志工具接口。\nevent HighestBidIncreased(address bidder, uint amount); // 事件 emit HighestBidIncreased(msg.sender, msg.value); // 触发事件   结构体\n理解为数据类。\n  枚举\n  合约函数可见性修饰\n","permalink":"https://zhenfeng-zhu.github.io/posts/contract/","summary":"类型 Solidity 是静态类型的语言。\n值类型  bool int/uint fixed/unfixed address  balance 和 transfer send call, callcode 和 delegatecall   byte bytes 和 string 十六进制 hex\u0026quot;0012\u0026quot; enum function  引用类型   数组\nuint[]\n  结构体\nstruct\n  Map\nmapping(key =\u0026gt; value)\n  单元和全局变量   以太币的单位\n在数字后面加上 wei、 finney、 szabo 或 ether。默认是 wei\n  时间单位\n数字后面带有 seconds、 minutes、 hours、 days、 weeks 和 years。默认是秒。\n  区块和交易","title":"contract"},{"content":"faas-provider 是一个模板，只要实现了这个模板的接口，就可以自定义实现自己的 provider。\nfaas-provider OpenFaaS 官方提供了两套后台 provider：\n Docker Swarm Kubernetes  这两者在部署和调用函数的时候流程图如下：\n部署一个函数\n调用一个函数\nprovider 要提供的一些 API 有：\n List / Create / Delete 一个函数  /system/functions\n方法: GET / POST / DELETE\n 获取一个函数  /system/function/{name:[-a-zA-Z_0-9]+}\n方法: GET\n 伸缩一个函数  /system/scale-function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n 调用一个函数  /function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n在 provider 的 server.go 的 serve 方法，可以看到这个 serve 方法创建了几个路由，接受一个 FaaSHandler 对象。\n// Serve load your handlers into the correct OpenFaaS route spec. This function is blocking. func Serve(handlers *types.FaaSHandlers, config *types.FaaSConfig) { r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.FunctionReader).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.DeployHandler).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.DeleteHandler).Methods(\u0026#34;DELETE\u0026#34;) r.HandleFunc(\u0026#34;/system/functions\u0026#34;, handlers.UpdateHandler).Methods(\u0026#34;PUT\u0026#34;) r.HandleFunc(\u0026#34;/system/function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.ReplicaReader).Methods(\u0026#34;GET\u0026#34;) r.HandleFunc(\u0026#34;/system/scale-function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.ReplicaUpdater).Methods(\u0026#34;POST\u0026#34;) r.HandleFunc(\u0026#34;/function/{name:[-a-zA-Z_0-9]+}\u0026#34;, handlers.FunctionProxy) r.HandleFunc(\u0026#34;/function/{name:[-a-zA-Z_0-9]+}/\u0026#34;, handlers.FunctionProxy) r.HandleFunc(\u0026#34;/system/info\u0026#34;, handlers.InfoHandler).Methods(\u0026#34;GET\u0026#34;) if config.EnableHealth { r.HandleFunc(\u0026#34;/healthz\u0026#34;, handlers.Health).Methods(\u0026#34;GET\u0026#34;) } // 省略 } 因此在自定义的 provider，只需实现 FaaSHandlers 中的几个路由处理函数即可。这几个 handler 是：\n// FaaSHandlers provide handlers for OpenFaaS type FaaSHandlers struct { FunctionReader http.HandlerFunc DeployHandler http.HandlerFunc DeleteHandler http.HandlerFunc ReplicaReader http.HandlerFunc FunctionProxy http.HandlerFunc ReplicaUpdater http.HandlerFunc // Optional: Update an existing function UpdateHandler http.HandlerFunc Health http.HandlerFunc InfoHandler http.HandlerFunc } 我们以官方实现的 faas-netes 为例，讲解一下这几个 hander 的实现过程。\nfaas-netes 我们看下在 faas-netes 的中的 FaaSHandlers 实现：\nbootstrapHandlers := bootTypes.FaaSHandlers{ FunctionProxy: handlers.MakeProxy(functionNamespace, cfg.ReadTimeout), DeleteHandler: handlers.MakeDeleteHandler(functionNamespace, clientset), DeployHandler: handlers.MakeDeployHandler(functionNamespace, clientset, deployConfig), FunctionReader: handlers.MakeFunctionReader(functionNamespace, clientset), ReplicaReader: handlers.MakeReplicaReader(functionNamespace, clientset), ReplicaUpdater: handlers.MakeReplicaUpdater(functionNamespace, clientset), UpdateHandler: handlers.MakeUpdateHandler(functionNamespace, clientset), Health: handlers.MakeHealthHandler(), InfoHandler: handlers.MakeInfoHandler(version.BuildVersion(), version.GitCommit), } 因为是 Kubernetes 上的 provider 实现，所以这些函数都带有一个 namespace 的参数。\nFunctionProxy 这里最重要的就是 FunctionProxy，它主要负责调用函数。这个 handler 其实也是起到了一个代理转发的作用，在这个函数中，只接受 get 和 post。调用函数只接受 post 和 get 请求\n  创建一个 http 的 client 对象\n  只处理 get 和 post 请求。\n  组装代理转发的 watchdog 的地址\nurl := forwardReq.ToURL(fmt.Sprintf(\u0026#34;%s.%s\u0026#34;, service, functionNamespace), watchdogPort) 所以最后请求的格式就会形如：\nhttp://函数名.namespace:监视器的端口/路径   将请求发出去\n  设置 http 响应的头\n  ReplicaReader 和 ReplicaUpdater 这两个是和副本数相关的，所以放在一起对比讲解。这两个的实现依赖于 Kubernetes 的客户端，获取代码如下：\nclientset, err := kubernetes.NewForConfig(config) 这个 config 主要满足以下几个条件就行：\nConfig{ // TODO: switch to using cluster DNS. Host: \u0026#34;https://\u0026#34; + net.JoinHostPort(host, port), BearerToken: string(token), TLSClientConfig: tlsClientConfig, } Kubernetes 的所有操作都可以通过 rest api 来完成，这两个 handler 也是通过调用 Kubernetes 的 api 来做的。\nReplicaReader MakeReplicaReader函数是获取当前的副本数：\n  通过 mux 从路由中获取到 name 参数\n  调用 getService 方法获取副本数，getService 的核心代码就一句：\nitem, err := clientset.ExtensionsV1beta1().Deployments(functionNamespace).Get(functionName, getOpts)   序列化之后，把结果返回\n  ReplicaUpdater MakeReplicaUpdater是解析从 gateway 传过来的 post 请求，调用 k8s 的 API 设置副本数。\n  从请求中取出 body\n  首先获取该函数的已部署的 deployment 对象\n  然后将 deployment 的副本数量设置为应设数量，这样做的目的是为了仅仅修改副本数，而不修改别的属性。\n_, err = clientset.ExtensionsV1beta1().Deployments(functionNamespace).Update(deployment)    注：mux 做路由的时候，如果成功的时候不对 w 做任何处理，是会默认状态码为 200，空字符串。\n DeleteHandler，DeployHandler，FunctionReader 和 UpdateHandler 这几个都是对函数的操作，其实就是调用一下 Kubernetes 的 API 进行操作。\n这几个是核心的几句代码：\nclientset.ExtensionsV1beta1().Deployments(functionNamespace).Delete(request.FunctionName, opts) deploy := clientset.Extensions().Deployments(functionNamespace) res, err := clientset.ExtensionsV1beta1().Deployments(functionNamespace).List(listOpts) _, updateErr := clientset.CoreV1().Services(functionNamespace).Update(service) 总结 官方还提供了一个 faas-swarm，其实现思路也是这样，操作 swarm 的 api 来做对容器的操作。至于如何调用一个函数，都是在函数的 watchdog 中实现。\n","permalink":"https://zhenfeng-zhu.github.io/posts/faas-provider/","summary":"faas-provider 是一个模板，只要实现了这个模板的接口，就可以自定义实现自己的 provider。\nfaas-provider OpenFaaS 官方提供了两套后台 provider：\n Docker Swarm Kubernetes  这两者在部署和调用函数的时候流程图如下：\n部署一个函数\n调用一个函数\nprovider 要提供的一些 API 有：\n List / Create / Delete 一个函数  /system/functions\n方法: GET / POST / DELETE\n 获取一个函数  /system/function/{name:[-a-zA-Z_0-9]+}\n方法: GET\n 伸缩一个函数  /system/scale-function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n 调用一个函数  /function/{name:[-a-zA-Z_0-9]+}\n方法: POST\n在 provider 的 server.go 的 serve 方法，可以看到这个 serve 方法创建了几个路由，接受一个 FaaSHandler 对象。\n// Serve load your handlers into the correct OpenFaaS route spec.","title":"faas-provider"},{"content":"OpenFaaS 的 Gateway 是一个 golang 实现的请求转发的网关，在这个网关服务中，主要有以下几个功能：\n UI 部署函数 监控 自动伸缩  架构分析 从图中可以发现，当 Gateway 作为一个入口，当 CLI 或者 web 页面发来要部署或者调用一个函数的时候，Gateway 会将请求转发给 Provider，同时会将监控指标发给 Prometheus。AlterManager 会根据需求，调用 API 自动伸缩函数。\n源码分析 依赖 github.com/gorilla/mux github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/nats-queue-worker github.com/prometheus/client_golang mux 是一个用来执行 http 请求的路由和分发的第三方扩展包。\ngo-nats-streaming，go-nats，nats-queue-worker 这三个依赖是异步函数的时候才会用到，在分析 queue-worker 的时候有说到 Gateway 也是一个发布者。\nclient_golang 是 Prometheus 的客户端。\n项目结构 ├── Dockerfile ├── Dockerfile.arm64 ├── Dockerfile.armhf ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── assets ├── build.sh ├── handlers │ ├── alerthandler.go │ ├── alerthandler_test.go │ ├── asyncreport.go │ ├── baseurlresolver_test.go │ ├── basic_auth.go │ ├── basic_auth_test.go │ ├── callid_middleware.go │ ├── cors.go │ ├── cors_test.go │ ├── forwarding_proxy.go │ ├── forwarding_proxy_test.go │ ├── function_cache.go │ ├── function_cache_test.go │ ├── infohandler.go │ ├── metrics.go │ ├── queueproxy.go │ ├── scaling.go │ └── service_query.go ├── metrics │ ├── add_metrics.go │ ├── add_metrics_test.go │ ├── externalwatcher.go │ ├── metrics.go │ └── prometheus_query.go ├── plugin │ ├── external.go │ └── external_test.go ├── queue │ └── types.go ├── requests │ ├── forward_request.go │ ├── forward_request_test.go │ ├── prometheus.go │ ├── prometheus_test.go │ └── requests.go ├── server.go ├── tests │ └── integration ├── types │ ├── handler_set.go │ ├── inforequest.go │ ├── load_credentials.go │ ├── proxy_client.go │ ├── readconfig.go │ └── readconfig_test.go ├── vendor │ └── github.com └── version └── version.go Gateway 的目录明显多了很多，看源码的时候，首先要找到的是 main 包，从 main 函数看起，就能很容易分析出来项目是如何运行的。\n从 server.go 的 main 函数中我们可以看到，其实有如下几个模块：\n 基本的安全验证 和函数相关的代理转发  同步函数  列出函数 部署函数 删除函数 更新函数   异步函数   Prometheus 的监控 ui 自动伸缩  基本的安全验证 如果配置了开启基本安全验证，会从磁盘中读取密钥：\nvar credentials *types.BasicAuthCredentials if config.UseBasicAuth { var readErr error reader := types.ReadBasicAuthFromDisk{ SecretMountPath: config.SecretMountPath, } credentials, readErr = reader.Read() if readErr != nil { log.Panicf(readErr.Error()) } } 在 Gateway 的配置相关的，都会有一个 read()方法，进行初始化赋值。\n如果 credentials 被赋值之后，就会对一些要加密的 API handler 进行一个修饰，被修饰的 API 有：\n UpdateFunction DeleteFunction DeployFunction ListFunctions ScaleFunction  if credentials != nil { faasHandlers.UpdateFunction = handlers.DecorateWithBasicAuth(faasHandlers.UpdateFunction, credentials) faasHandlers.DeleteFunction = handlers.DecorateWithBasicAuth(faasHandlers.DeleteFunction, credentials) faasHandlers.DeployFunction = handlers.DecorateWithBasicAuth(faasHandlers.DeployFunction, credentials) faasHandlers.ListFunctions = handlers.DecorateWithBasicAuth(faasHandlers.ListFunctions, credentials) faasHandlers.ScaleFunction = handlers.DecorateWithBasicAuth(faasHandlers.ScaleFunction, credentials) } 这个 DecorateWithBasicAuth()方法是一个路由中间件：\n 调用 mux 路由的 BasicAuth()，从 http 的 header 中取到用户名和密码 然后给请求头上设置一个字段WWW-Authenticate，值为Basic realm=\u0026quot;Restricted\u0026quot; 如果校验失败，则返回错误，成功的话调用 next 方法继续进入下一个 handler。  // DecorateWithBasicAuth enforces basic auth as a middleware with given credentials func DecorateWithBasicAuth(next http.HandlerFunc, credentials *types.BasicAuthCredentials) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { user, password, ok := r.BasicAuth() w.Header().Set(\u0026#34;WWW-Authenticate\u0026#34;, `Basic realm=\u0026#34;Restricted\u0026#34;`) if !ok || !(credentials.Password == password \u0026amp;\u0026amp; user == credentials.User) { w.WriteHeader(http.StatusUnauthorized) w.Write([]byte(\u0026#34;invalid credentials\u0026#34;)) return } next.ServeHTTP(w, r) } } 代理转发 Gateway 本身不做任何和部署发布函数的事情，它只是作为一个代理，把请求转发给相应的 Provider 去处理，所有的请求都要通过这个网关。\n同步函数转发 主要转发的 API 有：\n RoutelessProxy ListFunctions DeployFunction DeleteFunction UpdateFunction  faasHandlers.RoutelessProxy = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.ListFunctions = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.DeployFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.DeleteFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) faasHandlers.UpdateFunction = handlers.MakeForwardingProxyHandler(reverseProxy, forwardingNotifiers, urlResolver) MakeForwardingProxyHandler()有三个参数：\n  proxy\n这是一个 http 的客户端，作者把这个客户端抽成一个类，然后使用该类的 NewHTTPClientReverseProxy 方法创建实例，这样就简化了代码，不用每次都得写一堆相同的配置。\n  notifiers\n这个其实是要打印的日志，这里是一个 HTTPNotifier 的接口。而在这个 MakeForwardingProxyHandler 中其实有两个实现类，一个是 LoggingNotifier，一个是 PrometheusFunctionNotifier，分别用来打印和函数 http 请求相关的日志以及和 Prometheus 监控相关的日志。\n  baseURLResolver\n这个就是 Provider 的 url 地址。\n  在这个 MakeForwardingProxyHandler 中主要做了三件事儿：\n  解析要转发的 url\n  调用 forwardRequest 方法转发请求，\nforwardRequest 方法的逻辑比较简单，只是把请求发出去。这里就不深入分析了。\n  打印日志\n  // MakeForwardingProxyHandler create a handler which forwards HTTP requests func MakeForwardingProxyHandler(proxy *types.HTTPClientReverseProxy, notifiers []HTTPNotifier, baseURLResolver BaseURLResolver) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { baseURL := baseURLResolver.Resolve(r) requestURL := r.URL.Path start := time.Now() statusCode, err := forwardRequest(w, r, proxy.Client, baseURL, requestURL, proxy.Timeout) seconds := time.Since(start) if err != nil { log.Printf(\u0026#34;error with upstream request to: %s, %s\\n\u0026#34;, requestURL, err.Error()) } for _, notifier := range notifiers { notifier.Notify(r.Method, requestURL, statusCode, seconds) } } } 异步函数转发 前面说过，如果是异步函数，Gateway 就作为一个发布者，将函数放到队列里。MakeQueuedProxy 方法就是做这件事儿的：\n 读取请求体 将X-Callback-Url参数从参数中 http 的 header 中读出来 实例化用于异步处理的 Request 对象 调用 canQueueRequests.Queue(req)，将请求发布到队列中  // MakeQueuedProxy accepts work onto a queue func MakeQueuedProxy(metrics metrics.MetricOptions, wildcard bool, canQueueRequests queue.CanQueueRequests) http.HandlerFunc { return func(w http.ResponseWriter, r *http.Request) { defer r.Body.Close() body, err := ioutil.ReadAll(r.Body) // 省略错误处理代码 vars := mux.Vars(r) name := vars[\u0026#34;name\u0026#34;] callbackURLHeader := r.Header.Get(\u0026#34;X-Callback-Url\u0026#34;) var callbackURL *url.URL if len(callbackURLHeader) \u0026gt; 0 { urlVal, urlErr := url.Parse(callbackURLHeader) // 省略错误处理代码 callbackURL = urlVal } req := \u0026amp;queue.Request{ Function: name, Body: body, Method: r.Method, QueryString: r.URL.RawQuery, Header: r.Header, CallbackURL: callbackURL, } err = canQueueRequests.Queue(req) // 省略错误处理代码 w.WriteHeader(http.StatusAccepted) } } 自动伸缩 伸缩性其实有两种，一种是可以通过调用 API 接口，来将函数进行缩放。另外一种就是通过 AlertHandler。\n自动伸缩是 OpenFaaS 的一大特点，触发自动伸缩主要是根据不同的指标需求。\n  根据每秒请求数来做伸缩\nOpenFaaS 附带了一个自动伸缩的规则，这个规则是在 AlertManager 配置文件中定义。AlertManager 从 Prometheus 中读取使用情况（每秒请求数），然后在满足一定条件时向 Gateway 发送警报。\n可以通过删除 AlertManager，或者将部署扩展的环境变量设置为 0，来禁用此方式。\n  最小/最大副本数\n通过向函数添加标签, 可以在部署时设置最小 (初始) 和最大副本数。\n com.openfaas.scale.min 默认是 1 com.openfaas.scale.max 默认是 20 com.openfaas.scale.factor 默认是 20% ，在 0-100 之间，这是每次扩容的时候，新增实例的百分比，若是 100 的话，会瞬间飙升到副本数的最大值。  com.openfaas.scale.min 和 com.openfaas.scale.max值一样的时候，可以关闭自动伸缩。\ncom.openfaas.scale.factor是 0 时，也会关闭自动伸缩。\n  通过内存和 CPU 的使用量。\n使用 k8s 内置的 HPA，也可以触发 AlertManager。\n  手动指定伸缩的值 可以从这句代码中发现，调用这个路由，转发给了 provider 处理。\nr.HandleFunc(\u0026#34;/system/scale-function/{name:[-a-zA-Z_0-9]+}\u0026#34;, faasHandlers.ScaleFunction).Methods(http.MethodPost) 处理 AlertManager 的伸缩请求 Prometheus 将监控指标发给 AlertManager 之后，会触发 AlterManager 调用/system/alert接口，这个接口的 handler 是由handlers.MakeAlertHandler方法生成。\nMakeAlertHandler 方法接收的参数是 ServiceQuery。ServiceQuery 是一个接口，它有两个函数，用来 get 或者 ser 最大的副本数。Gateway 中实现这个接口的类是 ExternalServiceQuery，这个实现类是在 plugin 包中，我们也可以直接定制这个实现类，用来实现满足特定条件。\n// ServiceQuery provides interface for replica querying/setting type ServiceQuery interface { GetReplicas(service string) (response ServiceQueryResponse, err error) SetReplicas(service string, count uint64) error } // ExternalServiceQuery proxies service queries to external plugin via HTTP type ExternalServiceQuery struct { URL url.URL ProxyClient http.Client } 这个 ExternalServiceQuery 有一个NewExternalServiceQuery方法，这个方法也是一个工厂方法，用来创建实例。这个 url 其实就是 provider 的 url，proxyClient 就是一个 http 的 client 对象。\n  GetReplicas方法\n从system/function/:name接口获取到函数的信息，组装一个ServiceQueryResponse对象即可。\n  SetReplicas方法\n调用system/scale-function/:name接口，设置副本数。\n  MakeAlertHandler 的函数主要是从http.Request中读取 body，然后反序列化成PrometheusAlert对象：\n// PrometheusAlert as produced by AlertManager type PrometheusAlert struct { Status string `json:\u0026#34;status\u0026#34;` Receiver string `json:\u0026#34;receiver\u0026#34;` Alerts []PrometheusInnerAlert `json:\u0026#34;alerts\u0026#34;` } 可以发现，这个 Alerts 是一个数组对象，所以可以是对多个函数进行缩放。反序列化之后，调用handleAlerts方法，而handleAlerts对 Alerts 进行遍历，针对每个 Alerts 调用了scaleService方法。scaleService才是真正处理伸缩服务的函数。\nfunc scaleService(alert requests.PrometheusInnerAlert, service ServiceQuery) error { var err error serviceName := alert.Labels.FunctionName if len(serviceName) \u0026gt; 0 { queryResponse, getErr := service.GetReplicas(serviceName) if getErr == nil { status := alert.Status newReplicas := CalculateReplicas(status, queryResponse.Replicas, uint64(queryResponse.MaxReplicas), queryResponse.MinReplicas, queryResponse.ScalingFactor) log.Printf(\u0026#34;[Scale] function=%s %d =\u0026gt; %d.\\n\u0026#34;, serviceName, queryResponse.Replicas, newReplicas) if newReplicas == queryResponse.Replicas { return nil } updateErr := service.SetReplicas(serviceName, newReplicas) if updateErr != nil { err = updateErr } } } return err } 从代码总就可以看到，scaleService 做了三件事儿：\n  获取现在的副本数\n  计算新的副本数\n新副本数的计算方法是根据com.openfaas.scale.factor计算步长：\nstep := uint64((float64(maxReplicas) / 100) * float64(scalingFactor))   设置为新的副本数\n  从 0 增加副本到的最小值 我们在调用函数的时候，用的路由是：/function/:name。如果环境变量里有配置scale_from_zero为 true，先用MakeScalingHandler()方法对 proxyHandler 进行一次包装。\nMakeScalingHandler接受参数主要是：\n  next：就是下一个 httpHandlerFunc，中间件都会有这样一个参数\n  config：ScalingConfig的对象：\n// ScalingConfig for scaling behaviours type ScalingConfig struct { MaxPollCount uint // 查到的最大数量 FunctionPollInterval time.Duration // 函数调用时间间隔 CacheExpiry time.Duration // 缓存过期时间 ServiceQuery ServiceQuery // 外部服务调用的一个接口 }   这个MakeScalingHandler中间件主要做了如下的事情：\n 先从 FunctionCache 缓存中获取该函数的基本信息，从这个缓存可以拿到每个函数的副本数量。 为了加快函数的启动速度，如果缓存中可以获该得函数，且函数的副本数大于 0，满足条件，return 即可。 如果不满足上一步，就会调用SetReplicas方法设置副本数，并更新 FunctionCache 的缓存。  // MakeScalingHandler creates handler which can scale a function from // zero to 1 replica(s). func MakeScalingHandler(next http.HandlerFunc, upstream http.HandlerFunc, config ScalingConfig) http.HandlerFunc { cache := FunctionCache{ Cache: make(map[string]*FunctionMeta), Expiry: config.CacheExpiry, } return func(w http.ResponseWriter, r *http.Request) { functionName := getServiceName(r.URL.String()) if serviceQueryResponse, hit := cache.Get(functionName); hit \u0026amp;\u0026amp; serviceQueryResponse.AvailableReplicas \u0026gt; 0 { next.ServeHTTP(w, r) return } queryResponse, err := config.ServiceQuery.GetReplicas(functionName) cache.Set(functionName, queryResponse) // 省略错误处理 if queryResponse.AvailableReplicas == 0 { minReplicas := uint64(1) if queryResponse.MinReplicas \u0026gt; 0 { minReplicas = queryResponse.MinReplicas } err := config.ServiceQuery.SetReplicas(functionName, minReplicas) // 省略错误处理代码 for i := 0; i \u0026lt; int(config.MaxPollCount); i++ { queryResponse, err := config.ServiceQuery.GetReplicas(functionName) cache.Set(functionName, queryResponse) // 省略错误处理 time.Sleep(config.FunctionPollInterval) } } next.ServeHTTP(w, r) } } 监控 监控是一个定时任务，开启了一个新协程，利用 go 的 ticker.C 的间隔不停的去调用/system/functions接口。反序列化到 MetricOptions 对象中。\nfunc AttachExternalWatcher(endpointURL url.URL, metricsOptions MetricOptions, label string, interval time.Duration) { ticker := time.NewTicker(interval) quit := make(chan struct{}) proxyClient := // 省略创建一个http.Client对象 go func() { for { select { case \u0026lt;-ticker.C: get, _ := http.NewRequest(http.MethodGet, endpointURL.String()+\u0026#34;system/functions\u0026#34;, nil) services := []requests.Function{} res, err := proxyClient.Do(get) // 省略反序列的代码 for _, service := range services { metricsOptions.ServiceReplicasCounter. WithLabelValues(service.Name). Set(float64(service.Replicas)) } break case \u0026lt;-quit: return } } }() } UI UI 的代码很简单，主要就是一些前端的代码，调用上面的讲的一些 API 接口即可，这里就略去不表。\n总结 Gateway 是 OpenFaaS 最为重要的一个组件。回过头看整个项目的结构，Gateway 就是一个 rest 转发服务，一个一个的 handler，每个模块之间的耦合性不是很高，可以很容易的去拆卸，自定义实现相应的模块。\n","permalink":"https://zhenfeng-zhu.github.io/posts/gateway-reading/","summary":"OpenFaaS 的 Gateway 是一个 golang 实现的请求转发的网关，在这个网关服务中，主要有以下几个功能：\n UI 部署函数 监控 自动伸缩  架构分析 从图中可以发现，当 Gateway 作为一个入口，当 CLI 或者 web 页面发来要部署或者调用一个函数的时候，Gateway 会将请求转发给 Provider，同时会将监控指标发给 Prometheus。AlterManager 会根据需求，调用 API 自动伸缩函数。\n源码分析 依赖 github.com/gorilla/mux github.com/nats-io/go-nats-streaming github.com/nats-io/go-nats github.com/openfaas/nats-queue-worker github.com/prometheus/client_golang mux 是一个用来执行 http 请求的路由和分发的第三方扩展包。\ngo-nats-streaming，go-nats，nats-queue-worker 这三个依赖是异步函数的时候才会用到，在分析 queue-worker 的时候有说到 Gateway 也是一个发布者。\nclient_golang 是 Prometheus 的客户端。\n项目结构 ├── Dockerfile ├── Dockerfile.arm64 ├── Dockerfile.armhf ├── Gopkg.lock ├── Gopkg.toml ├── README.md ├── assets ├── build.sh ├── handlers │ ├── alerthandler.go │ ├── alerthandler_test.","title":"gateway-reading"},{"content":"市面上常见到的和 Nats 功能类似的消息通信系统有：\nActiveMQ（Java 编写）、KafKa（Scala 编写）、RabbitMq（Ruby 编写）、Nats（之前是 Ruby 编写现已修改为 Go）、Redis（C 语言编写）、Kestrel（Scala 编写不常用）、NSQ（Go 语言编写），这些消息通信系统在 Broker 吞吐量方面的比较：\n可以看到 NATS 的吞吐量特别高， NATS 原来是使用 Ruby 编写，可以实现每秒 150k 消息，后来使用 Go 语言重写，能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。关于 NATS 的详细介绍，请参考上篇文章：NATS 简介\nNATS Streaming NATS Streaming 是由 NATS 驱动的数据流系统，也是由 go 语言写成的，在保证吞吐量和时延的基础上，解决了 Nats 消息投递一致性的问题。nats streaming 可以和核心 nats 平台无缝嵌入，扩展和互动。\n功能 除了 nats 平台的一些功能，nats streaming 还支持以下的：\n 增强的消息协议 消息/事件持久化 至少一次投递 发布者速率限制 每个订阅者的速率匹配/限制 可重复消费 持久订阅  使用 首先安装 nats-streaming-server 服务，有多种方式，这里介绍两种：\n  homebrew\n直接在命令行启动\nbrew install nats-streaming-server   go get\n这种方式可以让我们直接运行源码启动\ngo get github.com/nats-io/nats-streaming-server   启动 nats-streaming-server\n有三种启动方式\n  直接启动\nnats-streaming-server   开启 nats 监控的启动\nnats-streaming-server -m 8222   源码方式启动\ncd $GOPATH/src/github.com/nats-io/nats-streaming-server go run nats-streaming-server.go   客户端 直接下载 go 的客户端\ngo get github.com/nats-io/go-nats-streaming 运行发布者\ncd $GOPATH/src/github.com/nats-io/go-nats-streaming/examples/stan-pub go run main.go foo \u0026#34;msg one\u0026#34; go run main.go foo \u0026#34;msg two\u0026#34; go run main.go foo \u0026#34;msg three\u0026#34; 如下图所示：\n运行订阅者\ncd $GOPATH/src/github.com/nats-io/go-nats-streaming/examples/stan-sub go run main.go --all -c test-cluster -id myID foo 实例 首先在本地启动 nats-streaming-server，然后下面的代码展示了发布订阅的过程：\npackage main import ( \u0026#34;github.com/nats-io/go-nats-streaming\u0026#34; \u0026#34;github.com/nats-io/go-nats-streaming/pb\u0026#34; \u0026#34;log\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;time\u0026#34; ) func main() { var clusterId string = \u0026#34;test-cluster\u0026#34; var clientId string = \u0026#34;test-client\u0026#34; sc, err := stan.Connect(clusterId, clientId, stan.NatsURL(\u0026#34;nats://localhost:4222\u0026#34;)) if err != nil { log.Fatal(err) return } // 开启一个协程，不停的生产数据 go func() { m := 0 for { m++ sc.Publish(\u0026#34;foo1\u0026#34;, []byte(\u0026#34;hello message \u0026#34;+strconv.Itoa(m))) time.Sleep(time.Second) } }() // 消费数据 i := 0 mcb := func(msg *stan.Msg) { i++ log.Println(i, \u0026#34;----\u0026gt;\u0026#34;, msg.Subject, msg) } startOpt := stan.StartAt(pb.StartPosition_LastReceived) //_, err = sc.QueueSubscribe(\u0026#34;foo1\u0026#34;, \u0026#34;\u0026#34;, mcb, startOpt) // 也可以用queue subscribe _, err = sc.Subscribe(\u0026#34;foo1\u0026#34;, mcb, startOpt) if err != nil { sc.Close() log.Fatal(err) } // 创建一个channel，阻塞着 signalChan := make(chan int) \u0026lt;-signalChan } 运行结果如下：\n2018/07/30 18:04:01 2 ----\u0026gt; foo1 sequence:546 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 1\u0026#34; timestamp:1532945041825538757 2018/07/30 18:04:02 3 ----\u0026gt; foo1 sequence:547 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 2\u0026#34; timestamp:1532945042828881383 2018/07/30 18:04:03 4 ----\u0026gt; foo1 sequence:548 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 3\u0026#34; timestamp:1532945043833360222 2018/07/30 18:04:04 5 ----\u0026gt; foo1 sequence:549 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 4\u0026#34; timestamp:1532945044833810697 2018/07/30 18:04:05 6 ----\u0026gt; foo1 sequence:550 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 5\u0026#34; timestamp:1532945045838056450 2018/07/30 18:04:06 7 ----\u0026gt; foo1 sequence:551 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 6\u0026#34; timestamp:1532945046838585417 2018/07/30 18:04:07 8 ----\u0026gt; foo1 sequence:552 subject:\u0026#34;foo1\u0026#34; data:\u0026#34;hello message 7\u0026#34; timestamp:1532945047840775810 源码在：https://github.com/zhenfeng-zhu/nats-demo\n总结 NATS Streaming 的高级功能类似于 Apache Kafka 的功能，但当你考虑简单性而非复杂性时前者更优。由于 NATS Streaming 相对来说是一项新技术，与 Apache Kafka 相比，它在某些领域需要改进，尤其是为负载均衡场景提供更好的解决方案。\n","permalink":"https://zhenfeng-zhu.github.io/posts/nats-streaming/","summary":"市面上常见到的和 Nats 功能类似的消息通信系统有：\nActiveMQ（Java 编写）、KafKa（Scala 编写）、RabbitMq（Ruby 编写）、Nats（之前是 Ruby 编写现已修改为 Go）、Redis（C 语言编写）、Kestrel（Scala 编写不常用）、NSQ（Go 语言编写），这些消息通信系统在 Broker 吞吐量方面的比较：\n可以看到 NATS 的吞吐量特别高， NATS 原来是使用 Ruby 编写，可以实现每秒 150k 消息，后来使用 Go 语言重写，能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。关于 NATS 的详细介绍，请参考上篇文章：NATS 简介\nNATS Streaming NATS Streaming 是由 NATS 驱动的数据流系统，也是由 go 语言写成的，在保证吞吐量和时延的基础上，解决了 Nats 消息投递一致性的问题。nats streaming 可以和核心 nats 平台无缝嵌入，扩展和互动。\n功能 除了 nats 平台的一些功能，nats streaming 还支持以下的：\n 增强的消息协议 消息/事件持久化 至少一次投递 发布者速率限制 每个订阅者的速率匹配/限制 可重复消费 持久订阅  使用 首先安装 nats-streaming-server 服务，有多种方式，这里介绍两种：\n  homebrew","title":"NATS streaming"},{"content":"nats 是一个开源的，云原生的消息系统。Apcera，百度，西门子，VMware，HTC 和爱立信等公司都有在使用。\n核心基于 EventMachine 开发，原理是基于消息发布订阅机制，每台服务器上的每个模块会根据自己的消息类别向 MessageBus 发布多个消息主题，而同时也向自己需要交互的模块，按照需要的主题订阅消息。能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。使用 nats streaming 可以做到持久化，缓存等功能。\nNATS server nats 提供了一个 go 编写的轻量级服务器。发行版包括二进制和 docker 镜像\nNATS clients\nnats 官方提供的客户端有 Go，Node，Ruby，Java，C，C＃，NGINX 等。\nNATS 设计目标\n核心原则是性能，可伸缩和易用性。\n 高效 始终在线和可用 非常轻巧 支持多种质量的服务 支持各种消息传递模型和使用场景  NATS 使用场景 nats 是一个简单且强大的消息系统，为支持现代云原生架构设计。由于可伸缩性的复杂性，nats 旨在容易使用和实现，且能提供多种质量的服务。\n一些适用 nats 的场景有：\n 高吞吐量的消息分散 —— 少数的生产者需要将数据发送给很多的消费者。 寻址和发现 —— 将数据发送给特定的应用实例，设备或者用户，也可用于发现并连接到基础架构中的实例，设备或用户。 命令和控制（控制面板）—— 向程序或设备发送指令，并从程序/设备中接收状态，如 SCADA，卫星遥感，物联网等。 负载均衡 —— 主要应用于程序会生成大量的请求，且可动态伸缩程序实例。 N 路可扩展性 —— 通信基础架构能够充分利用 go 的高效并发/调度机制，以增强水平和垂直的扩展性。 位置透明 —— 程序在各个地理位置上分布者大量实例，且你无法了解到程序之间的端点配置详情，及他们所生产或消费的数据。 容错  使用 nats-streaming 的附加场景有：\n 从特定时间或顺序消费 持久性 有保证的消息投递  NATS 消息传递模型  发布订阅 请求回复 排队  NATS 的特点 nats 的独特功能有：\n 纯净的 pub-sub 集群模式的 server 订阅者的自动裁剪 基于文本的协议 多种服务质量  最多一次投递 至少一次投递   持久 缓存  ","permalink":"https://zhenfeng-zhu.github.io/posts/nats/","summary":"nats 是一个开源的，云原生的消息系统。Apcera，百度，西门子，VMware，HTC 和爱立信等公司都有在使用。\n核心基于 EventMachine 开发，原理是基于消息发布订阅机制，每台服务器上的每个模块会根据自己的消息类别向 MessageBus 发布多个消息主题，而同时也向自己需要交互的模块，按照需要的主题订阅消息。能够达到每秒 8-11 百万个消息，整个程序很小只有 3M Docker image，它不支持持久化消息，如果你离线，你就不能获得消息。使用 nats streaming 可以做到持久化，缓存等功能。\nNATS server nats 提供了一个 go 编写的轻量级服务器。发行版包括二进制和 docker 镜像\nNATS clients\nnats 官方提供的客户端有 Go，Node，Ruby，Java，C，C＃，NGINX 等。\nNATS 设计目标\n核心原则是性能，可伸缩和易用性。\n 高效 始终在线和可用 非常轻巧 支持多种质量的服务 支持各种消息传递模型和使用场景  NATS 使用场景 nats 是一个简单且强大的消息系统，为支持现代云原生架构设计。由于可伸缩性的复杂性，nats 旨在容易使用和实现，且能提供多种质量的服务。\n一些适用 nats 的场景有：\n 高吞吐量的消息分散 —— 少数的生产者需要将数据发送给很多的消费者。 寻址和发现 —— 将数据发送给特定的应用实例，设备或者用户，也可用于发现并连接到基础架构中的实例，设备或用户。 命令和控制（控制面板）—— 向程序或设备发送指令，并从程序/设备中接收状态，如 SCADA，卫星遥感，物联网等。 负载均衡 —— 主要应用于程序会生成大量的请求，且可动态伸缩程序实例。 N 路可扩展性 —— 通信基础架构能够充分利用 go 的高效并发/调度机制，以增强水平和垂直的扩展性。 位置透明 —— 程序在各个地理位置上分布者大量实例，且你无法了解到程序之间的端点配置详情，及他们所生产或消费的数据。 容错  使用 nats-streaming 的附加场景有：","title":"nats 简介"},{"content":"OpenFaaS 概览  无服务器函数变得简单。\n 函数监视器  你可以通过添加函数监视器 (一个小型的 Golang HTTP 服务)把任何一个 Docker 镜像变成无服务器函数。 函数监视器是允许 HTTP 请求通过 STDIN 转发到目标进程的入口点。响应会从你应用写入 STDOUT 返回给调用者。  API 网关/UI 门户  API 网关为你的函数提供外部路由，并通过 Prometheus 收集云原生指标。 你的 API 网关将会根据需求更改 Docker Swarm 或 Kubernetes API 中的服务副本数来实现伸缩性。 UI 是允许你在浏览器中调用函数或者根据需要创建新的函数。   API 网关是一个 RESTful 形式的微服务，你可以在这里查看Swagger 文档。\n 命令行 Docker 中的任何容器或者进程都可以是 FaaS 中的一个无服务器函数。使用FaaS CLI ，你可以快速的部署函数。\n可以从 Node.js, Python, Go 或者更多的语言模板中创建新的函数。如果你无法找到一个合适的模板，甚至可以使用一个 Dockerfile。\n CLI 实际上是 API 网关的一个 RESTful 客户端。\n 在配置好 OpenFaaS 之后，你可以在这里开始学习 CLI开始学习 CLI\n函数示例 你可以通过 使用 FaaS-CLI 和其内置的模板创建新函数，也可以在 Docker 中使用 Windows 或 Linux 的二进制文件。\n Python 示例：  import requests def handle(req): r = requests.get(req, timeout = 1) print(req +\u0026#34; =\u0026gt; \u0026#34; + str(r.status_code)) handler.py\n Node.js 示例：  \u0026#34;use strict\u0026#34; module.exports = (callback, context) =\u0026gt; { callback(null, {\u0026#34;message\u0026#34;: \u0026#34;You said: \u0026#34; + context}) } handler.js\n在 Github 仓库中提供了一系列编程语言的其他示例函数 。\n","permalink":"https://zhenfeng-zhu.github.io/posts/overview-of-openfaas/","summary":"OpenFaaS 概览  无服务器函数变得简单。\n 函数监视器  你可以通过添加函数监视器 (一个小型的 Golang HTTP 服务)把任何一个 Docker 镜像变成无服务器函数。 函数监视器是允许 HTTP 请求通过 STDIN 转发到目标进程的入口点。响应会从你应用写入 STDOUT 返回给调用者。  API 网关/UI 门户  API 网关为你的函数提供外部路由，并通过 Prometheus 收集云原生指标。 你的 API 网关将会根据需求更改 Docker Swarm 或 Kubernetes API 中的服务副本数来实现伸缩性。 UI 是允许你在浏览器中调用函数或者根据需要创建新的函数。   API 网关是一个 RESTful 形式的微服务，你可以在这里查看Swagger 文档。\n 命令行 Docker 中的任何容器或者进程都可以是 FaaS 中的一个无服务器函数。使用FaaS CLI ，你可以快速的部署函数。\n可以从 Node.js, Python, Go 或者更多的语言模板中创建新的函数。如果你无法找到一个合适的模板，甚至可以使用一个 Dockerfile。\n CLI 实际上是 API 网关的一个 RESTful 客户端。\n 在配置好 OpenFaaS 之后，你可以在这里开始学习 CLI开始学习 CLI","title":"overview-of-openfaas"},{"content":"这是一篇关于如何在 Rancher 2.0 上创建 OpenFaaS 栈的文章。我假设你已经准备好了 Rancher 2.0 集群，如果没有请按照官方文档创建一个。\n下面的视频展示了如何创建 OpenFaaS 栈，并在实际中使用：\nhttps://www.youtube.com/watch?v=kX8mXv5d1qg\u0026amp;feature=youtu.be\n这里是创建栈的compose.yml文件：\nversion: \u0026#34;2\u0026#34; services: alertmanager: image: functions/alertmanager:latest labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 faas-rancher: environment: - CATTLE_URL=${CATTLE_URL} - CATTLE_ACCESS_KEY=${CATTLE_ACCESS_KEY} - CATTLE_SECRET_KEY=${CATTLE_SECRET_KEY} - FUNCTION_STACK_NAME=faas-functions image: kenfdev/faas-rancher:v3 labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 gateway: environment: - functions_provider_url=http://faas-rancher:8080/ image: functions/gateway:0.6.6-beta1 labels: io.rancher.container.pull_image: always ports: - 8080:8080/tcp stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 prometheus: command: [-config.file=/etc/prometheus/prometheus.yml, -storage.local.path=/prometheus, -storage.local.memory-chunks=10000, \u0026#39;--alertmanager.url=http://alertmanager:9093\u0026#39;] image: kenfdev/prometheus:latest-cattle labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 我在 Rancher 2.0 中找到一个比较酷的点是compose.yml文件中的变量都可以在 UI 中进行配置，如下图所示：\n新的faas-rancher项目已经转换为使用 Rancher 的 v3 版本的 API，而且基本上已经通过了测试。欢迎贡献和反馈。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-on-rancher/","summary":"这是一篇关于如何在 Rancher 2.0 上创建 OpenFaaS 栈的文章。我假设你已经准备好了 Rancher 2.0 集群，如果没有请按照官方文档创建一个。\n下面的视频展示了如何创建 OpenFaaS 栈，并在实际中使用：\nhttps://www.youtube.com/watch?v=kX8mXv5d1qg\u0026amp;feature=youtu.be\n这里是创建栈的compose.yml文件：\nversion: \u0026#34;2\u0026#34; services: alertmanager: image: functions/alertmanager:latest labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 faas-rancher: environment: - CATTLE_URL=${CATTLE_URL} - CATTLE_ACCESS_KEY=${CATTLE_ACCESS_KEY} - CATTLE_SECRET_KEY=${CATTLE_SECRET_KEY} - FUNCTION_STACK_NAME=faas-functions image: kenfdev/faas-rancher:v3 labels: io.rancher.container.pull_image: always stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 gateway: environment: - functions_provider_url=http://faas-rancher:8080/ image: functions/gateway:0.6.6-beta1 labels: io.rancher.container.pull_image: always ports: - 8080:8080/tcp stop_signal: SIGTERM restart: always stdin_open: true tty: true scale: 1 prometheus: command: [-config.","title":"OpenFaaS on Rancher 2.0"},{"content":"实验 4\u0026ndash;更深入地使用函数 在开始本实验之前，为你的文件创建一个新的文件夹。由于本实验是建立在早期实验的基础上的，所以请复制 lab3。\n$ cp -r lab3 lab4\\ \u0026amp;\u0026amp; cd lab4 通过环境变量注入配置 能够控制一个函数在运行时的行为方式是很有用的，我们至少可以通过两种方式来实现这一点。\n在部署时 *在部署时设置环境变量\n我们在Lab 3中用write_debug做了这个 - 你也可以在这里设置任何你想要的自定义环境变量 - 例如，如果你想为你的hello world函数配置一种语言，你可以引入一个spoken_language变量。\n使用 HTTP 上下文\u0026ndash;querystring / headers *使用 querystring 和 HTTP headers\n另一个更动态的、可以在每个请求层面上改变的选项是使用查询字符串和 HTTP 头信息，两者都可以通过faas-cli或curl传递。\n这些头信息通过环境变量暴露出来，所以它们很容易在你的函数中被使用。所以任何头信息都以Http_为前缀，所有-连字符都被替换成_下划线。\n让我们用 querystring 和一个列出所有环境变量的函数来试试。\n 使用 BusyBox 的内置命令，部署一个打印环境变量的函数。  faas-cli deploy --name env --fprocess=\u0026#34;env\u0026#34; --image=\u0026#34;function/alpine:latest\u0026#34;  用一个查询字符串调用该函数。  $ echo \u0026#34;\u0026#34; | faas-cli invoke env --query workshop=1 PATH=/usr/local/bin:/usr/local/bin:/usr/bin:/sbin:/bin HOSTNAME=05e8db360c5a fprocess=env HOME=/root Http_Connection=close Http_Content_Type=text/plain Http_X_Call_Id=cdbed396-a20a-43fe-9123-1d5a122c976d Http_X_Forwarded_For=10.255.0.2 Http_X_Start_Time=1519729562486546741 Http_User_Agent=Go-http-client/1.1 Http_Accept_Encoding=gzip Http_Method=POST Http_ContentLength=-1 Http_Path=/ ... Http_Query=workshop=1 ... 在 Python 代码中，你会输入os.getenv(\u0026quot;Http_Query\u0026quot;)。\n 将路径附加到你的函数 URL 上  用以下方法调用 env 函数。\n$ curl -X GET $OPENFAAS_URL/function/env/some/path -d \u0026#34;\u0026#34; PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/sbin:/bin HOSTNAME=fae2ac4b75f9 fprocess=env HOME=/root Http_X_Forwarded_Host=127.0.0.1:8080 Http_X_Start_Time=1539370471902481800 Http_Accept_Encoding=gzip Http_User_Agent=curl/7.54.0 Http_Accept=*/* Http_X_Forwarded_For=10.255.0.2:60460 Http_X_Call_Id=bb86b4fb-641b-463d-ae45-af68c1aa0d42 Http_Method=GET Http_ContentLength=0 ... Http_Path=/some/path ... 正如你所看到的，Http_Path头包含你的路径。 如果你想在你的代码中使用它，只要用os.getenv(\u0026quot;Http_Path\u0026quot;)来获取它。\n 现在用标头来调用它。  $ curl $OPENFAAS_URL/function/env --header \u0026#34;X-Output-Mode: json\u0026#34; -d \u0026#34;\u0026#34; PATH=/usr/local/bin:/usr/local/bin:/usr/bin:/sbin:/bin HOSTNAME=05e8db360c5a fprocess=env HOME=/root Http_X_Call_Id=8e597bcf-614f-4ca5-8f2e-f345d660db5e Http_X_Forwarded_For=10.255.0.2 Http_X_Start_Time=1519729577415481886 Http_Accept=*/* Http_Accept_Encoding=gzip Http_Connection=close Http_User_Agent=curl/7.55.1 Http_Method=GET Http_ContentLength=0 Http_Path=/ ... Http_X_Output_Mode=json ... 在 Python 代码中，你会输入`os.getenv(\u0026ldquo;Http_X_Output_Mode\u0026rdquo;)'。\n你可以看到所有其他的 HTTP 上下文也被提供了，比如当 Http_Method是 POST时的 Content-Length，User_Agent，Cookies 和其他你期望从 HTTP 请求中看到的东西。\n安全：只读文件系统 OpenFaaS 可以使用的容器安全特性之一是使我们执行环境的根文件系统只读的能力。如果一个函数被破坏，这可以减少攻击面。\n生成一个函数，将文件保存到函数的文件系统中。\nfaas-cli new --lang python3 ingest-file --prefix=your-name 更新处理程序。\nimport os import time def handle(req): # Read the path or a default from environment variable path = os.getenv(\u0026#34;save_path\u0026#34;, \u0026#34;/home/app/\u0026#34;) # generate a name using the current timestamp t = time.time() file_name = path + str(t) # write a file with open(file_name, \u0026#34;w\u0026#34;) as f: f.write(req) f.close() return file_name 建立这个例子。\nfaas-cli up -f ingest-file.yml 调用该例子。\necho \u0026#34;Hello function\u0026#34; \u0026gt; message.txt cat message.txt | faas-cli invoke -f ingest-file.yml ingest-file 该文件将被写入/home/app路径中。\n现在编辑 ingest-file.yml 并使该函数为只读。\n... functions: ingest-file: lang: python3 handler: ./ingest-file image: alexellis2/ingest-file:latest readonly_root_filesystem: true  也请参见。YAML 参考\n 再次部署。\nfaas-cli up -f ingest-file.yml 现在这将会失败。\necho \u0026#34;Hello function\u0026#34; \u0026gt; message.txt cat message.txt | faas-cli invoke -f ingest-file.yml ingest-file 请看错误。\nServer returned unexpected status code: 500 - exit status 1 Traceback (most recent call last): File \u0026#34;index.py\u0026#34;, line 19, in \u0026lt;module\u0026gt; ret = handler.handle(st) File \u0026#34;/home/app/function/handler.py\u0026#34;, line 13, in handle with open(file_name, \u0026#34;w\u0026#34;) as f: OSError: [Errno 30] Read-only file system: \u0026#39;/home/app/1556714998.092464\u0026#39; 为了写到一个临时区域，设置环境变量save_path。\n... functions: ingest-file: lang: python3 handler: ./ingest-file image: alexellis2/ingest-file:latest readonly_root_filesystem: true environment: save_path: \u0026#34;/tmp/\u0026#34; 现在你可以再运行一次faas-cli up -f ingest-file.yml来测试这个修正，文件将被写入/tmp/。\n我们现在有能力锁定我们的函数代码，使其不能被意外改变或恶意更新。\n利用日志记录 OpenFaaS 看门狗通过标准 I/O 流stdin和stdout传入 HTTP 请求和读取 HTTP 响应来运行。这意味着作为一个函数运行的进程不需要知道任何关于网络或 HTTP 的信息。\n一个有趣的情况是，当一个函数以非零退出代码退出时，stderr不是空的。 默认情况下，一个函数的stdout/stderr是合并的，stderr不被打印到日志中。\n让我们用Lab 3中的hello-openfaas函数来检查。\n将handler.py的代码改为\nimport sys import json def handle(req): sys.stderr.write(\u0026#34;This should be an error message.\\n\u0026#34;) return json.dumps({\u0026#34;Hello\u0026#34;: \u0026#34;OpenFaaS\u0026#34;}) 构建和部署\nfaas-cli up -f hello-openfaas.yml 现在用以下方法调用该函数\necho | faas-cli invoke hello-openfaas 你应该看到合并输出。\nThis should be an error message. {\u0026#34;Hello\u0026#34;: \u0026#34;OpenFaaS\u0026#34;}  注意：如果你用docker service logs hello-openfaas检查容器日志（或者kubectl logs deployment/hello-openfaas -n openfaas-fn），你应该看不到 stderr 输出。\n 在这个例子中，我们需要这个函数返回有效的 JSON，可以被解析。不幸的是，日志信息使输出无效。 所以我们需要将这些信息从 stderr 重定向到容器的日志中。 OpenFaaS 提供了一个解决方案，所以你可以将错误信息打印到日志中，并保持函数响应的清晰，只返回stdout。 为此你应该使用combine_output标志。\n让我们来试试。打开hello-openfaas.yml文件，添加这些行。\nenvironment: combine_output: false 部署并调用该函数。\n输出应该是。\n{\u0026#34;Hello\u0026#34;: \u0026#34;OpenFaaS\u0026#34;} 检查容器日志中的stderr。你应该看到类似的信息。\nhello-openfaas.1.2xtrr2ckkkth@linuxkit-025000000001 | 2018/04/03 08:35:24 stderr: This should be an error message. 创建工作流 在有些情况下，把一个函数的输出作为另一个函数的输入是很有用的。 这在客户端和通过 API 网关都可以实现。\n客户端上的连锁函数 你可以使用curl、faas-cli或一些你自己的代码将一个函数的结果输送到另一个函数。这里有一个例子。\n优点。\n 不需要代码 - 可以用 CLI 程序完成 *快速开发和测试 *容易在代码中建模  缺点。\n 额外的延迟 - 每个函数都要返回到服务器上 聊天（更多的信息）  例子。\n  从函数库部署 NodeInfo 函数\n  然后通过 Markdown 转换器推送 NodeInfo 的输出\n  $ echo -n \u0026#34;\u0026#34; | faas-cli invoke nodeinfo | faas-cli invoke markdown \u0026lt;p\u0026gt;Hostname: 64767782518c\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;Platform: linux Arch: x64 CPU count: 4 Uptime: 1121466\u0026lt;/p\u0026gt; 现在你会看到 NodeInfo 函数的输出被装饰成 HTML 标签，例如。\u0026lt;p\u0026gt;.\n另一个客户端函数链的例子可能是调用一个生成图像的函数，然后将该图像发送到另一个添加水印的函数中。\n从另一个函数中调用一个函数 从另一个函数中调用一个函数的最简单方法是通过 OpenFaaS API 网关通过 HTTP 进行调用。这个调用不需要知道外部域名或 IP 地址，它可以简单地通过 DNS 条目将 API 网关称为gateway。\n当从一个函数访问 API 网关等服务时，最好的做法是使用环境变量来配置主机名，这很重要，有两个原因\u0026ndash;名称可能会改变，在 Kubernetes 中有时需要一个后缀。\n优点。\n 函数之间可以直接利用对方 低延迟，因为函数可以在同一网络上相互访问  缺点。\n 需要一个代码库来进行 HTTP 请求  例子。\n在实验室 3中，我们介绍了 request 模块，并使用它来调用一个远程 API，以获得国际空间站上的一个宇航员的名字。我们可以使用同样的技术来调用部署在 OpenFaaS 上的另一个函数。\n 使用用户界面，进入函数商店并部署情感分析函数。  或者使用 CLI。\nfaas-cli store deploy SentimentAnalysis 情感分析函数将告诉你任何句子的主观性和极性（积极性评级）。该函数的结果是以 JSON 格式显示的，如下面的例子。\n$ echo -n \u0026#34;California is great, it\u0026#39;s always sunny there.\u0026#34; | faas-cli invoke sentimentanalysis {\u0026#34;polarity\u0026#34;: 0.8, \u0026#34;sentence_count\u0026#34;: 1, \u0026#34;subjectivity\u0026#34;: 0.75} 因此，结果显示我们的测试句子既非常主观（75%）又非常积极（80%）。这两个字段的值总是在-1.00和1.00之间。\n下面的代码可以用来调用情绪分析函数或任何其他函数。\n给网关主机加上openfaas命名空间的后缀。\nr = requests.get(\u0026#34;http://gateway.openfaas:8080/function/sentimentanalysis\u0026#34;, text= test_sentence) 或者通过一个环境变量。\ngateway_hostname = os.getenv(\u0026#34;gateway_hostname\u0026#34;, \u0026#34;gateway.openfaas\u0026#34;) # uses a default of \u0026#34;gateway.openfaas\u0026#34; for when \u0026#34;gateway_hostname\u0026#34; is not set test_sentence = \u0026#34;California is great, it\u0026#39;s always sunny there.\u0026#34; r = requests.get(\u0026#34;http://\u0026#34; + gateway_hostname + \u0026#34;:8080/function/sentimentanalysis\u0026#34;, data= test_sentence) 由于结果总是以 JSON 格式出现，我们可以利用辅助函数.json()来转换响应。\nresult = r.json() if result[\u0026#34;polarity\u0026#34;] \u0026gt; 0.45: return \u0026#34;That was probably positive\u0026#34; else: return \u0026#34;That was neutral or negative\u0026#34; 现在，在 Python 中创建一个新的函数，并将其全部整合起来\nimport os import requests import sys def handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; gateway_hostname = os.getenv(\u0026#34;gateway_hostname\u0026#34;, \u0026#34;gateway.openfaas\u0026#34;) # uses a default of \u0026#34;gateway\u0026#34; for when \u0026#34;gateway_hostname\u0026#34; is not set test_sentence = req r = requests.get(\u0026#34;http://\u0026#34; + gateway_hostname + \u0026#34;:8080/function/sentimentanalysis\u0026#34;, data= test_sentence) if r.status_code != 200: sys.exit(\u0026#34;Error with sentimentanalysis, expected: %d, got: %d\\n\u0026#34; % (200, r.status_code)) result = r.json() if result[\u0026#34;polarity\u0026#34;] \u0026gt; 0.45: return \u0026#34;That was probably positive\u0026#34; else: return \u0026#34;That was neutral or negative\u0026#34;  记得在你的requirements.txt文件中加入requests。  注意：你不需要修改或改变 SentimentAnalysis 函数的源代码，我们已经部署了它并将通过 API 网关访问它。\n现在转到实验室 5。\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab4/","summary":"实验 4\u0026ndash;更深入地使用函数 在开始本实验之前，为你的文件创建一个新的文件夹。由于本实验是建立在早期实验的基础上的，所以请复制 lab3。\n$ cp -r lab3 lab4\\ \u0026amp;\u0026amp; cd lab4 通过环境变量注入配置 能够控制一个函数在运行时的行为方式是很有用的，我们至少可以通过两种方式来实现这一点。\n在部署时 *在部署时设置环境变量\n我们在Lab 3中用write_debug做了这个 - 你也可以在这里设置任何你想要的自定义环境变量 - 例如，如果你想为你的hello world函数配置一种语言，你可以引入一个spoken_language变量。\n使用 HTTP 上下文\u0026ndash;querystring / headers *使用 querystring 和 HTTP headers\n另一个更动态的、可以在每个请求层面上改变的选项是使用查询字符串和 HTTP 头信息，两者都可以通过faas-cli或curl传递。\n这些头信息通过环境变量暴露出来，所以它们很容易在你的函数中被使用。所以任何头信息都以Http_为前缀，所有-连字符都被替换成_下划线。\n让我们用 querystring 和一个列出所有环境变量的函数来试试。\n 使用 BusyBox 的内置命令，部署一个打印环境变量的函数。  faas-cli deploy --name env --fprocess=\u0026#34;env\u0026#34; --image=\u0026#34;function/alpine:latest\u0026#34;  用一个查询字符串调用该函数。  $ echo \u0026#34;\u0026#34; | faas-cli invoke env --query workshop=1 PATH=/usr/local/bin:/usr/local/bin:/usr/bin:/sbin:/bin HOSTNAME=05e8db360c5a fprocess=env HOME=/root Http_Connection=close Http_Content_Type=text/plain Http_X_Call_Id=cdbed396-a20a-43fe-9123-1d5a122c976d Http_X_Forwarded_For=10.","title":"openfaas-workshop-lab4"},{"content":"sudo chown \u0026#34;$USER\u0026#34;:\u0026#34;$USER\u0026#34; /home/\u0026#34;$USER\u0026#34;/.docker -R sudo chmod g+rwx \u0026#34;/home/$USER/.docker\u0026#34; -R https://api.finochat.com/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI http://localhost:3000/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI ","permalink":"https://zhenfeng-zhu.github.io/posts/ubuntu-docker-sudo/","summary":"sudo chown \u0026#34;$USER\u0026#34;:\u0026#34;$USER\u0026#34; /home/\u0026#34;$USER\u0026#34;/.docker -R sudo chmod g+rwx \u0026#34;/home/$USER/.docker\u0026#34; -R https://api.finochat.com/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI http://localhost:3000/api/v1/platform/apps/RETAIL/profiles/@custom:finolabs.com.cn/avatar?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmY2lkIjoiQHBjdXN0b20tMTA6Zmlub2xhYnMuY29tLmNuIiwiaXNzIjoieUNkNXVhaWRhWU4zc1pwTTdHU2V5WWVqSGdlN3hSa1EiLCJpYXQiOjE1MzAyNjk5NDh9.UUsO2xw1f8cA6FiG1bNAGyYQh-vh32hKHKSJ2EKZicI ","title":"ubuntu-docker-sudo"},{"content":"实验 3\u0026ndash;函数介绍 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab3\\`s \u0026amp;\u0026amp; cd lab3 创建一个新的函数 有两种方法来创建一个新的函数。\n 使用一个内置的或社区的代码模板建立一个函数（默认情况下） 使用一个现有的二进制文件并将其作为你的函数（高级）  构建或生成一个新函数 在用模板创建新函数之前，请确保你从 GitHub 上提取了模板。\n$ faas-cli template pull Fetch templates from repository: https://github.com/openfaas/templates.git Attempting to expand templates from https://github.com/openfaas/templates.git 2021/08/25 15:58:10 Fetched 13 template(s) : [csharp dockerfile go java11 java11-vert-x node node12 node14 php7 python python3 python3-debian ruby] from https://github.com/openfaas/templates.git 之后，要想知道哪些语言是可用的，请键入。\n$ faas-cli new --list Languages available as templates: - csharp - dockerfile - go - java11 - java11-vert-x - node - node12 - node14 - php7 - python - python3 - python3-debian - ruby 或者创建一个包含Dockerfile的文件夹，然后在 YAML 文件中选择 Dockerfile语言类型。\n在这一点上，你可以为 Python、Python 3、Ruby、Go、Node、CSharp 等创建一个新函数。\n 关于我们的例子的说明  我们这次研讨会的所有例子都经过了 OpenFaaS 社区对Python 3的全面测试，但也应该与Python 2.7兼容。\n如果你喜欢使用 Python 2.7 而不是 Python 3，那么把faas-cli new --lang python3换成faas-cli new --lang python。\nPython 中的 Hello world 我们将在 Python 中创建一个 hello-world 函数，然后转到也使用额外依赖的东西上。\n 构建函数的脚手架  faas-cli new --lang python3 hello-openfaas --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 参数--prefix将更新image:\u0026ndash;prefix参数将更新hello-openfaas.yml中的值，其前缀应该是你的Docker Hub账号。对于[OpenFaaS](https://hub.docker.com/r/functions)来说，这是image: functions/hello-openfaas，参数将是\u0026ndash;prefix=\u0026ldquo;function\u0026rdquo;`。\n如果你在创建函数时没有指定前缀，那么在创建后编辑 YAML 文件。\n这将创建三个文件和一个目录。\n./hello-openfaas.yml ./hello-openfaas ./hello-openfaas/handler.py ./hello-openfaas/requirements.txt YAML (.yml) 文件是用来配置 CLI 来构建、推送和部署你的函数。\n 注意：每当你需要在 Kubernetes 或远程 OpenFaaS 实例上部署一个函数时，你必须在构建函数后推送它。在这种情况下，你也可以用一个环境变量覆盖默认的网关 URL，即 127.0.0.1:8080。export OPENFAAS_URL=127.0.0.1:31112`.\n 下面是 YAML 文件的内容。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: hello-openfaas: lang: python3 handler: ./hello-openfaas image: hello-openfaas  函数的名称由functions下的键表示，即hello-openfaas。 语言由 lang 字段表示。 用于构建的文件夹被称为 handler，它必须是一个文件夹而不是一个文件。 要使用的 Docker 镜像名称在image字段下。  请记住，gatewayURL 可以在 YAML 文件中（通过编辑provider:下的gateway:值）或在 CLI 上（通过使用--gateway或设置OPENFAAS_URL环境变量）进行覆盖。\n下面是handler.py文件的内容。\ndef handle(req): \u0026#34;\u0026#34;\u0026#34;handle a request to the function Args: req (str): request body \u0026#34;\u0026#34;\u0026#34; return req 这个函数将只是返回输入，所以它实际上是一个echo函数。\n编辑信息，使其返回 Hello OpenFaaS，例如。\nreturn \u0026#34;Hello OpenFaaS\u0026#34; 任何返回到 stdout 的值都会随后返回到调用程序。另外，也可以使用print()语句，它将表现出类似的流向，并传递给调用程序。\n这是本地开发人员对函数的工作流程。\nfaas-cli up -f hello-openfaas.yml  注意：在运行这个命令之前，请确保你已经用docker login命令登录了 docker 注册中心。 注意: faas-cli up命令将faas-cli的构建、推送和部署命令合并为一条命令。\n 随后通过用户界面、CLI、curl或其他应用程序调用该函数。\n该函数将始终获得一个路由，例如。\n$OPENFAAS_URL/function/\u0026lt;function_name\u0026gt;（函数名）。 $OPENFAAS_URL/function/figlet $OPENFAAS_URL/function/hello-openfaas  提示：如果你把 YAML 文件重命名为stack.yml，那么你就不需要向任何命令传递-f标志。\n 函数只能通过GET或POST方法来调用。\n 调用你的函数  用faas-cli invoke测试函数，查看faas-cli invoke --help获取更多选项。\n示例函数：astronaut-finder 我们将创建一个名为 astronaut-finder 的函数，在国际空间站（ISS）上随机拉出一个太空人的名字。\nfaas-cli new --lang python3 astronaut-finder --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 这将为我们写三个文件。\n./astronaut-finder/handler.py 函数的处理程序\u0026ndash;你会得到一个带有原始请求的req对象，并可以将函数的结果打印到控制台。\n./astronaut-finder/requirements.txt 这个文件用来管理函数\u0026ndash;它有函数的名称、Docker 镜像和任何其他需要的定制。\n./astronaut-finder.yml 使用该文件列出你要安装的任何pip模块，如requests或urllib。\n 编辑./astronaut-finder/requirements.txt。  requests 这告诉函数它需要使用一个名为requests的第三方模块，用于通过 HTTP 访问网站。\n 编写该函数的代码。  我们将从以下地方拉入数据： http://api.open-notify.org/astros.json\n下面是一个结果的例子。\n{\u0026#34;number\u0026#34;: 6, \u0026#34;people\u0026#34;: [{\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Alexander Misurkin\u0026#34;}, {\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Mark Vande Hei\u0026#34;}, {\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Joe Acaba\u0026#34;}, {\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Anton Shkaplerov\u0026#34;}, {\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Scott Tingle\u0026#34;}, {\u0026#34;craft\u0026#34;: \u0026#34;ISS\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Norishige Kanai\u0026#34;}], \u0026#34;message\u0026#34;: \u0026#34;success\u0026#34;} 更新handler.py。\nimport requests import random def handle(req): r = requests.get(\u0026#34;http://api.open-notify.org/astros.json\u0026#34;) result = r.json() index = random.randint(0, len(result[\u0026#34;people\u0026#34;])-1) name = result[\u0026#34;people\u0026#34;][index][\u0026#34;name\u0026#34;] return \u0026#34;%sis in space\u0026#34; % (name)  注意：在这个例子中，我们没有使用参数req，但必须把它放在函数的头部。\n 现在建立这个函数。\nfaas-cli build -f ./astronaut-finder.yml  提示。试着把 astronaut-finder.yml 重命名为stack.yml，然后只调用faas-cli build。stack.yml是 CLI 的默认文件名。\n 推送函数。\nfaas-cli push -f ./astronaut-finder.yml 部署该函数。\nfaas-cli deploy -f ./astronaut-finder.yml 调用该函数\n$ echo | faas-cli invoke astronaut-finder 安东-史卡普勒夫在太空中 $ echo | faas-cli invoke astronaut-finder 乔-阿卡巴在太空中 故障排除：找到容器的日志 你可以通过容器的日志找到你的函数的每次调用的高级信息。\nkubectl logs deployment/astronaut-finder -n openfaas-fn 故障排除：使用`write_debug\u0026rsquo;的 verbose 输出 让我们为你的函数打开 verbose 输出。这在默认情况下是关闭的，这样我们就不会用数据淹没你的函数的日志\u0026ndash;这在处理二进制数据时尤其重要，因为二进制数据在日志中没有意义。\n这是标准的 YAML 配置。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: astronaut-finder: lang: python3 handler: ./astronaut-finder image: astronaut-finder 为该函数编辑 YAML 文件，并添加一个 environment 部分。\nastronaut-finder: lang: python3 handler: ./astronaut-finder image: astronaut-finder environment: write_debug: true 现在用faas-cli deploy -f ./astronaut-finder.yml再次部署你的函数。\n调用该函数，然后再次检查日志，查看函数的响应。\nkubectl logs deployment/astronaut-finder -n openfaas-fn 管理多个函数 CLI 的 YAML 文件允许将函数分组为堆栈，这在处理一组相关函数时很有帮助。\n为了了解它是如何工作的，生成两个函数。\nfaas-cli new --lang python3 first 对于第二个函数使用--append标志。\nfaas-cli new --lang python3 second --append=./first.yml 为了方便起见，我们把first.yml改名为example.yml。\nmv first.yml example.yml 现在看看这个文件。\nprovider: name: openfaas gateway: http://127.0.0.1:8080 functions: first: lang: python3 handler: ./first image: first second: lang: python3 handler: ./second image: second 这里有几个标志，在处理函数堆栈时有帮助。\n 以并行方式构建。  faas-cli build -f ./example.yml --parallel=2  只建立/推送一个函数。  faas-cli build -f ./example.yml --filter=second 花点时间来探索build/push和deploy的选项。\n faas-cli build --help。 faas-cli push --help。 faas-cli deploy --help。  要同时运行faas-cli build \u0026amp;\u0026amp;faas-cli push \u0026amp;\u0026amp;faas-cli deploy，请使用faas-cli up代替。\n 专业提示：如果你不想传递-f参数，stack.yml是 faas-cli 寻找的默认名称。\n 你也可以使用faas-cli deploy -f https://....通过 HTTP（s）部署远程函数栈（yaml）文件。\n自定义模板 如果你有自己的一套分叉模板或自定义模板，那么你可以把它们拉下来，用 CLI 使用。\n下面是一个获取 Python 3 模板的例子，它使用 Debian Linux。\n使用 git URL 拉取模板。\nfaas-cli template pull https://github.com/openfaas-incubator/python3-debian 现在键入 faas-cli new --list。\n$ faas-cli new --list | grep python - python - python3 - python3-debian 这些新模板会被保存在你当前的工作目录下./templates/。\n自定义模板。模板商店 模板商店是一个类似于函数商店*的概念，它使用户可以通过分享他们的模板来进行协作。模板商店也意味着你不必记住任何 URL 来利用你喜欢的社区或项目模板。\n你可以使用以下两个命令来搜索和发现模板。\n$ faas-cli template store list $ faas-cli template store list -v NAME SOURCE DESCRIPTION csharp openfaas Classic C# template dockerfile openfaas Classic Dockerfile template go openfaas Classic Golang template ... 为了获得更多的细节，你可以使用--verbose标志，或者describe命令。\n让我们找到一个具有 HTTP 格式的 Golang 模板。\nfaas-cli template store list | grep golang golang-http openfaas Golang HTTP template golang-middleware openfaas Golang Middleware template 然后查看其上游仓库。\n$ faas-cli template store describe golang-http Name: golang-http Platform: x86_64 Language: Go Source: openfaas Description: Golang HTTP template Repository: https://github.com/openfaas/golang-http-template Official Template: true 把模板拉下来。\nfaas-cli template store pull golang-http 现在你可以通过输入以下内容用这个模板创建一个函数。\nbash faas-cli new \u0026ndash;lang golang-http NAME\n为了比运行`faas-cli template store pull golang-http`来创建函数更容易，你可以在你的stack.yml文件中附加以下内容。 ```yaml configuration: templates: - name: golang-http 然后运行以下内容，而不是指定模板名称。\nfaas-cli template store pull 也请参见。\n OpenFaaS YAML 参考指南 函数与模板存储  YAML 文件中的变量替换（可选练习) 用于配置 CLI 的.yml文件能够进行变量替换，这样你就能够使用同一个.yml文件进行多种配置。\n其中一个例子是，当开发和生产图像有不同的注册表时，这就很有用。你可以使用变量替换，使本地和测试环境使用默认账户，而 CI 服务器可以被配置为使用生产账户。\n 这是由[envsubst 库]（https://github.com/drone/envsubst）提供的。遵循该链接可以看到支持的变量的例子\n 编辑你的astronaut-finder.yml以匹配以下内容。\nastronaut-finder: lang: python3 handler: ./astronaut-finder image: ${DOCKER_USER:-development}/astronaut-finder environment: write_debug: true 你会注意到image属性已被更新，包括一个变量定义（DOCKER_USER）。该值将被替换为同名的环境变量的值。如果环境变量不存在，或为空，将使用默认值（development）。\n该变量将在整个文件中被替换成该值。所以，如果你的.yml文件中有几个函数，所有对DOCKER_USER变量的引用将被替换为该环境变量的值\n运行下面的命令并观察输出。\nfaas-cli build -f ./astronaut-finder.yml。\n输出应该显示，构建的镜像被标记为development/astronaut-finder:latest。\n现在，将环境变量设置为你的 Docker Hub 账户名（在这个例子中，我们将使用 OpenFaaS 的 function账户）。\nexport DOCKER_USER=functions 运行与之前相同的构建命令，观察输出。\nfaas-cli build -f ./astronaut-finder.yml。\n现在输出应该显示，镜像是用更新的标签 functions/astronaut-finder:latest构建的。\n自定义二进制文件作为函数(可选练习) 自定义二进制文件或容器可以作为函数使用，但大多数时候，使用语言模板应该涵盖所有最常见的情况。\n为了使用自定义二进制文件或 Dockerfile，使用dockerfile语言创建一个新函数。\nfaas-cli new --lang dockerfile sorter --prefix=\u0026#34;\u0026lt;your-docker-username-here\u0026gt;\u0026#34; 你会看到一个名为 sorter和 sorter.yml的文件夹被创建。\n编辑sorter/Dockerfile并更新设置fprocess'的那一行。让我们把它改成内置的bash命令sort`。我们可以用它来对一个字符串列表按字母数字顺序进行排序。\nENV fprocess=\u0026#34;sort\u0026#34;现在构建、推送和部署该函数。\nfaas-cli up -f sorter.yml 现在通过用户界面或 CLI 来调用该函数。\n$ echo -n \u0026#39; elephant zebra horse aardvark monkey\u0026#39;| faas-cli invoke sorter aardvark elephant horse monkey zebra 在这个例子中，我们使用了BusyBox中的sort，它是内置的函数。还有其他有用的命令，如sha512sum，甚至是bash或 shell 脚本，但你并不局限于这些内置命令。任何二进制或现有的容器都可以通过添加 OpenFaaS 函数看门狗而成为无服务器函数。\n 提示：你知道 OpenFaaS 也支持 Windows 二进制文件吗？比如 C#、VB 或 PowerShell？\n 现在进入实验室 4\n","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas-workshop-lab3/","summary":"实验 3\u0026ndash;函数介绍 在开始这个实验之前，为你的文件创建一个新的文件夹。\n$ mkdir -p lab3\\`s \u0026amp;\u0026amp; cd lab3 创建一个新的函数 有两种方法来创建一个新的函数。\n 使用一个内置的或社区的代码模板建立一个函数（默认情况下） 使用一个现有的二进制文件并将其作为你的函数（高级）  构建或生成一个新函数 在用模板创建新函数之前，请确保你从 GitHub 上提取了模板。\n$ faas-cli template pull Fetch templates from repository: https://github.com/openfaas/templates.git Attempting to expand templates from https://github.com/openfaas/templates.git 2021/08/25 15:58:10 Fetched 13 template(s) : [csharp dockerfile go java11 java11-vert-x node node12 node14 php7 python python3 python3-debian ruby] from https://github.com/openfaas/templates.git 之后，要想知道哪些语言是可用的，请键入。\n$ faas-cli new --list Languages available as templates: - csharp - dockerfile - go - java11 - java11-vert-x - node - node12 - node14 - php7 - python - python3 - python3-debian - ruby 或者创建一个包含Dockerfile的文件夹，然后在 YAML 文件中选择 Dockerfile语言类型。","title":"openfaas-workshop-lab3"},{"content":"今天大多数公司在开发应用程序并将其部署在服务器上的时候，无论是选择公有云还是私有的数据中心，都需要提前了解究竟需要多少台服务器、多大容量的存储和数据库的功能等。并需要部署运行应用程序和依赖的软件到基础设施之上。假设我们不想在这些细节上花费精力，是否有一种简单的架构模型能够满足我们这种想法？这个答案已经存在，这就是今天软件架构世界中新鲜但是很热门的一个话题——Serverless（无服务器）架构。\n目前已经有一批优秀的 serverless 架构开源项目，OpenFaas 就是其中的佼佼者。奈何其中的中文资料比较少，我也是边学边翻译，希望能够抛砖引玉，助力 serverless 的发展。\n这是一个自学研讨会，学习如何构建、部署和运行 OpenFaas 函数。\nLab1 - OpenFaas 的准备工作 OpenFaas 可以在 Docker Swarm 和 Kubernetes 的过几个主要平台之上运行。在此教程里，我们将会在的您本地电脑使用 Docker Swarm 来入门。\n预备条件 Docker Mac\n Docker CE for Mac Edge Edition  Windows\n 仅针对 windows10 专业版或企业版 安装Docker CE for Windows 安装Git Bash   备注：所有步骤中请使用 Git Bash：不要尝试使用 WSL 或 Bash for Windows。\n Linux - Ubuntu 或 Debian\n Docker CE for Linux   你可以从Docker Store中安装 Docker CE\n 设置一个单节点的 Docker Swarm OpenFaas 在 Docker Swarm 和 Kubernetes 上工作。因为 Docker Swarm 很容易设置，所以在此 Workshop 中我们使用 Docker Swarm。在文档中有他们两个的指南。\n在你的笔记本或虚拟机中设置一个单节点的 Docker Swarm：\ndocker swarm init  如果运行此命令出错，加上 \u0026ndash;advertise-addr 你的 IP 参数。\n Docker Hub 注册一个 Docker Hub 账号。Docker Hub 允许你在互联网中发布自己的 Docker 镜像来用于多节点集群或社区共享。在 Workshop 中我们使用 Docker Hub 发布函数。\n你可以在这里注册：Docker Hub\n 备注：Docker Hub 也可以设置为自动构建镜像。\n 打开一个终端或者 Git Bash 窗口，然后使用上面注册的用户名登陆 Docker Hub。\ndocker login OpenFaas CLI 你可以在 mac 上使用 brew 或者在 Linu 和 mac 上使用一个集成脚本来安装 OpenFaas CLI。\n在 Mac 或 Linux 上终端中输入：\ncurl -sL cli.openfaas.com | sudo sh 对于 windows 平台，从releases page中下载最新的的 faas-cli.exe。你可以把它放在一个 local 文件夹或者在 C:\\Windows\\路径中，这样它就可以在命令行中使用。\n 如果你是一个高级 Windows 用户，把 CLI 放在你自定义的文件夹中，然后把此文件夹添加到环境变量。\n 我们将会使用 faas-创建新函数的脚手架，build，deploy 和 invoke 函数。你可以从 faas-cli —help 中找到这些命令。\n测试 faas-cli\n打开一个终端或 Git Bash 窗口，然后输入：\nfaas-cli help faas-cli version 部署 OpenFaas 发布 OpenFaas 的说明文档修改了很多次，因为我们努力使他简单。接下来将会在 60 秒左右的时间使得 OpenFaas 部署起来。\n 首先 clone 项目  git clone https://github.com/openfaas/faas  然后使用 git 检出到最新版本  $ cd faas \u0026amp;\u0026amp; \\ git checkout master  备注：你也可以在project release page中找到最新导入 release 版本。\n  现在使用 Docker Swarm 部署 stack  ./deploy_stack.sh 你现在应该已经把 OpenFaas 部署了。\n如果你现在在一个共享 WIFI 连接中，它将会需要几分钟时间拉取镜像并启动。\n在此屏幕上检查服务是否显示为 1/1:\ndocker service ls 如果你期间有遇到任何问题，请查阅 Docker Swarm 的 部署指南。\n现在进入Lab 2。\n未完待续 ","permalink":"https://zhenfeng-zhu.github.io/posts/workshop-lab1/","summary":"今天大多数公司在开发应用程序并将其部署在服务器上的时候，无论是选择公有云还是私有的数据中心，都需要提前了解究竟需要多少台服务器、多大容量的存储和数据库的功能等。并需要部署运行应用程序和依赖的软件到基础设施之上。假设我们不想在这些细节上花费精力，是否有一种简单的架构模型能够满足我们这种想法？这个答案已经存在，这就是今天软件架构世界中新鲜但是很热门的一个话题——Serverless（无服务器）架构。\n目前已经有一批优秀的 serverless 架构开源项目，OpenFaas 就是其中的佼佼者。奈何其中的中文资料比较少，我也是边学边翻译，希望能够抛砖引玉，助力 serverless 的发展。\n这是一个自学研讨会，学习如何构建、部署和运行 OpenFaas 函数。\nLab1 - OpenFaas 的准备工作 OpenFaas 可以在 Docker Swarm 和 Kubernetes 的过几个主要平台之上运行。在此教程里，我们将会在的您本地电脑使用 Docker Swarm 来入门。\n预备条件 Docker Mac\n Docker CE for Mac Edge Edition  Windows\n 仅针对 windows10 专业版或企业版 安装Docker CE for Windows 安装Git Bash   备注：所有步骤中请使用 Git Bash：不要尝试使用 WSL 或 Bash for Windows。\n Linux - Ubuntu 或 Debian\n Docker CE for Linux   你可以从Docker Store中安装 Docker CE","title":"译：openfaas-workshop-Lab1"},{"content":"对于 mac 环境来讲，首先安装新版 docker:\nbrew cask install docker 然后启动 docker。\n命令行登陆 docker hub\ndocker login 启动 docker swarm\ndocker swarm init 安装 faas-cli\nbrew install faas-cli clone 下来代码：\ngit clone https://github.com/openfaas/faas 然后执行\n./deploy_stack.sh 部署一些示例\nfaas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 使用浏览器打开 http://127.0.0.1:8080 就可以看到 ui 界面了。\n安装 grafana 进行监控\ndocker service create -d \\ --name=grafana \\ --publish=3000:3000 \\ --network=func_functions \\ stefanprodan/faas-grafana:4.6.3 浏览器打开： http://127.0.0.1:3000 登陆 admin admin 查看。\n常用命令：\nfaas-cli new --list faas-cli build -f ./hello-openfaas.yml faas-cli push -f ./hello-openfaas.yml faas-cli deploy -f ./hello-openfaas.yml ","permalink":"https://zhenfeng-zhu.github.io/posts/openfaas/","summary":"对于 mac 环境来讲，首先安装新版 docker:\nbrew cask install docker 然后启动 docker。\n命令行登陆 docker hub\ndocker login 启动 docker swarm\ndocker swarm init 安装 faas-cli\nbrew install faas-cli clone 下来代码：\ngit clone https://github.com/openfaas/faas 然后执行\n./deploy_stack.sh 部署一些示例\nfaas-cli deploy -f https://raw.githubusercontent.com/openfaas/faas/master/stack.yml 使用浏览器打开 http://127.0.0.1:8080 就可以看到 ui 界面了。\n安装 grafana 进行监控\ndocker service create -d \\ --name=grafana \\ --publish=3000:3000 \\ --network=func_functions \\ stefanprodan/faas-grafana:4.6.3 浏览器打开： http://127.0.0.1:3000 登陆 admin admin 查看。\n常用命令：\nfaas-cli new --list faas-cli build -f .","title":"openfaas"},{"content":"Spring web mvc： 传统 servlet web\nspring web flux： Reactive web\n 编程模式： non-blocking 非阻塞  nio：同步？异步？   并行模型  sync 同步 async 异步    Reactive 概念 Reactive programming： 响应式编程\nIn computing, reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. With this paradigm it is possible to express static (e.g. arrays) or dynamic (e.g. event emitters) data streams with ease, and also communicate that an inferred dependency within the associated execution model exists, which facilitates the automatic propagation of the changed data flow.\n实现框架   RxJava\nReactiveX is a library for composing asynchronous and event-based programs by using observable sequences.\n这种就是推的模式\nint[] a=[1, 2, 3] for(int i: a){ } package com.reactive.demo.reactivedemo; import java.util.Observable; /** * todo * * @author zhuzhenfeng * @date 2018/6/23 */ public class ObserverPatternDemo { public static void main(String[] args) { MyObservable observable = new MyObservable(); // 1 observable n个observer observable.addObserver((o, value) -\u0026gt; { System.out.println(\u0026#34;1 收到数据更新\u0026#34; + value); }); observable.addObserver((o, value) -\u0026gt; { System.out.println(\u0026#34;2 收到数据更新\u0026#34; + value); }); observable.setChanged(); observable.notifyObservers(\u0026#34;hello world\u0026#34;);// push data 发布数据 } public static class MyObservable extends Observable { @Override protected synchronized void setChanged() { super.setChanged(); } } } /Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home/bin/java \u0026#34;- 2 收到数据更新hello world 1 收到数据更新hello world Process finished with exit code 0 当时不阻塞，后续回调。非阻塞基本上采用 callback 的形式。\n对于 java 来讲，异步代表切换了线程。\n当前的实现： 同步+非阻塞\n如果是切换了线程，代表是异步 的非阻塞，一般是 gui 程序的。\n  Reactor\n  特性  异步 非阻塞 事件驱动 可能有背压 backpressure 防止回调地狱  Reactive 使用场景 Long Live 模式： netty 的 io 连接（rpc） timeout\nshort live 模式：不太适合 Reactive web，因为这是等待。只是会快速返回，但是并不会给你真正的结果。短频快的连接，不太有用武之地。\n http http 超时时间  Reactive 理解误区 web：快速响应\n200 Q-\u0026gt;200 T -\u0026gt; 50T\n1-50\nTomcat connector thread pool(200)-\u0026gt;reactive thread pool(50)\nio 连接从 Tomcat-\u0026gt;Reactive\n连接\nReactive thread pool（50）\n不太适合 web 请求。\nwebflux 其实并不会提升性能。\n少量的线程，少量的内存来做更好的伸缩性，而并不是为了提升更好的性能。使用 Reactive 只会是使单位时间内接受请求的数量增加，单位时间内的处理请求的数量下降。\n","permalink":"https://zhenfeng-zhu.github.io/posts/java-reactive-web/","summary":"Spring web mvc： 传统 servlet web\nspring web flux： Reactive web\n 编程模式： non-blocking 非阻塞  nio：同步？异步？   并行模型  sync 同步 async 异步    Reactive 概念 Reactive programming： 响应式编程\nIn computing, reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change. With this paradigm it is possible to express static (e.g. arrays) or dynamic (e.g. event emitters) data streams with ease, and also communicate that an inferred dependency within the associated execution model exists, which facilitates the automatic propagation of the changed data flow.","title":"java-reactive-web"},{"content":"启动 zookeeper\nbin/zookeeper-server-start.sh config/zookeeper.properties 启动 kafka\nbin/kafka-server-start.sh config/server.properties 创建一个主题\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test bin/kafka-topics.sh --list --zookeeper localhost:2181 生产者\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 消费者\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning kafka connect\necho -e \u0026#34;zhisheng\\ntian\u0026#34; \u0026gt; test.txt ls\nzhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ echo -e \u0026#34;zhisheng\\ntian\u0026#34; \u0026gt; test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ ls LICENSE NOTICE bin config libs logs site-docs test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ 启动连接器\nbin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties 然后发现多了一个文件\n/Users/zhuzhenfeng/Documents/software/kafka_2.12-1.1.0 [kafka_2.12-1.1.0] ls 18:25:38 LICENSE NOTICE bin config libs logs site-docs test.sink.txt test.txt [kafka_2.12-1.1.0] 然后消费\n\u0026gt;\u0026gt; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning {\u0026#34;schema\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;optional\u0026#34;:false},\u0026#34;payload\u0026#34;:\u0026#34;zhisheng\u0026#34;} {\u0026#34;schema\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;optional\u0026#34;:false},\u0026#34;payload\u0026#34;:\u0026#34;tian\u0026#34;} {\u0026#34;schema\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;optional\u0026#34;:false},\u0026#34;payload\u0026#34;:\u0026#34;sd\u0026#34;} {\u0026#34;schema\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;optional\u0026#34;:false},\u0026#34;payload\u0026#34;:\u0026#34;sdafasdfasdfdsa\u0026#34;} ","permalink":"https://zhenfeng-zhu.github.io/posts/kafka/","summary":"启动 zookeeper\nbin/zookeeper-server-start.sh config/zookeeper.properties 启动 kafka\nbin/kafka-server-start.sh config/server.properties 创建一个主题\nbin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test bin/kafka-topics.sh --list --zookeeper localhost:2181 生产者\nbin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 消费者\nbin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning kafka connect\necho -e \u0026#34;zhisheng\\ntian\u0026#34; \u0026gt; test.txt ls\nzhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ echo -e \u0026#34;zhisheng\\ntian\u0026#34; \u0026gt; test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ ls LICENSE NOTICE bin config libs logs site-docs test.txt zhuzhenfengdeMacBook-Pro➜ kafka_2.12-1.1.0 ᐅ 启动连接器","title":"kafka"},{"content":" 尝试翻译 vertx 的文档。尊重原文，部分使用自己的理解。\n Vert.x 的 kotlin 协程提供了 async/await 或者和 go 类似的 channel。这使得你能够以熟悉的顺序风格写垂直代码。\nvertx-lang-kotlin-coroutines 集成了 kotlin 协程，用于执行异步操作和处理事件。这样就能够以同步代码的模型编写代码，而且不会阻塞内核线程。\n简介 vert.x 与许多旧的应用平台相比的一个主要优势是它几乎完全是非阻塞的（内核线程）。这允许基于 vert.x 的程序使用极少数的内核线程处理大量的并发（例如：许多连接和消息），可以获得更好的伸缩性。\nvert.x 的非阻塞特性形成了非阻塞 API。非阻塞 API 可以采用多种形式来实现，包括回调函数，promise，fibers 或者响应式扩展。vert.x 的核心 API 使用回调函数的风格，但是它也支持其他模型，如 RxJava 1 和 2。\n在某些情况下，使用异步的 API 编程可能比使用经典的顺序代码风格更具有挑战性，特别是需要按照顺序完成若干操作。另外，使用异步 API 时，错误的传播也更为复杂。\nvertx-lang-kotlin-coroutines 使用协程。协程是非常轻量级的线程，而且不与底层的内核线程对应。所以当协程需要“阻塞”时，它会暂停并释放当前的内核线程，使得另一个协程可以处理事件。\nvertx-lang-kotlin-coroutines 使用 kotlinx.coroutines 来实现协程。\n vertx-lang-kotlin-coroutines 目前仅适用于 kotlin，而且是 kotlin1.1 的一个实验特性。\n 从一个 vertx.x 的 contex 中启动协程 导入 io.vertx.kotlin.coroutines.VertxCoroutine，launch（协程生成器）方法中允许运行一段代码作为可以暂停的协程：\nval vertx = Vertx.vertx() vertx.deployVerticle(ExampleVerticle()) launch(vertx.dispatcher()) { val timerId = awaitEvent\u0026lt;Long\u0026gt; { handler -\u0026gt; vertx.setTimer(1000, handler) } println(\u0026#34;Event fired from timer with id ${timerId}\u0026#34;) } vertx.dispatcher()返回一个使用 vert.x 的事件循环执行协程的 disptacher。\nawaitEvent 函数暂停协程的执行直到定时器触发为止，并使用赋给 handler 的值恢复协程。\n有关 handlers，events 和事件流的更多细节，将在下一节中给出。\n继承 CoroutineVerticle 你可以将代码部署为 io.vertx.kotlin.coroutines.CoroutineVerticle 的实例，这是 kotlin 协程的专用类型。你应该重载 verticle 的 start()方法，stop()方法的重载是可选的：\nclass MyVerticle : CoroutineVerticle() { suspend override fun start() { // ...  } } 获得一次性的异步结果 vert.x 的许多异步操作都采用 Handler\u0026lt;AsyncResult\u0026lt;T\u0026gt;\u0026gt; 作为最后一个参数。一个例子就是使用 vert.x 的 mongo client 执行对象检索，或者是发送一个事件总线消息之后等待回复。\n这是通过 awaitResult 方法来实现，它返回一个值或者抛出一个异常。\n协程会一直处于暂停的状态知道事件被处理，并且这时没有内核线程被阻塞。\nThe method is executed by specifying the asynchronous operation that needs to be executed in the form of a block that is passed to the handler at run-time.\n这个方法是通过指定一个异步操作来执行，这个异步操作需要以块的形式执行，而这个异步操作块在运行时会被传给 handler。\n这里是一个例子：\nsuspend fun awaitResultExample() { val consumer = vertx.eventBus().localConsumer\u0026lt;String\u0026gt;(\u0026#34;a.b.c\u0026#34;) consumer.handler { message -\u0026gt; println(\u0026#34;Consumer received: ${message.body()}\u0026#34;) message.reply(\u0026#34;pong\u0026#34;) } // Send a message and wait for a reply  val reply = awaitResult\u0026lt;Message\u0026lt;String\u0026gt;\u0026gt; { h -\u0026gt; vertx.eventBus().send(\u0026#34;a.b.c\u0026#34;, \u0026#34;ping\u0026#34;, h) } println(\u0026#34;Reply received: ${reply.body()}\u0026#34;) } 当此块产生失败时，调用者可以使用 try/catch 结构处理异常。\nsuspend fun awaitResultFailureExample() { val consumer = vertx.eventBus().localConsumer\u0026lt;String\u0026gt;(\u0026#34;a.b.c\u0026#34;) consumer.handler { message -\u0026gt; // The consumer will get a failure  message.fail(0, \u0026#34;it failed!!!\u0026#34;) } // Send a message and wait for a reply  try { val reply: Message\u0026lt;String\u0026gt; = awaitResult\u0026lt;Message\u0026lt;String\u0026gt;\u0026gt; { h -\u0026gt; vertx.eventBus().send(\u0026#34;a.b.c\u0026#34;, \u0026#34;ping\u0026#34;, h) } } catch(e: ReplyException) { // Handle specific reply exception here  println(\u0026#34;Reply failure: ${e.message}\u0026#34;) } } 获取一次性事件 使用 awaitEvent 函数处理一次性事件（而不是下一次出现的事件）：\nsuspend fun awaitEventExample() { val id = awaitEvent\u0026lt;Long\u0026gt; { h -\u0026gt; vertx.setTimer(2000L, h) } println(\u0026#34;This should be fired in 2s by some time with id=$id\u0026#34;) } 获取一次性 worker 的结果 使用 awaitBlocking 函数处理阻塞计算：\nsuspend fun awaitBlockingExample() { val s = awaitBlocking\u0026lt;String\u0026gt; { Thread.sleep(1000) \u0026#34;some-string\u0026#34; } } 事件流 在 vert.x API 的很多地方，事件流都是通过 handler 来处理。这些例子包括事件消息总线的使用者和 http 服务器的请求。\nReceiveChannelHandler 类允许通过(suspendable)receive 方法接收事件：\nsuspend fun streamExample() { val adapter = vertx.receiveChannelHandler\u0026lt;Message\u0026lt;Int\u0026gt;\u0026gt;() vertx.eventBus().localConsumer\u0026lt;Int\u0026gt;(\u0026#34;a.b.c\u0026#34;).handler(adapter) // Send 15 messages  for (i in 0..15) vertx.eventBus().send(\u0026#34;a.b.c\u0026#34;, i) // Receive the first 10 messages  for (i in 0..10) { val message = adapter.receive() println(\u0026#34;Received: ${message.body()}\u0026#34;) } } 等待 vert.x 的 future 的完成 vert.x 的 future 类实例的扩展方法 await，可以暂停协程直到他们完成。在这种情况下，该方法返回相应的 AsyncResult\u0026lt;T\u0026gt; 对象。\nsuspend fun awaitingFuture() { val httpServerFuture = Future.future\u0026lt;HttpServer\u0026gt;() vertx.createHttpServer() .requestHandler { req -\u0026gt; req.response().end(\u0026#34;Hello!\u0026#34;) } .listen(8000, httpServerFuture) val httpServer = httpServerFuture.await() println(\u0026#34;HTTP server port: ${httpServer.actualPort()}\u0026#34;) val result = CompositeFuture.all(httpServerFuture, httpServerFuture).await() if (result.succeeded()) { println(\u0026#34;The server is now running!\u0026#34;) } else { result.cause().printStackTrace() } } 通道 channel 和 java 的 BlockingQueue 类似，只是 Channel 不会阻塞而是暂停协程。\n 将值发送到满了的 Channel 会暂停协程 从一个空 Channel 中接收值也会暂停协程  使用 toChannel 的扩展方法可以将 vert.x 的 ReadStream 和 WriteStream 适配成通道。\n这些适配器负责管理背压和流终端：\n ReadStream\u0026lt;T\u0026gt; 适配为 ReceiveChannel\u0026lt;T\u0026gt; WriteStream\u0026lt;T\u0026gt; 适配为 SendChannel\u0026lt;T\u0026gt;  接收数据 当你需要处理一系列相关值的时候，channel 可能非常有用：\nsuspend fun handleTemperatureStream() { val stream = vertx.eventBus().consumer\u0026lt;Double\u0026gt;(\u0026#34;temperature\u0026#34;) val channel = stream.toChannel(vertx) var min = Double.MAX_VALUE var max = Double.MIN_VALUE // Iterate until the stream is closed  // Non-blocking  for (msg in channel) { val temperature = msg.body() min = Math.min(min, temperature) max = Math.max(max, temperature) } // The stream is now closed } 他也可以用于解析协议。我们将构建一个非阻塞的 http 请求解析器来展示通道的功能。\n我们将依靠 RecordParser 将以\\r \\n 分割的 buffer 流进行分割。\n这是解析器的初始版本，它只处理 http 的请求行。\nval server = vertx.createNetServer().connectHandler { socket -\u0026gt; // The record parser provides a stream of buffers delimited by \\r\\n  val stream = RecordParser.newDelimited(\u0026#34;\\r\\n\u0026#34;, socket) // Convert the stream to a Kotlin channel  val channel = stream.toChannel(vertx) // Run the coroutine  launch(vertx.dispatcher()) { // Receive the request-line  // Non-blocking  val line = channel.receive().toString().split(\u0026#34; \u0026#34;) val method = line[0] val uri = line[1] println(\u0026#34;Received HTTP request ($method, $uri)\u0026#34;) // Still need to parse headers and body...  } } 解析请求行就像在 channel 上调用 receive 一样简单。\n下一步是通过接收块来解析 http 头，直到我们得到一个空块为止。\n// Receive HTTP headers val headers = HashMap\u0026lt;String, String\u0026gt;() while (true) { // Non-blocking  val header = channel.receive().toString() // Done with parsing headers  if (header.isEmpty()) { break } val pos = header.indexOf(\u0026#39;:\u0026#39;) headers[header.substring(0, pos).toLowerCase()] = header.substring(pos + 1).trim() } println(\u0026#34;Received HTTP request ($method, $uri) with headers ${headers.keys}\u0026#34;) 最后，我们通过处理可选的请求体来终止解析器。\n// Receive the request body val transferEncoding = headers[\u0026#34;transfer-encoding\u0026#34;] val contentLength = headers[\u0026#34;content-length\u0026#34;] val body : Buffer? if (transferEncoding == \u0026#34;chunked\u0026#34;) { // Handle chunked encoding, e.g  // 5\\r\\n  // HELLO\\r\\n  // 0\\r\\n  // \\r\\n  body = Buffer.buffer() while (true) { // Parse length chunk  // Non-blocking  val len = channel.receive().toString().toInt(16) if (len == 0) { break } // The stream is flipped to parse a chunk of the exact size  stream.fixedSizeMode(len + 2) // Receive the chunk and append it  // Non-blocking  val chunk = channel.receive() body.appendBuffer(chunk, 0, chunk.length() - 2) // The stream is flipped back to the \\r\\n delimiter to parse the next chunk  stream.delimitedMode(\u0026#34;\\r\\n\u0026#34;) } } else if (contentLength != null) { // The stream is flipped to parse a body of the exact size  stream.fixedSizeMode(contentLength.toInt()) // Non-blocking  body = channel.receive() } else { body = null } println(\u0026#34;Received HTTP request ($method, $uri) with headers ${headers.keys}and body with size ${body?.length() ?: 0}\u0026#34;) 发送数据 使用 channel 发送数据也非常直接：\nsuspend fun sendChannel() { val stream = vertx.eventBus().publisher\u0026lt;Double\u0026gt;(\u0026#34;temperature\u0026#34;) val channel = stream.toChannel(vertx) while (true) { val temperature = readTemperatureSensor() // Broadcast the temperature  // Non-blocking but could be suspended  channel.send(temperature) // Wait for one second  awaitEvent\u0026lt;Long\u0026gt; { vertx.setTimer(1000, it) } } } SendChannel#send 和 WriteStream#write 都是非阻塞操作。不像当 channel 满的时候 SendChannel#send 可以停止执行，而等效 WriteStream#writ 的无 channel 操作可能像这样：\n// Check we can write in the stream if (stream.writeQueueFull()) { // We can\u0026#39;t write so we set a drain handler to be called when we can write again  stream.drainHandler { broadcastTemperature() } } else { // Read temperature  val temperature = readTemperatureSensor() // Write it to the stream  stream.write(temperature) // Wait for one second  vertx.setTimer(1000) { broadcastTemperature() } } 延迟，取消和超时 借助于 vert.x 的定时器，vert.x 的调度器完全支持协程的 delay 函数：\nlaunch(vertx.dispatcher()) { // Set a one second Vertx timer  delay(1000) } 定时器也支持取消：\nval job = launch(vertx.dispatcher()) { // Set a one second Vertx timer  while (true) { delay(1000) // Do something periodically  } } // Sometimes later job.cancel() 取消是合作的。\n你也可以使用 withTimeout 函数安排超时。\nlaunch(vertx.dispatcher()) { try { val id = withTimeout\u0026lt;String\u0026gt;(1000) { return awaitEvent\u0026lt;String\u0026gt; { anAsyncMethod(it) } } } catch (e: TimeoutCancellationException) { // Cancelled  } } Vert.x 支持所有的协程构建器：launch，async 和 runBlocking。runBlocking 构建器不能再 vert.x 的时间循环线程中使用。\n协程的互操作性 vert.x 集成协程被设计为完全可以和 kotlin 协程互操作。\nkotlinx.coroutines.experimental.sync.Mutex 被执行在使用 vert.x 调度器的事件循环线程。\nRxJava 的互操作性 虽然 vertx-lang-kotlin-coroutines 模块没有与 RxJava 特定集成，但是 kotlin 协程提供了 RxJava 的集成。RxJava 可以和 vertx-lang-kotlin-coroutines 很好的协同工作。\n你可以阅读响应流和协程的指南。\n","permalink":"https://zhenfeng-zhu.github.io/posts/vertx-kotlin-coroutine/","summary":"尝试翻译 vertx 的文档。尊重原文，部分使用自己的理解。\n Vert.x 的 kotlin 协程提供了 async/await 或者和 go 类似的 channel。这使得你能够以熟悉的顺序风格写垂直代码。\nvertx-lang-kotlin-coroutines 集成了 kotlin 协程，用于执行异步操作和处理事件。这样就能够以同步代码的模型编写代码，而且不会阻塞内核线程。\n简介 vert.x 与许多旧的应用平台相比的一个主要优势是它几乎完全是非阻塞的（内核线程）。这允许基于 vert.x 的程序使用极少数的内核线程处理大量的并发（例如：许多连接和消息），可以获得更好的伸缩性。\nvert.x 的非阻塞特性形成了非阻塞 API。非阻塞 API 可以采用多种形式来实现，包括回调函数，promise，fibers 或者响应式扩展。vert.x 的核心 API 使用回调函数的风格，但是它也支持其他模型，如 RxJava 1 和 2。\n在某些情况下，使用异步的 API 编程可能比使用经典的顺序代码风格更具有挑战性，特别是需要按照顺序完成若干操作。另外，使用异步 API 时，错误的传播也更为复杂。\nvertx-lang-kotlin-coroutines 使用协程。协程是非常轻量级的线程，而且不与底层的内核线程对应。所以当协程需要“阻塞”时，它会暂停并释放当前的内核线程，使得另一个协程可以处理事件。\nvertx-lang-kotlin-coroutines 使用 kotlinx.coroutines 来实现协程。\n vertx-lang-kotlin-coroutines 目前仅适用于 kotlin，而且是 kotlin1.1 的一个实验特性。\n 从一个 vertx.x 的 contex 中启动协程 导入 io.vertx.kotlin.coroutines.VertxCoroutine，launch（协程生成器）方法中允许运行一段代码作为可以暂停的协程：\nval vertx = Vertx.vertx() vertx.deployVerticle(ExampleVerticle()) launch(vertx.dispatcher()) { val timerId = awaitEvent\u0026lt;Long\u0026gt; { handler -\u0026gt; vertx.","title":"译：vertx-kotlin-coroutine"},{"content":" Being happy doesn\u0026rsquo;t mean that everything is perfect. It means that you decided to look beyond the imperfections.\n 后端编程，涉及最多的就是并发。简单理解就是：\n 并发是同时管理多个任务去执行，并行是针对多核处理器，同时执行多个任务。可以理解为一个是 manage，一个是 run。\n 并发一般特指 IO，IO 是独立于 CPU 的设备，IO 设备通常远远慢于 CPU，所以我们引入了并发的概念，让 CPU 可以一次性发起多个 IO 操作而不用等待 IO 设备做完一个操作再做令一个。原理就是非阻塞操作+事件通知。\n硬件底层上我其实不关心，主要就是在写程序上，如何简单的去写并发的代码。在语法层面上对并发做的比较好的，很适合做服务端，比如 go，比如 node，又比如某些函数式语言。我最近最近主要使用的是 node 和 kotlin。\n那么在写并发代码的时候，就会时不时的想这样一个问题：\n一个问题 当代码遇到一个“暂时不能完成”的流程时（例如建立一个 tcp 链接，可能需要 5ms 才能建立），他不想阻塞在这里睡眠，想暂时离开现场去干点别的事情（例如看看另外一个已经建立的链接是否可以收包了）。问题是：离开现场后，当你回来的时候，上下文还像你走的时候吗？\n跳转离开，在任何语言里都有 2 种最基本的方法：1）从当前函数返回； 2）调用一个新的函数。 前者会把上下文中的局部变量和函数参数全部摧毁，除非他返回前把这些变量找个别的地方保存起来；后者则能保护住整个上下文的内存（除了协程切换后会摧毁一些寄存器），而且跳转回来也是常规方法：函数返回。\n在写 node 的时候，基本上是无脑上 async/await。每次看到回调函数的时候，强迫症就犯了，总是想方设法将那个方法转成 promise，然后使用 await 获得结果。无脑尝试了 bluebird 和 node 的 util，虽然有些是很好用的，但是有的还是无法达到我预期的。靠着无脑的 async/await，实现了很多功能，代码写起来也是快的飞起，但是只顾着做业务而不深入思考的话，是一个不好的表现，所以我就停下来搜了很多 async/await 的东西，特别是从阮一峰老师那里收获了很多。\njs 异步编程 因为 js 是单线程，所以异步编程对 js 特别重要。\n实现异步主要有如下几种：\n  回调函数\ncallback，英语直译就是重新调用。\n所谓的回调函数就是把任务的第二段单独写在一个函数里面，等到重新执行这个任务的时候，直接调用这个函数。\n回调本身没问题，但是就怕多重嵌套。\n  promise\npromise 是一种新的写法，把回调函数的横向嵌套，用 then 的形式改成纵向的加载。\n  协程\n协程就是比线程更小的单位。\n执行过程大致如下：\n第一步，协程 A 开始执行。\n第二步，协程 A 执行到一半，进入暂停，执行权转移到协程 B。\n第三步，（一段时间后）协程 B 交还执行权。\n第四步，协程 A 恢复执行。\n后面再展开说协程。\n  很明显，在 go 火起来之后，很多编程语言都在往协程上靠，因为协程很好的将异步的写法转化成了同步的写法，降低了心智负担。js 当然也不落后。\njs 的异步写法的演进\n  generator\nes6 增加了 generator 函数，就是协程的一种实现，最大特点就是使用 yield 关键字就是用来交出函数的执行权。\nfunction* gen(x){ var y = yield x + 2; return y; } 不同于普通函数的地方在于调用 generator 函数的时候，不返回结果，而是会返回一个内部的指针。调用指针的 next 方法，会移动内部指针（即执行异步任务的第一段），遇到的 yield 语句就交出执行权，执行别的代码。下次再调用该函数指针的 next 方法，就继续执行到该函数的下一个 yield 语句。\n虽然 Generator 函数将异步操作表示得很简洁，但是流程管理却不方便（即何时执行第一阶段、何时执行第二阶段），这样看来其实 generator 函数就是一个异步操作的容器，需要有一个触发它自动执行的机制。\n  Thunk 函数\n说到 thunk 函数，就得先了解一下参数的求值策略。\nlet m=1; function f(x){ return x*2 } f(m+5)   传值调用\n先计算出来 m+5 的值 6，然后再将值传给函数 f，即 6*2\n  传名调用\n把 m+5 传入到 f 中，在用到的时候再计算，即(x+5)*2。\n  传值调用比较简单，但是对参数求值的时候，实际上还没用到这个参数，有可能造成性能损失。\n编译器的\u0026quot;传名调用\u0026quot;实现，往往是将参数放到一个临时函数之中，再将这个临时函数传入函数体。这个临时函数就叫做 Thunk 函数。\njs 是传值调用。他的 thunk 函数是将多参数的函数，替换成了单参数的版本，而且只接受回调函数作为参数。\n这样就可以很方便的实现了基于 thunk 函数的 generator 自动执行器。\n具体的实现和如何使用，参考http://www.ruanyifeng.com/blog/2015/05/thunk.html。\n  co 函数\nco 函数是基于 Promise 的 generator 函数的自动执行器。\n源代码只有几十行，tj 大神太强👍了。\nhttp://www.ruanyifeng.com/blog/2015/05/co.html\n  async/await\nasync 函数就是 generator 函数的语法糖。\nasync 函数自带执行器，无脑写 async 和 await 的时候就是，几乎所有的函数都写成了 async 函数，只要需要等待的方法，都用 await 去等待，这样就造成了很多无意义的等待。本来两个不相干的操作，如果每个都是用 await 等的话，就会很影响性能。\n多个请求并发执行的时候，尽量选用 Promise.all 方法。\n  理解了以上的演进过程，感觉自己终于摆脱了 java 思维的枪，对 node 终于入门了。然后，同步地写着 kotlin 项目，又陷入了泥潭中。\nFuture、RxJava、Actor 和 kotlin 协程 我理解的也不是很深，求科普。\n以前写 java 的时候，自己都是无脑用线程池，开多线程去处理，一般这种情况下不需要线程的结果。\n  future\n因为不能直接从别的线程中得到函数的返回值，所以 future 就出场了。\nFutrue 可以监视目标线程调用 call 的情况，当你调用 Future 的 get()方法以获得结果时，当前线程就开始阻塞，直接 call 方法结束返回结果。\nFuture 对象本身可以看作是一个显式的引用，一个对异步处理结果的引用。由于其异步性质，在创建之初，它所引用的对象可能还并不可用（比如尚在运算中，网络传输中或等待中）。这时，得到 Future 的程序流程如果并不急于使用 Future 所引用的对象，那么它可以做其它任何想做的事儿，当流程进行到需要 Future 背后引用的对象时，可能有两种情况：\n  希望能看到这个对象可用，并完成一些相关的后续流程。\n可以通过调用 Future.isDone()判断引用的对象是否就绪，并采取不同的处理。\n  如果实在不可用，也可以进入其它分支流程。\n只需调用 get()或 get(long timeout, TimeUnit unit)通过同步阻塞方式等待对象就绪。实际运行期是阻塞还是立即返回就取决于 get()的调用时机和对象就绪的先后了。\n    rxjava\n  actor\n  coroutine\n  跪求科普，等理解了再接着完善。\n浅谈协程 说到协程，就要说线程。\n线程是操作系统的用户态概念，线程本身也依赖中断来进行调度。早期的用户态 IO 并发处理是用 poll(select)模型去轮询 IO 状态，然后发起相应的 IO 操作，称之为事件响应式的异步模型，这种方式并不容易使用，所以又发展出了阻塞式 IO 操作，让逻辑挂起并等待 IO 完成，为了让阻塞式 IO 能够并发就必须依赖多线程或者多进程模型来实现。但是线程的开销是非常大的，当遇到大规模并发的时候多线程模型就无法胜任了。所以大规模并发时我们又退回去使用事件响应，epoll 在本质上还是 poll 模型，只是在算法上优化了实现，此时我们只用单线程就可以处理上万的并发请求了。\n直到多核 CPU 的出现，我们发现只用一个线程是无法发挥多核 CPU 的威力的，所以再次引入线程池来分摊 IO 操作的 CPU 消耗，甚至 CPU 的中断响应也可以由多个核来分摊执行，此时的线程数量是大致等于 CPU 的核心数而远小于并发 IO 数的（这时 CPU 能处理百万级的并发），线程的引入完全是为了负载均衡而跟并发没有关系。所以不管是用 select/epoll/iocp 在逻辑层都绕不开基于事件响应的异步操作，面对异步逻辑本身的复杂性，我们才引入了 async/await 以及 coroutine 来降低复杂性。\ncoroutine 是个很宽泛的概念，async/await 也属于 coroutine 的一种。\n而协程在实现模式上又分为：stackful coroutine 和 stackless coroutine。\n所谓 stackful 是指每个 coroutine 有独立的运行栈，比如 go 语言的每个 goroutine 会分配一个 4k 的内存来做为运行栈，切换 goroutine 的时候运行栈也会切换。stackful 的好处在于这种 coroutine 是完整的，coroutine 可以嵌套、循环。\n与 stackful 对应的是 stackless coroutine，比如 js 的 generator 函数，这类 coroutine 不需要分配单独的栈空间，coroutine 状态保存在闭包里，但缺点是功能比较弱，不能被嵌套调用，也没办法和异步函数配合使用进行控制流的调度，所以基本上没办法跟 stackful coroutine 做比较。保存这些状态的时候，有的语言就引入了状态机的模型来实现线程。\nasync/await 的出现，实现了基于 stackless coroutine 的完整 coroutine。在特性上已经非常接近 stackful coroutine 了，不但可以嵌套使用也可以支持 try catch。\n结语 发现自己挺无脑的，学会了一个东西，就无脑的去用，直到碰壁了才会去思考。\n","permalink":"https://zhenfeng-zhu.github.io/posts/async/","summary":"Being happy doesn\u0026rsquo;t mean that everything is perfect. It means that you decided to look beyond the imperfections.\n 后端编程，涉及最多的就是并发。简单理解就是：\n 并发是同时管理多个任务去执行，并行是针对多核处理器，同时执行多个任务。可以理解为一个是 manage，一个是 run。\n 并发一般特指 IO，IO 是独立于 CPU 的设备，IO 设备通常远远慢于 CPU，所以我们引入了并发的概念，让 CPU 可以一次性发起多个 IO 操作而不用等待 IO 设备做完一个操作再做令一个。原理就是非阻塞操作+事件通知。\n硬件底层上我其实不关心，主要就是在写程序上，如何简单的去写并发的代码。在语法层面上对并发做的比较好的，很适合做服务端，比如 go，比如 node，又比如某些函数式语言。我最近最近主要使用的是 node 和 kotlin。\n那么在写并发代码的时候，就会时不时的想这样一个问题：\n一个问题 当代码遇到一个“暂时不能完成”的流程时（例如建立一个 tcp 链接，可能需要 5ms 才能建立），他不想阻塞在这里睡眠，想暂时离开现场去干点别的事情（例如看看另外一个已经建立的链接是否可以收包了）。问题是：离开现场后，当你回来的时候，上下文还像你走的时候吗？\n跳转离开，在任何语言里都有 2 种最基本的方法：1）从当前函数返回； 2）调用一个新的函数。 前者会把上下文中的局部变量和函数参数全部摧毁，除非他返回前把这些变量找个别的地方保存起来；后者则能保护住整个上下文的内存（除了协程切换后会摧毁一些寄存器），而且跳转回来也是常规方法：函数返回。\n在写 node 的时候，基本上是无脑上 async/await。每次看到回调函数的时候，强迫症就犯了，总是想方设法将那个方法转成 promise，然后使用 await 获得结果。无脑尝试了 bluebird 和 node 的 util，虽然有些是很好用的，但是有的还是无法达到我预期的。靠着无脑的 async/await，实现了很多功能，代码写起来也是快的飞起，但是只顾着做业务而不深入思考的话，是一个不好的表现，所以我就停下来搜了很多 async/await 的东西，特别是从阮一峰老师那里收获了很多。","title":"小议 async/await 和 coroutine"},{"content":"以前没有好好学的东西，现在在工作中慢慢的补回来了。\n基础概念  索引  es 是将数据存储在一个或者多个索引（index）中。\n索引就像是数据库。\n 文档  文档是 es 的实体。由字段构成，每个字段包含字段名和一个或者多个字段值。\n文档就像数据库中的一条条记录。\n 类型  每个文档都有一个类型与之相对应。\n类型就像数据库中的表。\n Map  所有文档在被写入到 es 中，都会被分析。由用户设置一些参数决定如何分割词条、哪些字应该被过滤掉等等。\n 节点  单个 es 服务实例就是一个节点。\n 集群  多个协同工作的 es 节点的集合就是集群。\n 分片  es 将数据分散到多个物理的 Lucene 索引上，这些物理 Lucene 索引被称为分片。\n 副本  副本就是每个分片都做冗余处理，一个宕机之后，不影响服务。\n快速入门 安装 es 的安装很简单，我这里使用的是 mac，下载下来 zip 包，解压即可使用。\n[elasticsearch-6.2.4] pwd /Users/zhuzhenfeng/Documents/software/elasticsearch-6.2.4 [elasticsearch-6.2.4] ./bin/elasticsearch Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. [2018-05-20T17:18:37,619][INFO ][o.e.n.Node ] [] initializing ... [2018-05-20T17:18:37,766][INFO ][o.e.e.NodeEnvironment ] [M41310-] using [1] data paths, mounts [[/ (/dev/disk1s1)]], net usable_space [136gb], net total_space [233.4gb], types [apfs] [2018-05-20T17:18:37,767][INFO ][o.e.e.NodeEnvironment ] [M41310-] heap size [990.7mb], compressed ordinary object pointers [true] 这样就将 es 启动了，然后在 chrome 中，输入http://localhost:9200，即可查看有没有启动成功。\n{ \u0026quot;name\u0026quot;: \u0026quot;M41310-\u0026quot;, \u0026quot;cluster_name\u0026quot;: \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot;: \u0026quot;58U11tViTYuXpI2b5SiGrg\u0026quot;, \u0026quot;version\u0026quot;: { \u0026quot;number\u0026quot;: \u0026quot;6.2.4\u0026quot;, \u0026quot;build_hash\u0026quot;: \u0026quot;ccec39f\u0026quot;, \u0026quot;build_date\u0026quot;: \u0026quot;2018-04-12T20:37:28.497551Z\u0026quot;, \u0026quot;build_snapshot\u0026quot;: false, \u0026quot;lucene_version\u0026quot;: \u0026quot;7.2.1\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot;: \u0026quot;5.6.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot;: \u0026quot;5.0.0\u0026quot; }, \u0026quot;tagline\u0026quot;: \u0026quot;You Know, for Search\u0026quot; } 常用的命令 使用 postman 来模拟发送请求。\n创建 index PUT\nhttp://127.0.0.1:9200/myindex response\n{ \u0026quot;acknowledged\u0026quot;: true, \u0026quot;shards_acknowledged\u0026quot;: true, \u0026quot;index\u0026quot;: \u0026quot;myindex\u0026quot; } 创建了一个叫 myindex 的索引\n删除 index DELETE\nhttp://127.0.0.1:9200/myindex response\n{ \u0026quot;acknowledged\u0026quot;: true } 使用 delete 方法就可以删除索引，而且可以发现 es 的 response 特别人性化。\n创建 maping POST\nhttp://localhost:9200/myindex/fulltext/_mapping body\n{ \u0026quot;properties\u0026quot;: { \u0026quot;content\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;, \u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;, \u0026quot;search_analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot; } } } response\n{ \u0026quot;acknowledged\u0026quot;: true } 在这里在创建一个 type 是 fulltext 的同时，指定了这个 fulltext 类型的字段 Map。在 mapping 中，一般是设置字段是什么类型的，比如 bool，text 等。analyzer 是给文档建索引的分词方法，search_analyzer 是搜索时对搜索的内容进行分词的方法。这里都是用了 ik 的分词器。\n新增 doc POST\nhttp://localhost:9200/myindex/fulltext/1 body\n{ \u0026quot;content\u0026quot;: \u0026quot;中国崛起哦\u0026quot; } response\n{ \u0026quot;_index\u0026quot;: \u0026quot;myindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;fulltext\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;_version\u0026quot;: 1, \u0026quot;result\u0026quot;: \u0026quot;created\u0026quot;, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 2, \u0026quot;successful\u0026quot;: 1, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;_seq_no\u0026quot;: 0, \u0026quot;_primary_term\u0026quot;: 1 } 如果没有指定 id 的话，每次新增的时候都会用 es 自动给的 id。如果不注意的话，可能会出现重复新增，所以我们一般情况下会使用自己给的的 id。\n搜索 POST\nhttp://127.0.0.1:9200/myindex/fulltext/_search body\n{ \u0026quot;query\u0026quot;: { \u0026quot;match\u0026quot;: { \u0026quot;content\u0026quot;: { \u0026quot;query\u0026quot;: \u0026quot;中国\u0026quot; } } } } response\n{ \u0026quot;took\u0026quot;: 98, \u0026quot;timed_out\u0026quot;: false, \u0026quot;_shards\u0026quot;: { \u0026quot;total\u0026quot;: 5, \u0026quot;successful\u0026quot;: 5, \u0026quot;skipped\u0026quot;: 0, \u0026quot;failed\u0026quot;: 0 }, \u0026quot;hits\u0026quot;: { \u0026quot;total\u0026quot;: 1, \u0026quot;max_score\u0026quot;: 0.2876821, \u0026quot;hits\u0026quot;: [ { \u0026quot;_index\u0026quot;: \u0026quot;myindex\u0026quot;, \u0026quot;_type\u0026quot;: \u0026quot;fulltext\u0026quot;, \u0026quot;_id\u0026quot;: \u0026quot;1\u0026quot;, \u0026quot;_score\u0026quot;: 0.2876821, \u0026quot;_source\u0026quot;: { \u0026quot;content\u0026quot;: \u0026quot;中国崛起哦\u0026quot; } } ] } }。 前面都没啥，主要就是如何把数据灌到 es 中。es 作为一个搜索引擎，肯定搜索才是最重要的。这里只是用的最简单的搜索。关于 es 的搜索，我在实际生产中主要使用的是，多字段的搜索，使用了 bool 操作符。\n原理 相关性得分 Elasticsearch 默认按照相关性得分排序，即每个文档跟查询的匹配程度。Elasticsearch 中的 相关性 概念非常重要，也是完全区别于传统关系型数据库的一个概念，数据库中的一条记录要么匹配要么不匹配。\n搜索 轻量级搜索 _search\n_search?q=content:中国\n这种搜索方式比较简单，很轻量。\n查询表达式 即 dsl 形式的。使用的是 POST 方法，在 body 中，写搜索的 dsl。\n简单的 dsl { \u0026#34;query\u0026#34;: { \u0026#34;match\u0026#34;: { \u0026#34;content\u0026#34;: { \u0026#34;query\u0026#34;: \u0026#34;中国\u0026#34; } } } } bool 操作符的 DSL { \u0026quot;query\u0026quot; : { \u0026quot;bool\u0026quot;: { \u0026quot;must\u0026quot;: { \u0026quot;match\u0026quot; : { \u0026quot;last_name\u0026quot; : \u0026quot;smith\u0026quot; } }, \u0026quot;filter\u0026quot;: { \u0026quot;range\u0026quot; : { \u0026quot;age\u0026quot; : { \u0026quot;gt\u0026quot; : 30 } } } } } } 我们添加了一个 过滤器 用于执行一个范围查询，并复用之前的 match 查询。\n短语搜索 { \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } } } 如果不用短语搜索的话，会将只含有 rock 或者 climbing 的返回。为了能让二者是短语形式，es 中新增了短语搜索 dsl。\n高亮 许多应用都倾向于在每个搜索结果中 高亮 部分文本片段，以便让用户知道为何该文档符合查询条件。在 Elasticsearch 中检索出高亮片段也很容易。\n{ \u0026quot;query\u0026quot; : { \u0026quot;match_phrase\u0026quot; : { \u0026quot;about\u0026quot; : \u0026quot;rock climbing\u0026quot; } }, \u0026quot;highlight\u0026quot;: { \u0026quot;fields\u0026quot; : { \u0026quot;about\u0026quot; : {} } } } 加上 highlight 关键字即可。\n聚合  Elasticsearch 有一个功能叫聚合（aggregations），允许我们基于数据生成一些精细的分析结果。聚合与 SQL 中的 GROUP BY 类似但更强大。\n{ \u0026quot;aggs\u0026quot;: { \u0026quot;all_interests\u0026quot;: { \u0026quot;terms\u0026quot;: { \u0026quot;field\u0026quot;: \u0026quot;interests\u0026quot; } } } } ","permalink":"https://zhenfeng-zhu.github.io/posts/elasticsearch/","summary":"以前没有好好学的东西，现在在工作中慢慢的补回来了。\n基础概念  索引  es 是将数据存储在一个或者多个索引（index）中。\n索引就像是数据库。\n 文档  文档是 es 的实体。由字段构成，每个字段包含字段名和一个或者多个字段值。\n文档就像数据库中的一条条记录。\n 类型  每个文档都有一个类型与之相对应。\n类型就像数据库中的表。\n Map  所有文档在被写入到 es 中，都会被分析。由用户设置一些参数决定如何分割词条、哪些字应该被过滤掉等等。\n 节点  单个 es 服务实例就是一个节点。\n 集群  多个协同工作的 es 节点的集合就是集群。\n 分片  es 将数据分散到多个物理的 Lucene 索引上，这些物理 Lucene 索引被称为分片。\n 副本  副本就是每个分片都做冗余处理，一个宕机之后，不影响服务。\n快速入门 安装 es 的安装很简单，我这里使用的是 mac，下载下来 zip 包，解压即可使用。\n[elasticsearch-6.2.4] pwd /Users/zhuzhenfeng/Documents/software/elasticsearch-6.2.4 [elasticsearch-6.2.4] ./bin/elasticsearch Java HotSpot(TM) 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.","title":"elasticsearch"},{"content":"整理一下常用的 git 操作，不用再到处找了。\ngit 放弃本地修改，强制更新 git fetch --all git reset --hard origin/master git 修改远程仓库地址 git remote set-url origin url cherry-pick 当你通过一番挣扎终于搞定一个 bug,顺手提交到 git 服务器,心里一阵暗爽. 这时发现你当前所在的分支是 master !!!\n这个分支不是开发者用来提交代码的,可惜现在剁手也晚了.\n 先切换到 master  git checkout master git log  复制提交的 commit id\n  切换到 dev, cherry-pick\n  git checkout dev git cherry-pic ${commit_id} 常用开发流程 git checkout -b feature1\ngit commit 之后，进行 rebase\ngit pull \u0026ndash;rebase\ngca!\ngit rvm\n","permalink":"https://zhenfeng-zhu.github.io/posts/git/","summary":"整理一下常用的 git 操作，不用再到处找了。\ngit 放弃本地修改，强制更新 git fetch --all git reset --hard origin/master git 修改远程仓库地址 git remote set-url origin url cherry-pick 当你通过一番挣扎终于搞定一个 bug,顺手提交到 git 服务器,心里一阵暗爽. 这时发现你当前所在的分支是 master !!!\n这个分支不是开发者用来提交代码的,可惜现在剁手也晚了.\n 先切换到 master  git checkout master git log  复制提交的 commit id\n  切换到 dev, cherry-pick\n  git checkout dev git cherry-pic ${commit_id} 常用开发流程 git checkout -b feature1\ngit commit 之后，进行 rebase\ngit pull \u0026ndash;rebase\ngca!\ngit rvm","title":"git 常用操作"},{"content":"我们知道 js 是运行单线程的，也就是说一个 node 进程只能运行在一个 cpu 上。那么如果用 node 来做 web server 的话，就无法享受到多核运算的好处。\n一个问题就是：\n如何榨干服务器资源，利用多核CPU的并发优势。 node 官方提供的解决方案是 cluster。\n1 cluster 是什么 简单来说：\n 在服务器上同时启动多个进程。 每个进程都跑的是同一份源码。 这些进程可以同时监听一个端口。  其中：\n 负责启动其他进程的叫做 master 进程，不做具体工作，只负责启动其他进程。 其他被启动的叫 worker 进程。他们接收请求，对外提供服务。 worker 进程的数量一般根据服务器的 cpu 核数来决定，这样就可以完美利用多核资源。  以下是官方文档的一个例子：\nconst cluster = require(\u0026#39;cluster\u0026#39;); const http = require(\u0026#39;http\u0026#39;); const numCPUs = require(\u0026#39;os\u0026#39;).cpus().length; if (cluster.isMaster) { console.log(`主进程 ${process.pid} 正在运行`); // 衍生工作进程。 for (let i = 0; i \u0026lt; numCPUs; i++) { cluster.fork(); } cluster.on(\u0026#39;exit\u0026#39;, (worker, code, signal) =\u0026gt; { console.log(`工作进程 ${worker.process.pid} 已退出`); }); } else { // 工作进程可以共享任何 TCP 连接。 // 在本例子中，共享的是一个 HTTP 服务器。 http.createServer((req, res) =\u0026gt; { res.writeHead(200); res.end(\u0026#39;你好世界\\n\u0026#39;); }).listen(8000); console.log(`工作进程 ${process.pid} 已启动`); } % node cluster.js 主进程 16391 正在运行 工作进程 16394 已启动 工作进程 16393 已启动 工作进程 16395 已启动 工作进程 16392 已启动 2 多进程模型 官网的示例很简单，但是我们还要考虑很多东西。\n worker 进程异常退出以后如何处理？ 多个 worker 进程之间如何共享资源？ 多个 worker 进程之间如何调度？ 。。。  进程守护 健壮性是我们做大型应用要考虑的一个问题。一般来说，node 的进程退出可以分为两类：\n 未捕获异常 内存溢出（OOM）或者系统异常  代码跑出了异常却没有没捕捉时，进程将会退出，此时 node 提供了 process.on(\u0026lsquo;uncaughtException\u0026rsquo;, handler)来捕获。但是当一个 worker 进程遇到未 捕获的异常时，他已经处于一个不确定的状态，此时我们应该让这个进程优雅的退出。\n优雅退出的流程是：\n 关闭异常 worker 进程和所有的 tcp server(将已有的连接快速断开，且不再接收新的连接)，断开和 master 的 ipc 通道，不再接收新的用户请求。 master 立即 fork 一个新的 worker 进程，保证在线的“工人”总数不变。 异常 worker 等待一段时间，处理完已经接受的请求后退出。  而当一个进程出现异常导致 crash 或者 OOM 被系统杀死时，不像未捕获异常发生时我们还有机会让进程继续执行，只能够让当前进程直接退出，Master 立刻 fork 一个新的 Worker。\nAgent 机制 有些工作并不需要每个 worker 都去做，如果都做，一个是浪费资源，另一个更重要的是可能会导致多进程之间资源访问冲突。\n比如：生产环境中一般会按照日期进行归档，在单进程模型的时候比较简单：\n 每天凌晨，批量将日志文件重命名 创建新的日志文件继续写入。  如果这个任务由 4 个进程同时做，就乱套了。所以对于这一类的后台运行逻辑，应该放到一个单独的进程去执行，这个进程就是 agent。agent 好比是给其他 worker 请的一个秘书，它不对外提供服务，只给 worker 打工，处理一些公共事务。\n另外，关于 Agent Worker 还有几点需要注意的是：\n 由于 Worker 依赖于 Agent，所以必须等 Agent 初始化完成后才能 fork Worker Agent 虽然是 Worker 的『小秘』，但是业务相关的工作不应该放到 Agent 上去做。 由于 Agent 的特殊定位，我们应该保证它相对稳定。当它发生未捕获异常，不应该像 Worker 一样让他退出重启，而是记录异常日志、报警等待人工处理。  3 进程间通讯（IPC） 虽然每个 Worker 进程是相对独立的，但是它们之间始终还是需要通讯的，叫进程间通讯（IPC）。\nif (cluster.isMaster) { const worker = cluster.fork(); worker.send(\u0026#39;hi there\u0026#39;); } else if (cluster.isWorker) { process.on(\u0026#39;message\u0026#39;, (msg) =\u0026gt; { process.send(msg); }); } 这个例子里面，工作进程将主进程发送的消息 echo 回去。\n4 长连接 一些中间件客户端需要和服务器建立长连接，理论上一台服务器最好只建立一个长连接，但多进程模型会导致 n 倍（n = Worker 进程数）连接被创建。\n为了尽可能的复用长连接（因为它们对于服务端来说是非常宝贵的资源），我们会把它放到 Agent 进程里维护，然后通过 messenger 将数据传递给各个 Worker。这种做法是可行的，但是往往需要写大量代码去封装接口和实现数据的传递，非常麻烦。\n另外，通过 messenger 传递数据效率是比较低的，因为它会通过 Master 来做中转；万一 IPC 通道出现问题还可能将 Master 进程搞挂。\n那么有没有更好的方法呢？答案是肯定的，我们提供一种新的模式来降低这类客户端封装的复杂度。通过建立 Agent 和 Worker 的 socket 直连跳过 Master 的中转。Agent 作为对外的门面维持多个 Worker 进程的共享连接。\n核心思想  受到 Leader/Follower 模式的启发 客户端会被区分为两种角色：  Leader: 负责和远程服务端维持连接，对于同一类的客户端只有一个 Leader Follower: 会将具体的操作委托给 Leader，常见的是订阅模型（让 Leader 和远程服务端交互，并等待其返回）。   如何确定谁是 Leader，谁是 Follower 呢？有两种模式：  自由竞争模式：客户端启动的时候通过本地端口的争夺来确定 Leader。例如：大家都尝试监听 7777 端口，最后只会有一个实例抢占到，那它就变成 Leader，其余的都是 Follower。 强制指定模式：框架指定某一个 Leader，其余的就是 Follower   启动的时候 Master 会随机选择一个可用的端口作为 Cluster Client 监听的通讯端口，并将它通过参数传递给 Agent 和 App Worker Leader 和 Follower 之间通过 socket 直连（通过通讯端口），不再需要 Master 中转   5 参考资料 多进程模型和进程间通讯\nNode.js v8.11.1 文档 cluster\n","permalink":"https://zhenfeng-zhu.github.io/posts/node%E7%9A%84cluster/","summary":"我们知道 js 是运行单线程的，也就是说一个 node 进程只能运行在一个 cpu 上。那么如果用 node 来做 web server 的话，就无法享受到多核运算的好处。\n一个问题就是：\n如何榨干服务器资源，利用多核CPU的并发优势。 node 官方提供的解决方案是 cluster。\n1 cluster 是什么 简单来说：\n 在服务器上同时启动多个进程。 每个进程都跑的是同一份源码。 这些进程可以同时监听一个端口。  其中：\n 负责启动其他进程的叫做 master 进程，不做具体工作，只负责启动其他进程。 其他被启动的叫 worker 进程。他们接收请求，对外提供服务。 worker 进程的数量一般根据服务器的 cpu 核数来决定，这样就可以完美利用多核资源。  以下是官方文档的一个例子：\nconst cluster = require(\u0026#39;cluster\u0026#39;); const http = require(\u0026#39;http\u0026#39;); const numCPUs = require(\u0026#39;os\u0026#39;).cpus().length; if (cluster.isMaster) { console.log(`主进程 ${process.pid} 正在运行`); // 衍生工作进程。 for (let i = 0; i \u0026lt; numCPUs; i++) { cluster.","title":"node 的 cluster"},{"content":"module 首先第一个就是 es6 的 module。\n看到别人写的\nimport { a } from \u0026#34;./module\u0026#34;; 所以自己也想要这么写，但是每次运行的时候都会报错。\n// demo2.js export const a = \u0026#34;hello\u0026#34;; //demo1.js import { a } from \u0026#34;./demo2\u0026#34;; function hello() { console.log(a); } zhuzhenfengdeMacBook-Pro :: node/node-example » node demo1.js /Users/zhuzhenfeng/Documents/github/node/node-example/demo1.js:1 (function (exports, require, module, __filename, __dirname) { import { a } from \u0026#34;./demo2\u0026#34;; ^ SyntaxError: Unexpected token { at new Script (vm.js:74:7) at createScript (vm.js:246:10) at Object.runInThisContext (vm.js:298:10) at Module._compile (internal/modules/cjs/loader.js:646:28) at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10) at Module.load (internal/modules/cjs/loader.js:589:32) at tryModuleLoad (internal/modules/cjs/loader.js:528:12) at Function.Module._load (internal/modules/cjs/loader.js:520:3) at Function.Module.runMain (internal/modules/cjs/loader.js:719:10) at startup (internal/bootstrap/node.js:228:19) zhuzhenfengdeMacBook-Pro :: node/node-example » 后来仔细查了资料之后，才发现，node 现在还不能这么使用。\n如下是解决的办法。\n给每个 js 文件都以 mjs 命名。\n// module.js export const a = \u0026#34;hello\u0026#34;; // useModule.js import { a } from \u0026#34;./module.mjs\u0026#34;; function hello() { console.log(a); } hello(); zhuzhenfengdeMacBook-Pro :: node/node-example » node --experimental-modules useModule.mjs (node:15282) ExperimentalWarning: The ESM module loader is experimental. hello zhuzhenfengdeMacBook-Pro :: node/node-example » 这样才能够正常使用。\n","permalink":"https://zhenfeng-zhu.github.io/posts/node%E8%B8%A9%E5%9D%91/","summary":"module 首先第一个就是 es6 的 module。\n看到别人写的\nimport { a } from \u0026#34;./module\u0026#34;; 所以自己也想要这么写，但是每次运行的时候都会报错。\n// demo2.js export const a = \u0026#34;hello\u0026#34;; //demo1.js import { a } from \u0026#34;./demo2\u0026#34;; function hello() { console.log(a); } zhuzhenfengdeMacBook-Pro :: node/node-example » node demo1.js /Users/zhuzhenfeng/Documents/github/node/node-example/demo1.js:1 (function (exports, require, module, __filename, __dirname) { import { a } from \u0026#34;./demo2\u0026#34;; ^ SyntaxError: Unexpected token { at new Script (vm.js:74:7) at createScript (vm.js:246:10) at Object.runInThisContext (vm.js:298:10) at Module._compile (internal/modules/cjs/loader.js:646:28) at Object.","title":"node 踩坑"},{"content":"写 node 也有一段时间了，整理一下学习笔记，共同进步\n什么是 node 首先看一下什么是 node.js\n Node 是一个服务器端 JavaScript Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效 Node.js 的包管理器 npm，是全球最大的开源库生态系统  模块系统是 node 最基本也是最常用的。一般可以分为四类：\n 原生模块 文件模块 第三方模块 自定义模块  node 社区崇尚 DRY 文化，即 Don\u0026rsquo;t repeate yourself。这种文化使得 node 的生态异常繁荣，同样也由于某些包的质量低下引来了一些诟病。\n谈谈自定义模块 我们在写 node 程序的时候，一般都是在写自定义模块。\n  创建模块\n// b.js function FunA(){ return \u0026#34;hello world\u0026#34;; } // 暴露方法FunA module.exports = FunA;   加载模块\n// a.js const FunA=require(\u0026#39;./b.js\u0026#39;); // 运行FunA const name=FunA(); console.log(name);   在做模块到处的时候有两种方式：\n  module.exports\nmodule.exports 就 Node.js 用于对外暴露，或者说对外开放指定访问权限的一个对象。\n一个模块中有且仅有一个 module.exports，如果有多个那后面的则会覆盖前面的。\n  exports\nexports 是 module 对象的一个属性，同时它也是一个对象。在很多时候一个 js 文件有多个需要暴露的方法或是对象，module.exports 又只能暴露一个，那这个时候就要用到 exports:\nfunction FunA(){ return \u0026#39;Tom\u0026#39;; } function FunB(){ return \u0026#39;Sam\u0026#39;; } exports.FunA = FunA; exports.FunB = FunB; //FunA = exports,exports 是一个对象 var FunA = require(\u0026#39;./b.js\u0026#39;); var name1 = FunA.FunA();// 运行 FunA，name = \u0026#39;Tom\u0026#39; var name2 = FunA.FunB();// 运行 FunB，name = \u0026#39;Sam\u0026#39; console.log(name1); console.log(name2); 当然在引入的时候也可以这样写：\n//FunA = exports,exports 是一个对象 var {FunA, FunB} = require(\u0026#39;./b.js\u0026#39;); var name1 = FunA();// 运行 FunA，name = \u0026#39;Tom\u0026#39; var name2 = FunB();// 运行 FunB，name = \u0026#39;Sam\u0026#39; console.log(name1); console.log(name2);   常用的原生模块 常用的原生模块有如下四个：\n http url queryString fs  http 所有后端的语言要想运行起来，都得有服务器。node 通过原生的 http 模块来搭建服务器：\n 加载 http 模块 调用 http.createServer() 方法创建服务，方法接受一个回调函数，回调函数中有两个参数，第一个是请求体，第二个是响应体。 在回调函数中一定要使用 response.end() 方法，用于结束当前请求，不然当前请求会一直处在等待的状态。 调用 listen 监听一个端口。  //原生模块 var http = require(\u0026#39;http\u0026#39;); http.createServer(function(reqeust, response){ response.end(\u0026#39;Hello Node\u0026#39;); }).listen(8080); 处理参数\n  get\n当 get 请求的时候，服务器通过 request.method 来判断当前的请求方式并通过 request.url 来获取当前的请求参数：\nvar http = require(\u0026#39;http\u0026#39;); var url = require(\u0026#39;url\u0026#39;); http.createServer(function(req, res){ var params = url.parse(req.url, true).query; res.end(params); }).listen(3000);   post\npost 请求则不能通过 url 来获取，这时候就得对请求体进行事件监听。\nvar http = require(\u0026#39;http\u0026#39;); var util = require(\u0026#39;util\u0026#39;); var querystring = require(\u0026#39;querystring\u0026#39;); http.createServer(function(req, res){ // 定义了一个post变量，用于暂存请求体的信息 var post = \u0026#39;\u0026#39;; // 通过req的data事件监听函数，每当接受到请求体的数据，就累加到post变量中 req.on(\u0026#39;data\u0026#39;, function(chunk){ post += chunk; }); // 在end事件触发后，通过querystring.parse将post解析为真正的POST请求格式，然后向客户端返回。 req.on(\u0026#39;end\u0026#39;, function(){ post = querystring.parse(post); res.end(util.inspect(post)); }); }).listen(3000);   url url 和 http 是配合使用的。一般情况下 url 都是字符串类型的，包含的信息也比较多，比如有：协议、主机名、端口、路径、参数、锚点等。如果是对字符串进行直接解析的话，相当麻烦，node 提供的 url 模块便可轻松解决这一类的问题。\n字符串转对象  格式：url.parse(urlstring, boolean) 参数  urlstring：字符串格式的 url boolean：在 url 中有参数，默认参数为字符串，如果此参数为 true，则会自动将参数转转对象   常用属性  href： 解析前的完整原始 URL，协议名和主机名已转为小写 protocol： 请求协议，小写 host： url 主机名，包括端口信息，小写 hostname: 主机名，小写 port: 主机的端口号 pathname: URL 中路径，下面例子的 /one search: 查询对象，即：queryString，包括之前的问号“?” path: pathname 和 search 的合集 query: 查询字符串中的参数部分（问号后面部分字符串），或者使用 querystring.parse() 解析后返回的对象 hash: 锚点部分（即：“#”及其后的部分）    对象转字符串  格式：url.format(urlObj) 参数 urlObj 在格式化的时候会做如下处理  href: 会被忽略，不做处理 protocol：无论末尾是否有冒号都会处理，协议包括 http, https, ftp, gopher, file 后缀是 :// (冒号-斜杠-斜杠) hostname：如果 host 属性没被定义，则会使用此属性 port：如果 host 属性没被定义，则会使用此属性 host：优先使用，将会替代 hostname 和 port pathname：将会同样处理无论结尾是否有/ (斜杠) search：将会替代 query 属性，无论前面是否有 ? (问号)，都会同样的处理 query：(object 类型; 详细请看 querystring) 如果没有 search,将会使用此属性. hash：无论前面是否有# (井号, 锚点)，都会同样处理    拼接 当有多个 url 需要拼接处理的时候，可以用到 url.resolve\nvar url = require(\u0026#39;url\u0026#39;); url.resolve(\u0026#39;http://dk-lan.com/\u0026#39;, \u0026#39;/one\u0026#39;)// \u0026#39;http://dk-lan.com/one\u0026#39; querystring url 是对 url 字符串的处理，而 querystring 就是仅针对参数的处理。\n字符串转对象 var str = \u0026#39;firstname=dk\u0026amp;url=http%3A%2F%2Fdk-lan.com\u0026amp;lastname=tom\u0026amp;passowrd=123456\u0026#39;; var param = querystring.parse(param); //结果 //{firstname:\u0026#34;dk\u0026#34;, url:\u0026#34;http://dk-lan.com\u0026#34;, lastname: \u0026#39;tom\u0026#39;, passowrd: 123456}; 对象转字符串 var querystring = require(\u0026#39;querystring\u0026#39;); var obj = {firstname:\u0026#34;dk\u0026#34;, url:\u0026#34;http://dk-lan.com\u0026#34;, lastname: \u0026#39;tom\u0026#39;, passowrd: 123456}; //将对象转换成字符串 var param = querystring.stringify(obj); //结果 //firstname=dk\u0026amp;url=http%3A%2F%2Fdk-lan.com\u0026amp;lastname=tom\u0026amp;passowrd=123456 fs 任何服务端语言都不能缺失文件的读写操作。\n读取文本 \u0026ndash; 异步读取 var fs = require(\u0026#39;fs\u0026#39;); // 异步读取 // 参数1：文件路径， // 参数2：读取文件后的回调 fs.readFile(\u0026#39;demoFile.txt\u0026#39;, function (err, data) { if (err) { return console.error(err); } console.log(\u0026#34;异步读取: \u0026#34; + data.toString()); }); 读取文本 \u0026ndash; 同步读取 var fs = require(\u0026#39;fs\u0026#39;); var data = fs.readFileSync(\u0026#39;demoFile.txt\u0026#39;); console.log(\u0026#34;同步读取: \u0026#34; + data.toString()); 写入文本 \u0026ndash; 覆盖写入 var fs = require(\u0026#39;fs\u0026#39;); //每次写入文本都会覆盖之前的文本内容 fs.writeFile(\u0026#39;input.txt\u0026#39;, \u0026#39;抵制一切不利于中国和世界和平的动机！\u0026#39;, function(err) { if (err) { return console.error(err); } console.log(\u0026#34;数据写入成功！\u0026#34;); console.log(\u0026#34;--------我是分割线-------------\u0026#34;) console.log(\u0026#34;读取写入的数据！\u0026#34;); fs.readFile(\u0026#39;input.txt\u0026#39;, function (err, data) { if (err) { return console.error(err); } console.log(\u0026#34;异步读取文件数据: \u0026#34; + data.toString()); }); }); 写入文本 \u0026ndash; 追加写入 var fs = require(\u0026#39;fs\u0026#39;); fs.appendFile(\u0026#39;input.txt\u0026#39;, \u0026#39;愿世界和平！\u0026#39;, function (err) { if (err) { return console.error(err); } console.log(\u0026#34;数据写入成功！\u0026#34;); console.log(\u0026#34;--------我是分割线-------------\u0026#34;) console.log(\u0026#34;读取写入的数据！\u0026#34;); fs.readFile(\u0026#39;input.txt\u0026#39;, function (err, data) { if (err) { return console.error(err); } console.log(\u0026#34;异步读取文件数据: \u0026#34; + data.toString()); }); }); 图片读取 图片读取不同于文本，因为文本读出来可以直接用 console.log() 打印，但图片则需要在浏览器中显示，所以需要先搭建 web 服务，然后把以字节方式读取的图片在浏览器中渲染。\n 图片读取是以字节的方式 图片在浏览器的渲染因为没有 img 标签，所以需要设置响应头为 image  var http = require(\u0026#39;http\u0026#39;); var fs = require(\u0026#39;fs\u0026#39;); var content = fs.readFileSync(\u0026#39;001.jpg\u0026#39;, \u0026#34;binary\u0026#34;); http.createServer(function(request, response){ response.writeHead(200, {\u0026#39;Content-Type\u0026#39;: \u0026#39;image/jpeg\u0026#39;}); response.write(content, \u0026#34;binary\u0026#34;); response.end(); }).listen(8888); console.log(\u0026#39;Server running at http://127.0.0.1:8888/\u0026#39;); stream 流处理 对 http 服务器发起请求的 request 对象就是一个 Stream，还有 stdout（标准输出）。往往用于打开大型的文本文件，创建一个读取操作的数据流。所谓大型文本文件，指的是文本文件的体积很大，读取操作的缓存装不下，只能分成几次发送，每次发送会触发一个 data 事件，发送结束会触发 end 事件。\n主要分为\n 读取流 写入流 管道流 链式流  这几种流都是 fs 的一部分。\n路由 在 BS 架构中，路由的概念都是一样的，可以理解为根据客户端请求的 url 映射到不同的方法实现。一般 web 框架中都会有相应的路由模块。但是在原生 node 中去处理的话只能是解析 url 来进行映射，实现起来不够简洁。\nfetch axios 是一种对 ajax 的封装，fetch 是一种浏览器原生实现的请求方式，跟 ajax 对等。\n在现在发起 http 请求里，都是通过 fetch 来发送请求，和 ajax 类似。\nconst fetch=require(\u0026#39;isomorphic-fetch\u0026#39;); const options={ header:{}, body:JSON.strify({}), method: \u0026#39;\u0026#39; } try{ const res=await fetch(\u0026#39;url\u0026#39;, options); }catch(err){ } Async Node.js 是一个异步机制的服务端语言，在大量异步的场景下需要按顺序执行，那正常做法就是回调嵌套回调，回调嵌套太多的问题被称之回调地狱。\nNode.js 为解决这一问题推出了异步控制流 ———— Async\nAsync/Await\nAsync/Await 就 ES7 的方案，结合 ES6 的 Promise 对象，使用前请确定 Node.js 的版本是 7.6 以上。\nAsync/await 的主要益处是可以避免回调地狱（callback hell），且以最接近同步代码的方式编写异步代码。\n基本规则\n async 表示这是一个 async 函数，await 只能用在这个函数里面。 await 表示在这里等待 promise 返回结果了，再继续执行。 await 后面跟着的应该是一个 promise 对象  express 框架 使用 node，都绕不开 express。\n简单使用 express 的使用比较简单，由于我最早接触的是 spring 那套 web 框架，所以在使用到 express 的时候觉得 node 的 web 特别轻量简单。\n加载模块\nconst express=require(\u0026#39;express\u0026#39;); const app=express(); 监听端口 8080\napp.listen(3000, ()=\u0026gt;consloe.log(\u0026#39;running\u0026#39;)); 路由 express 对路由的处理特别简单，配合中间件 body parser，很方便的提供 rest 接口：\napp.get(\u0026#39;/\u0026#39;, (req, res)=\u0026gt;{ res.send(\u0026#39;hello world\u0026#39;); }) response.send() 可理解为 response.end()，其中一个不同点在于 response.send() 参数可为对象。\nNode.js 默认是不能访问静态资源文件（.html、.js、.css、.jpg 等），如果要访问服务端的静态资源文件则要用到方法 sendFile\n__dirname 为 Node.js 的系统变量，指向文件的绝对路径。\napp.get(\u0026#39;/index.html\u0026#39;, function (req, res) { res.sendFile( __dirname + \u0026#34;/\u0026#34; + \u0026#34;index.html\u0026#34; ); }); Express \u0026ndash; GET 参数接收之路径方式\n访问地址：http://localhost:8080/getusers/admin/18，可通过 request.params 来获取参数\napp.get(\u0026#39;/getUsers/:username/:age\u0026#39;, function(request, response){ var params = { username: request.params.username, age: request.params.age } response.send(params); }) Express \u0026ndash; POST\n post 参数接收，可依赖第三方模块 body-parser 进行转换会更方便、更简单，该模块用于处理 JSON, Raw, Text 和 URL 编码的数据。 安装 body-parser npm install body-parser 参数接受和 GET 基本一样，不同的在于 GET 是 request.query 而 POST 的是 request.body  var bodyParser = require(\u0026#39;body-parser\u0026#39;); // 创建 application/x-www-form-urlencoded 编码解析 var urlencodedParser = bodyParser.urlencoded({ extended: false }) app.post(\u0026#39;/getUsers\u0026#39;, urlencodedParser, function (request, response) { var params = { username: request.body.username, age: request.body.age } response.send(params); }); Express \u0026ndash; 跨域支持(放在最前面)\napp.all(\u0026#39;*\u0026#39;, function(req, res, next) { res.header(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); res.header(\u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Content-Type,Content-Length, Authorization, Accept,X-Requested-With\u0026#34;); res.header(\u0026#34;Access-Control-Allow-Methods\u0026#34;,\u0026#34;PUT,POST,GET,DELETE,OPTIONS\u0026#34;); res.header(\u0026#34;X-Powered-By\u0026#34;,\u0026#39; 3.2.1\u0026#39;) if(req.method==\u0026#34;OPTIONS\u0026#34;) { res.send(200);/*让options请求快速返回*/ } else{ next(); } }); 中间件 express 的中间件编写——过滤器\n简单使用\nconst express = require(\u0026#39;express\u0026#39;) const app = express(); let filter = (req, res, next) =\u0026gt; { if(req.params.name == \u0026#39;admin\u0026#39; \u0026amp;\u0026amp; req.params.pwd == \u0026#39;admin\u0026#39;){ next() } else { next(\u0026#39;用户名密码不正确\u0026#39;) } } app.get(\u0026#39;/:name/:pwd\u0026#39;, filter, (req, res) =\u0026gt; { res.send(\u0026#39;ok\u0026#39;) }).listen(88) 这里写了一个 filter 方法，有一个 next 参数。在路由的时候，把 filter 作为一个参数，则就可以先执行 filter 函数，然后执行路由的逻辑。\n如果想要全局使用的话，就直接使用 use 方法即可。\napp.use(filter); 文件上传 前面说到的 body-parser 不支持文件上传，那么使用 multer 则可以实现。\n操作数据库 node 一般会使用 mongo 和 mysql，使用下面这个例子即可：\n操作 MongoDB 官方 api http://mongodb.github.io/node-mongodb-native/\nvar mongodb = require(\u0026#39;mongodb\u0026#39;); var MongoClient = mongodb.MongoClient; var db; MongoClient.connect(\u0026#34;mongodb://localhost:27017/test1705candel\u0026#34;, function(err, database) { if(err) throw err; db = database; }); module.exports = { insert: function(_collection, _data, _callback){ var i = db.collection(_collection).insert(_data).then(function(result){ _callback(result); }); }, select: function(_collection, _condition, _callback){ var i = db.collection(_collection).find(_condition || {}).toArray(function(error, dataset){ _callback({status: true, data: dataset}); }) } } 操作 MySql var mysql = require(\u0026#39;mysql\u0026#39;); //创建连接池 var pool = mysql.createPool({ host : \u0026#39;localhost\u0026#39;, user : \u0026#39;root\u0026#39;, password : \u0026#39;root\u0026#39;, port: 3306, database: \u0026#39;1000phone\u0026#39;, multipleStatements: true }); module.exports = { select: function(tsql, callback){ pool.query(tsql, function(error, rows){ if(rows.length \u0026gt; 1){ callback({rowsCount: rows[1][0][\u0026#39;rowsCount\u0026#39;], data: rows[0]}); } else { callback(rows); } }) } } session Session 是一种记录客户状态的机制，不同的是 Cookie 保存在客户端浏览器中，而 Session 保存在服务器上的进程中。\n客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上，这就是 Session。客户端浏览器再次访问时只需要从该 Session 中查找该客户的状态就可以了。\n如果说 Cookie 机制是通过检查客户身上的“通行证”来确定客户身份的话，那么 Session 机制就是通过检查服务器上的“客户明细表”来确认客户身份。\nSession 相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表就可以了。\nSession 不能跨域。\nnode 操作 session 和 cookie 也很简单，也是通过中间件的形式。\nconst express = require(\u0026#39;express\u0026#39;) const path = require(\u0026#39;path\u0026#39;) const app = express(); const bodyParser = require(\u0026#39;body-parser\u0026#39;); const cp = require(\u0026#39;cookie-parser\u0026#39;); const session = require(\u0026#39;express-session\u0026#39;); app.use(cp()); app.use(session({ secret: \u0026#39;12345\u0026#39;,//用来对session数据进行加密的字符串.这个属性值为必须指定的属性 name: \u0026#39;testapp\u0026#39;, //这里的name值得是cookie的name，默认cookie的name是：connect.sid cookie: {maxAge: 5000 }, //设置maxAge是5000ms，即5s后session和相应的cookie失效过期 resave: false, saveUninitialized: true, })) app.use(bodyParser.urlencoded({extended: false})); app.use(express.static(path.join(__dirname, \u0026#39;/\u0026#39;))); app.get(\u0026#39;/setsession\u0026#39;, (request, response) =\u0026gt; { request.session.user = {username: \u0026#39;admin\u0026#39;}; response.send(\u0026#39;set session success\u0026#39;); }) app.get(\u0026#39;/getsession\u0026#39;, (request, response) =\u0026gt; { response.send(request.session.user); }) app.get(\u0026#39;/delsession\u0026#39;, (request, response) =\u0026gt; { delete reqeust.session.user; response.send(request.session.user); }) app.listen(88) Token Token 的特点\n 随机性 不可预测性 时效性 无状态、可扩展 跨域  基于 Token 的身份验证场景\n 客户端使用用户名和密码请求登录 服务端收到请求，验证登录是否成功 验证成功后，服务端会返回一个 Token 给客户端，反之，返回身份验证失败的信息 客户端收到 Token 后把 Token 用一种方式(cookie/localstorage/sessionstorage/其他)存储起来 客户端每次发起请求时都选哦将 Token 发给服务端 服务端收到请求后，验证 Token 的合法性，合法就返回客户端所需数据，反之，返回验证失败的信息  Token 身份验证实现 —— jsonwebtoken\n先安装第三方模块 jsonwebtoken npm install jsonwebtoken\nconst express = require(\u0026#39;express\u0026#39;) const path = require(\u0026#39;path\u0026#39;) const app = express(); const bodyParser = require(\u0026#39;body-parser\u0026#39;); const jwt = require(\u0026#39;jsonwebtoken\u0026#39;); app.use(bodyParser.urlencoded({extended: false})); app.use(express.static(path.join(__dirname, \u0026#39;/\u0026#39;))); app.all(\u0026#39;*\u0026#39;, function(req, res, next) { res.header(\u0026#34;Access-Control-Allow-Origin\u0026#34;, \u0026#34;*\u0026#34;); res.header(\u0026#34;Access-Control-Allow-Headers\u0026#34;, \u0026#34;Content-Type,Content-Length, Auth, Accept,X-Requested-With\u0026#34;); res.header(\u0026#34;Access-Control-Allow-Methods\u0026#34;,\u0026#34;PUT,POST,GET,DELETE,OPTIONS\u0026#34;); res.header(\u0026#34;X-Powered-By\u0026#34;,\u0026#39; 3.2.1\u0026#39;) if(req.method==\u0026#34;OPTIONS\u0026#34;) { res.sendStatus(200);/*让options请求快速返回*/ } else{ next(); } }); app.get(\u0026#39;/createtoken\u0026#39;, (request, response) =\u0026gt; { //要生成 token 的主题信息 let user = { username: \u0026#39;admin\u0026#39;, } //这是加密的 key（密钥） let secret = \u0026#39;dktoken\u0026#39;; //生成 Token let token = jwt.sign(user, secret, { \u0026#39;expiresIn\u0026#39;: 60*60*24 // 设置过期时间, 24 小时 }) response.send({status: true, token}); }) app.post(\u0026#39;/verifytoken\u0026#39;, (request, response) =\u0026gt; { //这是加密的 key（密钥），和生成 token 时的必须一样 let secret = \u0026#39;dktoken\u0026#39;; let token = request.headers[\u0026#39;auth\u0026#39;]; if(!token){ response.send({status: false, message: \u0026#39;token不能为空\u0026#39;}); } jwt.verify(token, secret, (error, result) =\u0026gt; { if(error){ response.send({status: false}); } else { response.send({status: true, data: result}); } }) }) app.listen(88) web socket HTTP 协议可以总结几个特点：\n 一次性的、无状态的短连接：客户端发起请求、服务端响应、结束。 被动性响应：只有当客户端请求时才被执行，给予响应，不能主动向客户端发起响应。 信息安全性：得在服务器添加 SSL 证书，访问时用 HTTPS。 跨域：服务器默认不支持跨域，可在服务端设置支持跨域的代码或对应的配置。  TCP 协议可以总结几个特点：\n 有状态的长连接：客户端发起连接请求，服务端响应并建立连接，连接会一直保持直到一方主动断开。 主动性：建立起与客户端的连接后，服务端可主动向客户端发起调用。 信息安全性：同样可以使用 SSL 证书进行信息加密，访问时用 WSS 。 跨域：默认支持跨域。  安装第三方模块 ws：npm install ws\n开启一个 WebSocket 的服务器，端口为 8080\nvar socketServer = require(\u0026#39;ws\u0026#39;).Server; var wss = new socketServer({ port: 8080 }); 也可以利用 Express 来开启 WebSocket 的服务器\nvar app = require(\u0026#39;express\u0026#39;)(); var server = require(\u0026#39;http\u0026#39;).Server(app); var socketServer = require(\u0026#39;ws\u0026#39;).Server; var wss = new socketServer({server: server, port: 8080});  用 on 来进行事件监听 connection：连接监听，当客户端连接到服务端时触发该事件 close：连接断开监听，当客户端断开与服务器的连接时触发 message：消息接受监听，当客户端向服务端发送信息时触发该事件 send: 向客户端推送信息  soket.io 可以理解为对 WebSocket 的一种封装。好比前端的 jQuery 对原生 javascript 的封装。 soket.io 依靠事件驱动的模式，灵活的使用了自定义事件和调用事件来完成更多的场景，不必依赖过多的原生事件。\n 安装第三方模块 npm install express socket.io 开户 Socket 服务器，端口为 88  var express = require(\u0026#39;express\u0026#39;); var app = express(); var http = require(\u0026#39;http\u0026#39;).Server(app); var io = require(\u0026#39;socket.io\u0026#39;)(http); http.listen(88);  用 on 来进行事件监听和定义事件 connection：监听客户端连接,回调函数会传递本次连接的 socket emit：触发用客户端的事件  io.on(\u0026#39;connection\u0026#39;, function(client){ //把当前登录的用户保存到对象 onlinePersons，并向所有在线的用户发起上线提示 //serverLogin 为自定义事件，供客户端调用 client.on(\u0026#39;serverLogin\u0026#39;, function(_person){ var _personObj = JSON.parse(_person); onlinePersons[_personObj.id] = _personObj; //向所有在线的用户发起上线提示 //触发客户端的 clientTips 事件 //clientTips 为客户端的自定义事件 io.emit(\u0026#39;clientTips\u0026#39;, JSON.stringify(onlinePersons)); }) //当监听到客户端有用户在移动，就向所有在线用户发起移动信息，触发客户端 clientMove 事件 //serverMove 为自定义事件，供客户端调用 client.on(\u0026#39;serverMove\u0026#39;, function(_person){ var _personObj = JSON.parse(_person); onlinePersons[_personObj.id] = _personObj; console.log(\u0026#39;serverLogin\u0026#39;, onlinePersons); //clientTips 为客户端的自定义事件 io.emit(\u0026#39;clientMove\u0026#39;, _person); }); }) kafka-node node 也可以去读写 kafka，而且很简单。只需要引入 kafka 的库即可。\nyarn add kafka-node 具体 api 可以看文档：https://github.com/SOHU-Co/kafka-node\n生产者\nvar kafka = require(\u0026#39;..\u0026#39;); var Producer = kafka.Producer; var KeyedMessage = kafka.KeyedMessage; var Client = kafka.Client; var client = new Client(\u0026#39;localhost:2181\u0026#39;); var argv = require(\u0026#39;optimist\u0026#39;).argv; var topic = argv.topic || \u0026#39;topic1\u0026#39;; var p = argv.p || 0; var a = argv.a || 0; var producer = new Producer(client, { requireAcks: 1 }); producer.on(\u0026#39;ready\u0026#39;, function () { var message = \u0026#39;a message\u0026#39;; var keyedMessage = new KeyedMessage(\u0026#39;keyed\u0026#39;, \u0026#39;a keyed message\u0026#39;); producer.send([ { topic: topic, partition: p, messages: [message, keyedMessage], attributes: a } ], function (err, result) { console.log(err || result); process.exit(); }); }); producer.on(\u0026#39;error\u0026#39;, function (err) { console.log(\u0026#39;error\u0026#39;, err); }); 消费者\n\u0026#39;use strict\u0026#39;; var kafka = require(\u0026#39;..\u0026#39;); var Consumer = kafka.Consumer; var Offset = kafka.Offset; var Client = kafka.Client; var argv = require(\u0026#39;optimist\u0026#39;).argv; var topic = argv.topic || \u0026#39;topic1\u0026#39;; var client = new Client(\u0026#39;localhost:2181\u0026#39;); var topics = [{ topic: topic, partition: 1 }, { topic: topic, partition: 0 }]; var options = { autoCommit: false, fetchMaxWaitMs: 1000, fetchMaxBytes: 1024 * 1024 }; var consumer = new Consumer(client, topics, options); var offset = new Offset(client); consumer.on(\u0026#39;message\u0026#39;, function (message) { console.log(message); }); consumer.on(\u0026#39;error\u0026#39;, function (err) { console.log(\u0026#39;error\u0026#39;, err); }); /* * If consumer get `offsetOutOfRange` event, fetch data from the smallest(oldest) offset */ consumer.on(\u0026#39;offsetOutOfRange\u0026#39;, function (topic) { topic.maxNum = 2; offset.fetch([topic], function (err, offsets) { if (err) { return console.error(err); } var min = Math.min.apply(null, offsets[topic.topic][topic.partition]); consumer.setOffset(topic.topic, topic.partition, min); }); }); Node 单元测试 以 function 为最小单位，验证特定情况下的 input 和 output 是否正确。\n 防止改 A 坏 B，避免不能跑的代码比能跑的还多。 明确指出问题所在、告知正确的行为是什么，减少 debug 的时间。  对于 node 来说，单元测试也很容易做。\n测试主要分为两种，TDD 和 BDD。\nTDD VS. BDD 比较 TDD 与 BDD 的差异。\n    TDD BDD     全名 测试驱动开发 Test-Driven Development 行为驱动开发 Behavior Driven Development   定义 在开发前先撰写测试程式，以确保程式码品质与符合验收规格。 TDD 的进化版。除了实作前先写测试外，还要写一份「可以执行的规格」。   特性 从测试去思考程式如何实作。强调小步前进、快速且持续回馈、拥抱变化、重视沟通、满足需求。 从用户的需求出发，强调系统行为。使用自然语言描述测试案例，以减少使用者和工程师的沟通成本。测试后的输出结果可以直接做为文件阅读。    从代码层面来看：\nTDD\nsuite(\u0026#39;Array\u0026#39;, ()=\u0026gt;{ setup(()={ }); test(\u0026#39;equal -1 when index beyond array length\u0026#39;, ()=\u0026gt;{ assert.equal(-1, [1,2,3].indexOf(4)); }); }) BDD\ndescribe(\u0026#39;Array\u0026#39;, function() { before(function() { }); it(\u0026#39;should return -1 when no such index\u0026#39;, function() { [1,2,3].indexOf(4).should.equal(-1); }); }); 对比了这两种类型的语法之后，我选择了 BDD。\n测试框架实践 在 node 社区，比较成熟的是 mocha。mocha 本身是不提供断言库的，一般来说断言库比较常用的是 chai。mocha 和 chai，合起来就被戏称为抹茶。\nmocha 一般需要全局安装，chai 安装到项目目录下即可。\nyarn global add mocha yarn add chai mocha 语法说明  describe()：描述场景或圈出特定区块，例如：标明测试的功能或 function。 it()：撰写测试案例（Test Case）。 before()：在所有测试开始前会执行的代码。 after()：在所有测试结束后会执行的代码。 beforeEach()：在每个 Test Case 开始前执行的代码。 afterEach()：在每个 Test Case 结束后执行的代码。  代码示例 describe(\u0026#39;hooks\u0026#39;, function() { before(function() { }); after(function() { }); beforeEach(function() { }); afterEach(function() { }); it(\u0026#39;should ...\u0026#39;, function() { }); }); chai assert assert(expression, message)：测试这个项目的 expression 是否为真，若为假则显示错误消息 message。\nExpect / Should 预期 3 等于（===）2。这是使用可串连的操作符 来完成断言。这些可串联的有 to、is、have 等。它很像英文，用很口语的方式做判断。\n覆盖率 既然是给功能代码写单元测试，那就应该有个指标去衡量单元测试覆盖了哪些功能代码，这就是接下来要介绍的测试覆盖率。\n在 Node.js 中，我们使用 istanbul 作为覆盖率统计的工具，istanbul 可以帮助我们统计到代码的语句覆盖率、分支覆盖率、函数覆盖率以及行覆盖率。\n全局安装：\nyarn global add istanbul 只需要使用 istanbul cover 就可以得到覆盖率。\nistanbul cover simple.js 可以和 mocha 配合使用：\nisbuntal cover _mocha test/simple-test.js mocha 和 _mocha 是两个不同的命令，前者会新建一个进程执行测试，而后者是在当前进程（即 istanbul 所在的进程）执行测试，只有这样， istanbul 才会捕捉到覆盖率数据。其他测试框架也是如此，必须在同一个进程执行测试。\n引入 typescript typescript 其实就是加了类型的 js。\n所谓类型，就是约定变量的内存布局。js 作为一个动态弱类型的语言，在开发大型项目的时候，不免可能出现问题，所以有类型的语言可以在编译期就能检测到错误，减少 debug 的时间。\n安装 yarn global add typescript 新项目引入 ts 现在新建文件server.ts：\nimport * as http from \u0026#39;http\u0026#39;; const server = http.createServer(function (req, res) { res.end(\u0026#39;Hello, world\u0026#39;); }); server.listen(3000, function () { console.log(\u0026#39;server is listening\u0026#39;); }); 为了能执行此文件，需要通过 tsc 命令来编译该 TypeScript 源码：\ntsc server.ts 如果没有什么意外的话，此时控制台会打印出以下的出错信息：\nserver.ts(1,23): error TS2307: Cannot find module \u0026#39;http\u0026#39;. 这表示没有找到http这个模块定义（TyprScript 编译时是通过查找模块的 typings 声明文件来判断模块是否存在的，而不是根据真实的 js 文件，下文会详细解释），但是我们当前目录下还是生成了一个新的文件server.js，我们可以试着执行它：\nnode server.js 如果一切顺利，那么控制台将会打印出 server is listening 这样的信息，并且我们在浏览器中访问 http://127.0.0.1:3000时也能看到正确的结果：Hello, world\n现在再回过头来看看刚才的编译错误信息。由于这是一个 Node.js 项目，typescript 语言中并没有定义http这个模块，所以我们需要安装 Node.js 运行环境的声明文件：\nyarn global add @types/node 安装完毕之后，再重复上文的编译过程，此时 tsc 不再报错了。\n大多数时候，为了方便我们可以直接使用 ts-node 命令执行 TypeScript 源文件而不需要预先编译。首先执行以下命令安装 ts-node：\nyarn global add -g ts-node 然后使用 ts-node 命令执行即可：\nts-node --no-cache server.ts 说明：使用 ts-node 执行 TypeScript 程序时，为了提高编译速度，默认会缓存未修改过的 .ts 文件，但有时候会导致一些 Bug，所以建议启动时加上 --no-cache 参数。\ntsconfig.json 配置文件 每个 TypeScript 项目都需要一个 tsconfig.json 文件来指定相关的配置，比如告诉 TypeScript 编译器要将代码转换成 ES5 还是 ES6 代码等。\n可以使用 tsc 命令生成。\ntsc --init 使用第三方模块 一般情况下在 TypeScript 中是不能”直接“使用 npm 上的模块的，比如我们要使用 express 模块，先执行以下命令安装：\nyarn add express 然后新建文件 server.ts :\nimport * as express from \u0026#39;express\u0026#39;; const app = express(); app.get(\u0026#39;/\u0026#39;, function (req, res) { res.end(\u0026#39;hello, world\u0026#39;); }) app.listen(3000, function () { console.log(\u0026#39;server is listening\u0026#39;); }); 然后使用以下命令执行：\nts-node server.ts 如果不出意外，我们将会看到这样的报错信息：\nsrc/server.ts(1,26): error TS7016: Could not find a declaration file for module \u0026#39;express\u0026#39;. 报错的信息表明没有找到express模块的声明文件。由于 TypeScript 项目最终会编译成 JavaScript 代码执行，当我们在 TypeScript 源码中引入这些被编译成 JavaScript 的模块时，它需要相应的声明文件（.d.ts文件）来知道该模块类型信息，这些声明文件可以通过设置tsconfig.json中的declaration: true来自动生成。而那些不是使用 TypeScript 编写的模块，也可以通过手动编写声明文件来兼容 TypeScript。\n当遇到缺少模块声明文件的情况，开发者可以尝试通过 yarn addl @types/xxx 来安装模块声明文件即可。\n现在我们尝试执行以下命令安装 express 模块的声明文件：\nyarn add @types/express 没有意外，果然能成功安装。现在再通过 ts-node 来执行的时候，发现已经没有报错了。\n单元测试 直接使用 mocha 和 chai，进行 ts 的测试。\n旧项目迁移 通常来说这个过程包括了以下步骤：\n 添加 tsconfig.json 将你的源代码文件扩展名从 .js 改成 .ts。使用 any 来开始抑止错误。 使用 TypeScript 来编写新的代码并且尽可能少地使用 any。 返回到旧代码里并且开始加入类型标注和解决发现的 bugs。 为第三方 JavaScript 代码使用环境定义。  ","permalink":"https://zhenfeng-zhu.github.io/posts/node-learning/","summary":"写 node 也有一段时间了，整理一下学习笔记，共同进步\n什么是 node 首先看一下什么是 node.js\n Node 是一个服务器端 JavaScript Node.js 是一个基于 Chrome V8 引擎的 JavaScript 运行环境 Node.js 使用了一个事件驱动、非阻塞式 I/O 的模型，使其轻量又高效 Node.js 的包管理器 npm，是全球最大的开源库生态系统  模块系统是 node 最基本也是最常用的。一般可以分为四类：\n 原生模块 文件模块 第三方模块 自定义模块  node 社区崇尚 DRY 文化，即 Don\u0026rsquo;t repeate yourself。这种文化使得 node 的生态异常繁荣，同样也由于某些包的质量低下引来了一些诟病。\n谈谈自定义模块 我们在写 node 程序的时候，一般都是在写自定义模块。\n  创建模块\n// b.js function FunA(){ return \u0026#34;hello world\u0026#34;; } // 暴露方法FunA module.exports = FunA;   加载模块\n// a.js const FunA=require(\u0026#39;.","title":"node 学习笔记"},{"content":"Node.js Redis 客户端模块 为了追新，这里我使用的 yarn，毕竟我是 HDD（面向热点编程）编程实践者。\n模块安装\nyarn add redis 模块使用实例\nconst redis = require(\u0026#39;redis\u0026#39;) const client = redis.createClient(\u0026#39;6379\u0026#39;, \u0026#39;127.0.0.1\u0026#39;) client.on(\u0026#34;error\u0026#34;, function (err) { console.log(\u0026#34;Error \u0026#34; + err); }); client.set(\u0026#34;string key\u0026#34;, \u0026#34;string val\u0026#34;, redis.print); client.hset(\u0026#34;hash key\u0026#34;, \u0026#34;hashtest 1\u0026#34;, \u0026#34;some value\u0026#34;, redis.print); client.hset([\u0026#34;hash key\u0026#34;, \u0026#34;hashtest 2\u0026#34;, \u0026#34;some other value\u0026#34;], redis.print); client.hkeys(\u0026#34;hash key\u0026#34;, function (err, replies) { console.log(replies.length + \u0026#34; replies:\u0026#34;); replies.forEach(function (reply, i) { console.log(\u0026#34; \u0026#34; + i + \u0026#34;: \u0026#34; + reply); }); client.quit(); }); 输出的结果如下所示：\n➜ node-example git:(master) ✗ node redis-demo.js Reply: OK Reply: 0 Reply: 0 2 replies: 0: hashtest 1 1: hashtest 2 Promises\n如果是使用 node 8 或者之上的话，使用 node 的 util.promisify 来将请求变成 promise 的。\nconst {promisify}=require(\u0026#39;util\u0026#39;) const redis = require(\u0026#39;redis\u0026#39;) const client = redis.createClient(\u0026#39;6379\u0026#39;, \u0026#39;127.0.0.1\u0026#39;) const getAsync=promisify(client.get).bind(client) function getFoo(){ return getAsync(\u0026#39;foo\u0026#39;).then(res =\u0026gt; { console.log(res) }) } getFoo() 发送命令\n每个 redis 命令都会通过 client 对象的一个函数暴露，所有这些函数都会有一个 args 数组选项和一个 callback 回调函数。\n字符串操作\nset key value\nget key\n哈希操作\nhmset key field1 value1\nhget key field1 value1\n列表操作\nlpush key value1 value2\nlrange key 0 n\n集合操作\nsadd key member1 member2\nsmembers key\n有序集合操作\nzadd key index value\nzrange key 0 n\n","permalink":"https://zhenfeng-zhu.github.io/posts/node%E7%9A%84redis%E5%AE%9E%E6%88%98/","summary":"Node.js Redis 客户端模块 为了追新，这里我使用的 yarn，毕竟我是 HDD（面向热点编程）编程实践者。\n模块安装\nyarn add redis 模块使用实例\nconst redis = require(\u0026#39;redis\u0026#39;) const client = redis.createClient(\u0026#39;6379\u0026#39;, \u0026#39;127.0.0.1\u0026#39;) client.on(\u0026#34;error\u0026#34;, function (err) { console.log(\u0026#34;Error \u0026#34; + err); }); client.set(\u0026#34;string key\u0026#34;, \u0026#34;string val\u0026#34;, redis.print); client.hset(\u0026#34;hash key\u0026#34;, \u0026#34;hashtest 1\u0026#34;, \u0026#34;some value\u0026#34;, redis.print); client.hset([\u0026#34;hash key\u0026#34;, \u0026#34;hashtest 2\u0026#34;, \u0026#34;some other value\u0026#34;], redis.print); client.hkeys(\u0026#34;hash key\u0026#34;, function (err, replies) { console.log(replies.length + \u0026#34; replies:\u0026#34;); replies.forEach(function (reply, i) { console.log(\u0026#34; \u0026#34; + i + \u0026#34;: \u0026#34; + reply); }); client.","title":"node 的 redis 实战"},{"content":"这篇文章打的标签比较多，也基本涵盖了我所了解的一些知识，归纳总结一下自己对 web 框架的理解。自己了解的也不是很多，也请多多指教。\n写程序免不了要做 web 相关的，现在由于前后端的分离，后端一般只提供 rest 接口，前端一般使用 node 来做渲染。在之前使用 jsp 那一套的时候，基本上都要写 html+js 的前端的一套，也要写后端 java 的 CRUD。\n我理解的 web 框架中，大致是分为这么两类：\n router 框架 mvc 框架  mvc 类框架 mvc，初级程序员面试笔试的时候必考的一个知识点。model-view-controller，即模型-视图-控制器。\n m，模型主要用于封装与应用程序相关的数据以及对数据的处理方法。 v，在 View 中一般没有程序上的逻辑。为了实现 View 上的刷新功能，View 需要访问它监视的数据模型（Model），因此应该事先在被它监视的数据那里注册。 c，用于控制应用程序的流程。  我了解比较多的 mvc 框架是 spring mvc。spring、spring mvc 和 spring boot 等，他们并不是一个概念，也不是仅仅用于 web 开发。但是在这里我就不分那么细，统一用 spring 来代替。这里所说的 spring 都是指狭义上的 web 开发方面。\n在做 web 开发的时候，项目目录一般是这样的：\n$ tree [16:23:43] . ├── mvnw ├── mvnw.cmd ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── example │ │ └── demo │ │ └── DemoApplication.java │ └── resources │ ├── application.properties │ ├── static │ └── templates └── test └── java └── com └── example └── demo └── DemoApplicationTests.java 14 directories, 6 files 要渲染页面的时候，会把相关的类写在 controller 包下面，然后使用@Controlle 注解表示这是一个 controller。\n如果是实体类，一般会放在 entity 包或者 domain 包中。\n对数据库进行操作的类，一般会放在 repository 或者 dao 中。\ncontroller 一般不直接使用 dao，而是会单独写一个 service 负责去做一些其他的事情。\n每个包分工明确。\n而 url 的路由拦截处理是在 controller 了中去实现的。\nrouter 框架 我理解的 router 框架主要是以 express 为代表的框架。现在的轻量级的 web 框架会有路由这么一个重要的概念。\n路由用于确定应用程序如何响应对特定端点的客户机请求，包含一个 URI（或路径）和一个特定的 HTTP 请求方法（GET、POST 等）。\n每个路由可以具有一个或多个处理程序函数，这些函数在路由匹配时执行。\n路由一般采用如下的结构：\nrouter.METHOD(PATH, HANDLER) 其中：\n router 是路由实例。 METHOD 是 http 的请求方法，如 GET，POST 等。 PATH 是 URL 请求路径。 HANDLER 是一个回调函数，在路由匹配成功时执行的。  可以发现，在 router 类框架中，handler 是一个很常用的，这是一种编程的模式——行为参数化。\njava 的 vertx 和 go 的 gin 框架也是这样一种思路。\n下面这个示例是 gin 的：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { router:=gin.Default() router.GET(\u0026#34;/hello\u0026#34;, greeting) // 也可以写成匿名函数 router.GET(\u0026#34;/\u0026#34;, func(context *gin.Context) { context.String(http.StatusOK, \u0026#34;I am Lucas\u0026#34;) }) router.Run() } // 可以单独写一个handler函数 func greeting(context *gin.Context) { context.String(http.StatusOK, \u0026#34;hello world\u0026#34;) } 可以看到 router 类的框架特别轻量级，而且很适合写 rest api 接口。\nrouter 的原理 一般情况下，router 使用的数据结构是 radix tree，压缩字典树。\n字典树是一个比较常用的数据结构，下图是一个典型的字典树结构：\n字典树一般用来进行字符串的检索。对于目标字符串，只要从根节点开始深度优先搜索，即可判断出该字符串是否曾经出现过，时间复杂度为 O(n)，n 可以认为是目标字符串的长度。为什么要这样做？字符串本身不像数值类型可以进行数值比较，两个字符串对比的时间复杂度取决于字符串长度。如果不用字典树来完成上述功能，要对历史字符串进行排序，再利用二分查找之类的算法去搜索，时间复杂度只高不低。可认为字典树是一种空间换时间的典型做法。\n普通的字典树有一个比较明显的缺点，就是每个字母都需要建立一个孩子节点，这样会导致字典树的层树比较深，压缩字典树相对好地平衡了字典树的优点和缺点。下图是典型的压缩字典树结构：\n每个节点上不只存储一个字母了，这也是压缩字典树中“压缩”的主要含义。使用压缩字典树可以减少树的层数，同时因为每个节点上数据存储也比通常的字典树要多，所以程序的局部性较好(一个节点的 path 加载到 cache 即可进行多个字符的对比)，从而对 CPU 缓存友好。\n中间件 对于大多数的场景来讲，非业务的需求都是在 http 请求处理前做一些事情，或者/并且在响应完成之后做一些事情。我们有没有办法使用一些重构思路把这些公共的非业务功能代码剥离出去呢？\n这个时候就是就引入了中间件的概念。\n中间件函数能够访问请求对象 (req)、响应对象 (res) 以及应用程序的请求/响应循环中的下一个中间件函数。\n中间件函数可以执行以下任务：\n 执行任何代码。 对请求和响应对象进行更改。 结束请求/响应循环。 调用堆栈中的下一个中间件。  这些中间件其实就是一些可插拔的函数组件，对请求和响应的对象进行封装处理。\n哪些事情适合在中间件中做 以较流行的开源 go 框架 chi 为例：\ncompress.go =\u0026gt; 对 http 的 response body 进行压缩处理 heartbeat.go =\u0026gt; 设置一个特殊的路由，例如 /ping，/healthcheck，用来给 load balancer 一类的前置服务进行探活 logger.go =\u0026gt; 打印 request 处理日志，例如请求处理时间，请求路由 profiler.go =\u0026gt; 挂载 pprof 需要的路由，如 /pprof、/pprof/trace 到系统中 realip.go =\u0026gt; 从请求头中读取 X-Forwarded-For 和 X-Real-IP，将 http.Request 中的 RemoteAddr 修改为得到的 RealIP requestid.go =\u0026gt; 为本次请求生成单独的 requestid，可一路透传，用来生成分布式调用链路，也可用于在日志中串连单次请求的所有逻辑 timeout.go =\u0026gt; 用 context.Timeout 设置超时时间，并将其通过 http.Request 一路透传下去 throttler.go =\u0026gt; 通过定长大小的 channel 存储 token，并通过这些 token 对接口进行限流 我们可以发现，一些通用的非业务场景的都可以用中间件来包裹。\nspring 有 AOP 这个大杀器，它采用动态代理的方式也可以实现中间件的行为。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E8%B0%88%E8%B0%88web%E6%A1%86%E6%9E%B6/","summary":"这篇文章打的标签比较多，也基本涵盖了我所了解的一些知识，归纳总结一下自己对 web 框架的理解。自己了解的也不是很多，也请多多指教。\n写程序免不了要做 web 相关的，现在由于前后端的分离，后端一般只提供 rest 接口，前端一般使用 node 来做渲染。在之前使用 jsp 那一套的时候，基本上都要写 html+js 的前端的一套，也要写后端 java 的 CRUD。\n我理解的 web 框架中，大致是分为这么两类：\n router 框架 mvc 框架  mvc 类框架 mvc，初级程序员面试笔试的时候必考的一个知识点。model-view-controller，即模型-视图-控制器。\n m，模型主要用于封装与应用程序相关的数据以及对数据的处理方法。 v，在 View 中一般没有程序上的逻辑。为了实现 View 上的刷新功能，View 需要访问它监视的数据模型（Model），因此应该事先在被它监视的数据那里注册。 c，用于控制应用程序的流程。  我了解比较多的 mvc 框架是 spring mvc。spring、spring mvc 和 spring boot 等，他们并不是一个概念，也不是仅仅用于 web 开发。但是在这里我就不分那么细，统一用 spring 来代替。这里所说的 spring 都是指狭义上的 web 开发方面。\n在做 web 开发的时候，项目目录一般是这样的：\n$ tree [16:23:43] . ├── mvnw ├── mvnw.cmd ├── pom.xml └── src ├── main │ ├── java │ │ └── com │ │ └── example │ │ └── demo │ │ └── DemoApplication.","title":"谈谈 web 框架"},{"content":"创业公司真的比较锻炼人，接触了很多的东西，视野开阔了，但是在某些时候自己疲于奔命，每个东西都是接触了一点点就被赶鸭子上架开始开发了。\n技术栈  Docker  docker 是一个容器，以前就看过 docker 相关的东西，但是没有仔细研究，docker 的命令会用一些，在工作中使用了，看了一本 docker 的书，能够编写 docker 的 compose 文件。\n rancher  rancher 是一个做容器管理的。我们把主机添加到 rancher 中，他就可以自动做到 LB，服务的发现编排。我们部署的时候只需要编写 catalog，他就可以自动发现 docker 应用，然后拉取镜像，部署到相关的机器上，很是方便。\n aws  近期主要是对 aws 的进行公司服务的部署，搭建一套 rancher 的环境。aws 的服务特别多，ec2 是实例主机，就和虚拟机一样，VPC 就像机房，ec2 依托于 VPC 而存在，在这基础上又了解了子网、DHCP 弹性 IP 等等。\n kotlin  之前自己用 kotlin 开发过一个博客，对 kotlin 的感觉是有些东西写的很爽，但是还是觉得 java 好用一些，对 kotlin 的态度是用不用都无所谓。\n guice  这个我之前都读错了，我读成了盖斯，其实是和果汁的英文发音很像，ju 斯。只是一个依赖注入框架，只是单纯的去做 DI，比 spring 更轻量级一些。\n需要我们编写 AppModule.java 去手动配置哪个类注入哪个类。\n rxjava  rxjava 我都没有找到一个系统的教程，不知道该从哪里学习。\n vertx  vertx+Reactive 编程的方式相当考验心智，自己脑子中的编程方式还没转过来。\n ES6  node 代码中都是用 es6 来写的，async 和 await 现在也会用了。\n express  想到自己大学的时候看过 node 的书，里面讲的就是 express，只是自己当时没想明白，现在看的回调多了，算是熟悉了他这种的编程模式，所以觉得 express 特别简单易上手。\n typescript  还没它去写东西，可能下周会用它来写个机器人。\n貌似自己已经完全抛弃了 spring+java 的那一套东西，没机会用到。\n知识面扩展  监控  grafana+Prometheus+graylog 去做可视化和日志的监控。\n对于业务的数据，需要在代码层面进行埋点，把要监控的数据传给普罗米修斯。\n FSM 状态机  机器人的框架使用的是 FSM 状态机来管理，以前做游戏的时候接触过。\n 网关  网关现在已经是微服务架构中的标配了，用它来做一些限流，LB 和日志收集等等。\n我们使用的是 kong，在这里 kong 加上一些插件，相当好用。\n 规则引擎  在规则引擎中，都是一个个规则。\n DSL  领域特定语言，在规则引擎和机器人的时候，就用了 DSL。我现在的理解就是 DSL 就是用编程语言实现的一些函数。\n Key Transparency  谷歌的一个公钥管理库，保证了无法被篡改。\n未来可能要接触  go  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E6%8A%80%E6%9C%AF%E6%A0%88/","summary":"创业公司真的比较锻炼人，接触了很多的东西，视野开阔了，但是在某些时候自己疲于奔命，每个东西都是接触了一点点就被赶鸭子上架开始开发了。\n技术栈  Docker  docker 是一个容器，以前就看过 docker 相关的东西，但是没有仔细研究，docker 的命令会用一些，在工作中使用了，看了一本 docker 的书，能够编写 docker 的 compose 文件。\n rancher  rancher 是一个做容器管理的。我们把主机添加到 rancher 中，他就可以自动做到 LB，服务的发现编排。我们部署的时候只需要编写 catalog，他就可以自动发现 docker 应用，然后拉取镜像，部署到相关的机器上，很是方便。\n aws  近期主要是对 aws 的进行公司服务的部署，搭建一套 rancher 的环境。aws 的服务特别多，ec2 是实例主机，就和虚拟机一样，VPC 就像机房，ec2 依托于 VPC 而存在，在这基础上又了解了子网、DHCP 弹性 IP 等等。\n kotlin  之前自己用 kotlin 开发过一个博客，对 kotlin 的感觉是有些东西写的很爽，但是还是觉得 java 好用一些，对 kotlin 的态度是用不用都无所谓。\n guice  这个我之前都读错了，我读成了盖斯，其实是和果汁的英文发音很像，ju 斯。只是一个依赖注入框架，只是单纯的去做 DI，比 spring 更轻量级一些。\n需要我们编写 AppModule.java 去手动配置哪个类注入哪个类。\n rxjava  rxjava 我都没有找到一个系统的教程，不知道该从哪里学习。","title":"技术栈"},{"content":"具体方法 Configuring a remote for a fork  给 fork 配置一个 remote 主要使用 git remote -v 查看远程状态。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)  添加一个将被同步给 fork 远程的上游仓库  git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git  再次查看状态确认是否配置成功。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push) Syncing a fork  从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master git fetch upstream  git fetch upstream # remote: Counting objects: 75, done. # remote: Compressing objects: 100% (53/53), done. # remote: Total 62 (delta 27), reused 44 (delta 9) # Unpacking objects: 100% (62/62), done. # From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY # * [new branch] master -\u0026gt; upstream/master  切换到本地主分支(如果不在的话) git checkout master  git checkout master # Switched to branch \u0026#39;master\u0026#39;  把 upstream/master 分支合并到本地 master 上，这样就完成了同步，并且不会丢掉本地修改的内容。 git merge upstream/master  git merge upstream/master # Updating a422352..5fdff0f # Fast-forward # README | 9 ------- # README.md | 7 ++++++ # 2 files changed, 7 insertions(+), 9 deletions(-) # delete mode 100644 README # create mode 100644 README.md  如果想更新到 GitHub 的 fork 上，直接 git push origin master 就好了。  ","permalink":"https://zhenfeng-zhu.github.io/posts/%E5%90%8C%E6%AD%A5%E4%B8%80%E4%B8%AA-fork/","summary":"具体方法 Configuring a remote for a fork  给 fork 配置一个 remote 主要使用 git remote -v 查看远程状态。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push)  添加一个将被同步给 fork 远程的上游仓库  git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git  再次查看状态确认是否配置成功。  git remote -v # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (fetch) # origin https://github.com/YOUR_USERNAME/YOUR_FORK.git (push) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (fetch) # upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git (push) Syncing a fork  从上游仓库 fetch 分支和提交点，传送到本地，并会被存储在一个本地分支 upstream/master git fetch upstream  git fetch upstream # remote: Counting objects: 75, done.","title":"同步一个 fork"},{"content":"最近公司要统一技术栈，在 kotlin 和 go 之间选。我心里是比较倾向 go 的，主要有如下几点体会。\n 语言简单，上手快。 gorotuine 易发布 垃圾回收 约定大于配置  我最早听说协程，是在大三找实习的时候，那个时候面试会问线程和进程的关系，问的深一些就是协程和线程的区别。游戏公司基本都用 lua，看了 lua 的资料后，对协程有了一些自己的了解，随后就是在做 Unity 相关的开发，在 unity 中使用了很多的协程，但是在 unity 中使用的协程好像跟主流的不太一样，在看了 go 之后，豁然开朗。\ngoroutine 使用的内存比线程更少，go 在运行的时候会自动在配置的一组逻辑处理器上调度执行。比如：\nfunc log(msg string){ ... } go log(\u0026#34;\u0026#34;) 使用关键字 go，即可让 log 函数在一个 goroutine 里执行了。\n并发最难的部分是要确保其他并发运行的进程、线程或者 goroutine 不会以外的修改数据。go 使用了 Channel 的方式来解决这个问题。对于通道模式，保证同一时刻只会有一个 goroutine 修改数据。\n说起 go 的语言简单，其实主要是他的类型比较简单。go 使用的是组合模式，只需要将一个类型嵌入到另外一个类型就可以复用所有的功能。而且 go 还具有独特的接口实现机制，允许用户对行为进行建模，在 go 中不需要声明某个类型实现了某个接口，编译器会自动判断一个实例是使用什么接口。\n对于 java 来说，所有的设计都是围绕着接口展开，于是在设计模式中，就是面向接口编程：\ninterface User{ void login(); void logout(); } 在 java 中，继承的类必须显式声明继承了此接口。而在 go 中接口只是描述一个动作，如果说是实现这个接口，只需要让某个实例实现了这个接口中的所有方法就行了。\ntype Reader interface{ Read(p []byte))(n int, err error) } 这其实和传统的 oop 语言的接口有着本质的区别，go 中的接口一般只定义一个单一的动作，实际使用的过程中，这更有利于使用组合来复用代码。\n约定大于配置这点，go 在这方面上做的感觉有点儿吹毛求疵了，但是这样也使得程序可读性更强，没有很多垃圾代码。比如 go 的文件结构必须是 src pkg 和 bin 三个包，而且 go 也不允许你声明一个变量却不使用，导入了一个包却不使用，而且程序的代码也有约定，init 方法比 main 方法更早执行。\ngo 的并发 说到并发，就会想到另外一个概念，并行。可以简单这样的理解：\n并发是同时管理多个事情，而并行是同时做很多事情。也就是并发是manage，并行是run。 对于单核处理器来讲，同一时刻只能有一个任务在执行，那么并发就是同时管理多个任务，让他们交替执行。并行是针对于多核处理器的，同一时刻可以把多个任务放在不同的处理器上执行，这样就可以同时执行。\n在 go 里面主要是采用协程来实现并发的，也就是 goroutine。与其他语言不同的是，go 是在语法层面做到的，即 go func();\n语法 go f(x, y) go 是关键字，后面跟函数。\n例子 package main import ( \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func doSomething(id int) { log.Printf(\u0026#34;before do job:(%d) \\n\u0026#34;, id) time.Sleep(3 * time.Second) log.Printf(\u0026#34;after do job:(%d) \\n\u0026#34;, id) } func main() { doSomething(1) doSomething(2) doSomething(3) } 这个例子的输出是：\n2018/04/15 17:06:05 before do job:(1) 2018/04/15 17:06:08 after do job:(1) 2018/04/15 17:06:08 before do job:(2) 2018/04/15 17:06:11 after do job:(2) 2018/04/15 17:06:11 before do job:(3) 2018/04/15 17:06:14 after do job:(3) 可以看到是用了 9 秒的时间才完成，如果是采用 goroutine 的话，就很快。很简单，就是在执行 doSomething 之前，加上 go 关键字。\nimport ( \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) func doSomething(id int) { log.Printf(\u0026#34;before do job:(%d) \\n\u0026#34;, id) time.Sleep(3 * time.Second) log.Printf(\u0026#34;after do job:(%d) \\n\u0026#34;, id) } func main() { go doSomething(1) go doSomething(2) go doSomething(3) } 但是这样的话，什么结果也没有，是因为 main 函数本身也是一个 goroutine，main 执行完之后，其他的还没开始，所以什么也看不到。最简单的办法就是让 main 函数等待一段时间再结束，但是这样不够优雅。\n我们应该采用 sync.WaitGroup 来等待所有的 goroutine 结束。\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func doSomething(id int, wg *sync.WaitGroup) { defer wg.Done() log.Printf(\u0026#34;before do job:(%d) \\n\u0026#34;, id) time.Sleep(3 * time.Second) log.Printf(\u0026#34;after do job:(%d) \\n\u0026#34;, id) } func main() { var wg sync.WaitGroup wg.Add(3) // 因为我们要修改wg的状态，所以要传指针过去 go doSomething(1, \u0026amp;wg) go doSomething(2, \u0026amp;wg) go doSomething(3, \u0026amp;wg) wg.Wait() log.Printf(\u0026#34;finish all jobs\\n\u0026#34;) } 执行结果是：\n2018/04/15 17:13:14 before do job:(3) 2018/04/15 17:13:14 before do job:(2) 2018/04/15 17:13:14 before do job:(1) 2018/04/15 17:13:17 after do job:(2) 2018/04/15 17:13:17 after do job:(1) 2018/04/15 17:13:17 after do job:(3) 可以看到这次只用了 3 秒左右就执行完了，而且他们的执行顺序也不确定，竞争执行。\nchannel 每个协程之间要进行通信，那么在通信的时候采用的是 Channel 的形式，即一个 goroutine 将数据传递给 Channel，另一个 goroutine 从 Channel 中读取数据。\n创建 Channel 有两种方式：\n使用内建函数 make 可以创建 channel，举例如下：\nch := make(chan int) // 注意： channel 必须定义其传递的数据类型 也可以用 var 声明 channel, 如下：\nvar ch chan int 以上声明的 channel 都是双向的，意味着可以该 channel 可以发送数据，也可以接收数据。\n","permalink":"https://zhenfeng-zhu.github.io/posts/go%E8%AF%AD%E8%A8%80%E4%BD%93%E4%BC%9A/","summary":"最近公司要统一技术栈，在 kotlin 和 go 之间选。我心里是比较倾向 go 的，主要有如下几点体会。\n 语言简单，上手快。 gorotuine 易发布 垃圾回收 约定大于配置  我最早听说协程，是在大三找实习的时候，那个时候面试会问线程和进程的关系，问的深一些就是协程和线程的区别。游戏公司基本都用 lua，看了 lua 的资料后，对协程有了一些自己的了解，随后就是在做 Unity 相关的开发，在 unity 中使用了很多的协程，但是在 unity 中使用的协程好像跟主流的不太一样，在看了 go 之后，豁然开朗。\ngoroutine 使用的内存比线程更少，go 在运行的时候会自动在配置的一组逻辑处理器上调度执行。比如：\nfunc log(msg string){ ... } go log(\u0026#34;\u0026#34;) 使用关键字 go，即可让 log 函数在一个 goroutine 里执行了。\n并发最难的部分是要确保其他并发运行的进程、线程或者 goroutine 不会以外的修改数据。go 使用了 Channel 的方式来解决这个问题。对于通道模式，保证同一时刻只会有一个 goroutine 修改数据。\n说起 go 的语言简单，其实主要是他的类型比较简单。go 使用的是组合模式，只需要将一个类型嵌入到另外一个类型就可以复用所有的功能。而且 go 还具有独特的接口实现机制，允许用户对行为进行建模，在 go 中不需要声明某个类型实现了某个接口，编译器会自动判断一个实例是使用什么接口。\n对于 java 来说，所有的设计都是围绕着接口展开，于是在设计模式中，就是面向接口编程：\ninterface User{ void login(); void logout(); } 在 java 中，继承的类必须显式声明继承了此接口。而在 go 中接口只是描述一个动作，如果说是实现这个接口，只需要让某个实例实现了这个接口中的所有方法就行了。","title":"Go 语言体会"},{"content":"主动管理时间，敢于说不。\n有目标向前看，没目标向钱看。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E5%85%B3%E4%BA%8E%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86/","summary":"主动管理时间，敢于说不。\n有目标向前看，没目标向钱看。","title":"关于时间管理"},{"content":"当我们在做数据库分库分表或者做分布式缓存的时候，不可避免的都会遇到一个问题：\n如何将数据均匀的分散到各个节点中，并且尽量的在加减节点的时能使受影响的数据最少。\n1 hash 取模 随机放置就不多说了。通常最容易想到的方案是哈希取模了。\n可以将传入的 key 按照 $$ index=hash(key) % N $$ 这样来计算出需要存放的节点。\n这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性比较差。比如增加或者删除一个节点的时候，所有的 key 都要重新计算，显然这样的成本比较高，为此需要一个算法来满足均匀的同时也要有良好的容错性和扩展性。\n2 一致性 hash 算法 一致性 hash 算法是将所有的哈希值构成了一个环，其范围是 0~2^32-1。如图：\n之后将各个服务器节点散列到这个环上，可以用节点的 IP，hostname 这样唯一性的字段作为 key 进行 hash。散列之后如下：\n之后需要将数据定位到对应的节点上，使用同样的 hash 函数将 key 也映射到这个环上。\n这样就按照顺时针方向就可以将 k1 定位到 N1 节点，k2 定位到 N3 节点，k3 定位到 N2 节点。\n2.1 容错性 假设 N1 宕机了：\n依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少部分数据。\n2.2 扩展性 当新增一个节点时：\n在 N2 和 N3 之间新增了一个节点 N4，这时受影响的数据只有 k3，其余的数据也是保持不变。\n2.3 虚拟节点 到目前为止，该算法也有一些问题：\n当节点较少的时候可能出现数据不均匀的情况：\n这样会导致大部分数据都在 N1 节点，只有少量的数据在 N2 节点。\n为了解决这个问题，一致性哈希算法引入了虚拟节点。\n将每一个节点进行多次哈希，生成的节点放置在环上成为虚拟节点。\n计算时可以在 IP 后加上编号来生成哈希值。\n这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。\n3 参考 https://crossoverjie.top/2018/01/08/Consistent-Hash/#more\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95/","summary":"当我们在做数据库分库分表或者做分布式缓存的时候，不可避免的都会遇到一个问题：\n如何将数据均匀的分散到各个节点中，并且尽量的在加减节点的时能使受影响的数据最少。\n1 hash 取模 随机放置就不多说了。通常最容易想到的方案是哈希取模了。\n可以将传入的 key 按照 $$ index=hash(key) % N $$ 这样来计算出需要存放的节点。\n这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性比较差。比如增加或者删除一个节点的时候，所有的 key 都要重新计算，显然这样的成本比较高，为此需要一个算法来满足均匀的同时也要有良好的容错性和扩展性。\n2 一致性 hash 算法 一致性 hash 算法是将所有的哈希值构成了一个环，其范围是 0~2^32-1。如图：\n之后将各个服务器节点散列到这个环上，可以用节点的 IP，hostname 这样唯一性的字段作为 key 进行 hash。散列之后如下：\n之后需要将数据定位到对应的节点上，使用同样的 hash 函数将 key 也映射到这个环上。\n这样就按照顺时针方向就可以将 k1 定位到 N1 节点，k2 定位到 N3 节点，k3 定位到 N2 节点。\n2.1 容错性 假设 N1 宕机了：\n依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少部分数据。\n2.2 扩展性 当新增一个节点时：\n在 N2 和 N3 之间新增了一个节点 N4，这时受影响的数据只有 k3，其余的数据也是保持不变。","title":"一致性哈希算法"},{"content":"Spring Boot 启动原理分析 我们在开发 spring boot 应用的时候，一般会遇到如下的启动类：\n@SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 从这段代码可以看出，注解@SpringBootApplication 和 SpringApplication.run()是比较重要的两个东西。\n1 @SpringApplication 注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ... } 在这段代码里，比较重要的只有三个注解：\n @Configuration（@SpringBootConfiguration 点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan  其实，我们使用这三个注解来修饰 springboot 的启动类也可以正常运行,如下所示：\n@ComponentScan @EnableAutoConfiguration @Configuration public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 每次写这三个注解的话，比较繁琐，所以就 spring 团队就封装了一个@SpringBootApplication。\n1.1 @Configuration @Configuration 就是 JavaConfig 形式的 Spring Ioc 容器的配置类使用的那个@Configuration，SpringBoot 社区推荐使用基于 JavaConfig 的配置形式，所以，这里的启动类标注了@Configuration 之后，本身其实也是一个 IoC 容器的配置类。\nXML 跟 config 配置方式的区别可以从如下几个方面来说：\n  表达形式层面 基于 xml 的配置方式是这样的：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\u0026#34; default-lazy-init=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!--bean定义--\u0026gt; \u0026lt;/beans\u0026gt; 基于 java config 配置方式是这样的：\n@Configuration public class MockConfiguration{ //bean定义 }   注册 bean 定义层面 基于 XML 的配置形式是这样：\n\u0026lt;bean id=\u0026#34;mockService\u0026#34; class=\u0026#34;..MockServiceImpl\u0026#34;\u0026gt; ... \u0026lt;/bean\u0026gt; 而基于 Java config 的配置形式是这样的：\n@Configuration public class MockConfiguration{ @Bean public MockService mockService(){ return new MockServiceImpl(); } } 任何一个标注了@Bean 的方法，其返回值将作为一个 bean 定义注册到 Spring 的 IoC 容器，方法名将默认成该 bean 定义的 id。\n  表达依赖注入关系层面 为了表达 bean 与 bean 之间的依赖关系，在 XML 形式中一般是这样：\n\u0026lt;bean id=\u0026#34;mockService\u0026#34; class=\u0026#34;..MockServiceImpl\u0026#34;\u0026gt; \u0026lt;propery name =\u0026#34;dependencyService\u0026#34; ref=\u0026#34;dependencyService\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;dependencyService\u0026#34; class=\u0026#34;DependencyServiceImpl\u0026#34;\u0026gt;\u0026lt;/bean\u0026gt; 而基于 Java config 的配置形式是这样的：\n@Configuration public class MockConfiguration{ @Bean public MockService mockService(){ return new MockServiceImpl(dependencyService()); } @Bean public DependencyService dependencyService(){ return new DependencyServiceImpl(); } } 如果一个 bean 的定义依赖其他 bean,则直接调用对应的 JavaConfig 类中依赖 bean 的创建方法就可以了。\n  1.2 @ComponentScan @ComponentScan 的功能其实就是自动扫描并加载符合条件的组件（比如@Component 和@Repository 等）或者 bean 定义，最终将这些 bean 定义加载到 IoC 容器中。\n我们可以通过 basePackages 等属性来细粒度的定制@ComponentScan 自动扫描的范围，如果不指定，则默认 Spring 框架实现会从声明@ComponentScan 所在类的 package 进行扫描。\n所以 SpringBoot 的启动类最好是放在 root package 下，因为默认不指定 basePackages。\n1.3 @EnableAutoConfiguration Spring 框架提供了各种名字为@Enable 开头的 Annotation 定义，比如@EnableScheduling、@EnableCaching、@EnableMBeanExport 等。@EnableAutoConfiguration 的理念和做事方式其实一脉相承，简单概括一下就是，借助@Import 的支持，收集和注册特定场景相关的 bean 定义。\n@EnableAutoConfiguration 也是借助@Import 的帮助，将所有符合自动配置条件的 bean 定义加载到 IoC 容器。\n@SuppressWarnings(\u0026#34;deprecation\u0026#34;) @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(EnableAutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration { ... } @EnableAutoConfiguration 作为一个复合 Annotation，\n其中，最关键的要属@Import(EnableAutoConfigurationImportSelector.class)，借助 EnableAutoConfigurationImportSelector，@EnableAutoConfiguration 借助于 SpringFactoriesLoader 的支持可以帮助 SpringBoot 应用将所有符合条件的@Configuration 配置都加载到当前 SpringBoot 创建并使用的 IoC 容器。SpringFactoriesLoader 的支持。\n1.4 SpringFactoriesLoader SpringFactoriesLoader 属于 Spring 框架私有的一种扩展方案，其主要功能就是从指定的配置文件META-INF/spring.factories加载配置。\npublic abstract class SpringFactoriesLoader { public static \u0026lt;T\u0026gt; List\u0026lt;T\u0026gt; loadFactories(Class\u0026lt;T\u0026gt; factoryClass, ClassLoader classLoader) { ... } public static List\u0026lt;String\u0026gt; loadFactoryNames(Class\u0026lt;?\u0026gt; factoryClass, ClassLoader classLoader){ .... } } 配合@EnableAutoConfiguration 使用的话，它更多是提供一种配置查找的功能支持，即根据@EnableAutoConfiguration 的完整类名 org.springframework.boot.autoconfigure.EnableAutoConfiguration 作为查找的 Key,获取对应的一组@Configuration 类。\n@EnableAutoConfiguration 自动配置流程就是：\n 从 classpath 中搜寻所有的 META-INF/spring.factories 配置文件； 并将其中 org.springframework.boot.autoconfigure.EnableutoConfiguration 对应的配置项通过反射（Java Refletion）实例化为对应的标注了@Configuration 的 JavaConfig 形式的 IoC 容器配置类； 然后汇总为一个并加载到 IoC 容器。  2 SpringApplication SpringApplication 的 run 该方法的主要流程大体可以归纳如下：\n1） 如果我们使用的是 SpringApplication 的静态 run 方法，那么，这个方法里面首先要创建一个 SpringApplication 对象实例，然后调用这个创建好的 SpringApplication 的实例方法。在 SpringApplication 实例初始化的时候，它会提前做几件事情：\n 根据 classpath 里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为 Web 应用使用的 ApplicationContext 类型。 使用 SpringFactoriesLoader 在应用的 classpath 中查找并加载所有可用的 ApplicationContextInitializer。 使用 SpringFactoriesLoader 在应用的 classpath 中查找并加载所有可用的 ApplicationListener。 推断并设置 main 方法的定义类。  2） SpringApplication 实例初始化完成并且完成设置后，就开始执行 run 方法的逻辑了，方法执行伊始，首先遍历执行所有通过 SpringFactoriesLoader 可以查找到并加载的 SpringApplicationRunListener。调用它们的 started()方法，告诉这些 SpringApplicationRunListener，“嘿，SpringBoot 应用要开始执行咯！”。\n3） 创建并配置当前 Spring Boot 应用将要使用的 Environment（包括配置要使用的 PropertySource 以及 Profile）。\n4） 遍历调用所有 SpringApplicationRunListener 的 environmentPrepared()的方法，告诉他们：“当前 SpringBoot 应用使用的 Environment 准备好了咯！”。\n5） 如果 SpringApplication 的 showBanner 属性被设置为 true，则打印 banner。\n6） 根据用户是否明确设置了 applicationContextClass 类型以及初始化阶段的推断结果，决定该为当前 SpringBoot 应用创建什么类型的 ApplicationContext 并创建完成，然后根据条件决定是否添加 ShutdownHook，决定是否使用自定义的 BeanNameGenerator，决定是否使用自定义的 ResourceLoader，当然，最重要的，将之前准备好的 Environment 设置给创建好的 ApplicationContext 使用。\n7） ApplicationContext 创建好之后，SpringApplication 会再次借助 Spring-FactoriesLoader，查找并加载 classpath 中所有可用的 ApplicationContext-Initializer，然后遍历调用这些 ApplicationContextInitializer 的 initialize（applicationContext）方法来对已经创建好的 ApplicationContext 进行进一步的处理。\n8） 遍历调用所有 SpringApplicationRunListener 的 contextPrepared()方法。\n9） 最核心的一步，将之前通过@EnableAutoConfiguration 获取的所有配置以及其他形式的 IoC 容器配置加载到已经准备完毕的 ApplicationContext。\n10） 遍历调用所有 SpringApplicationRunListener 的 contextLoaded()方法。\n11） 调用 ApplicationContext 的 refresh()方法，完成 IoC 容器可用的最后一道工序。\n12） 查找当前 ApplicationContext 中是否注册有 CommandLineRunner，如果有，则遍历执行它们。\n13） 正常情况下，遍历执行 SpringApplicationRunListener 的 finished()方法、（如果整个过程出现异常，则依然调用所有 SpringApplicationRunListener 的 finished()方法，只不过这种情况下会将异常信息一并传入处理）\n去除事件通知点后，整个流程如下图所示：\n3 参考资料 Spring Boot 干货系列：（三）启动原理解析 SpringBoot 揭秘快速构建为服务体系\n","permalink":"https://zhenfeng-zhu.github.io/posts/spring-boot%E5%90%AF%E5%8A%A8%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90/","summary":"Spring Boot 启动原理分析 我们在开发 spring boot 应用的时候，一般会遇到如下的启动类：\n@SpringBootApplication public class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); } } 从这段代码可以看出，注解@SpringBootApplication 和 SpringApplication.run()是比较重要的两个东西。\n1 @SpringApplication 注解 @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ... } 在这段代码里，比较重要的只有三个注解：\n @Configuration（@SpringBootConfiguration 点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan  其实，我们使用这三个注解来修饰 springboot 的启动类也可以正常运行,如下所示：\n@ComponentScan @EnableAutoConfiguration @Configuration public class DemoApplication { public static void main(String[] args) { SpringApplication.","title":"Spring Boot 启动原理分析"},{"content":"为了解决抽象各个 Java 实体基本的“增删改查”操作，我们通常会以泛型的方式封装一个模板 Dao 来进行抽象简化，但是这样依然不是很方便，我们需要针对每个实体编写一个继承自泛型模板 Dao 的接口，再编写该接口的实现。虽然一些基础的数据访问已经可以得到很好的复用，但是在代码结构上针对每个实体都会有一堆 Dao 的接口和实现。\n由于模板 Dao 的实现，使得这些具体实体的 Dao 层已经变的非常“薄”，有一些具体实体的 Dao 实现可能完全就是对模板 Dao 的简单代理，并且往往这样的实现类可能会出现在很多实体上。Spring-data-jpa 的出现正可以让这样一个已经很“薄”的数据访问层变成只是一层接口的编写方式。\n1 工程配置 1.1 pom \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jpa-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;jpa-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.9.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 1.2 application.properties spring.datasource.url=jdbc:mysql://localhost:3306/test spring.datasource.username=root spring.datasource.password=root spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.jpa.properties.hibernate.hbm2ddl.auto=create-drop spring.jpa.properties.hibernate.hbm2ddl.auto是 hibernate 的配置属性，其主要作用是：自动创建、更新、验证数据库表结构。该参数的几种配置如下：\n create：每次加载 hibernate 时都会删除上一次的生成的表，然后根据你的 model 类再重新来生成新表，哪怕两次没有任何改变也要这样执行，这就是导致数据库表数据丢失的一个重要原因。 create-drop：每次加载 hibernate 时根据 model 类生成表，但是 sessionFactory 一关闭,表就自动删除。 update：最常用的属性，第一次加载 hibernate 时根据 model 类会自动建立起表的结构（前提是先建立好数据库），以后加载 hibernate 时根据 model 类自动更新表结构，即使表结构改变了但表中的行仍然存在不会删除以前的行。要注意的是当部署到服务器后，表结构是不会被马上建立起来的，是要等应用第一次运行起来后才会。 validate：每次加载 hibernate 时，验证创建数据库表结构，只会和数据库中的表进行比较，不会创建新表，但是会插入新值。  2 实体类 创建一个 User 实体，包含 id（主键）、name（姓名）、age（年龄）属性，通过 ORM 框架其会被映射到数据库表中，由于配置了hibernate.hbm2ddl.auto，在应用启动的时候框架会自动去数据库中创建对应的表。\n@Data @NoArgsConstructor @Entity public class Users { @Id @GeneratedValue private Long id; @Column(nullable = false) private String name; @Column(nullable = false) private Integer age; public Users(String name, Integer age) { this.name = name; this.age = age; } } 3 repository 针对 User 实体创建对应的Repository接口实现对该实体的数据访问：\n@Repository public interface UsersRepository extends JpaRepository\u0026lt;Users, Long\u0026gt; { Users findByName(String name); Users findByNameAndAge(String name, Integer age); @Query(\u0026#34;from Users u where u.name=:name\u0026#34;) Users findUser(@Param(\u0026#34;name\u0026#34;) String name); } 在 Spring-data-jpa 中，只需要编写类似上面这样的接口就可实现数据访问。不再像我们以往编写了接口时候还需要自己编写接口实现类，直接减少了我们的文件清单。\n下面对上面的UserRepository做一些解释，该接口继承自JpaRepository，通过查看JpaRepository接口的API 文档，可以看到该接口本身已经实现了创建（save）、更新（save）、删除（delete）、查询（findAll、findOne）等基本操作的函数，因此对于这些基础操作的数据访问就不需要开发者再自己定义。\n在上例中，我们可以看到下面两个函数：\n User findByName(String name) User findByNameAndAge(String name, Integer age)  它们分别实现了按 name 查询 User 实体和按 name 和 age 查询 User 实体，可以看到我们这里没有任何类 SQL 语句就完成了两个条件查询方法。这就是 Spring-data-jpa 的一大特性：通过解析方法名创建查询。\n除了通过解析方法名来创建查询外，它也提供通过使用@Query 注解来创建查询，您只需要编写 JPQL 语句，并通过类似“:name”来映射@Param 指定的参数，就像例子中的第三个 findUser 函数一样。\n4 单元测试 @RunWith(SpringRunner.class) @SpringBootTest public class JpaDemoApplicationTests { @Autowired private UsersRepository usersRepository; @Test public void contextLoads() { } @Test public void testJPA() { // 创建10条记录 usersRepository.save(new Users(\u0026#34;AAA\u0026#34;, 10)); usersRepository.save(new Users(\u0026#34;BBB\u0026#34;, 20)); usersRepository.save(new Users(\u0026#34;CCC\u0026#34;, 30)); usersRepository.save(new Users(\u0026#34;DDD\u0026#34;, 40)); usersRepository.save(new Users(\u0026#34;EEE\u0026#34;, 50)); usersRepository.save(new Users(\u0026#34;FFF\u0026#34;, 60)); usersRepository.save(new Users(\u0026#34;GGG\u0026#34;, 70)); usersRepository.save(new Users(\u0026#34;HHH\u0026#34;, 80)); usersRepository.save(new Users(\u0026#34;III\u0026#34;, 90)); usersRepository.save(new Users(\u0026#34;JJJ\u0026#34;, 100)); // 测试findAll, 查询所有记录 Assert.assertEquals(10, usersRepository.findAll().size()); // 测试findByName, 查询姓名为FFF的User Assert.assertEquals(60, usersRepository.findByName(\u0026#34;FFF\u0026#34;).getAge().longValue()); // 测试findUser, 查询姓名为FFF的User Assert.assertEquals(60, usersRepository.findUser(\u0026#34;FFF\u0026#34;).getAge().longValue()); // 测试findByNameAndAge, 查询姓名为FFF并且年龄为60的User Assert.assertEquals(\u0026#34;FFF\u0026#34;, usersRepository.findByNameAndAge(\u0026#34;FFF\u0026#34;, 60).getName()); // 测试删除姓名为AAA的User usersRepository.delete(usersRepository.findByName(\u0026#34;AAA\u0026#34;)); // 测试findAll, 查询所有记录, 验证上面的删除是否成功 Assert.assertEquals(9, usersRepository.findAll().size()); } } 5 参考资料 Spring Boot 使用 Spring-data-jpa 简化数据访问层\n","permalink":"https://zhenfeng-zhu.github.io/posts/spring-data-jpa%E5%AE%9E%E6%88%98/","summary":"为了解决抽象各个 Java 实体基本的“增删改查”操作，我们通常会以泛型的方式封装一个模板 Dao 来进行抽象简化，但是这样依然不是很方便，我们需要针对每个实体编写一个继承自泛型模板 Dao 的接口，再编写该接口的实现。虽然一些基础的数据访问已经可以得到很好的复用，但是在代码结构上针对每个实体都会有一堆 Dao 的接口和实现。\n由于模板 Dao 的实现，使得这些具体实体的 Dao 层已经变的非常“薄”，有一些具体实体的 Dao 实现可能完全就是对模板 Dao 的简单代理，并且往往这样的实现类可能会出现在很多实体上。Spring-data-jpa 的出现正可以让这样一个已经很“薄”的数据访问层变成只是一层接口的编写方式。\n1 工程配置 1.1 pom \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jpa-demo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;jpa-demo\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.9.RELEASE\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;project.reporting.outputEncoding\u0026gt;UTF-8\u0026lt;/project.reporting.outputEncoding\u0026gt; \u0026lt;java.version\u0026gt;1.8\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-jpa\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;runtime\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.","title":"Spring Data Jpa 实战"},{"content":"spring boot 多数据源配置 在单数据源的情况下，Spring Boot 的配置非常简单，只需要在 application.properties 文件中配置连接参数即可。但是往往随着业务量发展，我们通常会进行数据库拆分或是引入其他数据库，从而我们需要配置多个数据源。\n1 准备 1.1 禁止 DataSourceAutoConfiguration 首先要将 spring boot 自带的DataSourceAutoConfiguration禁掉，因为它会读取application.properties文件的spring.datasource.*属性并自动配置单数据源。在@SpringBootApplication注解中添加exclude属性即可：\n@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(JpaDemoApplication.class, args); } } 1.2 配置数据库连接 然后在application.properties中配置多数据源连接信息：\nspring.datasource.primary.url=jdbc:mysql://localhost:3306/test spring.datasource.primary.username=root spring.datasource.primary.password=root spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver spring.datasource.secondary.url=jdbc:mysql://localhost:3306/test1 spring.datasource.secondary.username=root spring.datasource.secondary.password=root spring.datasource.secondary.driver-class-name=com.mysql.jdbc.Driver 1.3 手段创建数据源 由于我们禁掉了自动数据源配置，因些下一步就需要手动将这些数据源创建出来：\n@Configuration public class DataSourceConfig { @Bean(name = \u0026#34;primaryDataSource\u0026#34;) // @Qualifier(value = \u0026#34;primaryDataSource\u0026#34;) @ConfigurationProperties(prefix = \u0026#34;spring.datasource.primary\u0026#34;) public DataSource primaryDataSource(){ return DataSourceBuilder.create().build(); } @Bean(name = \u0026#34;secondaryDataSource\u0026#34;) // @Qualifier(value = \u0026#34;secondaryDataSource\u0026#34;) @ConfigurationProperties(prefix = \u0026#34;spring.datasource.secondary\u0026#34;) public DataSource secondaryDataSource() { return DataSourceBuilder.create().build(); } } 2 jdbcTemplate 多数据源 2.1 jdbcTemplate 的数据源配置 新建 jdbcTemplate 的数据源配置：\n@Configuration public class JdbcTemplateConfig { @Bean(name = \u0026#34;primaryJdbcTemplate\u0026#34;) public JdbcTemplate primaryJdbcTemplate( @Qualifier(\u0026#34;primaryDataSource\u0026#34;) DataSource dataSource) { return new JdbcTemplate(dataSource); } @Bean(name = \u0026#34;secondaryJdbcTemplate\u0026#34;) public JdbcTemplate secondaryJdbcTemplate( @Qualifier(\u0026#34;secondaryDataSource\u0026#34;) DataSource dataSource) { return new JdbcTemplate(dataSource); } } 2.2 单元测试 然后编写单元测试用例：\n@RunWith(SpringRunner.class) @SpringBootTest public class JpaDemoApplicationTests { @Autowired @Qualifier(\u0026#34;primaryJdbcTemplate\u0026#34;) protected JdbcTemplate jdbcTemplate1; @Autowired @Qualifier(\u0026#34;secondaryJdbcTemplate\u0026#34;) protected JdbcTemplate jdbcTemplate2; @Test public void testJdbc() { // 往第一个数据源中插入两条数据 jdbcTemplate1.update(\u0026#34;insert into users(id,name,age) values(?, ?, ?)\u0026#34;, 1, \u0026#34;aaa\u0026#34;, 20); jdbcTemplate1.update(\u0026#34;insert into users(id,name,age) values(?, ?, ?)\u0026#34;, 2, \u0026#34;bbb\u0026#34;, 30); // 往第二个数据源中插入一条数据，若插入的是第一个数据源，则会主键冲突报错 jdbcTemplate2.update(\u0026#34;insert into users(id,name,age) values(?, ?, ?)\u0026#34;, 1, \u0026#34;aaa\u0026#34;, 20); // 查一下第一个数据源中是否有两条数据，验证插入是否成功 Assert.assertEquals(\u0026#34;2\u0026#34;, jdbcTemplate1.queryForObject(\u0026#34;select count(1) from users\u0026#34;, String.class)); // 查一下第一个数据源中是否有两条数据，验证插入是否成功 Assert.assertEquals(\u0026#34;1\u0026#34;, jdbcTemplate2.queryForObject(\u0026#34;select count(1) from users\u0026#34;, String.class)); } @Test public void contextLoads() { } } 3 mybatis 多数据源配置 3.1 自定义 SqlSessionFactory 新建两个 mybatis 的 SqlSessionFactory 配置：\n@Configuration @MapperScan(basePackages = {\u0026#34;com.example.jpademo.primary.mapper\u0026#34;}, sqlSessionFactoryRef = \u0026#34;sqlSessionFactory1\u0026#34;) public class MybatisPrimaryConfig { @Autowired @Qualifier(\u0026#34;primaryDataSource\u0026#34;) private DataSource primaryDataSource; @Bean public SqlSessionFactory sqlSessionFactory1() throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); // 使用primaryDataSource数据源 factoryBean.setDataSource(primaryDataSource); return factoryBean.getObject(); } @Bean public SqlSessionTemplate sqlSessionTemplate1() throws Exception { // 使用上面配置的Factory SqlSessionTemplate template = new SqlSessionTemplate(sqlSessionFactory1()); return template; } } 这样，com.example.jpademo.primary.mapper包下的所有 mapper 就会用sqlSessionFactory1。同理可以创建\nsqlSessionFactory2：\n@Configuration @MapperScan(basePackages = {\u0026#34;com.example.jpademo.secondary.mapper\u0026#34;}, sqlSessionFactoryRef = \u0026#34;sqlSessionFactory2\u0026#34;) public class MybatisSecondaryConfig { @Autowired @Qualifier(\u0026#34;secondaryDataSource\u0026#34;) private DataSource secondaryDataSource; @Bean public SqlSessionFactory sqlSessionFactory2() throws Exception { SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); // 使用primaryDataSource数据源 factoryBean.setDataSource(secondaryDataSource); return factoryBean.getObject(); } @Bean public SqlSessionTemplate sqlSessionTemplate1() throws Exception { // 使用上面配置的Factory SqlSessionTemplate template = new SqlSessionTemplate(sqlSessionFactory2()); return template; } } 3.2 mapper 和实体类 然后编写 mapper 和实体类：\n@Data public class User { private Integer id; private String name; private Integer age; } package com.example.jpademo.primary.mapper; import com.example.jpademo.domain.User; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; import org.apache.ibatis.annotations.Select; import org.springframework.beans.factory.annotation.Qualifier; @Mapper @Qualifier(\u0026#34;userMapper1\u0026#34;) public interface UserMapper1 { @Select(\u0026#34;select * from users where id=#{id}\u0026#34;) User findById(@Param(\u0026#34;id\u0026#34;) Integer id); } package com.example.jpademo.secondary.mapper; import com.example.jpademo.domain.User; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Select; import org.springframework.beans.factory.annotation.Qualifier; @Mapper @Qualifier(\u0026#34;userMapper2\u0026#34;) public interface UserMapper2 { @Select(\u0026#34;select * from users where id=#{id}\u0026#34;) User findById(Integer id); } 3.3 单元测试 编写单元测试用例：\n@RunWith(SpringRunner.class) @SpringBootTest public class JpaDemoApplicationTests { @Autowired private UserMapper1 userMapper1; @Autowired private UserMapper2 userMapper2; @Test public void testMybatis() { User user1 = userMapper1.findById(1); User user2 = userMapper2.findById(1); Assert.assertEquals(\u0026#34;aaa\u0026#34;, user1.getName()); Assert.assertEquals(\u0026#34;ccc\u0026#34;, user2.getName()); } } 4 参考资料 Spring Boot + Mybatis 多数据源和动态数据源配置\nSpring Boot 两种多数据源配置：JdbcTemplate、Spring-data-jpa\n","permalink":"https://zhenfeng-zhu.github.io/posts/spring-boot%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E9%85%8D%E7%BD%AE/","summary":"spring boot 多数据源配置 在单数据源的情况下，Spring Boot 的配置非常简单，只需要在 application.properties 文件中配置连接参数即可。但是往往随着业务量发展，我们通常会进行数据库拆分或是引入其他数据库，从而我们需要配置多个数据源。\n1 准备 1.1 禁止 DataSourceAutoConfiguration 首先要将 spring boot 自带的DataSourceAutoConfiguration禁掉，因为它会读取application.properties文件的spring.datasource.*属性并自动配置单数据源。在@SpringBootApplication注解中添加exclude属性即可：\n@SpringBootApplication(exclude = {DataSourceAutoConfiguration.class}) public class DemoApplication { public static void main(String[] args) { SpringApplication.run(JpaDemoApplication.class, args); } } 1.2 配置数据库连接 然后在application.properties中配置多数据源连接信息：\nspring.datasource.primary.url=jdbc:mysql://localhost:3306/test spring.datasource.primary.username=root spring.datasource.primary.password=root spring.datasource.primary.driver-class-name=com.mysql.jdbc.Driver spring.datasource.secondary.url=jdbc:mysql://localhost:3306/test1 spring.datasource.secondary.username=root spring.datasource.secondary.password=root spring.datasource.secondary.driver-class-name=com.mysql.jdbc.Driver 1.3 手段创建数据源 由于我们禁掉了自动数据源配置，因些下一步就需要手动将这些数据源创建出来：\n@Configuration public class DataSourceConfig { @Bean(name = \u0026#34;primaryDataSource\u0026#34;) // @Qualifier(value = \u0026#34;primaryDataSource\u0026#34;) @ConfigurationProperties(prefix = \u0026#34;spring.datasource.primary\u0026#34;) public DataSource primaryDataSource(){ return DataSourceBuilder.create().build(); } @Bean(name = \u0026#34;secondaryDataSource\u0026#34;) // @Qualifier(value = \u0026#34;secondaryDataSource\u0026#34;) @ConfigurationProperties(prefix = \u0026#34;spring.","title":"spring boot 多数据源配置"},{"content":"Spring-data-redis为 spring-data 模块中对 redis 的支持部分，简称为“SDR”，提供了基于 jedis 客户端 API 的高度封装以及与 spring 容器的整合，\njedis 客户端在编程实施方面存在如下不足：\n connection 管理缺乏自动化，connection-pool 的设计缺少必要的容器支持。 数据操作需要关注“序列化”/“反序列化”，因为 jedis 的客户端 API 接受的数据类型为 string 和 byte，对结构化数据(json,xml,pojo 等)操作需要额外的支持。 事务操作纯粹为硬编码 pub/sub 功能，缺乏必要的设计模式支持，对于开发者而言需要关注的太多。  1 spring-data-redis 特性  连接池自动管理，提供了一个高度封装的“RedisTemplate”类 针对 jedis 客户端中大量 api 进行了归类封装,将同一类型操作封装为 operation 接口  ValueOperations：简单 K-V 操作 SetOperations：set 类型数据操作 ZSetOperations：zset 类型数据操作 HashOperations：针对 map 类型的数据操作 ListOperations：针对 list 类型的数据操作   提供了对 key 的“bound”(绑定)便捷化操作 API，可以通过 bound 封装指定的 key，然后进行一系列的操作而无须“显式”的再次指定 Key，即 BoundKeyOperations：  BoundValueOperations BoundSetOperations BoundListOperations BoundSetOperations BoundHashOperations   将事务操作封装，有容器控制。 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)  JdkSerializationRedisSerializer：POJO 对象的存取场景，使用 JDK 本身序列化机制，将 pojo 类通过 ObjectInputStream/ObjectOutputStream 进行序列化操作，最终 redis-server 中将存储字节序列。是目前最常用的序列化策略。 StringRedisSerializer：Key 或者 value 为字符串的场景，根据指定的 charset 对数据的字节序列编码成 string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。 JacksonJsonRedisSerializer：jackson-json 工具提供了 javabean 与 json 之间的转换能力，可以将 pojo 实例序列化成 json 格式存储在 redis 中，也可以将 json 格式的数据转换成 pojo 实例。因为 jackson 工具在序列化和反序列化时，需要明确指定 Class 类型，因此此策略封装起来稍微复杂。 OxmSerializer：提供了将 javabean 与 xml 之间的转换能力，目前可用的三方支持包括 jaxb，apache-xmlbeans；redis 存储的数据将是 xml 工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。   基于设计模式，和 JMS 开发思路，将 pub/sub 的 API 设计进行了封装，使开发更加便捷。 spring-data-redis 中，并没有对 sharding 提供良好的封装，如果你的架构是基于 sharding，那么你需要自己去实现，这也是 sdr 和 jedis 相比，唯一缺少的特性。  2 引入依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-data-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 3 配置 # REDIS (RedisProperties) # Redis数据库索引（默认为0） spring.redis.database=0 # Redis服务器地址 spring.redis.host=localhost # Redis服务器连接端口 spring.redis.port=6379 # Redis服务器连接密码（默认为空） spring.redis.password=root # 连接池最大连接数（使用负值表示没有限制） spring.redis.pool.max-active=8 # 连接池最大阻塞等待时间（使用负值表示没有限制） spring.redis.pool.max-wait=-1 # 连接池中的最大空闲连接 spring.redis.pool.max-idle=8 # 连接池中的最小空闲连接 spring.redis.pool.min-idle=0 # 连接超时时间（毫秒） spring.redis.timeout=0 其中 spring.redis.database 的配置通常使用 0 即可，Redis 在配置的时候可以设置数据库数量，默认为 16，可以理解为数据库的 schema\n3.1 StringRedisTemplate @RunWith(SpringRunner.class) @SpringBootTest public class DemoApplicationTests { @Autowired private StringRedisTemplate stringRedisTemplate; @Test public void testRedis(){ stringRedisTemplate.opsForValue().set(\u0026#34;myKey\u0026#34;, \u0026#34;hello redis\u0026#34;); Assert.assertEquals(\u0026#34;hello redis\u0026#34;, stringRedisTemplate.opsForValue().get(\u0026#34;myKey\u0026#34;)); } } 通过上面这段极为简单的测试案例演示了如何通过自动配置的 StringRedisTemplate 对象进行 Redis 的读写操作，该对象从命名中就可注意到支持的是 String 类型。如果有使用过 spring-data-redis 的开发者一定熟悉 RedisTemplate\u0026lt;K, V\u0026gt;接口，StringRedisTemplate 就相当于 RedisTemplate\u0026lt;String, String\u0026gt;的实现。\n除了 String 类型，我们还经常会在 Redis 中存储对象。\n3.2 RedisTemplate\u0026lt;Object, Object\u0026gt; 3.2.1 新建 User 类 @Data @AllArgsConstructor public class User implements Serializable{ private static final long serialVersionUID = 1L; private Integer id; private String username; private Integer age; } 3.2.2 创建 UserRepository @Repository public class UserRepository { @Autowired private RedisTemplate\u0026lt;Object, Object\u0026gt; redisTemplate; // @Resource(name = \u0026#34;redisTemplate\u0026#34;) ValueOperations\u0026lt;Object, Object\u0026gt; valOps; /** * 保存 * @param user */ public void save(User user) { int id = user.getId(); valOps.set(id, user); } /** * 获取 * @param id * @return */ public User getUserById(int id) { return (User) valOps.get(id); } } @Resource 注解和@Autowired 一样，也可以标注在字段或属性的 setter 方法上，但它默认按名称装配。名称可以通过@Resource 的 name 属性指定，如果没有指定 name 属性，当注解标注在字段上，即默认取字段的名称作为 bean 名称寻找依赖对象，当注解标注在属性的 setter 方法上，即默认取属性名作为 bean 名称寻找依赖对象。\n3.2.3 单元测试 @RunWith(SpringRunner.class) @SpringBootTest public class DemoApplicationTests { @Autowired private UserRepository userRepository; @Test public void testRedis(){ User user=new User(1, \u0026#34;hello\u0026#34;, 12); userRepository.save(user); Assert.assertEquals(\u0026#34;hello\u0026#34;, userRepository.getUserById(1).getUsername()); } } 4 参考资料 SpringBoot 之 Redis 的支持\nSpring-data-redis 特性与实例\n","permalink":"https://zhenfeng-zhu.github.io/posts/spring-boot%E8%BF%9E%E6%8E%A5redis/","summary":"Spring-data-redis为 spring-data 模块中对 redis 的支持部分，简称为“SDR”，提供了基于 jedis 客户端 API 的高度封装以及与 spring 容器的整合，\njedis 客户端在编程实施方面存在如下不足：\n connection 管理缺乏自动化，connection-pool 的设计缺少必要的容器支持。 数据操作需要关注“序列化”/“反序列化”，因为 jedis 的客户端 API 接受的数据类型为 string 和 byte，对结构化数据(json,xml,pojo 等)操作需要额外的支持。 事务操作纯粹为硬编码 pub/sub 功能，缺乏必要的设计模式支持，对于开发者而言需要关注的太多。  1 spring-data-redis 特性  连接池自动管理，提供了一个高度封装的“RedisTemplate”类 针对 jedis 客户端中大量 api 进行了归类封装,将同一类型操作封装为 operation 接口  ValueOperations：简单 K-V 操作 SetOperations：set 类型数据操作 ZSetOperations：zset 类型数据操作 HashOperations：针对 map 类型的数据操作 ListOperations：针对 list 类型的数据操作   提供了对 key 的“bound”(绑定)便捷化操作 API，可以通过 bound 封装指定的 key，然后进行一系列的操作而无须“显式”的再次指定 Key，即 BoundKeyOperations：  BoundValueOperations BoundSetOperations BoundListOperations BoundSetOperations BoundHashOperations   将事务操作封装，有容器控制。 针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)  JdkSerializationRedisSerializer：POJO 对象的存取场景，使用 JDK 本身序列化机制，将 pojo 类通过 ObjectInputStream/ObjectOutputStream 进行序列化操作，最终 redis-server 中将存储字节序列。是目前最常用的序列化策略。 StringRedisSerializer：Key 或者 value 为字符串的场景，根据指定的 charset 对数据的字节序列编码成 string，是“new String(bytes, charset)”和“string.","title":"spring boot 连接 redis"},{"content":"最终一致性的实现手段 实现最终一致性有三种手段：可靠事件模式、业务补偿模式和 TCC 模式\n1 可靠事件模式 可靠事件模式属于事件驱动架构，当某件重要的事情发生时，比如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会将订阅事件的微服务推送事件。\n要实现这种模式需要消息队列实现事件的持久化和 at least once 的可靠事件投递模式。\n1.1 本地事件表 本地事件表方法是将事件和业务数据保存在同一个数据库中，使用一个额外的事件恢复服务来恢复事件，由本地事物保证更新业务和发布事件的原子性。\n但是业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。\n1.2 外部事件 此方法是将事件持久化到外部的事件系统，事件系统需要提供实时事件服务以接受微服务发布的事件，同时事件系统还需要提供事件恢复服务来确认恢复事件。\n1.3 不足 此过程可能出现重复消费的情况。\n2 补偿模式 一般来讲，异常一般是由以下两种情况造成的：\n业务异常：业务逻辑产生的错误，比如余额不足、库存不足等。\n技术异常：非业务逻辑产生的异常，比如网络连接异常、超时等。\n补偿模式就是使用一个额外的协调服务来协调各个需要保证一致性的其他服务。协调服务按顺序调用每一个服务，如果某个服务调用异常就取消之前所有已经调用成功的服务。\n建议仅用于技术异常的情况。对于业务异常来讲，应该尽可能的去优化业务模式，以避免要求补偿事务。\n2.1 常用手段 在实现补偿模式时应该做到两点：\n 首先要确定失败的步骤和状态，从而确定要补偿的范围。 其次要能提供补偿操作使用的业务数据。  可以通过记录完整的业务流水的方法来实现上面两点要求。但是对于一个通用的补偿框架来说，预先知道微服务需要记录的业务要素是不可能的，那么就需要一种办法来保证业务流水的可扩展性，实践中主要有两种方法：大表和关联表。\n 大表，顾明思议就是设计时除了必须的字段外，还需要预留大量的备用字段，框架可以提供辅助工具来将业务数据映射到备用字段中。大表对于框架层实现起来比较简单，但是也有一些难点，比如预留多少个字段合适，每个字段又需要预留多长。还有一个难点是如果仅从数据层面来查询数据，很难一眼看出备用字段的业务含义，维护过程不友好。 关联表，分为技术表和业务表。技术表中保存为实现补偿操作所需要的技术数据，业务表中保存业务数据。通过在技术表中增加业务表名和业务表主键来建立和业务数据的关联。关联表更灵活，能支持不同业务类型记录不同的业务要素。但是在框架的实现上难度较高，每次查询都需要复杂的关联动作，性能会受到影响。  2.2 重试 补偿过程作为一个服务，在调用的时候也会出现不成功的情况，这时就要通过重试机制来保证补偿的成功率。因此要求补偿操作具有幂等性。\n但是也不是盲目的重试，我们需要根据服务执行失败的原因来选择不同的策略：\n 因业务因素导致失败，需要停止重试。 罕见的异常，如网络中断，传输过程中数据丢失，应该立即重试。 如果是因为系统繁忙，此时需要等待一段时间再重试。  2.3 不足 在补偿模式中有一个明显的缺陷是隔离性，从第一个服务开始一直到补偿完成，不一致性是对其他服务可见的。另外补偿模式过分依赖协调服务的健壮性，如果协调服务异常，则没办法达到一致性。\n3 TCC 模式 TCC，是 Try，Confirm 和 Cancel 的缩写。一个完整的 TCC 业务一般是由一个主业务和若干个从业务组成。\n Try  完成所有业务检查 预留必须的业务资源   Confirm  真正执行业务 不做任何业务检查 只使用 Try 阶段预留的业务资源 满足幂等性   Cancel  释放 Try 阶段预留的业务资源 满足幂等性    3.1 实现过程 整个 TCC 业务分成两个阶段完成：\n第一阶段：主业务服务分别调用所有从业务的 try 操作，并在活动管理器中登记所有从业务服务。当所有从业务服务的 try 操作都调用成功或者某个从业务服务的 try 操作失败，进入第二阶段。\n第二阶段：活动管理器根据第一阶段的执行结果来执行 Confirm 或 Cancel 操作。如果第一阶段所有的 try 操作是成功的，则调用所有从业务的 Confirm 操作，否则都调用 Cancel 操作。\nTCC 模式不再需要记录详细的业务流水，在一定程度上弥补了补偿模式的缺陷，在 TCC 模式中，直到明确的 Confirm 动作，所有的业务操作都是隔离的。而且还可以通过指定 try 的超时时间，主动的 Cancel 预留的资源，从而实现了自治。\n3.2 不足 TCC 模式不能百分百保证一致性，如果某服务提交了 Confirm 成功，但是由于网络故障，导致主服务收到的失败，那么就会出现不一致性，这被称为 heuristic exception。因此为保证成功率，都需要支持重试。\nheuristic exception 是不可杜绝的，但是通过设置合理的超时时间、重试频率以及监控，可以使此异常的可能性降到很低，另外如果出现了此异常，还可通过人工手段补救。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E6%9C%80%E7%BB%88%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%89%8B%E6%AE%B5/","summary":"最终一致性的实现手段 实现最终一致性有三种手段：可靠事件模式、业务补偿模式和 TCC 模式\n1 可靠事件模式 可靠事件模式属于事件驱动架构，当某件重要的事情发生时，比如更新一个业务实体，微服务会向消息代理发布一个事件。消息代理会将订阅事件的微服务推送事件。\n要实现这种模式需要消息队列实现事件的持久化和 at least once 的可靠事件投递模式。\n1.1 本地事件表 本地事件表方法是将事件和业务数据保存在同一个数据库中，使用一个额外的事件恢复服务来恢复事件，由本地事物保证更新业务和发布事件的原子性。\n但是业务系统和事件系统耦合比较紧密，额外的事件数据库操作也会给数据库带来额外的压力，可能成为瓶颈。\n1.2 外部事件 此方法是将事件持久化到外部的事件系统，事件系统需要提供实时事件服务以接受微服务发布的事件，同时事件系统还需要提供事件恢复服务来确认恢复事件。\n1.3 不足 此过程可能出现重复消费的情况。\n2 补偿模式 一般来讲，异常一般是由以下两种情况造成的：\n业务异常：业务逻辑产生的错误，比如余额不足、库存不足等。\n技术异常：非业务逻辑产生的异常，比如网络连接异常、超时等。\n补偿模式就是使用一个额外的协调服务来协调各个需要保证一致性的其他服务。协调服务按顺序调用每一个服务，如果某个服务调用异常就取消之前所有已经调用成功的服务。\n建议仅用于技术异常的情况。对于业务异常来讲，应该尽可能的去优化业务模式，以避免要求补偿事务。\n2.1 常用手段 在实现补偿模式时应该做到两点：\n 首先要确定失败的步骤和状态，从而确定要补偿的范围。 其次要能提供补偿操作使用的业务数据。  可以通过记录完整的业务流水的方法来实现上面两点要求。但是对于一个通用的补偿框架来说，预先知道微服务需要记录的业务要素是不可能的，那么就需要一种办法来保证业务流水的可扩展性，实践中主要有两种方法：大表和关联表。\n 大表，顾明思议就是设计时除了必须的字段外，还需要预留大量的备用字段，框架可以提供辅助工具来将业务数据映射到备用字段中。大表对于框架层实现起来比较简单，但是也有一些难点，比如预留多少个字段合适，每个字段又需要预留多长。还有一个难点是如果仅从数据层面来查询数据，很难一眼看出备用字段的业务含义，维护过程不友好。 关联表，分为技术表和业务表。技术表中保存为实现补偿操作所需要的技术数据，业务表中保存业务数据。通过在技术表中增加业务表名和业务表主键来建立和业务数据的关联。关联表更灵活，能支持不同业务类型记录不同的业务要素。但是在框架的实现上难度较高，每次查询都需要复杂的关联动作，性能会受到影响。  2.2 重试 补偿过程作为一个服务，在调用的时候也会出现不成功的情况，这时就要通过重试机制来保证补偿的成功率。因此要求补偿操作具有幂等性。\n但是也不是盲目的重试，我们需要根据服务执行失败的原因来选择不同的策略：\n 因业务因素导致失败，需要停止重试。 罕见的异常，如网络中断，传输过程中数据丢失，应该立即重试。 如果是因为系统繁忙，此时需要等待一段时间再重试。  2.3 不足 在补偿模式中有一个明显的缺陷是隔离性，从第一个服务开始一直到补偿完成，不一致性是对其他服务可见的。另外补偿模式过分依赖协调服务的健壮性，如果协调服务异常，则没办法达到一致性。\n3 TCC 模式 TCC，是 Try，Confirm 和 Cancel 的缩写。一个完整的 TCC 业务一般是由一个主业务和若干个从业务组成。\n Try  完成所有业务检查 预留必须的业务资源   Confirm  真正执行业务 不做任何业务检查 只使用 Try 阶段预留的业务资源 满足幂等性   Cancel  释放 Try 阶段预留的业务资源 满足幂等性    3.","title":"最终一致性的实现手段"},{"content":"Reactive 微服务 分布式系统构建起来很困难，因为它们容易出问题，运行缓慢，并且被 CAP 和 FLP 理论所限制。换句话说，它们的构建和运维都特别复杂。为了解决这个问题，reactive 便出现了。\nReactive 编程：一种开发模型，其专注于数据流向、对变化的反馈，以及传播他们。\n在 reactive 编程中，刺激信号是数据的转移，叫做 streams。其实很像生产者——消费者模式，消费者对值进行订阅并响应。\nReactive 系统：一种架构风格，其基于异步消息来构建响应式的分布式系统。\nreactive 系统使用了消息驱动的方法。所有的构建通过异步消息的发送和接收来交互。消息投递的逻辑由底层的实现决定。发送者不会阻塞着等待回复，它们可能会稍后才接收到回复。\nreactive 系统会有两个重要的特征：\n  伸缩性——可以横向伸缩\n伸缩性来自消息传递的解耦。消息被发送到一个地址之后，可以被一组消费者按照一种负载均衡方法消费。当 reactive 系统遇到负载高峰时，它可以创造出新的消费者，并在此之后销毁它们。\n  恢复性——可以处理错误并且恢复\n首先，这种消息交互模式允许组件在其本地处理错误，组件不需要等待消息，因此当一个组件发生错误时，其他组件仍然会正常工作。其次，当一个处理消息的组件发生错误后，消息可以可以传递给在相同地址注册的其他组件。\n  reactive 微服务系统是由 reactive 微服务组成的。这些微服务有下面四个特征：\n 自治性 异步性 恢复性 伸缩性  Reactive 微服务是可自治的。他们可以根据周围的服务是否可用来调整自己的行为。自治性往往伴随着孤立性；Reactive 微服务可以在本地处理错误、独立地完成任务，并在必要时和其他服务合作。它们使用异步消息传递的机制和其他服务沟通；它们也会接收消息并且对其作出回应。\n得益于异步消息机制，reactive 微服务可以处理错误并根据情况调整自己的行为。错误不会被扩散，而是在靠近错误源头的地方被处理掉。当一个微服务挂掉之后，它的消费者微服务要能够处理错误并避免扩散。这一孤立原则是避免错误逐层上浮而毁掉整个系统的关键。可恢复性不只是关于处理错误，它还涉及到自愈性；一个 reactive 微服务应该能够从错误中恢复并且对错误进行补救。\n最后，reactive 微服务必须是可伸缩的，这样系统才可以根据负载情况来调整节点数量。这一特性意味着将会有一系列的限制，比如不能有在内存中的状态，要能够在必要时同步状态信息，或者要能够将消息路由到状态信息相同的节点。\nVert.x Vert.x 是一个用于构建 reactive 和分布式系统的工具箱，其使用了异步非阻塞编程模型。当使用 Vert.x 构建微服务的时候，微服务会自然地带上一个核心特征：所有事情都是异步的。\n传统编程模式\nint res = compute(1, 2); 在这段代码中，是在等待 compute 函数计算出来结果之后再进行剩下的操作。而在异步非阻塞的编程模式中，将会创建一个 handler：\ncompute(1, 2, res -\u0026gt; { // called with the result }); 在上述代码中，compute 函数不再返回一个结果，而是传一个 handler，当结果准备好时调用就可以了。得益于这种开发模型，可以使用很少的线程去处理高并发工作。在 vert.x 中，到处都可以看到这种形式的代码，比如创建 http 服务器时：\nvertx.createHttpServer() .requestHandler(request -\u0026gt; { request.response().end(\u0026#34;hello vert.x\u0026#34;); }) .listen(8080); 这个例子中，我们让一个 requestHandler 接收 HTTP 请求(事件)并且返回\u0026quot;hello vert.x\u0026quot;。Handler 是一个函数，当事件发生时，它会被调用。在我们的例子中，handler 代码会在每次请求进来时被调用执行。要注意的是，Handler 并不会返回一个结果，但是它可以提供一个结果；这个结果是怎样被提供的，这个要看是哪种交互行为。在上面的代码段中，它只是向一个 HTTP response 写入了结果。这个 Handler 后面跟了一个方法令其监听 8080 端口。调用这个 HTTP 服务它会返回一个简单的 response。\nevent loop 绝大多数情况，Vert.x 会用一个叫做 event loop 的线程来调用所有的 handler。\n基于消息循环的线程模型有一个很大的优点：它简化了并发。因为只有一个线程存在，因此永远都只被一个线程调用而不存在并发的情况。但是同样也有一个限制：\n 不要阻塞消息循环\n 因为没有阻塞，一个消息循环线程可以短时间内分发巨量的事件，这个模式就叫做 reactor 模式。\nverticles Verticles 是被 Vert.x 部署和运行的代码块。一个微服务的应用，是由运行在同一个 Vert.x 实例上的若干 verticle 组成的。一个 verticle 通常会创建服务器或客户端、注册一组 Handler，以及封装一部分系统的业务处理逻辑。\n标准的 verticle 标准的 verticle 会在 Vert.x 的消息循环中被执行，并且永远不会阻塞。Vert.x 保证了每一个 verticle 都会只被同一个线程执行而不会有并发发生，从而避免同步工作。\nWorker Verticle 和标准的 verticle 不同，worker verticle 不是在消息循环中执行的，这就意味着他们可以执行阻塞代码。但是，这会限制你的可扩展性。\nVerticle 可以访问 vertx 成员变量(是由 AbstractVerticle 类提供的)来创建服务器和客户端，以及和其他的 verticle 交互。Verticle 还可以部署其他的 verticle，对它们进行配置，并设置创建实例的数量。这些实例会和不同的消息循环线程绑定，Vert.x 通过这些实例来均衡负载。\n从 Callbacks 到 Observables 我们可以发现，Vert.x 开发模式使用回调方法。在组织管理多个异步动作时，这种基于回调的开发模式容易产生复杂的代码，陷入 callback hell。\nVert.x 提供了解决这个开发难题的答案——RxJava API。\n","permalink":"https://zhenfeng-zhu.github.io/posts/reactive%E5%BE%AE%E6%9C%8D%E5%8A%A1/","summary":"Reactive 微服务 分布式系统构建起来很困难，因为它们容易出问题，运行缓慢，并且被 CAP 和 FLP 理论所限制。换句话说，它们的构建和运维都特别复杂。为了解决这个问题，reactive 便出现了。\nReactive 编程：一种开发模型，其专注于数据流向、对变化的反馈，以及传播他们。\n在 reactive 编程中，刺激信号是数据的转移，叫做 streams。其实很像生产者——消费者模式，消费者对值进行订阅并响应。\nReactive 系统：一种架构风格，其基于异步消息来构建响应式的分布式系统。\nreactive 系统使用了消息驱动的方法。所有的构建通过异步消息的发送和接收来交互。消息投递的逻辑由底层的实现决定。发送者不会阻塞着等待回复，它们可能会稍后才接收到回复。\nreactive 系统会有两个重要的特征：\n  伸缩性——可以横向伸缩\n伸缩性来自消息传递的解耦。消息被发送到一个地址之后，可以被一组消费者按照一种负载均衡方法消费。当 reactive 系统遇到负载高峰时，它可以创造出新的消费者，并在此之后销毁它们。\n  恢复性——可以处理错误并且恢复\n首先，这种消息交互模式允许组件在其本地处理错误，组件不需要等待消息，因此当一个组件发生错误时，其他组件仍然会正常工作。其次，当一个处理消息的组件发生错误后，消息可以可以传递给在相同地址注册的其他组件。\n  reactive 微服务系统是由 reactive 微服务组成的。这些微服务有下面四个特征：\n 自治性 异步性 恢复性 伸缩性  Reactive 微服务是可自治的。他们可以根据周围的服务是否可用来调整自己的行为。自治性往往伴随着孤立性；Reactive 微服务可以在本地处理错误、独立地完成任务，并在必要时和其他服务合作。它们使用异步消息传递的机制和其他服务沟通；它们也会接收消息并且对其作出回应。\n得益于异步消息机制，reactive 微服务可以处理错误并根据情况调整自己的行为。错误不会被扩散，而是在靠近错误源头的地方被处理掉。当一个微服务挂掉之后，它的消费者微服务要能够处理错误并避免扩散。这一孤立原则是避免错误逐层上浮而毁掉整个系统的关键。可恢复性不只是关于处理错误，它还涉及到自愈性；一个 reactive 微服务应该能够从错误中恢复并且对错误进行补救。\n最后，reactive 微服务必须是可伸缩的，这样系统才可以根据负载情况来调整节点数量。这一特性意味着将会有一系列的限制，比如不能有在内存中的状态，要能够在必要时同步状态信息，或者要能够将消息路由到状态信息相同的节点。\nVert.x Vert.x 是一个用于构建 reactive 和分布式系统的工具箱，其使用了异步非阻塞编程模型。当使用 Vert.x 构建微服务的时候，微服务会自然地带上一个核心特征：所有事情都是异步的。\n传统编程模式\nint res = compute(1, 2); 在这段代码中，是在等待 compute 函数计算出来结果之后再进行剩下的操作。而在异步非阻塞的编程模式中，将会创建一个 handler：\ncompute(1, 2, res -\u0026gt; { // called with the result }); 在上述代码中，compute 函数不再返回一个结果，而是传一个 handler，当结果准备好时调用就可以了。得益于这种开发模型，可以使用很少的线程去处理高并发工作。在 vert.","title":"Reactive 微服务"},{"content":"Guice 快速入门 接手的新项目主要是使用 kotlin+vert.x 来写的，使用 gradle 构建，依赖注入框架使用了 guice。这段时间都是在熟悉代码的过程，恶补一些知识。\nguice 是谷歌推出的一个轻量级的依赖注入框架，当然 spring 也可以实现依赖注入，只是 spring 太庞大了。\n1 基本使用 引入依赖 使用 gradle 或者 maven，引入 guice。\nmaven:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.inject\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guice\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Gradle:\ncompile \u0026#34;com.google.inject:guice:4.1.0\u0026#34; 项目骨架 首先需要一个业务接口，包含一个方法来执行业务逻辑，它的实现非常简单：\npackage com.learning.guice; public interface UserService { void process(); } package com.learning.guice; public class UserServiceImpl implements UserService { @Override public void process() { System.out.println(\u0026#34;我需要做一些业务逻辑\u0026#34;); } } 然后写一个日志的接口：\npackage com.learning.guice; public interface LogService { void log(String msg); } package com.learning.guice; public class LogServiceImpl implements LogService { @Override public void log(String msg) { System.out.println(\u0026#34;------LOG: \u0026#34; + msg); } } 最后是一个系统接口和相应的实现，在实现中使用了业务接口和日志接口处理业务逻辑和打印日志信息：\npackage com.learning.guice; public interface Application { void work(); } package com.learning.guice; import com.google.inject.Inject; public class MyApp implements Application { private UserService userService; private LogService logService; @Inject public MyApp(UserService userService, LogService logService) { this.userService = userService; this.logService = logService; } @Override public void work() { userService.process(); logService.log(\u0026#34;程序正常运行\u0026#34;); } } 配置依赖注入 guice 是使用 java 代码来配置依赖。继承 AbstractModule 类，并重写其中的 config 方法。在 config 方法中，调用 AbstractModule 类中提供的方法来配置依赖关系。最常用的是 bind(接口).to(实现类)。\npackage com.learning.guice; import com.google.inject.AbstractModule; public class MyAppModule extends AbstractModule { @Override protected void configure() { bind(LogService.class).to(LogServiceImpl.class); bind(UserService.class).to(UserServiceImpl.class); bind(Application.class).to(MyApp.class); } } 单元测试 guice 配置完之后，我们需要调用 Guice.createInjector 方法传入配置类来创建一个注入器，然后使用注入器中的 getInstance 方法获取目标类。\npackage com.learning.guice; import com.google.inject.Guice; import com.google.inject.Injector; import org.junit.BeforeClass; import org.junit.Test; public class MyAppTest { private static Injector injector; @BeforeClass public static void init(){ injector= Guice.createInjector(new MyAppModule()); } @Test public void testMyApp(){ Application application=injector.getInstance(Application.class); application.work(); } } 程序执行结果是：\n/Library/Java/JavaVirtualMachines/jdk1.8.0_152.jdk/Contents/Home/bin/java -ea -... 我需要做一些业务逻辑 ------LOG: 程序正常运行 Process finished with exit code 0 2 基本概念 2.1 Bingdings 绑定   链式绑定\n在绑定依赖的时候不仅可以将父类和子类绑定，还可以将子类和子类的子类进行绑定。\npublic class BillingModule extends AbstractModule { @Override protected void configure() { bind(TransactionLog.class).to(DatabaseTransactionLog.class); bind(DatabaseTransactionLog.class).to(MySqlDatabaseTransactionLog.class); } } 在这种情况下，injector 会把所有 TransactionLog 替换为 MySqlDatabaseTransactionLog。\n  注解绑定\n当我们需要将多个同一类型的对象注入不同对象的时候，就需要使用注解区分这些依赖了。最简单的办法就是使用@Named 注解进行区分。\n首先需要在要注入的地方添加@Named 注解。\npublic class RealBillingService implements BillingService { @Inject public RealBillingService(@Named(\u0026#34;Checkout\u0026#34;) CreditCardProcessor processor, TransactionLog transactionLog) { ... } 然后在绑定中添加 annotatedWith 方法指定@Named 中指定的名称。由于编译器无法检查字符串，所以 Guice 官方建议我们保守地使用这种方式。\nbind(CreditCardProcessor.class) .annotatedWith(Names.named(\u0026#34;Checkout\u0026#34;)) .to(CheckoutCreditCardProcessor.class);   实例绑定\n有时候需要直接注入一个对象的实例，而不是从依赖关系中解析。如果我们要注入基本类型的话只能这么做。\nbind(String.class) .annotatedWith(Names.named(\u0026#34;JDBC URL\u0026#34;)) .toInstance(\u0026#34;jdbc:mysql://localhost/pizza\u0026#34;); bind(Integer.class) .annotatedWith(Names.named(\u0026#34;login timeout seconds\u0026#34;)) .toInstance(10);   @Privides 方法\n当一个对象很复杂，无法使用简单的构造器来生成的时候，我们可以使用@Provides 方法，也就是在配置类中生成一个注解了@Provides 的方法。在该方法中我们可以编写任意代码来构造对象。\n@Provides 方法也可以应用@Named 和自定义注解，还可以注入其他依赖，Guice 会在调用方法之前注入需要的对象。\npublic class BillingModule extends AbstractModule { @Override protected void configure() { ... } @Provides TransactionLog provideTransactionLog() { DatabaseTransactionLog transactionLog = new DatabaseTransactionLog(); transactionLog.setJdbcUrl(\u0026#34;jdbc:mysql://localhost/pizza\u0026#34;); transactionLog.setThreadPoolSize(30); return transactionLog; } }   Provider 绑定\n如果项目中存在多个比较复杂的对象需要构建，使用@Provide 方法会让配置类变得比较乱。我们可以使用 Guice 提供的 Provider 接口将复杂的代码放到单独的类中。办法很简单，实现 Provider接口的 get 方法即可。在 Provider 类中，我们可以使用@Inject 任意注入对象。\npublic class DatabaseTransactionLogProvider implements Provider\u0026lt;TransactionLog\u0026gt; { private final Connection connection; @Inject public DatabaseTransactionLogProvider(Connection connection) { this.connection = connection; } public TransactionLog get() { DatabaseTransactionLog transactionLog = new DatabaseTransactionLog(); transactionLog.setConnection(connection); return transactionLog; } } 然后在 config 方法中，调用.toProvider 方法：\npublic class BillingModule extends AbstractModule { @Override protected void configure() { bind(TransactionLog.class) .toProvider(DatabaseTransactionLogProvider.class); } }   无目标绑定\n无目标绑定没有 to 子句\n  构造器绑定\n某些场景下，你能需要把某个类型绑定到任意一个构造函数上。以下情况会有这种需求：1、 @Inject 注解无法被应用到目标构造函数；2、目标类是一个第三方类；3、目标类有多个构造函数参与 DI。\n为了解决这个问题，guice 提供了 toConstructor()绑定 ，它需要你指定要使用的确切的某个目标构造函数，并处理 \u0026ldquo;constructor annot be found\u0026rdquo; 异常：\npublic class BillingModule extends AbstractModule { @Override protected void configure() { try { bind(TransactionLog.class).toConstructor( DatabaseTransactionLog.class.getConstructor(DatabaseConnection.class)); } catch (NoSuchMethodException e) { addError(e); } } }   内置绑定\n除了显示绑定和即时绑定 just-in-time bindings，剩下的绑定都属于 injector 的内置绑定。这些绑定只能由 injector 自己创建，不允许外部调用。\n  即时绑定\n当 injector 需要某一个类型的实例的时候，它需要获取一个绑定。在 Module 类中的绑定叫做显式绑定，只要他们可用，injector 就会在任何时候使用它们。如果需要某一类型的实例，但是又没有显式绑定，那么 injector 将会试图创建一个即时绑定（Just-in-time Bindings），也被称为 JIT 绑定 或 隐式绑定。\n  2.2 作用域 默认情况下 Guice 会在每次注入的时候创建一个新对象。如果希望创建一个单例依赖的话，可以在实现类上应用@Singleton 注解。\n@Singleton public class InMemoryTransactionLog implements TransactionLog { /* everything here should be threadsafe! */ } 或者也可以在配置类中指定。\nbind(TransactionLog.class).to(InMemoryTransactionLog.class).in(Singleton.class); 在@Provides方法中也可以指定单例。\n@Provides @Singleton TransactionLog provideTransactionLog() { ... } 如果一个类型上存在多个冲突的作用域，Guice 会使用 bind()方法中指定的作用域。如果不想使用注解的作用域，可以在 bind()方法中将对象绑定为 Scopes.NO_SCOPE。\nGuice 和它的扩展提供了很多作用域，和 spring 一样，有单例 Singleton，Session 作用域 SessionScoped，Request 请求作用域 RequestScoped 等等。我们可以根据需要选择合适的作用域。\n2.3 注入 guice 的注入和 spring 类似，而且还做了一些扩展。\n  构造器注入\n使用 @Inject 注解标记类的构造方法，这个构造方法需要接受类依赖作为参数。大多数构造子将会把接收到的参数分派给内部成员变量。\n  方法注入\nGuice 可以向标注了 @Inject 的方法中注入依赖。依赖项以参数的形式传给方法，Guice 会在调用注入方法前完成依赖项的构建。注入方法可以有任意数量的参数，并且方法名对注入操作不会有任何影响。\n  字段注入\n使用 @Inject 注解标记字段。这是最简洁的注入方式。\n注意：不能给 final 字段加@Inject 注解。\n  可选注入\n有的时候，可能需要一个依赖项存在则进行注入，不存在则不注入。此时可以使用方法注入或字段注入来做这件事，当依赖项不可用的时候 Guice 就会忽略这些注入。如果你需要配置可选注入的话，使用 @Inject(optional = true) 注解就可以了。\n  按需注入\n方法注入和字段注入可以可以用来初始化现有实例，你可以使用 Injector.injectMembers。\n这个不常用。\n  静态注入\n不建议使用静态注入。\n  自动注入\nGuice 会对以下情形做自动注入：\n 在绑定语句里，通过 toInstance() 注入实例。 在绑定语句里，通过 toProvider() 注入 Provider 实例。这些对象会在注入器创建的时候被创建并注入容器。如果它们需要满足其他启动注入，Guice 会在它们被使用前将他们注入进去。    2.4 AOP guice 的 aop 功能较弱，时间原因还没研究透，后续继续写。\n","permalink":"https://zhenfeng-zhu.github.io/posts/guice%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","summary":"Guice 快速入门 接手的新项目主要是使用 kotlin+vert.x 来写的，使用 gradle 构建，依赖注入框架使用了 guice。这段时间都是在熟悉代码的过程，恶补一些知识。\nguice 是谷歌推出的一个轻量级的依赖注入框架，当然 spring 也可以实现依赖注入，只是 spring 太庞大了。\n1 基本使用 引入依赖 使用 gradle 或者 maven，引入 guice。\nmaven:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.google.inject\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;guice\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.1.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Gradle:\ncompile \u0026#34;com.google.inject:guice:4.1.0\u0026#34; 项目骨架 首先需要一个业务接口，包含一个方法来执行业务逻辑，它的实现非常简单：\npackage com.learning.guice; public interface UserService { void process(); } package com.learning.guice; public class UserServiceImpl implements UserService { @Override public void process() { System.out.println(\u0026#34;我需要做一些业务逻辑\u0026#34;); } } 然后写一个日志的接口：\npackage com.learning.guice; public interface LogService { void log(String msg); } package com.","title":"Guice 快速入门"},{"content":"快速浏览一下 Kotlin 的语法。\n基本语法 包定义和引用 在源文件头部：\npackage my.demo import java.util.* 方法定义  带有方法体，并且返回确定类型数据的定义方式，例如接受 Int 类型的参数并返回 Int 类型的值：  fun sum(a: Int, b: Int): Int { return a + b }  带有方法体，返回推断类型数据的定义方式，例如：  fun sum(a: Int, b: Int) = a + b  返回无意义类型的定义方式：  fun printSum(a: Int, b: Int): Unit { println(\u0026#34;sum of $aand $bis ${a + b}\u0026#34;) } 或者省略 Unit：\nfun printSum(a: Int, b: Int) { println(\u0026#34;sum of $aand $bis ${a + b}\u0026#34;) } 变量定义  只赋值一次（只读）本地变量，val：  val a:Int = 1 // 指定初始值 val b = 2 // 类型自推断为 `Int` val c:Int // 当不指定初始值时需要指定类型 c = 3 // 延迟赋值   可变变量， var：  var x = 5 // 类型自推断为 `Int` x += 1  顶层变量  val PI = 3.14 var x = 0 fun incrementX() { x += 1 } 注释 与 Java 和 JavaScript 一样，Kotlin 支持行尾注释和块注释：\n// 行尾注释 /* 多行 块注释 */ 与 Java 不同，Kotlin 中的块注释可以嵌套。\nstring 模板 var a = 1 val s1 = \u0026#34;a is $a\u0026#34; a = 2 val s2 = \u0026#34;${s1.replace(\u0026#34;is\u0026#34;, \u0026#34;was\u0026#34;)}, but now is $a}\u0026#34; 条件表达式 fun maxOf(a:Int, b:Int): Int { if (a \u0026gt; b) { return a } else { return b } } 使用 if 做为表达式：\nfun maxOf(a:Int, b:Int) = if (a \u0026gt; b) a else b 可能为 null 的值，检查是否为 null 如果值可能为 null 时，必须显示的指出。 例如：\nfun parseInt(str: String): Int? { // ... } 使用上面定义的方法：\nfun printProduct(arg1: String, arg2: String) { val x = parseInt(arg1) val y = parseInt(arg2) if (x != null \u0026amp;\u0026amp; y != null) { println(x * y) } else { println(either \u0026#39;$arg1\u0026#39; or \u0026#39;$arg2\u0026#39; is not a number) } 或者：\nif (x == null) { println(\u0026#34;Wrong number format in arg1: \u0026#39;$arg1\u0026#39;\u0026#34;) return } if (y == null) { println(\u0026#34;Wrong number format in arg2: \u0026#39;$arg2\u0026#39;\u0026#34;) return } println(x * y) 类型检查和自动转换 is 操作符用于检查某个实例是否为某种类型。如果一个不可变本地变量或属性已经做过类型检查，那么可以不必显示的进行类型转换就可以使用对应类型的属性或方法。\nfun getStringLength(obj: Any): Int? { if (obj is String) { return obj.length // 在这个类型检查分支中，`obj` 自动转换为 `String`  } return null // 在类型检查分支外，`obj` 仍然为 `Any` } 或者：\nfun getStringLength(obj: Any): Int? { if (obj !is String) return null return obj.length // 在这个分支中，`obj` 自动转换为 `String` } 再或者：\nfun getStringLength(obj: Any): Int? { if (obj is String \u0026amp;\u0026amp; obj.length \u0026gt; 0) { // 在 `\u0026amp;\u0026amp;` 操作符的右侧，`obj` 自动转换为 `String`  return obj.length } return null } for 循环 val items = listOf(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;kiwi\u0026#34;) for (item in items) { println(item) } 或者：\nval items = listOf(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;kiwi\u0026#34;) for (index in items.indices) { println(\u0026#34;item at $indexis ${items[index]}\u0026#34;) } while 循环 val items = listOf(\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;kiwi\u0026#34;) var index = 0 while (index \u0026lt; items.size) { println(\u0026#34;item at $indexis ${items[index]}\u0026#34;) index ++ } when 表达式 fun describe(obj: Any): String = when (obj) { 1 -\u0026gt; \u0026#34;one\u0026#34; \u0026#34;hello\u0026#34; -\u0026gt; \u0026#34;Greeting\u0026#34; is Long -\u0026gt; \u0026#34;Long\u0026#34; !is String -\u0026gt; \u0026#34;Not a String\u0026#34; else -\u0026gt; \u0026#34;Unknown\u0026#34; } 区间  使用 in 操作符检查数字是否在区间内：  val x = 10 val y = 9 if (x in 1..y+1) { println(\u0026#34;fits in range\u0026#34;) }  检查数字是否在范围外：  val list = listOf(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;) if (-1 !in 0..list.lastIndex) { println(\u0026#34;-1 is out of range\u0026#34;) } if (list.size !in list.indices) { println(\u0026#34;list size is out of valid list indices range too\u0026#34;) }  区间遍历  for (x in 1..5) { print(x) } 集合  遍历集合：  for (item in items) { println(item) }  使用 in 操作符判断集合中是否包含某个对象：  when { \u0026#34;orange\u0026#34; in items -\u0026gt; println(\u0026#34;juicy\u0026#34;) \u0026#34;apple\u0026#34; in items -\u0026gt; println(\u0026#34;apple is fine too\u0026#34;) }  使用 lambda 表达式过滤和 map 集合：  val fruits = listOf(\u0026#34;banana\u0026#34;, \u0026#34;avocado\u0026#34;, \u0026#34;apple\u0026#34;, \u0026#34;kiwi\u0026#34;) fruits .filter {it.startWith(\u0026#34;a\u0026#34;)} .sortedBy {it} .map {it.upperCase()} .forEach {println(it)} 创建基本类和实例 fun main(args: Array\u0026lt;String\u0026gt;) { val rectangle = Rectangle(5.0, 2.0) // 不需要使用 \u0026#39;new\u0026#39; 关键词  val triangle = Triangle(3.0, 4.0, 5.0) println(\u0026#34;Area of rectangle is ${rectangle.calculateArea()}, its perimeter is ${rectangle.perimeter}\u0026#34;) println(\u0026#34;Area of triangle is ${triangle.calculateArea()}, its perimeter is ${triangle.perimeter}\u0026#34;) } abstract class Shape(val sides: List\u0026lt;Double\u0026gt;) { val perimeter: Double get() = sides.sum() abstract fun calculateArea(): Double } interface RectangleProperties { val isSquare: Boolean } class Rectangle( var height: Double, var length: Double ) : Shape(listOf(height, length, height, length)), RectangleProperties { override val isSquare: Boolean get() = height == length override fun calculateArea(): Double = height * length } class Triangle( var sideA: Double, var sideB: Double, var sideC: Double ) : Shape(listOf(sideA, sideB, sideC)) { override fyb calculateArre(): Double { val s = perimeter / 2 return Math.sqrt(s * (s - sideA) * (s - sideB) * (s - sideC)) } }  以上引自：\n http://kotlinlang.org/docs/reference/basic-syntax.html\n ","permalink":"https://zhenfeng-zhu.github.io/posts/kotlin%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","summary":"快速浏览一下 Kotlin 的语法。\n基本语法 包定义和引用 在源文件头部：\npackage my.demo import java.util.* 方法定义  带有方法体，并且返回确定类型数据的定义方式，例如接受 Int 类型的参数并返回 Int 类型的值：  fun sum(a: Int, b: Int): Int { return a + b }  带有方法体，返回推断类型数据的定义方式，例如：  fun sum(a: Int, b: Int) = a + b  返回无意义类型的定义方式：  fun printSum(a: Int, b: Int): Unit { println(\u0026#34;sum of $aand $bis ${a + b}\u0026#34;) } 或者省略 Unit：\nfun printSum(a: Int, b: Int) { println(\u0026#34;sum of $aand $bis ${a + b}\u0026#34;) } 变量定义  只赋值一次（只读）本地变量，val：  val a:Int = 1 // 指定初始值 val b = 2 // 类型自推断为 `Int` val c:Int // 当不指定初始值时需要指定类型 c = 3 // 延迟赋值   可变变量， var：  var x = 5 // 类型自推断为 `Int` x += 1  顶层变量  val PI = 3.","title":"kotlin 快速入门"},{"content":"RxJava2 快速入门 引入依赖 compile \u0026#39;io.reactivex.rxjava2:rxjava:2.0.1\u0026#39; 写法 简单版本 private static void helloSimple() { Consumer\u0026lt;String\u0026gt; consumer = new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { System.out.println(\u0026#34;consumer accept is \u0026#34; + s); } }; Observable.just(\u0026#34;hello world\u0026#34;).subscribe(consumer); } 复杂版本 private static void helloComplex() { Observer\u0026lt;String\u0026gt; observer = new Observer\u0026lt;String\u0026gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(\u0026#34;onSubscribe: \u0026#34; + d); } @Override public void onNext(String s) { System.out.println(\u0026#34;onNext: \u0026#34; + s); } @Override public void onError(Throwable e) { System.out.println(\u0026#34;onError: \u0026#34; + e); } @Override public void onComplete() { System.out.println(\u0026#34;onComplete: \u0026#34;); } }; Observable.just(\u0026#34;Hello world\u0026#34;).subscribe(observer); } 变态版本 private static void helloPlus() { Observer\u0026lt;String\u0026gt; observer = new Observer\u0026lt;String\u0026gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(\u0026#34;onSubscribe: \u0026#34; + d); } @Override public void onNext(String s) { System.out.println(\u0026#34;onNext: \u0026#34; + s); } @Override public void onError(Throwable e) { System.out.println(\u0026#34;onError: \u0026#34; + e); } @Override public void onComplete() { System.out.println(\u0026#34;onComplete: \u0026#34;); } }; Observable\u0026lt;String\u0026gt; observable = Observable.create(new ObservableOnSubscribe\u0026lt;String\u0026gt;() { @Override public void subscribe(ObservableEmitter\u0026lt;String\u0026gt; e) throws Exception { e.onNext(\u0026#34;hello world\u0026#34;); e.onComplete(); } }); observable.subscribe(observer); } 常用操作符 filter 你早上去吃早餐，师傅是被观察者，说咱这有\u0026quot;包子\u0026quot;, \u0026ldquo;馒头\u0026rdquo;, \u0026ldquo;花生\u0026rdquo;, \u0026ldquo;牛奶\u0026rdquo;, \u0026ldquo;饺子\u0026rdquo;, \u0026ldquo;春卷\u0026rdquo;, \u0026ldquo;油条\u0026rdquo;，你仔细想了想，发现你是最喜欢饺子的，所以把其他的都排除掉， 于是你就吃到了饺子。\nprivate static void helloFilter() { Consumer\u0026lt;String\u0026gt; consumer = new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { System.out.println(\u0026#34;accept: \u0026#34; + s); } }; Observable.just(\u0026#34;包子\u0026#34;, \u0026#34;馒头\u0026#34;, \u0026#34;花生\u0026#34;, \u0026#34;牛奶\u0026#34;, \u0026#34;饺子\u0026#34;, \u0026#34;春卷\u0026#34;, \u0026#34;油条\u0026#34;) .filter(new Predicate\u0026lt;String\u0026gt;() { @Override public boolean test(String s) throws Exception { System.out.println(\u0026#34;test: \u0026#34; + s); return s.equals(\u0026#34;饺子\u0026#34;); } }) .subscribe(consumer); } Map map 操作符能够完成数据类型的转换。\n将 String 类型转换为 Integer 类型。\nprivate static void helloMap() { // 观察者观察Integer Observer\u0026lt;Integer\u0026gt; observer = new Observer\u0026lt;Integer\u0026gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(\u0026#34;onSubscribe: \u0026#34; + d); } @Override public void onNext(Integer s) { System.out.println(\u0026#34;onNext: \u0026#34; + s); } @Override public void onError(Throwable e) { System.out.println(\u0026#34;onError: \u0026#34; + e); } @Override public void onComplete() { System.out.println(\u0026#34;onComplete: \u0026#34;); } }; Observable.just(\u0026#34;100\u0026#34;) .map(new Function\u0026lt;String, Integer\u0026gt;() { @Override public Integer apply(String s) throws Exception { return Integer.valueOf(s); } }) .subscribe(observer); } FlatMap flatmap 能够链式地完成数据类型的转换和加工。\n遍历一个学校所有班级所有组的所有学生\nprivate void flatmapClassToGroupToStudent() { Observable.fromIterable(new School().getClasses()) //输入是Class类型，输出是ObservableSource\u0026lt;Group\u0026gt;类型 .flatMap(new Function\u0026lt;Class, ObservableSource\u0026lt;Group\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;Group\u0026gt; apply(Class aClass) throws Exception { Log.d(TAG, \u0026#34;apply: \u0026#34; + aClass.toString()); return Observable.fromIterable(aClass.getGroups()); } }) //输入类型是Group，输出类型是ObservableSource\u0026lt;Student\u0026gt;类型 .flatMap(new Function\u0026lt;Group, ObservableSource\u0026lt;Student\u0026gt;\u0026gt;() { @Override public ObservableSource\u0026lt;Student\u0026gt; apply(Group group) throws Exception { Log.d(TAG, \u0026#34;apply: \u0026#34; + group.toString()); return Observable.fromIterable(group.getStudents()); } }) .subscribe( new Observer\u0026lt;Student\u0026gt;() { @Override public void onSubscribe(Disposable d) { Log.d(TAG, \u0026#34;onSubscribe: \u0026#34;); } @Override public void onNext(Student value) { Log.d(TAG, \u0026#34;onNext: \u0026#34; + value.toString()); } @Override public void onError(Throwable e) { } @Override public void onComplete() { } }); } 线程调度 关于 RxJava 的线程调度，初学者只需要掌握两个 api 就够够的啦。\nsubscribeOn 指定 Observable 在一个指定的线程调度器上创建。只能指定一次，如果指定多次则以第一次为准\nobserveOn 指定在事件传递，转换，加工和最终被观察者接受发生在哪一个线程调度器。可指定多次，每次指定完都在下一步生效。\n常用线程调度器类型  Schedulers.single() 单线程调度器，线程可复用 Schedulers.newThread() 为每个任务创建新的线程 Schedulers.io() 处理 io 密集型任务，内部是线程池实现，可自动根据需求增长 Schedulers.computation() 处理计算任务，如事件循环和回调任务 AndroidSchedulers.mainThread() Android 主线程调度器  ","permalink":"https://zhenfeng-zhu.github.io/posts/rxjava2%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/","summary":"RxJava2 快速入门 引入依赖 compile \u0026#39;io.reactivex.rxjava2:rxjava:2.0.1\u0026#39; 写法 简单版本 private static void helloSimple() { Consumer\u0026lt;String\u0026gt; consumer = new Consumer\u0026lt;String\u0026gt;() { @Override public void accept(String s) throws Exception { System.out.println(\u0026#34;consumer accept is \u0026#34; + s); } }; Observable.just(\u0026#34;hello world\u0026#34;).subscribe(consumer); } 复杂版本 private static void helloComplex() { Observer\u0026lt;String\u0026gt; observer = new Observer\u0026lt;String\u0026gt;() { @Override public void onSubscribe(Disposable d) { System.out.println(\u0026#34;onSubscribe: \u0026#34; + d); } @Override public void onNext(String s) { System.out.println(\u0026#34;onNext: \u0026#34; + s); } @Override public void onError(Throwable e) { System.","title":"RxJava2 快速入门"},{"content":"在看项目代码的时候，发现了 entity 包和 dto 包，里面都是只保存数据的类，仔细查了资料，才发现 java 对于只保存数据的类有好几个分类。\n pojo 类：这是普通的 java 类，具有一部分的 get 和 set 方法。 dto 类：data transfer object 数据传输对象类，泛指用于展示层与服务层之间传输的对象。 vo 类：vo 有两种说法，一种是 view object，一种是 value object。 po 类：persisent object 持久对象。和 pojo 类一样，也是只有 get set 方法，但是这种类一般是用于持久层。 bo 类：business object，业务对象，表示应用程序领域内事物的所有实体类。 do 类：domain object，领域对象，就是从现实中抽象出来的有形或者无形的业务实体。  根据我的经验来看，大部分人都没有分那么清楚，一般是把数据类放在 domain 包，或者 entity 包里。再细分一下的话，可以把 dto 类单独提取到一个包里。\n","permalink":"https://zhenfeng-zhu.github.io/posts/%E9%A2%86%E5%9F%9F%E5%AE%9E%E4%BD%93%E7%B1%BB/","summary":"在看项目代码的时候，发现了 entity 包和 dto 包，里面都是只保存数据的类，仔细查了资料，才发现 java 对于只保存数据的类有好几个分类。\n pojo 类：这是普通的 java 类，具有一部分的 get 和 set 方法。 dto 类：data transfer object 数据传输对象类，泛指用于展示层与服务层之间传输的对象。 vo 类：vo 有两种说法，一种是 view object，一种是 value object。 po 类：persisent object 持久对象。和 pojo 类一样，也是只有 get set 方法，但是这种类一般是用于持久层。 bo 类：business object，业务对象，表示应用程序领域内事物的所有实体类。 do 类：domain object，领域对象，就是从现实中抽象出来的有形或者无形的业务实体。  根据我的经验来看，大部分人都没有分那么清楚，一般是把数据类放在 domain 包，或者 entity 包里。再细分一下的话，可以把 dto 类单独提取到一个包里。","title":"领域实体类"},{"content":"docker 常用命令 docker   获取镜像\ndocker pull\n  新建并启动\ndocker run\n  列出镜像\ndocker image ls\ndocker images\n  删除虚悬镜像\ndocker image prune\n  删除本地镜像\ndocker iamge rm\n  查看应用信息\ndocker logs\n  dockerfile 一般步骤  在一个目录里，新建一个文件，命名为 Dockerfile 在 Dockerfile 的目录内，执行 docker build  常用指令   FROM 指定基础镜像，且是第一条命令\n  RUN 执行命令\nshell 格式\nexec 格式\n  COPY 和 ADD 指令是复制文件\n  CMD 指令和 RUN 类似，容器启动命令\nshell 格式\nexec 格式\n参数列表格式\n  ENV 设置环境变量\n  EXPOSE 声明对外暴露的端口\n  WORKDIR 指定工作目录\n  compose 两个重要的概念  service 服务：一个应用的容器，实际上可以包括若干运行相同镜像的实例。 project 项目：由一组关联的容器组成一个完整业务单元，在 docker-compose.yml 文件中定义。  一般步骤   在一个项目目录里，新建一个 Dockerfile\n  新建一个文件 docker-compose.yml\n模板格式\nversion: 3.0 services: web: build: . ports: - \u0026#34;5000:5000\u0026#34; redis: images: \u0026#34;redis:alpine\u0026#34;   docker-compose up 运行项目\n  常用命令  docker-compose build 重新构建项目中的服务容器 config 验证 compose 文件格式是否正确 down 停止 up 命令所启动的容器 images 列出 compose 文件中包含的镜像 exec 进入指定的容器 kill 强制停止服务容器 ps 列出目前所有容器 rm 删除停止状态的容器 top 显示所有容器的进程  compose 模板文件 每个服务都必须通过 image 指令指定镜像或者 build 指令（需要 dockerfile）来构建生成的镜像。\n  build\n指定 dockerfile 所在的文件夹路径，compose 将会利用它来自动构建这个镜像，然后使用。\n  depends_on\n解决容器的依赖和先后启动问题。但是不会等待完成启动之后再启动，而是在他们启动之后就去启动。\n  environment\n设置环境变量，在这里指定程序或者容器启动时所依赖的环境参数。\n  expose\n指定暴露的端口，只被连接的服务访问。\n  image\n指定镜像名称，如果本地不存在则去拉取这个镜像。\n  labels\n为容器添加 docker 元数据信息，即一些辅助说明。\n  ports\n暴露端口信息，宿主端口:容器端口，或者只指定容器端口。\n  ","permalink":"https://zhenfeng-zhu.github.io/posts/docker/","summary":"docker 常用命令 docker   获取镜像\ndocker pull\n  新建并启动\ndocker run\n  列出镜像\ndocker image ls\ndocker images\n  删除虚悬镜像\ndocker image prune\n  删除本地镜像\ndocker iamge rm\n  查看应用信息\ndocker logs\n  dockerfile 一般步骤  在一个目录里，新建一个文件，命名为 Dockerfile 在 Dockerfile 的目录内，执行 docker build  常用指令   FROM 指定基础镜像，且是第一条命令\n  RUN 执行命令\nshell 格式\nexec 格式\n  COPY 和 ADD 指令是复制文件","title":"docker"},{"content":"Express 快速入门 安装 npm init npm install --save express hello world var express = require(\u0026#39;express\u0026#39;); var app = express(); app.get(\u0026#39;/\u0026#39;, function (req, res) { res.send(\u0026#39;Hello World!\u0026#39;); }); app.listen(3000, function () { console.log(\u0026#39;Example app listening on port 3000!\u0026#39;); }); 执行命令运行应用程序\nnode app.js 然后，在浏览器中输入 http://localhost:3000/ 以查看输出。\nexpress 程序生成器 安装 npm install -g express-generator 示例 以下语句在当前工作目录中创建名为 myapp 的 Express 应用程序：\nexpress --view=pug myapp 在 MacOS 或 Linux 上，采用以下命令运行此应用程序：\nDEBUG=myapp:* npm start 然后在浏览器中输入 http://localhost:3000/ 以访问此应用程序。\n路由 基本路由 路由用于确定应用程序如何响应对特定端点的客户机请求，包含一个 URI（或路径）和一个特定的 HTTP 请求方法（GET、POST 等）。\n每个路由可以具有一个或多个处理程序函数，这些函数在路由匹配时执行。\n路由定义采用以下结构：\napp.METHOD(PATH, HANDLER) 其中：\n app 是 express 的实例。 METHOD 是 HTTP 请求方法。 PATH 是服务器上的路径。 HANDLER 是在路由匹配时执行的函数。  比如简单的 Hello world：\napp.get(\u0026#39;/\u0026#39;, function (req, res) { res.send(\u0026#39;Hello World!\u0026#39;); }); 响应方法 下表中响应对象 (res) 的方法可以向客户机发送响应，并终止请求/响应循环。如果没有从路由处理程序调用其中任何方法，客户机请求将保持挂起状态。\n   方法 描述     res.download() 提示将要下载文件。   res.end() 结束响应进程。   res.json() 发送 JSON 响应。   res.jsonp() 在 JSONP 的支持下发送 JSON 响应。   res.redirect() 重定向请求。   res.render() 呈现视图模板。   res.send() 发送各种类型的响应。   res.sendFile 以八位元流形式发送文件。   res.sendStatus() 设置响应状态码并以响应主体形式发送其字符串表示。    app.route() 可以使用 app.route() 为路由路径创建可链接的路由处理程序。 因为在单一位置指定路径，所以可以减少冗余和输入错误。\napp.route(\u0026#39;/book\u0026#39;) .get(function(req, res) { res.send(\u0026#39;Get a random book\u0026#39;); }) .post(function(req, res) { res.send(\u0026#39;Add a book\u0026#39;); }) .put(function(req, res) { res.send(\u0026#39;Update the book\u0026#39;); }); express.Router 使用 express.Router 类来创建可安装的模块化路由处理程序。Router 实例是完整的中间件和路由系统；因此，常常将其称为“微型应用程序”。\n以下示例将路由器创建为模块，在其中装入中间件，定义一些路由，然后安装在主应用程序的路径中。\n在应用程序目录中创建名为 birds.js 的路由器文件，其中包含以下内容：\nvar express = require(\u0026#39;express\u0026#39;); var router = express.Router(); // middleware that is specific to this router router.use(function timeLog(req, res, next) { console.log(\u0026#39;Time: \u0026#39;, Date.now()); next(); }); // define the home page route router.get(\u0026#39;/\u0026#39;, function(req, res) { res.send(\u0026#39;Birds home page\u0026#39;); }); // define the about route router.get(\u0026#39;/about\u0026#39;, function(req, res) { res.send(\u0026#39;About birds\u0026#39;); }); module.exports = router; 接着，在应用程序中装入路由器模块：\nvar birds = require(\u0026#39;./birds\u0026#39;); ... app.use(\u0026#39;/birds\u0026#39;, birds); 此应用程序现在可处理针对 /birds 和 /birds/about 的请求，调用特定于此路由的 timeLog 中间件函数。\n中间件 中间件函数能够访问请求对象 (req)、响应对象 (res) 以及应用程序的请求/响应循环中的下一个中间件函数。下一个中间件函数通常由名为 next 的变量来表示。\n next() 函数不是 Node.js 或 Express API 的一部分，而是传递给中间件函数的第三自变量。next() 函数可以命名为任何名称，但是按约定，始终命名为“next”。\n 中间件函数可以执行以下任务：\n 执行任何代码。 对请求和响应对象进行更改。 结束请求/响应循环。 调用堆栈中的下一个中间件。  如果当前中间件函数没有结束请求/响应循环，那么它必须调用 next()，以将控制权传递给下一个中间件函数。否则，请求将保持挂起状态。\nExpress 应用程序可以使用以下类型的中间件：\n 应用层中间件 路由器层中间件 错误处理中间件 内置中间件 第三方中间件  模板引擎 在 Express 可以呈现模板文件之前，必须设置以下应用程序设置：\n views：模板文件所在目录。例如：app.set('views', './views') view engine：要使用的模板引擎。例如：app.set('view engine', 'pug')  然后安装对应的模板引擎 npm 包：\nnpm install pug --save 在 views 目录中创建名为 index.pug 的 Pug 模板文件，其中包含以下内容：\nhtml head title!= title body h1!= message 随后创建路由以呈现 index.pug 文件。如果未设置 view engine 属性，必须指定 view 文件的扩展名。否则，可以将其忽略。\napp.get(\u0026#39;/\u0026#39;, function (req, res) { res.render(\u0026#39;index\u0026#39;, { title: \u0026#39;Hey\u0026#39;, message: \u0026#39;Hello there!\u0026#39;}); }); 向主页发出请求时，index.pug 文件将呈现为 HTML。\n","permalink":"https://zhenfeng-zhu.github.io/posts/express/","summary":"Express 快速入门 安装 npm init npm install --save express hello world var express = require(\u0026#39;express\u0026#39;); var app = express(); app.get(\u0026#39;/\u0026#39;, function (req, res) { res.send(\u0026#39;Hello World!\u0026#39;); }); app.listen(3000, function () { console.log(\u0026#39;Example app listening on port 3000!\u0026#39;); }); 执行命令运行应用程序\nnode app.js 然后，在浏览器中输入 http://localhost:3000/ 以查看输出。\nexpress 程序生成器 安装 npm install -g express-generator 示例 以下语句在当前工作目录中创建名为 myapp 的 Express 应用程序：\nexpress --view=pug myapp 在 MacOS 或 Linux 上，采用以下命令运行此应用程序：\nDEBUG=myapp:* npm start 然后在浏览器中输入 http://localhost:3000/ 以访问此应用程序。","title":"express"},{"content":"一直没有机会写 2017 的年终总结，想到去年写的新的一年的计划，好像自己都没有按照计划来做，而且写的计划也不知道写到哪里去了。\n站在现在的时间点去审视过去的一年，这个本命年还是发生了很多对自己的未来有着比较大影响的的事情。房子+女朋友+新工作，这些事情突然的涌现出来，搞得自己有些手忙脚乱。\n梳理一下自己的收获吧：\n首先当然是结识了一帮小伙伴，我们一起打农药，一起调 bug，一起奋战双十一。\n在技术上也有了一定的提升，关键是自己的视野上有了很大的变化，不再是像当初大学的时候，不知道自己在做什么。这里对我影响比较大的一个是 phodal，看了他写的博客和书之后，对自己的触动很大，感觉他懂得很多东西，知识面很广，而且能够写出来，扩大了自己的影响力，所以我就想着自己能不能模仿他。另外一个就是田哥了，我觉得他是我认识的同龄人中，比较有自己想法的一个人，打进 acm world final 的人就是不一样，他看问题的角度比较新颖，而且归纳总结能力很强，给了我一些在编程上的指点，让我少走了很多弯路。\n也很感谢自己的几个室友，让我不再感到孤单。自从刘巍来了深圳之后，11I 更欢乐了，也更污了。我们经常在家里煮火锅吃，吃的特别爽，以至于现在我都不想去火锅店里吃，总觉得在家吃的比较爽。\n女朋友，出乎我的意料，现在想想还是感觉活在梦里，略过略过。\n至于买房，没买之前的想法盲目乐观，后来算了一下，要是在深圳买房的话，我每个月的房贷是 2 万多，关键是首付还不一定能搞得出来。还是建议在北上广深工作的人，有机会现在老家的省会一类的城市，先搞一套，以后可以置换，能上车的时候早点上车，也是相当于变相攒钱了。对于不会投资或者创业的朋友，有时候辛辛苦苦干一年之后算一下，不知不觉中，自己的钱都不知道花在了哪里，如果有房贷的话，等用的时候说不定卖掉还能赚一些钱。\n感觉自己换公司还是挺戏剧化的，当时也没想着真的就换工作吧，只是想投投简历，然后去面试一波看看自己的水平怎么样。总觉得自己在招银的舒适区待的太久了，没有什么激情了。同时自己也想出来试试，万一公司上市，摇身一变成为富翁了。当然这是白日梦了，路还是要一步一步的走的。\n总感觉自己想了很多东西，但是就是写不出来，自己讲故事的能力还是要提升一些。\n","permalink":"https://zhenfeng-zhu.github.io/posts/a-month-in-finogeeks/","summary":"一直没有机会写 2017 的年终总结，想到去年写的新的一年的计划，好像自己都没有按照计划来做，而且写的计划也不知道写到哪里去了。\n站在现在的时间点去审视过去的一年，这个本命年还是发生了很多对自己的未来有着比较大影响的的事情。房子+女朋友+新工作，这些事情突然的涌现出来，搞得自己有些手忙脚乱。\n梳理一下自己的收获吧：\n首先当然是结识了一帮小伙伴，我们一起打农药，一起调 bug，一起奋战双十一。\n在技术上也有了一定的提升，关键是自己的视野上有了很大的变化，不再是像当初大学的时候，不知道自己在做什么。这里对我影响比较大的一个是 phodal，看了他写的博客和书之后，对自己的触动很大，感觉他懂得很多东西，知识面很广，而且能够写出来，扩大了自己的影响力，所以我就想着自己能不能模仿他。另外一个就是田哥了，我觉得他是我认识的同龄人中，比较有自己想法的一个人，打进 acm world final 的人就是不一样，他看问题的角度比较新颖，而且归纳总结能力很强，给了我一些在编程上的指点，让我少走了很多弯路。\n也很感谢自己的几个室友，让我不再感到孤单。自从刘巍来了深圳之后，11I 更欢乐了，也更污了。我们经常在家里煮火锅吃，吃的特别爽，以至于现在我都不想去火锅店里吃，总觉得在家吃的比较爽。\n女朋友，出乎我的意料，现在想想还是感觉活在梦里，略过略过。\n至于买房，没买之前的想法盲目乐观，后来算了一下，要是在深圳买房的话，我每个月的房贷是 2 万多，关键是首付还不一定能搞得出来。还是建议在北上广深工作的人，有机会现在老家的省会一类的城市，先搞一套，以后可以置换，能上车的时候早点上车，也是相当于变相攒钱了。对于不会投资或者创业的朋友，有时候辛辛苦苦干一年之后算一下，不知不觉中，自己的钱都不知道花在了哪里，如果有房贷的话，等用的时候说不定卖掉还能赚一些钱。\n感觉自己换公司还是挺戏剧化的，当时也没想着真的就换工作吧，只是想投投简历，然后去面试一波看看自己的水平怎么样。总觉得自己在招银的舒适区待的太久了，没有什么激情了。同时自己也想出来试试，万一公司上市，摇身一变成为富翁了。当然这是白日梦了，路还是要一步一步的走的。\n总感觉自己想了很多东西，但是就是写不出来，自己讲故事的能力还是要提升一些。","title":"碎碎念"},{"content":"java 内存模型和线程  并发不一定依赖多线程，但是在 java 里面谈论并发，大多与线程脱不开关系。\n 线程是大多是面试都会问到的问题。我们都知道，线程是比进程更轻量级的调度单位，线程之间可以共享内存。之前面试的时候，也是这样回答，迷迷糊糊，没有一个清晰的概念。\n大学的学习的时候，写 C 和 C++，自己都没有用过多线程，看过一个 Windows 编程的书，里面讲多线程的时候，一大堆大写的字母，看着一点都不爽，也是惭愧。后来的实习，写 unity，unity 的 C#使用的是协程。只有在做了 java 后端之后，才知道线程到底是怎么用的。了解了java 内存模型之后，仔细看了一些资料，对 java 线程有了更深入的认识，整理写成这篇文章，用来以后参考。\n1 Java 内存模型 Java 虚拟机规范试图定义一种 java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 java 程序在各种平台下都能达到一致性内存访问的效果。\njava 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量的底层细节。（这里所说的变量包括了实例字段、静态字段和数组等，但不包括局部变量与方法参数，因为这些是线程私有的，不被共享。）\n1.1 主内存和工作内存 java 规定所有的变量都存储在主内存。每条线程有自己的工作内存。\n线程的工作内存中的变量是主内存中该变量的副本，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存来完成。\n1.2 内存之间的交互 关于主内存和工作内存之间的具体交互协议，java 内存模型定义了 8 中操作来完成，虚拟机实现的时候必须保证每个操作都是原子的，不可分割的（对于 long 和 double 有例外）\n lock 锁定：作用于主内存变量，代表一个变量是一条线程独占。 unlock 解锁：作用于主内存变量，把锁定的变量解锁。 read 读取：作用于主内存变量，把变量值从主内存传到线程的工作内存中，供 load 使用。 load 载入：作用工作内存变量，把上一个 read 到的值放入到工作内存中的变量中。 use 使用：作用于工作内存变量，把工作内存中的一个变量的值传递给执行引擎。 assign：作用于工作内存变量，把执行引擎执行过的值赋给工作内存中的变量。 store 存储：作用于工作内存变量，把工作内存中的变量值传给主内存，供 write 使用。  这些操作要满足一定的规则。\n1.3 volatile volatile 可以说是 java 的最轻量级的同步机制。\n当一个变量被定义为 volatile 之后，他就具备两种特性：\n  保证此变量对所有线程都是可见的\n这里的可见性是指当一个线程修改了某变量的值，新值对于其他线程来讲是立即得知的。而普通变量做不到，因为普通变量需要传递到主内存中才可以做到这点。\n  禁止指令重排\n对于普通变量来说，仅仅会保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序与程序代码中的执性顺序一致。\n若用 volatile 修饰变量，在编译时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。\n  volatile 对于单个的共享变量的读/写具有原子性，但是像 num++这种复合操作，volatile 无法保证其原子性。\n1.4 long 和 double long 和 double 是一个 64 位的数据类型。\n虚拟机允许将没有被 volatile 修饰的 64 位变量的读写操作分为两次 32 位的操作来进行。因此当多个线程操作一个没有声明为 volatile 的 long 或者 double 变量，可能出现操作半个变量的情况。\n但是这种情况是罕见的，一般商用的虚拟机都是讲 long 和 double 的读写当成原子操作进行的，所以在写代码时不需要将 long 和 double 专门声明为 volatile。\n1.5 原子性、可见性和有序性 java 的内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性。\n原子性\n基本数据类型的访问读写是剧本原子性的。\n如果需要一个更大范围的原子性保证，java 提供了 lock 和 unlock 操作，对应于写代码时就是 synchronized 关键字，因此在 synchronized 块之间的操作也是具备原子性的。\n可见性\n可见性是指当一个线程修改到了一个共享变量的值，其他的线程能够立即得知这个修改。共享变量的读写都是通过主内存作为媒介来处理可见性的。\nvolatile 的特殊规则保证了新值可以立即同步到主内存，每次使用前立即从主内存刷新。\nsynchronized 同步块的可见性是由”对于一个变量 unlock 操作之前，必须先把此变量同步回内存中“来实现的。\nfinal 的可见性是指被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把 this 的引用传递出去，那么在其他线程中就能看见 final 字段的值。\n有序性\n如果在本线程内观察，所有的操作都是有序的；如果在一个线程内观察另一个线程，所有的操作都是无序的。 volatile 关键字本身就包含了禁止指令重排的语义，而 synchronized 则是由“一个变量在同一时刻只允许一条线程对其进行 lock 操作”这条规则来实现有序性的。\n1.6 先行发生原则 如果 java 内存模型中的所有有序性都是靠着 volatile 和 synchronized 来完成，那有些操作将会变得很繁琐，但是我们在写 java 并发代码的时候没有感受到这一点，都是因为 java 有一个“先行发生”原则。\n先行发生是 java 内存模型中定义的两项操作之间的偏序关系，如果说操作 A 先发生于操作 B，其实就是说在发生 B 之前，A 产生的影响都能被 B 观察到，这里的影响包括修改了内存中共享变量的值、发送了消息、调用了方法等等。\n  程序次序规则\n在一个线程内，按程序代码控制流顺序执行。\n  管程锁定规则\nunlock 发生在后面时间同一个锁的 lock 操作。\n  volatile 变量规则\nvolatile 变量的写操作发生在后面时间的读操作。\n  线程启动规则\n  线程终止规则\n  线程中断规则\n  对象终结规则\n一个对象的初始化完成在 finalize 方法之前。\n  传递性\n如果 A 先行发生 B，B 先行发生 C，那么 A 先行发生 C。\n  由于指令重排的原因，所以一个操作的时间上的先发生，不代表这个操作就是先行发生；同样一个操作的先行发生，也不代表这个操作必定在时间上先发生。\n2 Java 线程 2.1 线程的实现 主流的操作系统都提供了线程的实现，java 则是在不同的硬件和操作系统的平台下，对线程的操作提供了统一的处理，一个 Thread 类的实例就代表了一个线程。Thread 类的关键方法都是 native 的，所以 java 的线程实现也都是依赖于平台相关的技术手段来实现的。\n实现线程主要有 3 种方式：使用内核线程实现，使用用户线程实现和使用用户线程加轻量级进程实现。\n2.1.1 使用内核线程实现 内核线程就是直接由操作系统内核支持的线程，这种线程由内核来完成线程的切换，内核通过操纵调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。\n程序一般不会直接去调用内核线程，而是使用内核线程的一个高级接口——轻量级进程（Light Weigh Process），LWP 就是我们通常意义上所说的线程。\n由于每个轻量级进程都由一个内核线程支持，这种轻量级进程与内核线程之间 1:1 的关系成为一对一线程模型。\n局限性\n虽然由于内核线程的支持，每个轻量级进程都成为了一个独立的调度单元，即使有一个阻塞，也不影响整个进程的工作，但是还是有一定的局限性：\n  系统调用代价较高\n由于基于内核线程实现，所以各种线程的操作都要进行系统调用。而系统调用的代价比较高，需要在用户态和内核态来回切换。\n  系统支持数量有限\n每个轻量级进程都需要一个内核线程支持，需要消耗一定的内核资源，所以支持的线程数量是有限的。\n  2.1.2 使用用户线程实现 指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同布、销毁和调度完全在用户态中完成，不需要内核帮助。\n如果程序实现得当，则这些线程都不需要切换到内核态，操作非常快速消耗低，可以支持大规模线程数量。这种进程和用户线程之间 1:N 的关系成为一对多线程模型。\n局限性\n不需要系统内核的，既是优势也是劣势。由于没有系统内核支援，所有的操作都需要程序去处理，由于操作系统只是把处理器资源分给进程，那“阻塞如何处理”、“多处理器系统如何将线程映射到其他处理器上”这类问题的解决十分困难，所以现在使用用户线程的越来越少了。\n2.1.3 使用用户线程加轻量级进程混合实现 在这种混合模式下，既存在用户线程，也存在轻量级进程。\n用户线程还是完全建立在用户空间中，因此用户线程的创建、切换、析构等操作依然廉价，而且支持大规模用户线程并发、而操作系统提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度和处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，大大降低了整个进程被完全阻塞的风险。\n在这种模式下，用户线程和轻量级进程数量比不固定 N:M，这种模式就是多对多线程模型。\n2.1.4 java 线程的实现 目前的 jdk 版本中，操作系统支持怎样的线程模型，很大程度上就决定了 jvm 的线程是怎么映射的，这点在不同的平台没办法打成一致。线程模型只对线程的并发规模和操作成本产生影响，对编码和运行都没什么差异。\nwindows 和 linux 都是一对一的线程模型。\n2.2 线程调度 线程的调度是指系统为线程分配处理器使用权的过程，主要的调度方式有两种：协同式线程调度和抢占式线程调度。\n2.2.1 协同式线程调度 线程的执性时间由线程本身来控制，线程把自己的工作执性完了之后，要主动通知系统切换到另外一个线程上。Lua 的协程就是这样。\n好处\n协同式多线程最大的好处就是实现简单。\n由于线程要把自己的事情干完之后才进行线程切换，切换操作对线程是克制的，所以没有什么线程同步的问题。\n坏处\n坏处也很明显，线程执行时间不可控。甚至如果一个线程写的问题，一直不告诉系统切换，那程序就会一直阻塞。\n2.2.2 抢占式线程调度 每个线程由系统分配执行时间，线程的切换不是又线程本身来决定。\n使用 yield 方法是可以让出执行时间，但是要获取执行时间，线程本身是没有什么办法的。\n在这种调度模式下，线程的执行时间是系统可控的，也就不会出现一个线程导致整个进程阻塞。\n2.2.3 java 线程调度 java 使用的是抢占式线程调度。\n虽然 java 的线程调度是系统来控制的，但是可以通过设置线程优先级的方式，让某些线程多分配一些时间，某些线程少分配一些时间。\n不过线程优先级还是不太靠谱，原因就是 java 的线程是通过映射到系统的原生线程来实现的，所以线程的调度还是取决于操作系统，操作系统的线程优先级不一定和 java 的线程优先级一一对应。而且优先级还可能被系统自行改变。所以我们不能在程序中通过优先级来准确的判断先执行哪一个线程。\n2.3 线程的状态转换 看到网上有好多种说法，不过大致也都是说 5 种状态：新建（new）、可运行（runnable）、运行（running）、阻塞（blocked）和死亡（dead）。\n而深入理解 jvm 虚拟机中说 java 定义了 5 种线程状态，在任一时间点，一个线程只能有其中的一种状态：\n  新建 new\n  运行 runnable\n包括了操作系统线程状态的 running 和 ready，也就是说处于此状态的线程可能正在执行，也可能正在等待 cpu 给分配执行时间。\n  无限期等待 waiting\n处于这种状态的线程不会被 cpu 分配执行时间，需要被其他线程显示唤醒，能够导致线程陷入无限期等待的方法有：\n 没有设置 timeout 参数的 wait 方法。 没有设置 timeout 参数的 join 方法。 LockSupport.park 方法。    限期等待 timed waiting\n处于这种状态的线程也不会被 cpu 分配执行时间，不过不需要被其他线程显示唤醒，是经过一段时间之后，被操作系统自动唤醒。能够导致线程陷入限期等待的方法有：\n sleep 方法。 设置 timeout 参数的 wait 方法。 设置参数的 join 方法。 LockSupport.parkNanos 方法。 LockSupport.parkUntil 方法。    阻塞 blocked\n线程被阻塞了。在线程等待进入同步区域的时候是这个状态。\n阻塞和等待的区别是：阻塞是排队等待获取一个排他锁，而等待是指等一段时间或者一个唤醒动作。\n  结束 terminated\n已经终止的线程。\n  3 写在最后 并发处理的广泛应用是使得 Amdahl 定律代替摩尔定律成为计算机性能发展源动力的根本原因，也是人类压榨计算机运算能力的最有力武器。有些问题使用越多的资源就能越快地解决——越多的工人参与收割庄稼，那么就能越快地完成收获。但是另一些任务根本就是串行化的——增加更多的工人根本不可能提高收割速度。\n我们使用线程的重要原因之一是为了支配多处理器的能力，我们必须保证问题被恰当地进行了并行化的分解，并且我们的程序有效地使用了这种并行的潜能。有时候良好的设计原则不得不向现实做出一些让步，我们必须让计算机正确无误的运行，首先保证并发的正确性，才能够在此基础上谈高效，所以线程的安全问题是一个很值得考虑的问题。\n虽然一直说 java 不好，但是 java 带给我的影响确实最大的，从 java 这个平台里学到了很多有用的东西。现在 golang，nodejs，python 等语言，每个都是在一方面能秒 java，可是 java 生态和 java 对软件行业的影响，是无法被超越的，java 这种语言，从出生到现在几十年了，基本上每次软件技术的革命都没有落下，每次都觉得要死的时候，忽然间柳暗花明，枯木逢春。咳咳，扯远了。\n","permalink":"https://zhenfeng-zhu.github.io/posts/java-memory-thread/","summary":"java 内存模型和线程  并发不一定依赖多线程，但是在 java 里面谈论并发，大多与线程脱不开关系。\n 线程是大多是面试都会问到的问题。我们都知道，线程是比进程更轻量级的调度单位，线程之间可以共享内存。之前面试的时候，也是这样回答，迷迷糊糊，没有一个清晰的概念。\n大学的学习的时候，写 C 和 C++，自己都没有用过多线程，看过一个 Windows 编程的书，里面讲多线程的时候，一大堆大写的字母，看着一点都不爽，也是惭愧。后来的实习，写 unity，unity 的 C#使用的是协程。只有在做了 java 后端之后，才知道线程到底是怎么用的。了解了java 内存模型之后，仔细看了一些资料，对 java 线程有了更深入的认识，整理写成这篇文章，用来以后参考。\n1 Java 内存模型 Java 虚拟机规范试图定义一种 java 内存模型来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 java 程序在各种平台下都能达到一致性内存访问的效果。\njava 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量的底层细节。（这里所说的变量包括了实例字段、静态字段和数组等，但不包括局部变量与方法参数，因为这些是线程私有的，不被共享。）\n1.1 主内存和工作内存 java 规定所有的变量都存储在主内存。每条线程有自己的工作内存。\n线程的工作内存中的变量是主内存中该变量的副本，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程间也无法直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存来完成。\n1.2 内存之间的交互 关于主内存和工作内存之间的具体交互协议，java 内存模型定义了 8 中操作来完成，虚拟机实现的时候必须保证每个操作都是原子的，不可分割的（对于 long 和 double 有例外）\n lock 锁定：作用于主内存变量，代表一个变量是一条线程独占。 unlock 解锁：作用于主内存变量，把锁定的变量解锁。 read 读取：作用于主内存变量，把变量值从主内存传到线程的工作内存中，供 load 使用。 load 载入：作用工作内存变量，把上一个 read 到的值放入到工作内存中的变量中。 use 使用：作用于工作内存变量，把工作内存中的一个变量的值传递给执行引擎。 assign：作用于工作内存变量，把执行引擎执行过的值赋给工作内存中的变量。 store 存储：作用于工作内存变量，把工作内存中的变量值传给主内存，供 write 使用。  这些操作要满足一定的规则。","title":"Java 内存模型和线程"},{"content":"一些基础概念\nEC2 云服务器，可以理解成虚拟机，新建一个实例，就是新建一个虚拟机并安装操作系统（Linux 或者 windows）。\nVPC Virtual Private Cloud。可以理解成数据中心，机房。对于灾备或者双活需要的，可以创建两个 VPC。\n子网 一个 VPC 里可以有多个子网。比如某机构的一个 VPC 可以办公网和生产网段，或者内网和外网。一般外网可以被访问，内网的话可以是数据库的服务器之类的。\nIAM 角色 类似于用户，可以被分配权限。\n安全组 控制连接到此 EC2 实例的流量，或者是控制对外暴露的端口。\nCIDR CIDR 主要是一个按位的、基于前缀的，用于解释 IP 地址的标准。当用二进制表示这些地址时，它们有着在开头部分的一系列相同的位。\nIPv4 的 CIDR 地址块的表示方法和 IPv4 地址的表示方法是相似的：由四部分组成的点分十进制地址，后跟一个斜线，最后是范围在 0 到 32 之间的一个数字：A.B.C.D/N。点分十进制的部分和 IPv4 地址一样是一个被分成四个八位位组的 32 位二进制数。斜线后面的数字就是前缀长度，也就是从左到右，被地址块里的地址所共享的位的数目。\n十进制部分有时会被省略，因此，/20 就表示一个前缀长度是 20 的 CIDR 地址块。如果一个 IP 地址的前 N 位与一个 CIDR 地址块的前缀是相同的话，那么就说这个地址属于这个 CIDR 地址块，也可以说是与 CIDR 地址块的前缀匹配。所以，要理解 CIDR，就要把地址写成二进制的形式。\n","permalink":"https://zhenfeng-zhu.github.io/posts/aws-md/","summary":"一些基础概念\nEC2 云服务器，可以理解成虚拟机，新建一个实例，就是新建一个虚拟机并安装操作系统（Linux 或者 windows）。\nVPC Virtual Private Cloud。可以理解成数据中心，机房。对于灾备或者双活需要的，可以创建两个 VPC。\n子网 一个 VPC 里可以有多个子网。比如某机构的一个 VPC 可以办公网和生产网段，或者内网和外网。一般外网可以被访问，内网的话可以是数据库的服务器之类的。\nIAM 角色 类似于用户，可以被分配权限。\n安全组 控制连接到此 EC2 实例的流量，或者是控制对外暴露的端口。\nCIDR CIDR 主要是一个按位的、基于前缀的，用于解释 IP 地址的标准。当用二进制表示这些地址时，它们有着在开头部分的一系列相同的位。\nIPv4 的 CIDR 地址块的表示方法和 IPv4 地址的表示方法是相似的：由四部分组成的点分十进制地址，后跟一个斜线，最后是范围在 0 到 32 之间的一个数字：A.B.C.D/N。点分十进制的部分和 IPv4 地址一样是一个被分成四个八位位组的 32 位二进制数。斜线后面的数字就是前缀长度，也就是从左到右，被地址块里的地址所共享的位的数目。\n十进制部分有时会被省略，因此，/20 就表示一个前缀长度是 20 的 CIDR 地址块。如果一个 IP 地址的前 N 位与一个 CIDR 地址块的前缀是相同的话，那么就说这个地址属于这个 CIDR 地址块，也可以说是与 CIDR 地址块的前缀匹配。所以，要理解 CIDR，就要把地址写成二进制的形式。","title":"aws.md"},{"content":" 软件工程师\n 编程小语种爱好者，精通各种语言的hello world，目前沉迷Clojure、elixir Get Started工程师，止步于大量框架和包的readme 后端开发工程师，偶尔写一些前端，伪全栈 也是一名数据工程师，朝着SQL Boy进化   Skills Languages, software and services used:\n Python | Django Go | Gin Node.js | Vue.js MongoDB | Mysql Docker | K8S Git Hugo | Markdown Hive | Flink  Tools  VSCode Postman  Education 北京邮电大学\nYou can also find me on:  知乎 微博 twitter  ","permalink":"https://zhenfeng-zhu.github.io/about/","summary":"about","title":"About Me"},{"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server hexo server More info: Server\nGenerate static files hexo generate More info: Generating\nDeploy to remote sites hexo deploy More info: Deployment\n","permalink":"https://zhenfeng-zhu.github.io/posts/hello-world/","summary":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick Start Create a new post hexo new \u0026#34;My New Post\u0026#34; More info: Writing\nRun server hexo server More info: Server\nGenerate static files hexo generate More info: Generating\nDeploy to remote sites hexo deploy More info: Deployment","title":"Hello World"}]